diff --git a/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb b/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
index 4ec3a0c..9879da6 100644
--- a/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/PPO-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 15,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: 1x8v92mc\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\n"
+      "Create sweep with ID: 9xhkl8my\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 16,
    "metadata": {},
    "outputs": [
     {
@@ -100,67 +100,13616 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-13 11:45:51,946 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-13 11:45:52,259 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 11:45:52,260 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-13 11:45:52,261 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python RandomGreedy.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-01 11:53:51,776 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-01 11:53:52,086 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 11:53:52,086 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la11.txt\n",
+      "2020-11-01 11:53:52,088 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la11.txt\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrandom\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3qwfavbb\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_114553-3qwfavbb\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisty-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/kqo0l7if\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_115353-kqo0l7if\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 11:45:57,278 - wandb.wandb_agent - INFO - Running runs: ['3qwfavbb']\n",
+      "2020-11-01 11:53:57,102 - wandb.wandb_agent - INFO - Running runs: ['kqo0l7if']\n",
+      "2020-11-01 11:53:57,683\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 39394\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=20230)\u001b[0m 2020-11-01 11:54:00,466\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=20215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20199)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20199)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20198)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20198)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20195)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20195)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=20225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=20225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1434.4832653061223\n",
+      "    time_step_min: 1245\n",
+      "  date: 2020-11-01_11-54-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.93913043478261\n",
+      "  episode_reward_max: 45.68367346938774\n",
+      "  episode_reward_mean: 35.80144389771718\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1265\n",
+      "  episodes_total: 1265\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1484567523002625\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006624576014777024\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007466505475652714\n",
+      "        total_loss: 52.51902961730957\n",
+      "        vf_explained_var: 0.7593300342559814\n",
+      "        vf_loss: 52.52574666341146\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.92222222222222\n",
+      "    gpu_util_percent0: 0.3044444444444444\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4370370370370376\n",
+      "    vram_util_percent0: 0.0819728386963546\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17175637313856013\n",
+      "    mean_env_wait_ms: 0.6787065283307273\n",
+      "    mean_inference_ms: 5.169812775871786\n",
+      "    mean_raw_obs_processing_ms: 0.45531381926816505\n",
+      "  time_since_restore: 22.264521837234497\n",
+      "  time_this_iter_s: 22.264521837234497\n",
+      "  time_total_s: 22.264521837234497\n",
+      "  timers:\n",
+      "    learn_throughput: 11076.145\n",
+      "    learn_time_ms: 14607.249\n",
+      "    sample_throughput: 21315.374\n",
+      "    sample_time_ms: 7590.39\n",
+      "    update_time_ms: 20.181\n",
+      "  timestamp: 1604231667\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      1 |          22.2645 | 161792 |  35.8014 |              45.6837 |              15.7347 |            116.939 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1426.9196226415095\n",
+      "    time_step_min: 1245\n",
+      "  date: 2020-11-01_11-54-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 115.78401486988848\n",
+      "  episode_reward_max: 45.68367346938774\n",
+      "  episode_reward_mean: 36.37903042257795\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1425\n",
+      "  episodes_total: 2690\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.130055993795395\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00956034411986669\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011216347149456851\n",
+      "        total_loss: 10.385109821955362\n",
+      "        vf_explained_var: 0.894355058670044\n",
+      "        vf_loss: 10.394978761672974\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.388\n",
+      "    gpu_util_percent0: 0.3824\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16652532875458848\n",
+      "    mean_env_wait_ms: 0.6684123457284149\n",
+      "    mean_inference_ms: 4.952915318761355\n",
+      "    mean_raw_obs_processing_ms: 0.44064388796599707\n",
+      "  time_since_restore: 43.21846151351929\n",
+      "  time_this_iter_s: 20.95393967628479\n",
+      "  time_total_s: 43.21846151351929\n",
+      "  timers:\n",
+      "    learn_throughput: 11096.611\n",
+      "    learn_time_ms: 14580.307\n",
+      "    sample_throughput: 23271.686\n",
+      "    sample_time_ms: 6952.311\n",
+      "    update_time_ms: 21.999\n",
+      "  timestamp: 1604231689\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      2 |          43.2185 | 323584 |   36.379 |              45.6837 |              15.7347 |            115.784 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1408.408178256611\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.67119301648884\n",
+      "  episode_reward_max: 46.85714285714286\n",
+      "  episode_reward_mean: 37.28042419683683\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1434\n",
+      "  episodes_total: 4124\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1140848398208618\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009810077414537469\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015473847355072698\n",
+      "        total_loss: 7.254512945810954\n",
+      "        vf_explained_var: 0.9246422648429871\n",
+      "        vf_loss: 7.2685816287994385\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.775000000000002\n",
+      "    gpu_util_percent0: 0.34500000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516666666666667\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16318379996682947\n",
+      "    mean_env_wait_ms: 0.662199655734115\n",
+      "    mean_inference_ms: 4.788160816000921\n",
+      "    mean_raw_obs_processing_ms: 0.43056477316095654\n",
+      "  time_since_restore: 63.56497097015381\n",
+      "  time_this_iter_s: 20.34650945663452\n",
+      "  time_total_s: 63.56497097015381\n",
+      "  timers:\n",
+      "    learn_throughput: 11127.786\n",
+      "    learn_time_ms: 14539.46\n",
+      "    sample_throughput: 24626.159\n",
+      "    sample_time_ms: 6569.924\n",
+      "    update_time_ms: 21.5\n",
+      "  timestamp: 1604231709\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      3 |           63.565 | 485376 |  37.2804 |              46.8571 |              15.7347 |            114.671 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1389.7721856660146\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.25304608864559\n",
+      "  episode_reward_max: 46.857142857142875\n",
+      "  episode_reward_mean: 38.234928122758895\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1539\n",
+      "  episodes_total: 5663\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0880944629510243\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009488985563317934\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01440603454830125\n",
+      "        total_loss: 5.48736047744751\n",
+      "        vf_explained_var: 0.9440011978149414\n",
+      "        vf_loss: 5.500412583351135\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.516666666666666\n",
+      "    gpu_util_percent0: 0.34874999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5125000000000006\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16068983053902333\n",
+      "    mean_env_wait_ms: 0.6583389151369388\n",
+      "    mean_inference_ms: 4.664128900411232\n",
+      "    mean_raw_obs_processing_ms: 0.42299876801925573\n",
+      "  time_since_restore: 84.06657981872559\n",
+      "  time_this_iter_s: 20.501608848571777\n",
+      "  time_total_s: 84.06657981872559\n",
+      "  timers:\n",
+      "    learn_throughput: 11095.44\n",
+      "    learn_time_ms: 14581.846\n",
+      "    sample_throughput: 25479.527\n",
+      "    sample_time_ms: 6349.882\n",
+      "    update_time_ms: 24.143\n",
+      "  timestamp: 1604231730\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      4 |          84.0666 | 647168 |  38.2349 |              46.8571 |              15.7347 |            113.253 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1374.424760022586\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-55-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.05460415496911\n",
+      "  episode_reward_max: 46.857142857142875\n",
+      "  episode_reward_mean: 39.03776398262842\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1461\n",
+      "  episodes_total: 7124\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0627730786800385\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009283728742351135\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015454331073366726\n",
+      "        total_loss: 4.347856322924296\n",
+      "        vf_explained_var: 0.9541513323783875\n",
+      "        vf_loss: 4.3619853258132935\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.604166666666668\n",
+      "    gpu_util_percent0: 0.3541666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5124999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15895058912495744\n",
+      "    mean_env_wait_ms: 0.6558977259961688\n",
+      "    mean_inference_ms: 4.577574740810779\n",
+      "    mean_raw_obs_processing_ms: 0.4175203436251983\n",
+      "  time_since_restore: 104.25312542915344\n",
+      "  time_this_iter_s: 20.186545610427856\n",
+      "  time_total_s: 104.25312542915344\n",
+      "  timers:\n",
+      "    learn_throughput: 11116.23\n",
+      "    learn_time_ms: 14554.575\n",
+      "    sample_throughput: 26067.237\n",
+      "    sample_time_ms: 6206.718\n",
+      "    update_time_ms: 26.186\n",
+      "  timestamp: 1604231750\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      5 |          104.253 | 808960 |  39.0378 |              46.8571 |              15.7347 |            112.055 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1360.2383485601943\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.9338091400944\n",
+      "  episode_reward_max: 46.85714285714288\n",
+      "  episode_reward_mean: 39.78162771958098\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1563\n",
+      "  episodes_total: 8687\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0209535757700603\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009677846527968844\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013495485666984072\n",
+      "        total_loss: 3.3039915561676025\n",
+      "        vf_explained_var: 0.9663781523704529\n",
+      "        vf_loss: 3.3160619735717773\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.1\n",
+      "    gpu_util_percent0: 0.3948\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.52\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15752045783718058\n",
+      "    mean_env_wait_ms: 0.6540636684528683\n",
+      "    mean_inference_ms: 4.50681489407211\n",
+      "    mean_raw_obs_processing_ms: 0.4129356375354034\n",
+      "  time_since_restore: 124.68163776397705\n",
+      "  time_this_iter_s: 20.42851233482361\n",
+      "  time_total_s: 124.68163776397705\n",
+      "  timers:\n",
+      "    learn_throughput: 11114.998\n",
+      "    learn_time_ms: 14556.188\n",
+      "    sample_throughput: 26385.183\n",
+      "    sample_time_ms: 6131.926\n",
+      "    update_time_ms: 25.903\n",
+      "  timestamp: 1604231771\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      6 |          124.682 | 970752 |  39.7816 |              46.8571 |              15.7347 |            110.934 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1346.8549304058029\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.96026166764304\n",
+      "  episode_reward_max: 46.85714285714288\n",
+      "  episode_reward_mean: 40.448761402627824\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 10242\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9796850432952245\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008622131776064634\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012602110786247067\n",
+      "        total_loss: 2.7198241551717124\n",
+      "        vf_explained_var: 0.9723749160766602\n",
+      "        vf_loss: 2.731191635131836\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.520833333333332\n",
+      "    gpu_util_percent0: 0.36541666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5208333333333335\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15640676678928592\n",
+      "    mean_env_wait_ms: 0.6528313389539068\n",
+      "    mean_inference_ms: 4.45161866768078\n",
+      "    mean_raw_obs_processing_ms: 0.40931756815016995\n",
+      "  time_since_restore: 145.21865725517273\n",
+      "  time_this_iter_s: 20.53701949119568\n",
+      "  time_total_s: 145.21865725517273\n",
+      "  timers:\n",
+      "    learn_throughput: 11103.013\n",
+      "    learn_time_ms: 14571.9\n",
+      "    sample_throughput: 26614.769\n",
+      "    sample_time_ms: 6079.031\n",
+      "    update_time_ms: 25.131\n",
+      "  timestamp: 1604231791\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      7 |          145.219 | 1132544 |  40.4488 |              46.8571 |              15.7347 |             109.96 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1335.6309301139263\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-56-52\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.09913573970513\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.02892366911177\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 11802\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.937453493475914\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007955724994341532\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01194375741033582\n",
+      "        total_loss: 2.2597323656082153\n",
+      "        vf_explained_var: 0.9770286083221436\n",
+      "        vf_loss: 2.2705536683400473\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.436000000000003\n",
+      "    gpu_util_percent0: 0.3632\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1554915965562696\n",
+      "    mean_env_wait_ms: 0.6518904790353526\n",
+      "    mean_inference_ms: 4.406507393012131\n",
+      "    mean_raw_obs_processing_ms: 0.40631830746764874\n",
+      "  time_since_restore: 166.04925441741943\n",
+      "  time_this_iter_s: 20.830597162246704\n",
+      "  time_total_s: 166.04925441741943\n",
+      "  timers:\n",
+      "    learn_throughput: 11082.871\n",
+      "    learn_time_ms: 14598.383\n",
+      "    sample_throughput: 26705.585\n",
+      "    sample_time_ms: 6058.358\n",
+      "    update_time_ms: 26.617\n",
+      "  timestamp: 1604231812\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      8 |          166.049 | 1294336 |  41.0289 |              46.8571 |              15.7347 |            109.099 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1325.960990247562\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.36514584891549\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.523987605513405\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1568\n",
+      "  episodes_total: 13370\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8931734959284464\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007821322418749332\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011547995522657098\n",
+      "        total_loss: 1.8110616604487102\n",
+      "        vf_explained_var: 0.9818581938743591\n",
+      "        vf_loss: 1.8214919765790303\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.3625\n",
+      "    gpu_util_percent0: 0.34625\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15472443847934\n",
+      "    mean_env_wait_ms: 0.6512116120864969\n",
+      "    mean_inference_ms: 4.368900491259558\n",
+      "    mean_raw_obs_processing_ms: 0.40380683055783845\n",
+      "  time_since_restore: 186.4968512058258\n",
+      "  time_this_iter_s: 20.447596788406372\n",
+      "  time_total_s: 186.4968512058258\n",
+      "  timers:\n",
+      "    learn_throughput: 11083.852\n",
+      "    learn_time_ms: 14597.092\n",
+      "    sample_throughput: 26872.567\n",
+      "    sample_time_ms: 6020.713\n",
+      "    update_time_ms: 27.945\n",
+      "  timestamp: 1604231833\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |      9 |          186.497 | 1456128 |   41.524 |              46.8571 |              15.7347 |            108.365 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1317.3690564013145\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.72182462711524\n",
+      "  episode_reward_max: 46.8571428571429\n",
+      "  episode_reward_mean: 41.96634652790953\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1581\n",
+      "  episodes_total: 14951\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8531899998585383\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007403539726510644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011224584576363364\n",
+      "        total_loss: 1.351464072863261\n",
+      "        vf_explained_var: 0.9865902066230774\n",
+      "        vf_loss: 1.3616345326105754\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.612\n",
+      "    gpu_util_percent0: 0.37999999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.572\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15406610086889994\n",
+      "    mean_env_wait_ms: 0.6506878167628722\n",
+      "    mean_inference_ms: 4.336866675743429\n",
+      "    mean_raw_obs_processing_ms: 0.4016399376622533\n",
+      "  time_since_restore: 207.11356925964355\n",
+      "  time_this_iter_s: 20.61671805381775\n",
+      "  time_total_s: 207.11356925964355\n",
+      "  timers:\n",
+      "    learn_throughput: 11075.434\n",
+      "    learn_time_ms: 14608.186\n",
+      "    sample_throughput: 27020.124\n",
+      "    sample_time_ms: 5987.833\n",
+      "    update_time_ms: 29.042\n",
+      "  timestamp: 1604231854\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     10 |          207.114 | 1617920 |  41.9663 |              46.8571 |              15.7347 |            107.722 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1309.7214852504694\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-57-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.15910326907971\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 42.36176364315742\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 16549\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8141860415538152\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006707225965025525\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011368195065491212\n",
+      "        total_loss: 1.1314103106657665\n",
+      "        vf_explained_var: 0.9888380169868469\n",
+      "        vf_loss: 1.1418441633383434\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.291666666666668\n",
+      "    gpu_util_percent0: 0.38208333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15349391695430212\n",
+      "    mean_env_wait_ms: 0.6503003794675789\n",
+      "    mean_inference_ms: 4.309108284972775\n",
+      "    mean_raw_obs_processing_ms: 0.3997656568156822\n",
+      "  time_since_restore: 227.4893569946289\n",
+      "  time_this_iter_s: 20.37578773498535\n",
+      "  time_total_s: 227.4893569946289\n",
+      "  timers:\n",
+      "    learn_throughput: 11080.893\n",
+      "    learn_time_ms: 14600.989\n",
+      "    sample_throughput: 27896.222\n",
+      "    sample_time_ms: 5799.782\n",
+      "    update_time_ms: 29.058\n",
+      "  timestamp: 1604231875\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     11 |          227.489 | 1779712 |  42.3618 |              46.8571 |              15.7347 |            107.159 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1303.0352388842862\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.65836318545054\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 42.7044331097002\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 18145\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7753126074870428\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006863077365172406\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012638252902737198\n",
+      "        total_loss: 0.8784026602904002\n",
+      "        vf_explained_var: 0.9913859963417053\n",
+      "        vf_loss: 0.8900559494892756\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.460000000000004\n",
+      "    gpu_util_percent0: 0.35159999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15300041083206697\n",
+      "    mean_env_wait_ms: 0.6500163020439707\n",
+      "    mean_inference_ms: 4.28507024712119\n",
+      "    mean_raw_obs_processing_ms: 0.39814727184542376\n",
+      "  time_since_restore: 248.12101984024048\n",
+      "  time_this_iter_s: 20.631662845611572\n",
+      "  time_total_s: 248.12101984024048\n",
+      "  timers:\n",
+      "    learn_throughput: 11075.423\n",
+      "    learn_time_ms: 14608.2\n",
+      "    sample_throughput: 28116.695\n",
+      "    sample_time_ms: 5754.304\n",
+      "    update_time_ms: 29.472\n",
+      "  timestamp: 1604231896\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     12 |          248.121 | 1941504 |  42.7044 |              46.8571 |              15.7347 |            106.658 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1297.1705583756345\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.2274062816616\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.00436542398114\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1595\n",
+      "  episodes_total: 19740\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7383754253387451\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006651315527657668\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010724902463455996\n",
+      "        total_loss: 0.7107721914847692\n",
+      "        vf_explained_var: 0.9930524230003357\n",
+      "        vf_loss: 0.720536028345426\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.279166666666665\n",
+      "    gpu_util_percent0: 0.3491666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15256633452651727\n",
+      "    mean_env_wait_ms: 0.649802245161823\n",
+      "    mean_inference_ms: 4.264010160654567\n",
+      "    mean_raw_obs_processing_ms: 0.39671502855945817\n",
+      "  time_since_restore: 268.6334173679352\n",
+      "  time_this_iter_s: 20.512397527694702\n",
+      "  time_total_s: 268.6334173679352\n",
+      "  timers:\n",
+      "    learn_throughput: 11061.736\n",
+      "    learn_time_ms: 14626.276\n",
+      "    sample_throughput: 28152.503\n",
+      "    sample_time_ms: 5746.985\n",
+      "    update_time_ms: 29.255\n",
+      "  timestamp: 1604231917\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     13 |          268.633 | 2103296 |  43.0044 |              46.8571 |              15.7347 |            106.227 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1292.0809922014469\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-58-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.85140204445278\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.26472333282933\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1586\n",
+      "  episodes_total: 21326\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7001272787650427\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0061410532022515936\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010832997679244727\n",
+      "        total_loss: 0.6119682043790817\n",
+      "        vf_explained_var: 0.9940410256385803\n",
+      "        vf_loss: 0.621923049290975\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.02\n",
+      "    gpu_util_percent0: 0.368\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15218124195639093\n",
+      "    mean_env_wait_ms: 0.6496403257727554\n",
+      "    mean_inference_ms: 4.245421485662705\n",
+      "    mean_raw_obs_processing_ms: 0.3954453584998017\n",
+      "  time_since_restore: 289.35663652420044\n",
+      "  time_this_iter_s: 20.72321915626526\n",
+      "  time_total_s: 289.35663652420044\n",
+      "  timers:\n",
+      "    learn_throughput: 11062.187\n",
+      "    learn_time_ms: 14625.679\n",
+      "    sample_throughput: 28102.045\n",
+      "    sample_time_ms: 5757.304\n",
+      "    update_time_ms: 34.762\n",
+      "  timestamp: 1604231938\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     14 |          289.357 | 2265088 |  43.2647 |              46.8571 |              15.7347 |            105.851 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1287.5182239314745\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-59-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.5031847133758\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.497414924437614\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 22922\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6637579500675201\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005367214015374581\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009309418620735718\n",
+      "        total_loss: 0.47650496910015744\n",
+      "        vf_explained_var: 0.9953997731208801\n",
+      "        vf_loss: 0.4850728213787079\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.845833333333335\n",
+      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15183678083046764\n",
+      "    mean_env_wait_ms: 0.6495392872625815\n",
+      "    mean_inference_ms: 4.2286469238398325\n",
+      "    mean_raw_obs_processing_ms: 0.39431499646823304\n",
+      "  time_since_restore: 309.672310590744\n",
+      "  time_this_iter_s: 20.31567406654358\n",
+      "  time_total_s: 309.672310590744\n",
+      "  timers:\n",
+      "    learn_throughput: 11054.878\n",
+      "    learn_time_ms: 14635.35\n",
+      "    sample_throughput: 28119.821\n",
+      "    sample_time_ms: 5753.664\n",
+      "    update_time_ms: 33.135\n",
+      "  timestamp: 1604231958\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     15 |          309.672 | 2426880 |  43.4974 |              46.8571 |              15.7347 |            105.503 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1283.4805964052287\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_11-59-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.19265905383361\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.70432092086426\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 24520\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6296272675196329\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0055771675348902745\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009812832868192345\n",
+      "        total_loss: 0.3527320822079976\n",
+      "        vf_explained_var: 0.9965917468070984\n",
+      "        vf_loss: 0.3617442895968755\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.162500000000005\n",
+      "    gpu_util_percent0: 0.42416666666666664\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1515236024097143\n",
+      "    mean_env_wait_ms: 0.6494728987544927\n",
+      "    mean_inference_ms: 4.213501380549204\n",
+      "    mean_raw_obs_processing_ms: 0.3932868129355243\n",
+      "  time_since_restore: 330.0610761642456\n",
+      "  time_this_iter_s: 20.388765573501587\n",
+      "  time_total_s: 330.0610761642456\n",
+      "  timers:\n",
+      "    learn_throughput: 11058.672\n",
+      "    learn_time_ms: 14630.328\n",
+      "    sample_throughput: 28143.68\n",
+      "    sample_time_ms: 5748.786\n",
+      "    update_time_ms: 32.726\n",
+      "  timestamp: 1604231979\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     16 |          330.061 | 2588672 |  43.7043 |              46.8571 |              15.7347 |            105.193 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1279.8473329245862\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.910927456382\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 43.890595815920484\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1616\n",
+      "  episodes_total: 26136\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5843918571869532\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005636528095540901\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009946482673209781\n",
+      "        total_loss: 0.2803831646839778\n",
+      "        vf_explained_var: 0.9972963333129883\n",
+      "        vf_loss: 0.28949454923470813\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.984\n",
+      "    gpu_util_percent0: 0.36920000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15123654271663214\n",
+      "    mean_env_wait_ms: 0.6494373187304042\n",
+      "    mean_inference_ms: 4.199623866436883\n",
+      "    mean_raw_obs_processing_ms: 0.3923463354120984\n",
+      "  time_since_restore: 350.56322145462036\n",
+      "  time_this_iter_s: 20.502145290374756\n",
+      "  time_total_s: 350.56322145462036\n",
+      "  timers:\n",
+      "    learn_throughput: 11060.535\n",
+      "    learn_time_ms: 14627.863\n",
+      "    sample_throughput: 28221.412\n",
+      "    sample_time_ms: 5732.952\n",
+      "    update_time_ms: 40.383\n",
+      "  timestamp: 1604232000\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     17 |          350.563 | 2750464 |  43.8906 |              46.8571 |              15.7347 |            104.911 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1276.563322872705\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.65475633036776\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.05809376302477\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1627\n",
+      "  episodes_total: 27763\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5512450536092123\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052360318368300796\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00858212105807373\n",
+      "        total_loss: 0.2300113836924235\n",
+      "        vf_explained_var: 0.997800350189209\n",
+      "        vf_loss: 0.2378219154973825\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.133333333333336\n",
+      "    gpu_util_percent0: 0.3545833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15097539441634178\n",
+      "    mean_env_wait_ms: 0.649425583111441\n",
+      "    mean_inference_ms: 4.186930579711764\n",
+      "    mean_raw_obs_processing_ms: 0.3914892612304368\n",
+      "  time_since_restore: 371.091876745224\n",
+      "  time_this_iter_s: 20.528655290603638\n",
+      "  time_total_s: 371.091876745224\n",
+      "  timers:\n",
+      "    learn_throughput: 11066.918\n",
+      "    learn_time_ms: 14619.428\n",
+      "    sample_throughput: 28359.109\n",
+      "    sample_time_ms: 5705.116\n",
+      "    update_time_ms: 40.411\n",
+      "  timestamp: 1604232021\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     18 |          371.092 | 2912256 |  44.0581 |              46.8571 |              15.7347 |            104.655 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1273.6519278628166\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-00-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.42508426105607\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.20715088200534\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 29373\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.525387316942215\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004920089112905164\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008422184953815304\n",
+      "        total_loss: 0.1757721391816934\n",
+      "        vf_explained_var: 0.9983048439025879\n",
+      "        vf_loss: 0.1834729996820291\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.212000000000003\n",
+      "    gpu_util_percent0: 0.336\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15073736984322064\n",
+      "    mean_env_wait_ms: 0.649427266881627\n",
+      "    mean_inference_ms: 4.175450336968136\n",
+      "    mean_raw_obs_processing_ms: 0.3907110068982923\n",
+      "  time_since_restore: 391.7044517993927\n",
+      "  time_this_iter_s: 20.6125750541687\n",
+      "  time_total_s: 391.7044517993927\n",
+      "  timers:\n",
+      "    learn_throughput: 11052.788\n",
+      "    learn_time_ms: 14638.117\n",
+      "    sample_throughput: 28425.972\n",
+      "    sample_time_ms: 5691.696\n",
+      "    update_time_ms: 45.734\n",
+      "  timestamp: 1604232043\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     19 |          391.704 | 3074048 |  44.2072 |              46.8571 |              15.7347 |            104.425 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1271.0431296475913\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.21682273167582\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.34093230446844\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 30970\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49314410984516144\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005798064754344523\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009414856787770987\n",
+      "        total_loss: 0.13895704535146555\n",
+      "        vf_explained_var: 0.9986486434936523\n",
+      "        vf_loss: 0.1480386642118295\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.116666666666664\n",
+      "    gpu_util_percent0: 0.35833333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15052181952677304\n",
+      "    mean_env_wait_ms: 0.649438443211961\n",
+      "    mean_inference_ms: 4.164995515225137\n",
+      "    mean_raw_obs_processing_ms: 0.3900008446460127\n",
+      "  time_since_restore: 412.16121435165405\n",
+      "  time_this_iter_s: 20.456762552261353\n",
+      "  time_total_s: 412.16121435165405\n",
+      "  timers:\n",
+      "    learn_throughput: 11057.384\n",
+      "    learn_time_ms: 14632.032\n",
+      "    sample_throughput: 28470.363\n",
+      "    sample_time_ms: 5682.822\n",
+      "    update_time_ms: 44.871\n",
+      "  timestamp: 1604232064\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     20 |          412.161 | 3235840 |  44.3409 |              46.8571 |              15.7347 |            104.217 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1268.6647814593964\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.02566464051084\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.4626028897468\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1604\n",
+      "  episodes_total: 32574\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.46102594832579297\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005838079610839486\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00808940147787022\n",
+      "        total_loss: 0.11789208464324474\n",
+      "        vf_explained_var: 0.9988470077514648\n",
+      "        vf_loss: 0.12562819197773933\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.463999999999995\n",
+      "    gpu_util_percent0: 0.3728\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15032141681707573\n",
+      "    mean_env_wait_ms: 0.6494592765291238\n",
+      "    mean_inference_ms: 4.155300920389142\n",
+      "    mean_raw_obs_processing_ms: 0.3893410843403339\n",
+      "  time_since_restore: 432.50473642349243\n",
+      "  time_this_iter_s: 20.34352207183838\n",
+      "  time_total_s: 432.50473642349243\n",
+      "  timers:\n",
+      "    learn_throughput: 11057.81\n",
+      "    learn_time_ms: 14631.468\n",
+      "    sample_throughput: 28523.95\n",
+      "    sample_time_ms: 5672.146\n",
+      "    update_time_ms: 46.215\n",
+      "  timestamp: 1604232084\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     21 |          432.505 | 3397632 |  44.4626 |              46.8571 |              15.7347 |            104.026 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1266.4863559173157\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-01-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.8470199450196\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.57447720270771\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1620\n",
+      "  episodes_total: 34194\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.43294235815604526\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005431869920964043\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009014388362023359\n",
+      "        total_loss: 0.08529840596020222\n",
+      "        vf_explained_var: 0.9991478323936462\n",
+      "        vf_loss: 0.09398608033855756\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.592\n",
+      "    gpu_util_percent0: 0.35\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.572\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1501333983360748\n",
+      "    mean_env_wait_ms: 0.6494934869624449\n",
+      "    mean_inference_ms: 4.146224608744544\n",
+      "    mean_raw_obs_processing_ms: 0.3887246826845676\n",
+      "  time_since_restore: 453.3322539329529\n",
+      "  time_this_iter_s: 20.82751750946045\n",
+      "  time_total_s: 453.3322539329529\n",
+      "  timers:\n",
+      "    learn_throughput: 11039.758\n",
+      "    learn_time_ms: 14655.394\n",
+      "    sample_throughput: 28584.579\n",
+      "    sample_time_ms: 5660.115\n",
+      "    update_time_ms: 47.568\n",
+      "  timestamp: 1604232106\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     22 |          453.332 | 3559424 |  44.5745 |              46.8571 |              15.7347 |            103.847 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1264.481222756231\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.68064083956682\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.67719666296796\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1634\n",
+      "  episodes_total: 35828\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4028966749707858\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0056398319235692424\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010392234045866644\n",
+      "        total_loss: 0.08119491549829642\n",
+      "        vf_explained_var: 0.9991843700408936\n",
+      "        vf_loss: 0.0912246151516835\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.024999999999995\n",
+      "    gpu_util_percent0: 0.36624999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14995601669875397\n",
+      "    mean_env_wait_ms: 0.6495352227224097\n",
+      "    mean_inference_ms: 4.137711997351269\n",
+      "    mean_raw_obs_processing_ms: 0.38814230126504\n",
+      "  time_since_restore: 473.85256695747375\n",
+      "  time_this_iter_s: 20.520313024520874\n",
+      "  time_total_s: 473.85256695747375\n",
+      "  timers:\n",
+      "    learn_throughput: 11045.845\n",
+      "    learn_time_ms: 14647.318\n",
+      "    sample_throughput: 28580.616\n",
+      "    sample_time_ms: 5660.9\n",
+      "    update_time_ms: 49.009\n",
+      "  timestamp: 1604232127\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     23 |          473.853 | 3721216 |  44.6772 |              46.8571 |              15.7347 |            103.681 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1262.6683067707777\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.53063895715354\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.77006117651676\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1608\n",
+      "  episodes_total: 37436\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3745071937640508\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005321652473260959\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007234078652497071\n",
+      "        total_loss: 0.05749547202140093\n",
+      "        vf_explained_var: 0.9994208812713623\n",
+      "        vf_loss: 0.06438463802138965\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.864\n",
+      "    gpu_util_percent0: 0.39199999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14979390065628823\n",
+      "    mean_env_wait_ms: 0.649588420666768\n",
+      "    mean_inference_ms: 4.1299192587977664\n",
+      "    mean_raw_obs_processing_ms: 0.38760946260698614\n",
+      "  time_since_restore: 494.24922704696655\n",
+      "  time_this_iter_s: 20.396660089492798\n",
+      "  time_total_s: 494.24922704696655\n",
+      "  timers:\n",
+      "    learn_throughput: 11054.341\n",
+      "    learn_time_ms: 14636.061\n",
+      "    sample_throughput: 28685.318\n",
+      "    sample_time_ms: 5640.237\n",
+      "    update_time_ms: 42.265\n",
+      "  timestamp: 1604232148\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:02:29,652\tWARNING util.py:136 -- The `process_trial` operation took 0.5228226184844971 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     24 |          494.249 | 3883008 |  44.7701 |              46.8571 |              15.7347 |            103.531 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1261.0109236371095\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-02-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.39151595880936\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.854644767892296\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 39038\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3481475959221522\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004828551318496466\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0070124387663478656\n",
+      "        total_loss: 0.06740419659763575\n",
+      "        vf_explained_var: 0.9993410706520081\n",
+      "        vf_loss: 0.07410785431663196\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.944000000000003\n",
+      "    gpu_util_percent0: 0.3452\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14964195104865902\n",
+      "    mean_env_wait_ms: 0.6496402901027807\n",
+      "    mean_inference_ms: 4.122656867380491\n",
+      "    mean_raw_obs_processing_ms: 0.3871109943323948\n",
+      "  time_since_restore: 514.7466752529144\n",
+      "  time_this_iter_s: 20.497448205947876\n",
+      "  time_total_s: 514.7466752529144\n",
+      "  timers:\n",
+      "    learn_throughput: 11049.552\n",
+      "    learn_time_ms: 14642.403\n",
+      "    sample_throughput: 28661.043\n",
+      "    sample_time_ms: 5645.014\n",
+      "    update_time_ms: 44.89\n",
+      "  timestamp: 1604232170\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:02:51,023\tWARNING util.py:136 -- The `process_trial` operation took 0.5479519367218018 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     25 |          514.747 | 4044800 |  44.8546 |              46.8571 |              15.7347 |            103.392 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1259.4838947990543\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.26077543790592\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 44.933213572774115\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 40648\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.32285959521929425\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005153231516790886\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006437089536727096\n",
+      "        total_loss: 0.04760071821510792\n",
+      "        vf_explained_var: 0.9995192885398865\n",
+      "        vf_loss: 0.05394157860428095\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.183333333333334\n",
+      "    gpu_util_percent0: 0.30583333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14949842842548025\n",
+      "    mean_env_wait_ms: 0.6496982049535759\n",
+      "    mean_inference_ms: 4.115822249881849\n",
+      "    mean_raw_obs_processing_ms: 0.3866408622949027\n",
+      "  time_since_restore: 535.2055022716522\n",
+      "  time_this_iter_s: 20.458827018737793\n",
+      "  time_total_s: 535.2055022716522\n",
+      "  timers:\n",
+      "    learn_throughput: 11044.133\n",
+      "    learn_time_ms: 14649.588\n",
+      "    sample_throughput: 28693.76\n",
+      "    sample_time_ms: 5638.578\n",
+      "    update_time_ms: 44.672\n",
+      "  timestamp: 1604232191\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:12,271\tWARNING util.py:136 -- The `process_trial` operation took 0.5345759391784668 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     26 |          535.206 | 4206592 |  44.9332 |              46.8571 |              15.7347 |            103.261 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1258.0401912516568\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.137958758986\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.007320067641125\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1640\n",
+      "  episodes_total: 42288\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2982073624928792\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004597992869094014\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007848733845700432\n",
+      "        total_loss: 0.03614849457517266\n",
+      "        vf_explained_var: 0.9996141791343689\n",
+      "        vf_loss: 0.043916432497402035\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.736\n",
+      "    gpu_util_percent0: 0.4024000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14936013846680316\n",
+      "    mean_env_wait_ms: 0.6497567301190108\n",
+      "    mean_inference_ms: 4.109265721932972\n",
+      "    mean_raw_obs_processing_ms: 0.38618524014647837\n",
+      "  time_since_restore: 555.6780240535736\n",
+      "  time_this_iter_s: 20.472521781921387\n",
+      "  time_total_s: 555.6780240535736\n",
+      "  timers:\n",
+      "    learn_throughput: 11047.092\n",
+      "    learn_time_ms: 14645.664\n",
+      "    sample_throughput: 28676.643\n",
+      "    sample_time_ms: 5641.943\n",
+      "    update_time_ms: 36.998\n",
+      "  timestamp: 1604232212\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:33,510\tWARNING util.py:136 -- The `process_trial` operation took 0.567908525466919 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     27 |          555.678 | 4368384 |  45.0073 |              46.8571 |              15.7347 |            103.138 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1256.7130644903914\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-03-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.02484797412713\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.07519232440738\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 43907\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.27154965202013653\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004386523951931546\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006109707096281151\n",
+      "        total_loss: 0.029498847822348278\n",
+      "        vf_explained_var: 0.9996840357780457\n",
+      "        vf_loss: 0.03563466699173053\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.215999999999998\n",
+      "    gpu_util_percent0: 0.35719999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14923164336873793\n",
+      "    mean_env_wait_ms: 0.6498215067723312\n",
+      "    mean_inference_ms: 4.103192802934885\n",
+      "    mean_raw_obs_processing_ms: 0.3857616555198185\n",
+      "  time_since_restore: 576.108469247818\n",
+      "  time_this_iter_s: 20.430445194244385\n",
+      "  time_total_s: 576.108469247818\n",
+      "  timers:\n",
+      "    learn_throughput: 11053.539\n",
+      "    learn_time_ms: 14637.122\n",
+      "    sample_throughput: 28704.812\n",
+      "    sample_time_ms: 5636.407\n",
+      "    update_time_ms: 34.761\n",
+      "  timestamp: 1604232233\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:03:54,833\tWARNING util.py:136 -- The `process_trial` operation took 0.5623390674591064 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     28 |          576.108 | 4530176 |  45.0752 |              46.8571 |              15.7347 |            103.025 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1255.498240520806\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-04-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.92078315900501\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.13765263071036\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 45508\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.012500000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.25443976496656734\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004423999693244696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005417319412420814\n",
+      "        total_loss: 0.024296301572273176\n",
+      "        vf_explained_var: 0.9997418522834778\n",
+      "        vf_loss: 0.02978554057578246\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.112\n",
+      "    gpu_util_percent0: 0.33520000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1491126560484596\n",
+      "    mean_env_wait_ms: 0.6498944683718904\n",
+      "    mean_inference_ms: 4.097513752031446\n",
+      "    mean_raw_obs_processing_ms: 0.38536978766235913\n",
+      "  time_since_restore: 596.6098058223724\n",
+      "  time_this_iter_s: 20.501336574554443\n",
+      "  time_total_s: 596.6098058223724\n",
+      "  timers:\n",
+      "    learn_throughput: 11066.443\n",
+      "    learn_time_ms: 14620.054\n",
+      "    sample_throughput: 28671.129\n",
+      "    sample_time_ms: 5643.029\n",
+      "    update_time_ms: 27.975\n",
+      "  timestamp: 1604232255\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:04:16,277\tWARNING util.py:136 -- The `process_trial` operation took 0.5899343490600586 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | RUNNING  | 172.17.0.4:20230 |     29 |           596.61 | 4691968 |  45.1377 |              46.8571 |              15.7347 |            102.921 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ed52d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1737\n",
+      "    time_step_mean: 1254.3588893845729\n",
+      "    time_step_min: 1222\n",
+      "  date: 2020-11-01_12-04-36\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.82308492348184\n",
+      "  episode_reward_max: 46.857142857142904\n",
+      "  episode_reward_mean: 45.196090857543105\n",
+      "  episode_reward_min: 15.734693877551013\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 47113\n",
+      "  experiment_id: 620cee76ed6f483492f5b5ea167d8862\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.006250000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.23119975750645003\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004294859090199073\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006582304151379503\n",
+      "        total_loss: 0.016346099126773577\n",
+      "        vf_explained_var: 0.9998031258583069\n",
+      "        vf_loss: 0.02301716012880206\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.433333333333334\n",
+      "    gpu_util_percent0: 0.3558333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 20230\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1489996674476156\n",
+      "    mean_env_wait_ms: 0.6499679628512286\n",
+      "    mean_inference_ms: 4.0921381946019215\n",
+      "    mean_raw_obs_processing_ms: 0.38499719572571234\n",
+      "  time_since_restore: 616.9446895122528\n",
+      "  time_this_iter_s: 20.33488368988037\n",
+      "  time_total_s: 616.9446895122528\n",
+      "  timers:\n",
+      "    learn_throughput: 11076.785\n",
+      "    learn_time_ms: 14606.404\n",
+      "    sample_throughput: 28687.763\n",
+      "    sample_time_ms: 5639.757\n",
+      "    update_time_ms: 27.238\n",
+      "  timestamp: 1604232276\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: ed52d_00000\n",
+      "  \n",
+      "2020-11-01 12:04:37,528\tWARNING util.py:136 -- The `process_trial` operation took 0.6967248916625977 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.59 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ed52d_00000 | TERMINATED |       |     30 |          616.945 | 4853760 |  45.1961 |              46.8571 |              15.7347 |            102.823 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 20006\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_115353-kqo0l7if/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_115353-kqo0l7if/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1222\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 645\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604232278\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1737\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1254.35889\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 46.85714\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 15.73469\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 45.19609\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47113\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmisty-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/kqo0l7if\u001b[0m\n",
+      "2020-11-01 12:04:48,722 - wandb.wandb_agent - INFO - Cleaning up finished run: kqo0l7if\n",
+      "2020-11-01 12:04:49,030 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:04:49,030 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la12.txt\n",
+      "2020-11-01 12:04:49,033 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la12.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:04:54,049 - wandb.wandb_agent - INFO - Running runs: ['tkx2xsoj']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/tkx2xsoj\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_120450-tkx2xsoj\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:04:54,756\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=52265)\u001b[0m 2020-11-01 12:04:57,569\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52231)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52231)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52227)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52227)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1270.6712550607288\n",
+      "    time_step_min: 1054\n",
+      "  date: 2020-11-01_12-05-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.74350904799371\n",
+      "  episode_reward_max: 41.65306122448979\n",
+      "  episode_reward_mean: 30.6028275983879\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1271\n",
+      "  episodes_total: 1271\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1384523808956146\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006007326611628135\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006815222654646884\n",
+      "        total_loss: 36.897240002950035\n",
+      "        vf_explained_var: 0.7482123374938965\n",
+      "        vf_loss: 36.903422355651855\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.62222222222222\n",
+      "    gpu_util_percent0: 0.40222222222222226\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4333333333333336\n",
+      "    vram_util_percent0: 0.08172381958869332\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16969461340934525\n",
+      "    mean_env_wait_ms: 0.6709388448442125\n",
+      "    mean_inference_ms: 5.213710332296094\n",
+      "    mean_raw_obs_processing_ms: 0.4500044725167772\n",
+      "  time_since_restore: 22.275667190551758\n",
+      "  time_this_iter_s: 22.275667190551758\n",
+      "  time_total_s: 22.275667190551758\n",
+      "  timers:\n",
+      "    learn_throughput: 11194.703\n",
+      "    learn_time_ms: 14452.55\n",
+      "    sample_throughput: 20900.055\n",
+      "    sample_time_ms: 7741.224\n",
+      "    update_time_ms: 42.347\n",
+      "  timestamp: 1604232325\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      1 |          22.2757 | 161792 |  30.6028 |              41.6531 |              10.2755 |            116.744 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1252.1281568036186\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-05-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.04722945332837\n",
+      "  episode_reward_max: 42.41836734693876\n",
+      "  episode_reward_mean: 31.48901419995294\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1418\n",
+      "  episodes_total: 2689\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1159119109312694\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010711442679166794\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012819082303982062\n",
+      "        total_loss: 9.95718256632487\n",
+      "        vf_explained_var: 0.8801858425140381\n",
+      "        vf_loss: 9.968417485555014\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.4\n",
+      "    gpu_util_percent0: 0.3830769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1663996838490878\n",
+      "    mean_env_wait_ms: 0.6661199624654368\n",
+      "    mean_inference_ms: 5.065247663215141\n",
+      "    mean_raw_obs_processing_ms: 0.443431096131331\n",
+      "  time_since_restore: 43.45249390602112\n",
+      "  time_this_iter_s: 21.17682671546936\n",
+      "  time_total_s: 43.45249390602112\n",
+      "  timers:\n",
+      "    learn_throughput: 11200.574\n",
+      "    learn_time_ms: 14444.974\n",
+      "    sample_throughput: 22507.211\n",
+      "    sample_time_ms: 7188.452\n",
+      "    update_time_ms: 40.119\n",
+      "  timestamp: 1604232346\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      2 |          43.4525 | 323584 |   31.489 |              42.4184 |              10.2755 |            116.047 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1229.5523227383862\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.94789142026175\n",
+      "  episode_reward_max: 42.41836734693877\n",
+      "  episode_reward_mean: 32.67046455033783\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1437\n",
+      "  episodes_total: 4126\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0916709005832672\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011045165204753479\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012844632374860035\n",
+      "        total_loss: 6.921001553535461\n",
+      "        vf_explained_var: 0.9159042239189148\n",
+      "        vf_loss: 6.9321829080581665\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.06\n",
+      "    gpu_util_percent0: 0.4312\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16376589972908362\n",
+      "    mean_env_wait_ms: 0.6617033666285996\n",
+      "    mean_inference_ms: 4.920294910569432\n",
+      "    mean_raw_obs_processing_ms: 0.43664206722952675\n",
+      "  time_since_restore: 63.84919023513794\n",
+      "  time_this_iter_s: 20.39669632911682\n",
+      "  time_total_s: 63.84919023513794\n",
+      "  timers:\n",
+      "    learn_throughput: 11232.084\n",
+      "    learn_time_ms: 14404.451\n",
+      "    sample_throughput: 23846.064\n",
+      "    sample_time_ms: 6784.851\n",
+      "    update_time_ms: 37.748\n",
+      "  timestamp: 1604232366\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      3 |          63.8492 | 485376 |  32.6705 |              42.4184 |              10.2755 |            114.948 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1208.264137437366\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.67087482219061\n",
+      "  episode_reward_max: 42.41836734693879\n",
+      "  episode_reward_mean: 33.766906406944\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1498\n",
+      "  episodes_total: 5624\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.064699391523997\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010414493580659231\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015563213809703788\n",
+      "        total_loss: 5.088392059008281\n",
+      "        vf_explained_var: 0.9388461709022522\n",
+      "        vf_loss: 5.102404753367106\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.656000000000002\n",
+      "    gpu_util_percent0: 0.4268\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16163926361569136\n",
+      "    mean_env_wait_ms: 0.6582592695889212\n",
+      "    mean_inference_ms: 4.803322913432019\n",
+      "    mean_raw_obs_processing_ms: 0.43060689585891204\n",
+      "  time_since_restore: 84.06805443763733\n",
+      "  time_this_iter_s: 20.21886420249939\n",
+      "  time_total_s: 84.06805443763733\n",
+      "  timers:\n",
+      "    learn_throughput: 11266.122\n",
+      "    learn_time_ms: 14360.931\n",
+      "    sample_throughput: 24659.344\n",
+      "    sample_time_ms: 6561.083\n",
+      "    update_time_ms: 34.947\n",
+      "  timestamp: 1604232387\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      4 |          84.0681 | 647168 |  33.7669 |              42.4184 |              10.2755 |            113.671 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1189.914229193161\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-06-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.46028398706594\n",
+      "  episode_reward_max: 42.4183673469388\n",
+      "  episode_reward_mean: 34.71768564026201\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1489\n",
+      "  episodes_total: 7113\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0440024832884471\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009285129917164644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013422702313012755\n",
+      "        total_loss: 3.5668797492980957\n",
+      "        vf_explained_var: 0.956657886505127\n",
+      "        vf_loss: 3.5789673924446106\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.128\n",
+      "    gpu_util_percent0: 0.3836\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15996949149852113\n",
+      "    mean_env_wait_ms: 0.6557683164407656\n",
+      "    mean_inference_ms: 4.714004318455946\n",
+      "    mean_raw_obs_processing_ms: 0.42569876525023526\n",
+      "  time_since_restore: 104.25618076324463\n",
+      "  time_this_iter_s: 20.1881263256073\n",
+      "  time_total_s: 104.25618076324463\n",
+      "  timers:\n",
+      "    learn_throughput: 11286.122\n",
+      "    learn_time_ms: 14335.482\n",
+      "    sample_throughput: 25221.502\n",
+      "    sample_time_ms: 6414.844\n",
+      "    update_time_ms: 36.706\n",
+      "  timestamp: 1604232407\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      5 |          104.256 | 808960 |  34.7177 |              42.4184 |              10.2755 |             112.46 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1173.5402272200324\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.30085430616485\n",
+      "  episode_reward_max: 42.4183673469388\n",
+      "  episode_reward_mean: 35.54994369024451\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 8662\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.00481882194678\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00909763171027104\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013866825815057382\n",
+      "        total_loss: 2.7730772693951926\n",
+      "        vf_explained_var: 0.9670748114585876\n",
+      "        vf_loss: 2.785626987616221\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.65416666666667\n",
+      "    gpu_util_percent0: 0.4445833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5083333333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1585845452097359\n",
+      "    mean_env_wait_ms: 0.6539711743603752\n",
+      "    mean_inference_ms: 4.639796008274598\n",
+      "    mean_raw_obs_processing_ms: 0.4215553460221708\n",
+      "  time_since_restore: 124.31111264228821\n",
+      "  time_this_iter_s: 20.05493187904358\n",
+      "  time_total_s: 124.31111264228821\n",
+      "  timers:\n",
+      "    learn_throughput: 11300.348\n",
+      "    learn_time_ms: 14317.435\n",
+      "    sample_throughput: 25694.821\n",
+      "    sample_time_ms: 6296.677\n",
+      "    update_time_ms: 36.949\n",
+      "  timestamp: 1604232428\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      6 |          124.311 | 970752 |  35.5499 |              42.4184 |              10.2755 |            111.301 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1160.6071287908626\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.30445447409733\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 36.22964990548809\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1530\n",
+      "  episodes_total: 10192\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9723203877607981\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008056929800659418\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013902826050374037\n",
+      "        total_loss: 2.177985966205597\n",
+      "        vf_explained_var: 0.9740824103355408\n",
+      "        vf_loss: 2.1907635927200317\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.691999999999997\n",
+      "    gpu_util_percent0: 0.4035999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15747431107692764\n",
+      "    mean_env_wait_ms: 0.652680726552872\n",
+      "    mean_inference_ms: 4.58049716107533\n",
+      "    mean_raw_obs_processing_ms: 0.4181133612914104\n",
+      "  time_since_restore: 144.8035752773285\n",
+      "  time_this_iter_s: 20.492462635040283\n",
+      "  time_total_s: 144.8035752773285\n",
+      "  timers:\n",
+      "    learn_throughput: 11282.551\n",
+      "    learn_time_ms: 14340.019\n",
+      "    sample_throughput: 25937.899\n",
+      "    sample_time_ms: 6237.668\n",
+      "    update_time_ms: 37.177\n",
+      "  timestamp: 1604232448\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      7 |          144.804 | 1132544 |  36.2296 |              42.4184 |              10.2755 |            110.304 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1148.888252883383\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-07-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.45600885784856\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 36.816230060715206\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 11741\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9466134955485662\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007931554379562536\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013606403217030069\n",
+      "        total_loss: 1.6076118151346843\n",
+      "        vf_explained_var: 0.9807720184326172\n",
+      "        vf_loss: 1.6201052069664001\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.764000000000006\n",
+      "    gpu_util_percent0: 0.38\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15654498685345614\n",
+      "    mean_env_wait_ms: 0.6516967139634099\n",
+      "    mean_inference_ms: 4.530832158888852\n",
+      "    mean_raw_obs_processing_ms: 0.4150856418377815\n",
+      "  time_since_restore: 165.37314867973328\n",
+      "  time_this_iter_s: 20.569573402404785\n",
+      "  time_total_s: 165.37314867973328\n",
+      "  timers:\n",
+      "    learn_throughput: 11279.608\n",
+      "    learn_time_ms: 14343.761\n",
+      "    sample_throughput: 26039.205\n",
+      "    sample_time_ms: 6213.4\n",
+      "    update_time_ms: 37.773\n",
+      "  timestamp: 1604232469\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      8 |          165.373 | 1294336 |  36.8162 |              42.4184 |              10.2755 |            109.456 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1139.0165774998115\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.7133839332682\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 37.319474329147006\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1566\n",
+      "  episodes_total: 13307\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9164896359046301\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007841601696175834\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011578070591591919\n",
+      "        total_loss: 1.2525162895520527\n",
+      "        vf_explained_var: 0.985228955745697\n",
+      "        vf_loss: 1.262984275817871\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.692000000000004\n",
+      "    gpu_util_percent0: 0.4428\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15575594110735325\n",
+      "    mean_env_wait_ms: 0.6509075806283173\n",
+      "    mean_inference_ms: 4.488645311807507\n",
+      "    mean_raw_obs_processing_ms: 0.41243497179424105\n",
+      "  time_since_restore: 185.73600935935974\n",
+      "  time_this_iter_s: 20.362860679626465\n",
+      "  time_total_s: 185.73600935935974\n",
+      "  timers:\n",
+      "    learn_throughput: 11283.252\n",
+      "    learn_time_ms: 14339.128\n",
+      "    sample_throughput: 26176.544\n",
+      "    sample_time_ms: 6180.801\n",
+      "    update_time_ms: 37.693\n",
+      "  timestamp: 1604232490\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |      9 |          185.736 | 1456128 |  37.3195 |              42.4184 |              10.2755 |            108.713 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1130.5417816982022\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.05662658695506\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 37.75363452292987\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1580\n",
+      "  episodes_total: 14887\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.879222497344017\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007466738965983192\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010042240721910881\n",
+      "        total_loss: 1.0435242255528767\n",
+      "        vf_explained_var: 0.9878211617469788\n",
+      "        vf_loss: 1.0525127152601879\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.332000000000004\n",
+      "    gpu_util_percent0: 0.3956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15508348116310283\n",
+      "    mean_env_wait_ms: 0.6503758051109494\n",
+      "    mean_inference_ms: 4.452355943495541\n",
+      "    mean_raw_obs_processing_ms: 0.41015056238268827\n",
+      "  time_since_restore: 206.0984218120575\n",
+      "  time_this_iter_s: 20.362412452697754\n",
+      "  time_total_s: 206.0984218120575\n",
+      "  timers:\n",
+      "    learn_throughput: 11288.763\n",
+      "    learn_time_ms: 14332.129\n",
+      "    sample_throughput: 26298.441\n",
+      "    sample_time_ms: 6152.152\n",
+      "    update_time_ms: 42.189\n",
+      "  timestamp: 1604232510\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     10 |          206.098 | 1617920 |  37.7536 |              42.4184 |              10.2755 |            108.057 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1123.1655117918795\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-08-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.44680980106745\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 38.12998569151096\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 16488\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.852480560541153\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006807499914430082\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010430590346610794\n",
+      "        total_loss: 0.7860654095808665\n",
+      "        vf_explained_var: 0.9908618927001953\n",
+      "        vf_loss: 0.7955607374509176\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.468000000000004\n",
+      "    gpu_util_percent0: 0.3796\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15448994642998015\n",
+      "    mean_env_wait_ms: 0.6499845600676837\n",
+      "    mean_inference_ms: 4.420542043950926\n",
+      "    mean_raw_obs_processing_ms: 0.408110786931221\n",
+      "  time_since_restore: 226.6547131538391\n",
+      "  time_this_iter_s: 20.556291341781616\n",
+      "  time_total_s: 226.6547131538391\n",
+      "  timers:\n",
+      "    learn_throughput: 11290.905\n",
+      "    learn_time_ms: 14329.409\n",
+      "    sample_throughput: 27104.621\n",
+      "    sample_time_ms: 5969.167\n",
+      "    update_time_ms: 41.488\n",
+      "  timestamp: 1604232531\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     11 |          226.655 | 1779712 |    38.13 |              42.4184 |              10.2755 |            107.447 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1116.8649711879432\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.92020570670206\n",
+      "  episode_reward_max: 42.41836734693881\n",
+      "  episode_reward_mean: 38.44685289510628\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1596\n",
+      "  episodes_total: 18084\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8233269800742468\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00662518401319782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011712064248664925\n",
+      "        total_loss: 0.6785962084929148\n",
+      "        vf_explained_var: 0.9921655654907227\n",
+      "        vf_loss: 0.6893948912620544\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.354166666666668\n",
+      "    gpu_util_percent0: 0.39875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15396759428958923\n",
+      "    mean_env_wait_ms: 0.6497269679106826\n",
+      "    mean_inference_ms: 4.392758580495196\n",
+      "    mean_raw_obs_processing_ms: 0.4063257369659057\n",
+      "  time_since_restore: 247.07435011863708\n",
+      "  time_this_iter_s: 20.419636964797974\n",
+      "  time_total_s: 247.07435011863708\n",
+      "  timers:\n",
+      "    learn_throughput: 11289.741\n",
+      "    learn_time_ms: 14330.887\n",
+      "    sample_throughput: 27482.894\n",
+      "    sample_time_ms: 5887.007\n",
+      "    update_time_ms: 40.889\n",
+      "  timestamp: 1604232552\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     12 |          247.074 | 1941504 |  38.4469 |              42.4184 |              10.2755 |             106.92 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1111.391848572737\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.44390268677942\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 38.727613885718846\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 19689\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7883199751377106\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006895307102240622\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01035230930817003\n",
+      "        total_loss: 0.501528188586235\n",
+      "        vf_explained_var: 0.9942240118980408\n",
+      "        vf_loss: 0.5108955974380175\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.084\n",
+      "    gpu_util_percent0: 0.40480000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15350402726485754\n",
+      "    mean_env_wait_ms: 0.6495522826808918\n",
+      "    mean_inference_ms: 4.367981018992163\n",
+      "    mean_raw_obs_processing_ms: 0.40472308429202836\n",
+      "  time_since_restore: 267.40077471733093\n",
+      "  time_this_iter_s: 20.326424598693848\n",
+      "  time_total_s: 267.40077471733093\n",
+      "  timers:\n",
+      "    learn_throughput: 11287.514\n",
+      "    learn_time_ms: 14333.714\n",
+      "    sample_throughput: 27563.917\n",
+      "    sample_time_ms: 5869.703\n",
+      "    update_time_ms: 41.691\n",
+      "  timestamp: 1604232573\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     13 |          267.401 | 2103296 |  38.7276 |              42.4184 |              10.2755 |            106.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1106.5129543424084\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-09-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.01774397972116\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 38.97570046184929\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1614\n",
+      "  episodes_total: 21303\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7583291182915369\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006845557557729383\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010322557670103075\n",
+      "        total_loss: 0.39304836342732113\n",
+      "        vf_explained_var: 0.9954751133918762\n",
+      "        vf_loss: 0.40238098055124283\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.124000000000002\n",
+      "    gpu_util_percent0: 0.4536\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15309019602292354\n",
+      "    mean_env_wait_ms: 0.6494461564466915\n",
+      "    mean_inference_ms: 4.34582608361679\n",
+      "    mean_raw_obs_processing_ms: 0.40327786899763196\n",
+      "  time_since_restore: 287.4316370487213\n",
+      "  time_this_iter_s: 20.03086233139038\n",
+      "  time_total_s: 287.4316370487213\n",
+      "  timers:\n",
+      "    learn_throughput: 11292.259\n",
+      "    learn_time_ms: 14327.692\n",
+      "    sample_throughput: 27660.58\n",
+      "    sample_time_ms: 5849.19\n",
+      "    update_time_ms: 42.894\n",
+      "  timestamp: 1604232593\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     14 |          287.432 | 2265088 |  38.9757 |              42.4184 |              10.2755 |            106.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1102.2523617914626\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.64558951965066\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.19350548079495\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 22900\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7275536010662714\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006344522737587492\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01266244207120811\n",
+      "        total_loss: 0.31657364467779797\n",
+      "        vf_explained_var: 0.9963433742523193\n",
+      "        vf_loss: 0.32833095143238705\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.668000000000003\n",
+      "    gpu_util_percent0: 0.4212\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15272256161153888\n",
+      "    mean_env_wait_ms: 0.6493956761565493\n",
+      "    mean_inference_ms: 4.3261627778248455\n",
+      "    mean_raw_obs_processing_ms: 0.40199333508455115\n",
+      "  time_since_restore: 308.00055265426636\n",
+      "  time_this_iter_s: 20.568915605545044\n",
+      "  time_total_s: 308.00055265426636\n",
+      "  timers:\n",
+      "    learn_throughput: 11279.674\n",
+      "    learn_time_ms: 14343.677\n",
+      "    sample_throughput: 27657.34\n",
+      "    sample_time_ms: 5849.876\n",
+      "    update_time_ms: 42.541\n",
+      "  timestamp: 1604232614\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     15 |          308.001 | 2426880 |  39.1935 |              42.4184 |              10.2755 |            105.646 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1098.492356115108\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.31371428571428\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.386209912536444\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1600\n",
+      "  episodes_total: 24500\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6992116371790568\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00605107715819031\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010152409401295396\n",
+      "        total_loss: 0.2749015986919403\n",
+      "        vf_explained_var: 0.9968383312225342\n",
+      "        vf_loss: 0.28419339408477146\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.163999999999998\n",
+      "    gpu_util_percent0: 0.4179999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1523902557025731\n",
+      "    mean_env_wait_ms: 0.6493845108910767\n",
+      "    mean_inference_ms: 4.308344642074162\n",
+      "    mean_raw_obs_processing_ms: 0.4008263717279235\n",
+      "  time_since_restore: 328.0859045982361\n",
+      "  time_this_iter_s: 20.085351943969727\n",
+      "  time_total_s: 328.0859045982361\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.087\n",
+      "    learn_time_ms: 14346.967\n",
+      "    sample_throughput: 27688.425\n",
+      "    sample_time_ms: 5843.308\n",
+      "    update_time_ms: 42.686\n",
+      "  timestamp: 1604232635\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     16 |          328.086 | 2588672 |  39.3862 |              42.4184 |              10.2755 |            105.314 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1095.0764746490756\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-10-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.01325162772883\n",
+      "  episode_reward_max: 42.418367346938815\n",
+      "  episode_reward_mean: 39.561036900397845\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 26110\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6637826611598333\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006695269180151324\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012259619931379953\n",
+      "        total_loss: 0.2071586512029171\n",
+      "        vf_explained_var: 0.9976064562797546\n",
+      "        vf_loss: 0.21841111406683922\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.967999999999996\n",
+      "    gpu_util_percent0: 0.3992\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15208441102089912\n",
+      "    mean_env_wait_ms: 0.649415271515101\n",
+      "    mean_inference_ms: 4.292010650770931\n",
+      "    mean_raw_obs_processing_ms: 0.3997617754479261\n",
+      "  time_since_restore: 348.3640911579132\n",
+      "  time_this_iter_s: 20.278186559677124\n",
+      "  time_total_s: 348.3640911579132\n",
+      "  timers:\n",
+      "    learn_throughput: 11280.385\n",
+      "    learn_time_ms: 14342.773\n",
+      "    sample_throughput: 27802.66\n",
+      "    sample_time_ms: 5819.299\n",
+      "    update_time_ms: 42.587\n",
+      "  timestamp: 1604232655\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     17 |          348.364 | 2750464 |   39.561 |              42.4184 |              10.2755 |            105.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1091.992488262911\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.74269638606363\n",
+      "  episode_reward_max: 42.41836734693882\n",
+      "  episode_reward_mean: 39.71753728541839\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1616\n",
+      "  episodes_total: 27726\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6395211120446523\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005430514691397548\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008808797846237818\n",
+      "        total_loss: 0.18516152476270994\n",
+      "        vf_explained_var: 0.9978885650634766\n",
+      "        vf_loss: 0.19320398072401682\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.428\n",
+      "    gpu_util_percent0: 0.4108\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15180253257231568\n",
+      "    mean_env_wait_ms: 0.6494706645035929\n",
+      "    mean_inference_ms: 4.277042903419588\n",
+      "    mean_raw_obs_processing_ms: 0.3987841767593947\n",
+      "  time_since_restore: 368.70942068099976\n",
+      "  time_this_iter_s: 20.345329523086548\n",
+      "  time_total_s: 368.70942068099976\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.054\n",
+      "    learn_time_ms: 14347.01\n",
+      "    sample_throughput: 27960.312\n",
+      "    sample_time_ms: 5786.488\n",
+      "    update_time_ms: 42.249\n",
+      "  timestamp: 1604232676\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     18 |          368.709 | 2912256 |  39.7175 |              42.4184 |              10.2755 |            104.743 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1089.2314356857796\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.499846693694\n",
+      "  episode_reward_max: 42.41836734693882\n",
+      "  episode_reward_mean: 39.85814856041556\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1627\n",
+      "  episodes_total: 29353\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6059375007947286\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006107187946327031\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009194978279992938\n",
+      "        total_loss: 0.15118268628915152\n",
+      "        vf_explained_var: 0.9982755184173584\n",
+      "        vf_loss: 0.15945919354756674\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.02\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15154050336998873\n",
+      "    mean_env_wait_ms: 0.6495464583308167\n",
+      "    mean_inference_ms: 4.263205291197448\n",
+      "    mean_raw_obs_processing_ms: 0.39787967312168704\n",
+      "  time_since_restore: 389.13511419296265\n",
+      "  time_this_iter_s: 20.42569351196289\n",
+      "  time_total_s: 389.13511419296265\n",
+      "  timers:\n",
+      "    learn_throughput: 11265.913\n",
+      "    learn_time_ms: 14361.197\n",
+      "    sample_throughput: 28034.364\n",
+      "    sample_time_ms: 5771.203\n",
+      "    update_time_ms: 43.0\n",
+      "  timestamp: 1604232697\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     19 |          389.135 | 3074048 |  39.8581 |              42.4184 |              10.2755 |              104.5 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1086.7530964007374\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-11-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.28143673891276\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 39.98449496404396\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1606\n",
+      "  episodes_total: 30959\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5802051573991776\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006146465195342898\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010908293537795544\n",
+      "        total_loss: 0.12315286882221699\n",
+      "        vf_explained_var: 0.9985630512237549\n",
+      "        vf_loss: 0.13312197600801787\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.708000000000002\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130250937481887\n",
+      "    mean_env_wait_ms: 0.649629966463628\n",
+      "    mean_inference_ms: 4.25060756388231\n",
+      "    mean_raw_obs_processing_ms: 0.39705657157981417\n",
+      "  time_since_restore: 409.49588918685913\n",
+      "  time_this_iter_s: 20.360774993896484\n",
+      "  time_total_s: 409.49588918685913\n",
+      "  timers:\n",
+      "    learn_throughput: 11247.919\n",
+      "    learn_time_ms: 14384.172\n",
+      "    sample_throughput: 28152.747\n",
+      "    sample_time_ms: 5746.935\n",
+      "    update_time_ms: 38.327\n",
+      "  timestamp: 1604232718\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     20 |          409.496 | 3235840 |  39.9845 |              42.4184 |              10.2755 |            104.281 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1084.4941429669484\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-12-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.08316697890113\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.09885276551578\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 32561\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5567689687013626\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0057975016146277385\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010689061540081942\n",
+      "        total_loss: 0.10724692543347676\n",
+      "        vf_explained_var: 0.9987431168556213\n",
+      "        vf_loss: 0.11705487407743931\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.752000000000002\n",
+      "    gpu_util_percent0: 0.2972\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15108181784508506\n",
+      "    mean_env_wait_ms: 0.6497188533760437\n",
+      "    mean_inference_ms: 4.2389675381303915\n",
+      "    mean_raw_obs_processing_ms: 0.3962976370894028\n",
+      "  time_since_restore: 429.649621963501\n",
+      "  time_this_iter_s: 20.153732776641846\n",
+      "  time_total_s: 429.649621963501\n",
+      "  timers:\n",
+      "    learn_throughput: 11259.927\n",
+      "    learn_time_ms: 14368.833\n",
+      "    sample_throughput: 28275.485\n",
+      "    sample_time_ms: 5721.988\n",
+      "    update_time_ms: 38.431\n",
+      "  timestamp: 1604232739\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     21 |           429.65 | 3397632 |  40.0989 |              42.4184 |              10.2755 |            104.083 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1082.431136496778\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-12-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.90098314606742\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.20364481818009\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 34176\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5254394511381785\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005307760516492029\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007776977017783793\n",
+      "        total_loss: 0.0964116957038641\n",
+      "        vf_explained_var: 0.9988983273506165\n",
+      "        vf_loss: 0.10338984616100788\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.846153846153847\n",
+      "    gpu_util_percent0: 0.39384615384615385\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15087377501627616\n",
+      "    mean_env_wait_ms: 0.6498094517683312\n",
+      "    mean_inference_ms: 4.22804968427196\n",
+      "    mean_raw_obs_processing_ms: 0.3955819072644963\n",
+      "  time_since_restore: 449.9894530773163\n",
+      "  time_this_iter_s: 20.339831113815308\n",
+      "  time_total_s: 449.9894530773163\n",
+      "  timers:\n",
+      "    learn_throughput: 11271.985\n",
+      "    learn_time_ms: 14353.461\n",
+      "    sample_throughput: 28273.456\n",
+      "    sample_time_ms: 5722.399\n",
+      "    update_time_ms: 39.023\n",
+      "  timestamp: 1604232760\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     22 |          449.989 | 3559424 |  40.2036 |              42.4184 |              10.2755 |            103.901 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1080.5109731890743\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.7305683563748\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.301032520255696\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1629\n",
+      "  episodes_total: 35805\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5021042550603548\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0054971032465497656\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00953363478280759\n",
+      "        total_loss: 0.06499722289542358\n",
+      "        vf_explained_var: 0.9992148876190186\n",
+      "        vf_loss: 0.07368248887360096\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.044\n",
+      "    gpu_util_percent0: 0.4084\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15067991150821478\n",
+      "    mean_env_wait_ms: 0.649905891759336\n",
+      "    mean_inference_ms: 4.2178278275443795\n",
+      "    mean_raw_obs_processing_ms: 0.39491348951426497\n",
+      "  time_since_restore: 470.5632412433624\n",
+      "  time_this_iter_s: 20.573788166046143\n",
+      "  time_total_s: 470.5632412433624\n",
+      "  timers:\n",
+      "    learn_throughput: 11273.798\n",
+      "    learn_time_ms: 14351.154\n",
+      "    sample_throughput: 28167.439\n",
+      "    sample_time_ms: 5743.937\n",
+      "    update_time_ms: 38.419\n",
+      "  timestamp: 1604232781\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     23 |          470.563 | 3721216 |   40.301 |              42.4184 |              10.2755 |            103.731 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1078.7812073715463\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.57635678593378\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.38915989130335\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1618\n",
+      "  episodes_total: 37423\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.47640378028154373\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005069411902998884\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007647299599436034\n",
+      "        total_loss: 0.07074602444966634\n",
+      "        vf_explained_var: 0.9991908073425293\n",
+      "        vf_loss: 0.07761764402190845\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.191999999999997\n",
+      "    gpu_util_percent0: 0.3423999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1505016968490393\n",
+      "    mean_env_wait_ms: 0.6500103427408599\n",
+      "    mean_inference_ms: 4.208361564693216\n",
+      "    mean_raw_obs_processing_ms: 0.39429321916174187\n",
+      "  time_since_restore: 490.8706216812134\n",
+      "  time_this_iter_s: 20.307380437850952\n",
+      "  time_total_s: 490.8706216812134\n",
+      "  timers:\n",
+      "    learn_throughput: 11268.008\n",
+      "    learn_time_ms: 14358.528\n",
+      "    sample_throughput: 28090.142\n",
+      "    sample_time_ms: 5759.743\n",
+      "    update_time_ms: 37.55\n",
+      "  timestamp: 1604232802\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:13:23,494\tWARNING util.py:136 -- The `process_trial` operation took 0.5319008827209473 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     24 |          490.871 | 3883008 |  40.3892 |              42.4184 |              10.2755 |            103.576 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1077.1880225698897\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-13-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.43532516783682\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.4702521709755\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 39026\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4569598063826561\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005172949323120217\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008714882539303895\n",
+      "        total_loss: 0.04905764168749253\n",
+      "        vf_explained_var: 0.999389111995697\n",
+      "        vf_loss: 0.056966414054234825\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.62\n",
+      "    gpu_util_percent0: 0.41119999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15033752613342766\n",
+      "    mean_env_wait_ms: 0.6501147929596541\n",
+      "    mean_inference_ms: 4.199582565004314\n",
+      "    mean_raw_obs_processing_ms: 0.3937192610273736\n",
+      "  time_since_restore: 511.1436126232147\n",
+      "  time_this_iter_s: 20.272990942001343\n",
+      "  time_total_s: 511.1436126232147\n",
+      "  timers:\n",
+      "    learn_throughput: 11277.804\n",
+      "    learn_time_ms: 14346.056\n",
+      "    sample_throughput: 28126.832\n",
+      "    sample_time_ms: 5752.23\n",
+      "    update_time_ms: 37.351\n",
+      "  timestamp: 1604232823\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:13:44,581\tWARNING util.py:136 -- The `process_trial` operation took 0.5550427436828613 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     25 |          511.144 | 4044800 |  40.4703 |              42.4184 |              10.2755 |            103.435 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1075.718860070445\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.30375292235757\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.545045112914124\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1609\n",
+      "  episodes_total: 40635\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4321967264016469\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0049026469544818\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00738874361559283\n",
+      "        total_loss: 0.0522269361341993\n",
+      "        vf_explained_var: 0.9993705749511719\n",
+      "        vf_loss: 0.058851247653365135\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.028000000000002\n",
+      "    gpu_util_percent0: 0.35119999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15018377726680818\n",
+      "    mean_env_wait_ms: 0.650226839982744\n",
+      "    mean_inference_ms: 4.191307577339299\n",
+      "    mean_raw_obs_processing_ms: 0.39318264874410647\n",
+      "  time_since_restore: 531.2994961738586\n",
+      "  time_this_iter_s: 20.15588355064392\n",
+      "  time_total_s: 531.2994961738586\n",
+      "  timers:\n",
+      "    learn_throughput: 11281.716\n",
+      "    learn_time_ms: 14341.08\n",
+      "    sample_throughput: 28095.697\n",
+      "    sample_time_ms: 5758.604\n",
+      "    update_time_ms: 36.136\n",
+      "  timestamp: 1604232844\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:05,496\tWARNING util.py:136 -- The `process_trial` operation took 0.5645184516906738 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     26 |          531.299 | 4206592 |   40.545 |              42.4184 |              10.2755 |            103.304 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1074.3374860851236\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.18162671273399\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.61544301559989\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1622\n",
+      "  episodes_total: 42257\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.41156937927007675\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005988262050474684\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0108474350903028\n",
+      "        total_loss: 0.03666358132613823\n",
+      "        vf_explained_var: 0.9995186924934387\n",
+      "        vf_loss: 0.04711797585090002\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.450000000000003\n",
+      "    gpu_util_percent0: 0.37384615384615383\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15003777931603987\n",
+      "    mean_env_wait_ms: 0.6503388710349208\n",
+      "    mean_inference_ms: 4.1834680864066325\n",
+      "    mean_raw_obs_processing_ms: 0.39267008619808885\n",
+      "  time_since_restore: 551.8160552978516\n",
+      "  time_this_iter_s: 20.51655912399292\n",
+      "  time_total_s: 551.8160552978516\n",
+      "  timers:\n",
+      "    learn_throughput: 11287.466\n",
+      "    learn_time_ms: 14333.775\n",
+      "    sample_throughput: 28001.168\n",
+      "    sample_time_ms: 5778.045\n",
+      "    update_time_ms: 35.1\n",
+      "  timestamp: 1604232866\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:26,878\tWARNING util.py:136 -- The `process_trial` operation took 0.603750467300415 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     27 |          551.816 | 4368384 |  40.6154 |              42.4184 |              10.2755 |            103.182 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1073.064150513113\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-14-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.0678804174452\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.68016949294415\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1629\n",
+      "  episodes_total: 43886\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.38193487375974655\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0054754362208768725\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007502093746249254\n",
+      "        total_loss: 0.052860286086797714\n",
+      "        vf_explained_var: 0.999366819858551\n",
+      "        vf_loss: 0.06000580328206221\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.916000000000004\n",
+      "    gpu_util_percent0: 0.35960000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1498996451948512\n",
+      "    mean_env_wait_ms: 0.6504529892483883\n",
+      "    mean_inference_ms: 4.176045627745146\n",
+      "    mean_raw_obs_processing_ms: 0.3921857888681881\n",
+      "  time_since_restore: 572.0441946983337\n",
+      "  time_this_iter_s: 20.228139400482178\n",
+      "  time_total_s: 572.0441946983337\n",
+      "  timers:\n",
+      "    learn_throughput: 11297.604\n",
+      "    learn_time_ms: 14320.912\n",
+      "    sample_throughput: 28005.61\n",
+      "    sample_time_ms: 5777.128\n",
+      "    update_time_ms: 32.987\n",
+      "  timestamp: 1604232887\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:14:47,924\tWARNING util.py:136 -- The `process_trial` operation took 0.6126041412353516 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     28 |          572.044 | 4530176 |  40.6802 |              42.4184 |              10.2755 |            103.068 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1071.8849808631385\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-15-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.9628774891204\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.74035570973741\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 45498\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3544607609510422\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005010240633661549\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006979774484837738\n",
+      "        total_loss: 0.030745272990316153\n",
+      "        vf_explained_var: 0.999602735042572\n",
+      "        vf_loss: 0.037401253978411354\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.657692307692308\n",
+      "    gpu_util_percent0: 0.32384615384615384\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1497713859875804\n",
+      "    mean_env_wait_ms: 0.650569464769825\n",
+      "    mean_inference_ms: 4.169137947749732\n",
+      "    mean_raw_obs_processing_ms: 0.39173452138746384\n",
+      "  time_since_restore: 592.6739168167114\n",
+      "  time_this_iter_s: 20.629722118377686\n",
+      "  time_total_s: 592.6739168167114\n",
+      "  timers:\n",
+      "    learn_throughput: 11299.681\n",
+      "    learn_time_ms: 14318.28\n",
+      "    sample_throughput: 27922.916\n",
+      "    sample_time_ms: 5794.237\n",
+      "    update_time_ms: 30.389\n",
+      "  timestamp: 1604232908\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:15:09,523\tWARNING util.py:136 -- The `process_trial` operation took 0.6120882034301758 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | RUNNING  | 172.17.0.4:52265 |     29 |          592.674 | 4691968 |  40.7404 |              42.4184 |              10.2755 |            102.963 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_74f1e_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1669\n",
+      "    time_step_mean: 1070.7854881546798\n",
+      "    time_step_min: 1039\n",
+      "  date: 2020-11-01_12-15-29\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.86573533470627\n",
+      "  episode_reward_max: 42.41836734693883\n",
+      "  episode_reward_mean: 40.79621711744931\n",
+      "  episode_reward_min: 10.27551020408163\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 47101\n",
+      "  experiment_id: 230a00995083408db67ee3cc3bc356c5\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3281017740567525\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005293768752987186\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007335715092873822\n",
+      "        total_loss: 0.022672869653130572\n",
+      "        vf_explained_var: 0.9996854662895203\n",
+      "        vf_loss: 0.029643258700768154\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.851999999999997\n",
+      "    gpu_util_percent0: 0.41879999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52265\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1496498957417332\n",
+      "    mean_env_wait_ms: 0.6506846363524779\n",
+      "    mean_inference_ms: 4.162635555621303\n",
+      "    mean_raw_obs_processing_ms: 0.39130720698712607\n",
+      "  time_since_restore: 613.0474860668182\n",
+      "  time_this_iter_s: 20.37356925010681\n",
+      "  time_total_s: 613.0474860668182\n",
+      "  timers:\n",
+      "    learn_throughput: 11310.582\n",
+      "    learn_time_ms: 14304.481\n",
+      "    sample_throughput: 27887.371\n",
+      "    sample_time_ms: 5801.623\n",
+      "    update_time_ms: 30.76\n",
+      "  timestamp: 1604232929\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 74f1e_00000\n",
+      "  \n",
+      "2020-11-01 12:15:30,803\tWARNING util.py:136 -- The `process_trial` operation took 0.6821863651275635 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_74f1e_00000 | TERMINATED |       |     30 |          613.047 | 4853760 |  40.7962 |              42.4184 |              10.2755 |            102.866 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 52047\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_120450-tkx2xsoj/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_120450-tkx2xsoj/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1039\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 641\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604232931\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1669\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1070.78549\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 42.41837\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 10.27551\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 40.79622\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47101\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdecent-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/tkx2xsoj\u001b[0m\n",
+      "2020-11-01 12:15:40,799 - wandb.wandb_agent - INFO - Cleaning up finished run: tkx2xsoj\n",
+      "2020-11-01 12:15:41,119 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:15:41,119 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la13.txt\n",
+      "2020-11-01 12:15:41,121 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la13.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:15:46,139 - wandb.wandb_agent - INFO - Running runs: ['dcx4y6ut']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdaily-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/dcx4y6ut\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_121542-dcx4y6ut\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:15:46,749\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=2614)\u001b[0m 2020-11-01 12:15:49,495\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=2570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2594)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2594)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2511)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2511)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2501)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2501)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2502)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2502)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2504)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2504)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2505)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2505)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2602)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2602)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2577)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2577)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1589\n",
+      "    time_step_mean: 1337.9852140077821\n",
+      "    time_step_min: 1155\n",
+      "  date: 2020-11-01_12-16-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.43149129447389\n",
+      "  episode_reward_max: 47.39175257731958\n",
+      "  episode_reward_mean: 38.01323583352193\n",
+      "  episode_reward_min: 22.08247422680411\n",
+      "  episodes_this_iter: 1321\n",
+      "  episodes_total: 1321\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1485573450724285\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005282467735620837\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007238074458048989\n",
+      "        total_loss: 63.078263918558754\n",
+      "        vf_explained_var: 0.7385819554328918\n",
+      "        vf_loss: 63.0850191116333\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.44814814814815\n",
+      "    gpu_util_percent0: 0.3718518518518519\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4370370370370376\n",
+      "    vram_util_percent0: 0.08366130971903357\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16663877415658362\n",
+      "    mean_env_wait_ms: 0.6660098682308551\n",
+      "    mean_inference_ms: 4.715280418736184\n",
+      "    mean_raw_obs_processing_ms: 0.42943359101439976\n",
+      "  time_since_restore: 21.794464588165283\n",
+      "  time_this_iter_s: 21.794464588165283\n",
+      "  time_total_s: 21.794464588165283\n",
+      "  timers:\n",
+      "    learn_throughput: 11044.835\n",
+      "    learn_time_ms: 14648.658\n",
+      "    sample_throughput: 22922.781\n",
+      "    sample_time_ms: 7058.131\n",
+      "    update_time_ms: 38.538\n",
+      "  timestamp: 1604232976\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      1 |          21.7945 | 161792 |  38.0132 |              47.3918 |              22.0825 |            114.431 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1326.7179115300942\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-16-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.38081603435934\n",
+      "  episode_reward_max: 47.64948453608249\n",
+      "  episode_reward_mean: 38.63342287228155\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1473\n",
+      "  episodes_total: 2794\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1314232647418976\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009286719684799513\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01014851212191085\n",
+      "        total_loss: 10.35303783416748\n",
+      "        vf_explained_var: 0.901028573513031\n",
+      "        vf_loss: 10.361894766489664\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.084615384615383\n",
+      "    gpu_util_percent0: 0.4496153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16450090814338433\n",
+      "    mean_env_wait_ms: 0.6642577249066655\n",
+      "    mean_inference_ms: 4.744188369781305\n",
+      "    mean_raw_obs_processing_ms: 0.42877125861262844\n",
+      "  time_since_restore: 43.1419882774353\n",
+      "  time_this_iter_s: 21.34752368927002\n",
+      "  time_total_s: 43.1419882774353\n",
+      "  timers:\n",
+      "    learn_throughput: 11211.024\n",
+      "    learn_time_ms: 14431.51\n",
+      "    sample_throughput: 23059.328\n",
+      "    sample_time_ms: 7016.336\n",
+      "    update_time_ms: 41.882\n",
+      "  timestamp: 1604232997\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      2 |           43.142 | 323584 |  38.6334 |              47.6495 |              21.2577 |            113.381 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1309.3502958579882\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-16-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.32527575686458\n",
+      "  episode_reward_max: 47.64948453608249\n",
+      "  episode_reward_mean: 39.48478286641973\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1467\n",
+      "  episodes_total: 4261\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1132993400096893\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010391402058303356\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014095689790944258\n",
+      "        total_loss: 6.80802857875824\n",
+      "        vf_explained_var: 0.9351071715354919\n",
+      "        vf_loss: 6.820602655410767\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.832000000000004\n",
+      "    gpu_util_percent0: 0.4172\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16256613873280876\n",
+      "    mean_env_wait_ms: 0.6625184290389695\n",
+      "    mean_inference_ms: 4.69345067144062\n",
+      "    mean_raw_obs_processing_ms: 0.4260658546666288\n",
+      "  time_since_restore: 63.90490484237671\n",
+      "  time_this_iter_s: 20.762916564941406\n",
+      "  time_total_s: 63.90490484237671\n",
+      "  timers:\n",
+      "    learn_throughput: 11227.805\n",
+      "    learn_time_ms: 14409.94\n",
+      "    sample_throughput: 23883.846\n",
+      "    sample_time_ms: 6774.118\n",
+      "    update_time_ms: 41.076\n",
+      "  timestamp: 1604233018\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      3 |          63.9049 | 485376 |  39.4848 |              47.6495 |              21.2577 |            112.325 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1293.2727912706794\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-17-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.25918153200419\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 40.30362789959723\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1457\n",
+      "  episodes_total: 5718\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.084079662958781\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009383795782923698\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013835826587940877\n",
+      "        total_loss: 4.933180093765259\n",
+      "        vf_explained_var: 0.9529300332069397\n",
+      "        vf_loss: 4.94568133354187\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.936\n",
+      "    gpu_util_percent0: 0.4576\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16088212665214047\n",
+      "    mean_env_wait_ms: 0.660815453354488\n",
+      "    mean_inference_ms: 4.632879361030093\n",
+      "    mean_raw_obs_processing_ms: 0.42268288067938126\n",
+      "  time_since_restore: 84.33310127258301\n",
+      "  time_this_iter_s: 20.4281964302063\n",
+      "  time_total_s: 84.33310127258301\n",
+      "  timers:\n",
+      "    learn_throughput: 11238.354\n",
+      "    learn_time_ms: 14396.415\n",
+      "    sample_throughput: 24616.712\n",
+      "    sample_time_ms: 6572.446\n",
+      "    update_time_ms: 38.648\n",
+      "  timestamp: 1604233039\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      4 |          84.3331 | 647168 |  40.3036 |              47.6495 |              21.2577 |            111.259 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1278.2911882694702\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-17-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.2100481761872\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 41.07122129117859\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1547\n",
+      "  episodes_total: 7265\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0668250819047291\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008654051227495074\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015438533756726732\n",
+      "        total_loss: 3.750304361184438\n",
+      "        vf_explained_var: 0.9650198817253113\n",
+      "        vf_loss: 3.764545480410258\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.02\n",
+      "    gpu_util_percent0: 0.3504\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1594046299420155\n",
+      "    mean_env_wait_ms: 0.6591918943938871\n",
+      "    mean_inference_ms: 4.572498944569763\n",
+      "    mean_raw_obs_processing_ms: 0.4190994577823986\n",
+      "  time_since_restore: 104.45204615592957\n",
+      "  time_this_iter_s: 20.118944883346558\n",
+      "  time_total_s: 104.45204615592957\n",
+      "  timers:\n",
+      "    learn_throughput: 11259.021\n",
+      "    learn_time_ms: 14369.989\n",
+      "    sample_throughput: 25254.408\n",
+      "    sample_time_ms: 6406.486\n",
+      "    update_time_ms: 37.632\n",
+      "  timestamp: 1604233059\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      5 |          104.452 | 808960 |  41.0712 |              47.6495 |              21.2577 |             110.21 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1266.0983158852982\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.32014959202176\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 41.69816035928256\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 8824\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.034409632285436\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008218800959487757\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015976834343746305\n",
+      "        total_loss: 3.275542378425598\n",
+      "        vf_explained_var: 0.9698309898376465\n",
+      "        vf_loss: 3.2903926372528076\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.4375\n",
+      "    gpu_util_percent0: 0.43624999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5208333333333335\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15817094139921792\n",
+      "    mean_env_wait_ms: 0.6579144407066476\n",
+      "    mean_inference_ms: 4.520312188626085\n",
+      "    mean_raw_obs_processing_ms: 0.41585575516420453\n",
+      "  time_since_restore: 124.74504113197327\n",
+      "  time_this_iter_s: 20.2929949760437\n",
+      "  time_total_s: 124.74504113197327\n",
+      "  timers:\n",
+      "    learn_throughput: 11268.321\n",
+      "    learn_time_ms: 14358.128\n",
+      "    sample_throughput: 25609.299\n",
+      "    sample_time_ms: 6317.705\n",
+      "    update_time_ms: 37.615\n",
+      "  timestamp: 1604233080\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      6 |          124.745 | 970752 |  41.6982 |              47.6495 |              21.2577 |             109.32 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1255.5475730032877\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.51175563692426\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 42.23890644960692\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1554\n",
+      "  episodes_total: 10378\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9993852277596792\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008948890104268989\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011871834401972592\n",
+      "        total_loss: 2.572846511999766\n",
+      "        vf_explained_var: 0.9761440753936768\n",
+      "        vf_loss: 2.5834282437960305\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.36\n",
+      "    gpu_util_percent0: 0.3956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5120000000000005\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15713379589800733\n",
+      "    mean_env_wait_ms: 0.6568649191044983\n",
+      "    mean_inference_ms: 4.475812919755018\n",
+      "    mean_raw_obs_processing_ms: 0.4129610571474045\n",
+      "  time_since_restore: 144.9028398990631\n",
+      "  time_this_iter_s: 20.157798767089844\n",
+      "  time_total_s: 144.9028398990631\n",
+      "  timers:\n",
+      "    learn_throughput: 11276.333\n",
+      "    learn_time_ms: 14347.927\n",
+      "    sample_throughput: 25944.994\n",
+      "    sample_time_ms: 6235.962\n",
+      "    update_time_ms: 37.126\n",
+      "  timestamp: 1604233100\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      7 |          144.903 | 1132544 |  42.2389 |              47.6495 |              21.2577 |            108.512 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1246.681210592686\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-18-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.82323359316068\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 42.700832190594205\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1553\n",
+      "  episodes_total: 11931\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9713874608278275\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00811462321629127\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013652926543727517\n",
+      "        total_loss: 2.0792956252892814\n",
+      "        vf_explained_var: 0.9808939099311829\n",
+      "        vf_loss: 2.0918113390604653\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.708000000000002\n",
+      "    gpu_util_percent0: 0.412\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.52\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15626045608420333\n",
+      "    mean_env_wait_ms: 0.6560445478078366\n",
+      "    mean_inference_ms: 4.437668893602004\n",
+      "    mean_raw_obs_processing_ms: 0.41044660220855933\n",
+      "  time_since_restore: 165.08657550811768\n",
+      "  time_this_iter_s: 20.183735609054565\n",
+      "  time_total_s: 165.08657550811768\n",
+      "  timers:\n",
+      "    learn_throughput: 11297.099\n",
+      "    learn_time_ms: 14321.553\n",
+      "    sample_throughput: 26119.381\n",
+      "    sample_time_ms: 6194.327\n",
+      "    update_time_ms: 35.89\n",
+      "  timestamp: 1604233121\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      8 |          165.087 | 1294336 |  42.7008 |              47.6495 |              21.2577 |            107.823 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1238.4053151213718\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.21781298585918\n",
+      "  episode_reward_max: 47.649484536082525\n",
+      "  episode_reward_mean: 43.115104119360794\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1576\n",
+      "  episodes_total: 13507\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9416759212811788\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0077835753715286655\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013627580524674462\n",
+      "        total_loss: 1.650565932194392\n",
+      "        vf_explained_var: 0.9848251938819885\n",
+      "        vf_loss: 1.663107653458913\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.308000000000003\n",
+      "    gpu_util_percent0: 0.392\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15550241078926047\n",
+      "    mean_env_wait_ms: 0.6554019389170324\n",
+      "    mean_inference_ms: 4.404255773765493\n",
+      "    mean_raw_obs_processing_ms: 0.40821271351444455\n",
+      "  time_since_restore: 185.5122389793396\n",
+      "  time_this_iter_s: 20.425663471221924\n",
+      "  time_total_s: 185.5122389793396\n",
+      "  timers:\n",
+      "    learn_throughput: 11288.215\n",
+      "    learn_time_ms: 14332.825\n",
+      "    sample_throughput: 26270.178\n",
+      "    sample_time_ms: 6158.771\n",
+      "    update_time_ms: 34.616\n",
+      "  timestamp: 1604233141\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |      9 |          185.512 | 1456128 |  43.1151 |              47.6495 |              21.2577 |            107.218 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1231.2265303412562\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.66975758378594\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 43.48257774293858\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 15098\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9080682247877121\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007657797929520409\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010565590860399729\n",
+      "        total_loss: 1.296636829773585\n",
+      "        vf_explained_var: 0.988224446773529\n",
+      "        vf_loss: 1.3061249554157257\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.03333333333333\n",
+      "    gpu_util_percent0: 0.4579166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15484288964237733\n",
+      "    mean_env_wait_ms: 0.6549145589836158\n",
+      "    mean_inference_ms: 4.3750244337617135\n",
+      "    mean_raw_obs_processing_ms: 0.4062248434702486\n",
+      "  time_since_restore: 205.5452425479889\n",
+      "  time_this_iter_s: 20.033003568649292\n",
+      "  time_total_s: 205.5452425479889\n",
+      "  timers:\n",
+      "    learn_throughput: 11294.037\n",
+      "    learn_time_ms: 14325.435\n",
+      "    sample_throughput: 26494.427\n",
+      "    sample_time_ms: 6106.643\n",
+      "    update_time_ms: 33.514\n",
+      "  timestamp: 1604233162\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     10 |          205.545 | 1617920 |  43.4826 |              47.6495 |              21.2577 |             106.67 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1224.8779111644658\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-19-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.19435793004313\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 43.804279931238554\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 16696\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8727221091588339\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007556108757853508\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012766734405886382\n",
+      "        total_loss: 1.0635682841142018\n",
+      "        vf_explained_var: 0.9903334975242615\n",
+      "        vf_loss: 1.0752601623535156\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.6375\n",
+      "    gpu_util_percent0: 0.4445833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1542607271772269\n",
+      "    mean_env_wait_ms: 0.6545202251025621\n",
+      "    mean_inference_ms: 4.349215320409436\n",
+      "    mean_raw_obs_processing_ms: 0.4044561449167446\n",
+      "  time_since_restore: 225.5202054977417\n",
+      "  time_this_iter_s: 19.974962949752808\n",
+      "  time_total_s: 225.5202054977417\n",
+      "  timers:\n",
+      "    learn_throughput: 11330.871\n",
+      "    learn_time_ms: 14278.867\n",
+      "    sample_throughput: 27121.909\n",
+      "    sample_time_ms: 5965.362\n",
+      "    update_time_ms: 33.265\n",
+      "  timestamp: 1604233182\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     11 |           225.52 | 1779712 |  43.8043 |              47.6495 |              21.2577 |            106.194 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1219.3561336254106\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.77831219938784\n",
+      "  episode_reward_max: 47.64948453608253\n",
+      "  episode_reward_mean: 44.08295937594382\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1600\n",
+      "  episodes_total: 18296\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8348831733067831\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007376410067081451\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009320069143238166\n",
+      "        total_loss: 0.8637631287177404\n",
+      "        vf_explained_var: 0.99216228723526\n",
+      "        vf_loss: 0.8720253507296244\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.623999999999995\n",
+      "    gpu_util_percent0: 0.364\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15375450185882147\n",
+      "    mean_env_wait_ms: 0.6542416074847509\n",
+      "    mean_inference_ms: 4.326388244632185\n",
+      "    mean_raw_obs_processing_ms: 0.4028915881034749\n",
+      "  time_since_restore: 245.75802636146545\n",
+      "  time_this_iter_s: 20.237820863723755\n",
+      "  time_total_s: 245.75802636146545\n",
+      "  timers:\n",
+      "    learn_throughput: 11325.614\n",
+      "    learn_time_ms: 14285.495\n",
+      "    sample_throughput: 27660.054\n",
+      "    sample_time_ms: 5849.302\n",
+      "    update_time_ms: 30.809\n",
+      "  timestamp: 1604233202\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     12 |          245.758 | 1941504 |   44.083 |              47.6495 |              21.2577 |            105.778 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1214.5580739397603\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.4173956762192\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.32935526840925\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1594\n",
+      "  episodes_total: 19890\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7998430083195368\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006828729490128656\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011044965135321641\n",
+      "        total_loss: 0.67805515229702\n",
+      "        vf_explained_var: 0.9938119053840637\n",
+      "        vf_loss: 0.6881343126296997\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.831999999999997\n",
+      "    gpu_util_percent0: 0.43200000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.153302992513867\n",
+      "    mean_env_wait_ms: 0.6540089232561519\n",
+      "    mean_inference_ms: 4.306101213317678\n",
+      "    mean_raw_obs_processing_ms: 0.40148742506884494\n",
+      "  time_since_restore: 266.1050407886505\n",
+      "  time_this_iter_s: 20.34701442718506\n",
+      "  time_total_s: 266.1050407886505\n",
+      "  timers:\n",
+      "    learn_throughput: 11312.078\n",
+      "    learn_time_ms: 14302.589\n",
+      "    sample_throughput: 27960.684\n",
+      "    sample_time_ms: 5786.411\n",
+      "    update_time_ms: 28.901\n",
+      "  timestamp: 1604233223\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     13 |          266.105 | 2103296 |  44.3294 |              47.6495 |              21.2577 |            105.417 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1210.317556539986\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-20-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.1013919277501\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.54546357677872\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 21481\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7677376766999563\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00645853765308857\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009221890567763088\n",
+      "        total_loss: 0.5704321513573328\n",
+      "        vf_explained_var: 0.9948087334632874\n",
+      "        vf_loss: 0.5787462194760641\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.299999999999997\n",
+      "    gpu_util_percent0: 0.3692\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15289862610010913\n",
+      "    mean_env_wait_ms: 0.6538353499990455\n",
+      "    mean_inference_ms: 4.287840220794161\n",
+      "    mean_raw_obs_processing_ms: 0.40022401934261076\n",
+      "  time_since_restore: 286.03195905685425\n",
+      "  time_this_iter_s: 19.926918268203735\n",
+      "  time_total_s: 286.03195905685425\n",
+      "  timers:\n",
+      "    learn_throughput: 11326.239\n",
+      "    learn_time_ms: 14284.707\n",
+      "    sample_throughput: 28153.263\n",
+      "    sample_time_ms: 5746.83\n",
+      "    update_time_ms: 28.453\n",
+      "  timestamp: 1604233243\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     14 |          286.032 | 2265088 |  44.5455 |              47.6495 |              21.2577 |            105.101 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1206.554523354749\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.81341019417475\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.73924255043826\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1591\n",
+      "  episodes_total: 23072\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.733478844165802\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00630180553222696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01086452438418443\n",
+      "        total_loss: 0.44883622725804645\n",
+      "        vf_explained_var: 0.9958701133728027\n",
+      "        vf_loss: 0.4588071381052335\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.691666666666666\n",
+      "    gpu_util_percent0: 0.42\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1525331053770261\n",
+      "    mean_env_wait_ms: 0.6537007767835614\n",
+      "    mean_inference_ms: 4.271271460769205\n",
+      "    mean_raw_obs_processing_ms: 0.39907289277823804\n",
+      "  time_since_restore: 306.18409848213196\n",
+      "  time_this_iter_s: 20.15213942527771\n",
+      "  time_total_s: 306.18409848213196\n",
+      "  timers:\n",
+      "    learn_throughput: 11336.437\n",
+      "    learn_time_ms: 14271.856\n",
+      "    sample_throughput: 28161.1\n",
+      "    sample_time_ms: 5745.23\n",
+      "    update_time_ms: 27.237\n",
+      "  timestamp: 1604233264\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     15 |          306.184 | 2426880 |  44.7392 |              47.6495 |              21.2577 |            104.813 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1203.1918253034055\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.54650832894256\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 44.91062311529655\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 24673\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7046740502119064\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00598089622023205\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010109954212869829\n",
+      "        total_loss: 0.3878796820839246\n",
+      "        vf_explained_var: 0.9964661002159119\n",
+      "        vf_loss: 0.39714578290780383\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.084\n",
+      "    gpu_util_percent0: 0.4572\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15220062387999952\n",
+      "    mean_env_wait_ms: 0.653596423305203\n",
+      "    mean_inference_ms: 4.256089606710892\n",
+      "    mean_raw_obs_processing_ms: 0.3980153671992771\n",
+      "  time_since_restore: 326.27552032470703\n",
+      "  time_this_iter_s: 20.091421842575073\n",
+      "  time_total_s: 326.27552032470703\n",
+      "  timers:\n",
+      "    learn_throughput: 11333.689\n",
+      "    learn_time_ms: 14275.316\n",
+      "    sample_throughput: 28301.321\n",
+      "    sample_time_ms: 5716.765\n",
+      "    update_time_ms: 25.405\n",
+      "  timestamp: 1604233285\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     16 |          326.276 | 2588672 |  44.9106 |              47.6495 |              21.2577 |            104.547 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1200.1823688521467\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-21-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.30184515883583\n",
+      "  episode_reward_max: 47.64948453608254\n",
+      "  episode_reward_mean: 45.06611508661011\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 26285\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6727208147446314\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0061663844001789885\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00950972737094465\n",
+      "        total_loss: 0.2949073016643524\n",
+      "        vf_explained_var: 0.9973233342170715\n",
+      "        vf_loss: 0.3035201082626979\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.068\n",
+      "    gpu_util_percent0: 0.38800000000000007\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15189563586672175\n",
+      "    mean_env_wait_ms: 0.653528700746639\n",
+      "    mean_inference_ms: 4.242058406187237\n",
+      "    mean_raw_obs_processing_ms: 0.3970431055250104\n",
+      "  time_since_restore: 346.44066858291626\n",
+      "  time_this_iter_s: 20.16514825820923\n",
+      "  time_total_s: 346.44066858291626\n",
+      "  timers:\n",
+      "    learn_throughput: 11331.786\n",
+      "    learn_time_ms: 14277.714\n",
+      "    sample_throughput: 28373.21\n",
+      "    sample_time_ms: 5702.28\n",
+      "    update_time_ms: 26.064\n",
+      "  timestamp: 1604233305\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     17 |          346.441 | 2750464 |  45.0661 |              47.6495 |              21.2577 |            104.302 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1197.4265528618562\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.07865329512894\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.20858749593833\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1635\n",
+      "  episodes_total: 27920\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6462279756863912\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005753972722838323\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01063174061710015\n",
+      "        total_loss: 0.2318790778517723\n",
+      "        vf_explained_var: 0.997880220413208\n",
+      "        vf_loss: 0.2416831391553084\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.45416666666667\n",
+      "    gpu_util_percent0: 0.44875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5749999999999997\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1516142332871325\n",
+      "    mean_env_wait_ms: 0.6534803822249593\n",
+      "    mean_inference_ms: 4.229062941307127\n",
+      "    mean_raw_obs_processing_ms: 0.3961363429731068\n",
+      "  time_since_restore: 366.4673285484314\n",
+      "  time_this_iter_s: 20.026659965515137\n",
+      "  time_total_s: 366.4673285484314\n",
+      "  timers:\n",
+      "    learn_throughput: 11321.995\n",
+      "    learn_time_ms: 14290.061\n",
+      "    sample_throughput: 28529.416\n",
+      "    sample_time_ms: 5671.059\n",
+      "    update_time_ms: 25.131\n",
+      "  timestamp: 1604233326\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     18 |          366.467 | 2912256 |  45.2086 |              47.6495 |              21.2577 |            104.079 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1194.9799281209737\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.87829326109042\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.33514231552049\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1610\n",
+      "  episodes_total: 29530\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6139073818922043\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005659738904796541\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009704548533287985\n",
+      "        total_loss: 0.19860607013106346\n",
+      "        vf_explained_var: 0.9981780648231506\n",
+      "        vf_loss: 0.20748562117417654\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.747999999999998\n",
+      "    gpu_util_percent0: 0.39640000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15135749897686426\n",
+      "    mean_env_wait_ms: 0.6534384087466466\n",
+      "    mean_inference_ms: 4.217280786349381\n",
+      "    mean_raw_obs_processing_ms: 0.3953083892816526\n",
+      "  time_since_restore: 386.6138005256653\n",
+      "  time_this_iter_s: 20.146471977233887\n",
+      "  time_total_s: 386.6138005256653\n",
+      "  timers:\n",
+      "    learn_throughput: 11328.703\n",
+      "    learn_time_ms: 14281.599\n",
+      "    sample_throughput: 28668.019\n",
+      "    sample_time_ms: 5643.641\n",
+      "    update_time_ms: 26.007\n",
+      "  timestamp: 1604233347\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     19 |          386.614 | 3074048 |  45.3351 |              47.6495 |              21.2577 |            103.878 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1192.755491943006\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-22-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.69467022199376\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.44938246008456\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 31127\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5885171492894491\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00575300360408922\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008459999109618366\n",
+      "        total_loss: 0.1491255114475886\n",
+      "        vf_explained_var: 0.9986266493797302\n",
+      "        vf_loss: 0.15672916546463966\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.32\n",
+      "    gpu_util_percent0: 0.33520000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15111988887105687\n",
+      "    mean_env_wait_ms: 0.6534000992030266\n",
+      "    mean_inference_ms: 4.206433415272165\n",
+      "    mean_raw_obs_processing_ms: 0.39454176059647716\n",
+      "  time_since_restore: 406.58024430274963\n",
+      "  time_this_iter_s: 19.96644377708435\n",
+      "  time_total_s: 406.58024430274963\n",
+      "  timers:\n",
+      "    learn_throughput: 11334.136\n",
+      "    learn_time_ms: 14274.754\n",
+      "    sample_throughput: 28704.988\n",
+      "    sample_time_ms: 5636.372\n",
+      "    update_time_ms: 26.077\n",
+      "  timestamp: 1604233367\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     20 |           406.58 | 3235840 |  45.4494 |              47.6495 |              21.2577 |            103.695 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1190.7317714705164\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.52679335207137\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.553595837989505\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 32732\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5605561385552088\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0051246628087634844\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00707746635695609\n",
+      "        total_loss: 0.12786801221470037\n",
+      "        vf_explained_var: 0.9988241195678711\n",
+      "        vf_loss: 0.13420082504550615\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.108\n",
+      "    gpu_util_percent0: 0.36239999999999994\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1508982454274576\n",
+      "    mean_env_wait_ms: 0.6533685645927871\n",
+      "    mean_inference_ms: 4.196348243483211\n",
+      "    mean_raw_obs_processing_ms: 0.393820825357919\n",
+      "  time_since_restore: 426.77583384513855\n",
+      "  time_this_iter_s: 20.195589542388916\n",
+      "  time_total_s: 426.77583384513855\n",
+      "  timers:\n",
+      "    learn_throughput: 11330.776\n",
+      "    learn_time_ms: 14278.986\n",
+      "    sample_throughput: 28644.617\n",
+      "    sample_time_ms: 5648.251\n",
+      "    update_time_ms: 25.717\n",
+      "  timestamp: 1604233388\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     21 |          426.776 | 3397632 |  45.5536 |              47.6495 |              21.2577 |            103.527 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1188.871339064549\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.37087712148119\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.649092584828495\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 34351\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5297549913326899\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005221013678237796\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007347211508507219\n",
+      "        total_loss: 0.11089812219142914\n",
+      "        vf_explained_var: 0.9989762306213379\n",
+      "        vf_loss: 0.11746600580712159\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.358333333333334\n",
+      "    gpu_util_percent0: 0.4533333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15069056354724808\n",
+      "    mean_env_wait_ms: 0.6533427688463339\n",
+      "    mean_inference_ms: 4.1868632869880145\n",
+      "    mean_raw_obs_processing_ms: 0.3931430489205958\n",
+      "  time_since_restore: 447.03629064559937\n",
+      "  time_this_iter_s: 20.260456800460815\n",
+      "  time_total_s: 447.03629064559937\n",
+      "  timers:\n",
+      "    learn_throughput: 11328.702\n",
+      "    learn_time_ms: 14281.601\n",
+      "    sample_throughput: 28676.086\n",
+      "    sample_time_ms: 5642.053\n",
+      "    update_time_ms: 25.502\n",
+      "  timestamp: 1604233409\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     22 |          447.036 | 3559424 |  45.6491 |              47.6495 |              21.2577 |            103.371 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1187.1485870048955\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-23-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.22507502500834\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.737731878552886\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1637\n",
+      "  episodes_total: 35988\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5043502772847811\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0051153005721668405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007804131872641544\n",
+      "        total_loss: 0.08389338354269664\n",
+      "        vf_explained_var: 0.9992172718048096\n",
+      "        vf_loss: 0.09092663104335467\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.10769230769231\n",
+      "    gpu_util_percent0: 0.4111538461538462\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1504958593946037\n",
+      "    mean_env_wait_ms: 0.6533264567796601\n",
+      "    mean_inference_ms: 4.177979473432433\n",
+      "    mean_raw_obs_processing_ms: 0.39250620871910297\n",
+      "  time_since_restore: 467.43437933921814\n",
+      "  time_this_iter_s: 20.398088693618774\n",
+      "  time_total_s: 467.43437933921814\n",
+      "  timers:\n",
+      "    learn_throughput: 11352.718\n",
+      "    learn_time_ms: 14251.389\n",
+      "    sample_throughput: 28591.581\n",
+      "    sample_time_ms: 5658.729\n",
+      "    update_time_ms: 26.115\n",
+      "  timestamp: 1604233430\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     23 |          467.434 | 3721216 |  45.7377 |              47.6495 |              21.2577 |            103.225 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1185.5975664953805\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.0935496741588\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.817267047191805\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1607\n",
+      "  episodes_total: 37595\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.477857805788517\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005301223369315267\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007187186017593679\n",
+      "        total_loss: 0.0712860906496644\n",
+      "        vf_explained_var: 0.9993272423744202\n",
+      "        vf_loss: 0.07765195891261101\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.808000000000003\n",
+      "    gpu_util_percent0: 0.41159999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1503165502098337\n",
+      "    mean_env_wait_ms: 0.6533168664023659\n",
+      "    mean_inference_ms: 4.1697739229427855\n",
+      "    mean_raw_obs_processing_ms: 0.39192023267055776\n",
+      "  time_since_restore: 487.5962927341461\n",
+      "  time_this_iter_s: 20.16191339492798\n",
+      "  time_total_s: 487.5962927341461\n",
+      "  timers:\n",
+      "    learn_throughput: 11345.276\n",
+      "    learn_time_ms: 14260.737\n",
+      "    sample_throughput: 28572.718\n",
+      "    sample_time_ms: 5662.465\n",
+      "    update_time_ms: 25.82\n",
+      "  timestamp: 1604233451\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     24 |          487.596 | 3883008 |  45.8173 |              47.6495 |              21.2577 |            103.094 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1184.1811960574025\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.9715546711567\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.8903373462669\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 39198\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4582882300019264\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004777276888489723\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006818818922814292\n",
+      "        total_loss: 0.06491830727706353\n",
+      "        vf_explained_var: 0.9993811249732971\n",
+      "        vf_loss: 0.07101081249614556\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.5\n",
+      "    gpu_util_percent0: 0.4164\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15014800244823473\n",
+      "    mean_env_wait_ms: 0.6533117275008512\n",
+      "    mean_inference_ms: 4.162086682670796\n",
+      "    mean_raw_obs_processing_ms: 0.3913710326970964\n",
+      "  time_since_restore: 507.939138174057\n",
+      "  time_this_iter_s: 20.34284543991089\n",
+      "  time_total_s: 507.939138174057\n",
+      "  timers:\n",
+      "    learn_throughput: 11324.044\n",
+      "    learn_time_ms: 14287.476\n",
+      "    sample_throughput: 28578.2\n",
+      "    sample_time_ms: 5661.378\n",
+      "    update_time_ms: 26.054\n",
+      "  timestamp: 1604233472\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:24:33,109\tWARNING util.py:136 -- The `process_trial` operation took 0.5145235061645508 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     25 |          507.939 | 4044800 |  45.8903 |              47.6495 |              21.2577 |            102.972 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1182.8508853681267\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-24-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.8577064444989\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 45.95893087655392\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1612\n",
+      "  episodes_total: 40810\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4304437041282654\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005302870219262938\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005320634130233278\n",
+      "        total_loss: 0.04602197107548515\n",
+      "        vf_explained_var: 0.9995622038841248\n",
+      "        vf_loss: 0.05102753918617964\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.031999999999996\n",
+      "    gpu_util_percent0: 0.4016\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14998848423358552\n",
+      "    mean_env_wait_ms: 0.6533120076712385\n",
+      "    mean_inference_ms: 4.154808738528033\n",
+      "    mean_raw_obs_processing_ms: 0.39085074710802764\n",
+      "  time_since_restore: 528.287171125412\n",
+      "  time_this_iter_s: 20.34803295135498\n",
+      "  time_total_s: 528.287171125412\n",
+      "  timers:\n",
+      "    learn_throughput: 11314.942\n",
+      "    learn_time_ms: 14298.969\n",
+      "    sample_throughput: 28539.444\n",
+      "    sample_time_ms: 5669.066\n",
+      "    update_time_ms: 26.44\n",
+      "  timestamp: 1604233493\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:24:54,161\tWARNING util.py:136 -- The `process_trial` operation took 0.5190365314483643 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     26 |          528.287 | 4206592 |  45.9589 |              47.6495 |              21.2577 |            102.858 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1181.6014053620693\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.75047708799623\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.02298669108478\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1635\n",
+      "  episodes_total: 42445\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.40619519104560214\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004850935540162027\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00712713325143947\n",
+      "        total_loss: 0.04109010814378659\n",
+      "        vf_explained_var: 0.9995940327644348\n",
+      "        vf_loss: 0.047935244316856064\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.9\n",
+      "    gpu_util_percent0: 0.4608\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14983678273441456\n",
+      "    mean_env_wait_ms: 0.6533202946066505\n",
+      "    mean_inference_ms: 4.147883359756837\n",
+      "    mean_raw_obs_processing_ms: 0.3903567513935103\n",
+      "  time_since_restore: 548.3913764953613\n",
+      "  time_this_iter_s: 20.10420536994934\n",
+      "  time_total_s: 548.3913764953613\n",
+      "  timers:\n",
+      "    learn_throughput: 11320.7\n",
+      "    learn_time_ms: 14291.696\n",
+      "    sample_throughput: 28538.222\n",
+      "    sample_time_ms: 5669.309\n",
+      "    update_time_ms: 25.152\n",
+      "  timestamp: 1604233514\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:14,990\tWARNING util.py:136 -- The `process_trial` operation took 0.5334711074829102 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     27 |          548.391 | 4368384 |   46.023 |              47.6495 |              21.2577 |             102.75 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1180.4515455020326\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.6508271495677\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.08214646909499\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1622\n",
+      "  episodes_total: 44067\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.380776509642601\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005104163157132764\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008030562166823074\n",
+      "        total_loss: 0.03263539479424556\n",
+      "        vf_explained_var: 0.9996626377105713\n",
+      "        vf_loss: 0.0406011367837588\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.724\n",
+      "    gpu_util_percent0: 0.3708000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14969387594042302\n",
+      "    mean_env_wait_ms: 0.6533341674809083\n",
+      "    mean_inference_ms: 4.141387554786562\n",
+      "    mean_raw_obs_processing_ms: 0.3898925942202909\n",
+      "  time_since_restore: 568.5405015945435\n",
+      "  time_this_iter_s: 20.14912509918213\n",
+      "  time_total_s: 568.5405015945435\n",
+      "  timers:\n",
+      "    learn_throughput: 11317.578\n",
+      "    learn_time_ms: 14295.638\n",
+      "    sample_throughput: 28540.327\n",
+      "    sample_time_ms: 5668.891\n",
+      "    update_time_ms: 27.131\n",
+      "  timestamp: 1604233535\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:35,895\tWARNING util.py:136 -- The `process_trial` operation took 0.5552034378051758 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     28 |          568.541 | 4530176 |  46.0821 |              47.6495 |              21.2577 |            102.651 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1179.389183503528\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-25-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 102.55971097000219\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.136667351393584\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1603\n",
+      "  episodes_total: 45670\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3589545438687007\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005236083525232971\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005505533023097087\n",
+      "        total_loss: 0.02439635860112806\n",
+      "        vf_explained_var: 0.9997479915618896\n",
+      "        vf_loss: 0.029819565049062174\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.04\n",
+      "    gpu_util_percent0: 0.3832\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14955992403902243\n",
+      "    mean_env_wait_ms: 0.65334881821503\n",
+      "    mean_inference_ms: 4.135306265563136\n",
+      "    mean_raw_obs_processing_ms: 0.3894575857046042\n",
+      "  time_since_restore: 588.7653107643127\n",
+      "  time_this_iter_s: 20.224809169769287\n",
+      "  time_total_s: 588.7653107643127\n",
+      "  timers:\n",
+      "    learn_throughput: 11315.541\n",
+      "    learn_time_ms: 14298.212\n",
+      "    sample_throughput: 28543.882\n",
+      "    sample_time_ms: 5668.185\n",
+      "    update_time_ms: 27.394\n",
+      "  timestamp: 1604233556\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:25:56,904\tWARNING util.py:136 -- The `process_trial` operation took 0.5792350769042969 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | RUNNING  | 172.17.0.4:2614 |     29 |          588.765 | 4691968 |  46.1367 |              47.6495 |              21.2577 |             102.56 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f98d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1662\n",
+      "    time_step_mean: 1178.4016808145811\n",
+      "    time_step_min: 1150\n",
+      "  date: 2020-11-01_12-26-17\n",
+      "  done: true\n",
+      "  episode_len_mean: 102.47428873611845\n",
+      "  episode_reward_max: 47.64948453608255\n",
+      "  episode_reward_mean: 46.187587432602626\n",
+      "  episode_reward_min: 21.25773195876288\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 47275\n",
+      "  experiment_id: 4f772b2988194f3c8d0ee5aa58be90b8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.34163280328114826\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005014610709622502\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006093008596508298\n",
+      "        total_loss: 0.02250015801594903\n",
+      "        vf_explained_var: 0.9997627139091492\n",
+      "        vf_loss: 0.028513251959035795\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.592000000000002\n",
+      "    gpu_util_percent0: 0.4032\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2614\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14943275367352743\n",
+      "    mean_env_wait_ms: 0.6533656820836667\n",
+      "    mean_inference_ms: 4.129545135974801\n",
+      "    mean_raw_obs_processing_ms: 0.38904409500028486\n",
+      "  time_since_restore: 608.9674067497253\n",
+      "  time_this_iter_s: 20.202095985412598\n",
+      "  time_total_s: 608.9674067497253\n",
+      "  timers:\n",
+      "    learn_throughput: 11308.582\n",
+      "    learn_time_ms: 14307.01\n",
+      "    sample_throughput: 28493.852\n",
+      "    sample_time_ms: 5678.137\n",
+      "    update_time_ms: 27.445\n",
+      "  timestamp: 1604233577\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: f98d0_00000\n",
+      "  \n",
+      "2020-11-01 12:26:18,072\tWARNING util.py:136 -- The `process_trial` operation took 0.6780698299407959 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f98d0_00000 | TERMINATED |       |     30 |          608.967 | 4853760 |  46.1876 |              47.6495 |              21.2577 |            102.474 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 2387\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201013_114553-3qwfavbb/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201013_114553-3qwfavbb/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_121542-dcx4y6ut/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_121542-dcx4y6ut/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 4473\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 261.82891\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 280.71717\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     time_step_min 3203\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 607\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602590160\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1150\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 636\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604233578\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1662\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1178.40168\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 47.64948\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 21.25773\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 46.18759\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 47275\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mrandom\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3qwfavbb\u001b[0m\n",
-      "2020-10-13 11:56:07,517 - wandb.wandb_agent - INFO - Cleaning up finished run: 3qwfavbb\n",
-      "2020-10-13 11:56:07,847 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 11:56:07,847 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-13 11:56:07,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python RandomGreedy.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdaily-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/dcx4y6ut\u001b[0m\n",
+      "2020-11-01 12:26:27,483 - wandb.wandb_agent - INFO - Cleaning up finished run: dcx4y6ut\n",
+      "2020-11-01 12:26:27,816 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:26:27,816 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la14.txt\n",
+      "2020-11-01 12:26:27,818 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la14.txt\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:26:32,836 - wandb.wandb_agent - INFO - Running runs: ['fdb3wrbz']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrandom\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/1x8v92mc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/av30c7rd\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_115608-av30c7rd\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpretty-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/fdb3wrbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_122629-fdb3wrbz\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 11:56:12,862 - wandb.wandb_agent - INFO - Running runs: ['av30c7rd']\n"
+      "2020-11-01 12:26:33,451\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m 2020-11-01 12:26:36,168\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34537)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34537)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34504)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34504)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1454.2822384428223\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.8627760252366\n",
+      "  episode_reward_max: 43.628865979381466\n",
+      "  episode_reward_mean: 35.1516797294221\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1268\n",
+      "  episodes_total: 1268\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1449244519074757\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007437704674278696\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00946940048985804\n",
+      "        total_loss: 55.00797367095947\n",
+      "        vf_explained_var: 0.7487528324127197\n",
+      "        vf_loss: 55.01652844746908\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.32592592592592\n",
+      "    gpu_util_percent0: 0.37481481481481477\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4333333333333336\n",
+      "    vram_util_percent0: 0.08172381958869332\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17352791633057102\n",
+      "    mean_env_wait_ms: 0.6811877523118316\n",
+      "    mean_inference_ms: 5.513942130136428\n",
+      "    mean_raw_obs_processing_ms: 0.46789447756981023\n",
+      "  time_since_restore: 22.46462392807007\n",
+      "  time_this_iter_s: 22.46462392807007\n",
+      "  time_total_s: 22.46462392807007\n",
+      "  timers:\n",
+      "    learn_throughput: 11371.952\n",
+      "    learn_time_ms: 14227.284\n",
+      "    sample_throughput: 19879.837\n",
+      "    sample_time_ms: 8138.497\n",
+      "    update_time_ms: 45.686\n",
+      "  timestamp: 1604233624\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      1 |          22.4646 | 161792 |  35.1517 |              43.6289 |              15.1237 |            116.863 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1429.8942416258938\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 115.70282317979198\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 36.47211286591811\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1424\n",
+      "  episodes_total: 2692\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1268550356229146\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008950442192144692\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011557365185581148\n",
+      "        total_loss: 11.271961530049643\n",
+      "        vf_explained_var: 0.8903374671936035\n",
+      "        vf_loss: 11.282292207082113\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.204166666666666\n",
+      "    gpu_util_percent0: 0.3720833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5041666666666664\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16745964588212917\n",
+      "    mean_env_wait_ms: 0.6700706773938075\n",
+      "    mean_inference_ms: 5.2198211020760175\n",
+      "    mean_raw_obs_processing_ms: 0.44909095470061955\n",
+      "  time_since_restore: 43.08302044868469\n",
+      "  time_this_iter_s: 20.618396520614624\n",
+      "  time_total_s: 43.08302044868469\n",
+      "  timers:\n",
+      "    learn_throughput: 11459.566\n",
+      "    learn_time_ms: 14118.51\n",
+      "    sample_throughput: 22090.571\n",
+      "    sample_time_ms: 7324.03\n",
+      "    update_time_ms: 43.623\n",
+      "  timestamp: 1604233644\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      2 |           43.083 | 323584 |  36.4721 |              43.6289 |              15.1237 |            115.703 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1407.1911728846624\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-27-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.6612669245648\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 37.6345041775509\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1444\n",
+      "  episodes_total: 4136\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1022506852944691\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010415543181200823\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012739738527064523\n",
+      "        total_loss: 7.215804258982341\n",
+      "        vf_explained_var: 0.9305369257926941\n",
+      "        vf_loss: 7.227012077967326\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.087500000000002\n",
+      "    gpu_util_percent0: 0.37166666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5083333333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16367371839915396\n",
+      "    mean_env_wait_ms: 0.6634994267663006\n",
+      "    mean_inference_ms: 5.010201052450705\n",
+      "    mean_raw_obs_processing_ms: 0.43679686634070053\n",
+      "  time_since_restore: 63.11474633216858\n",
+      "  time_this_iter_s: 20.031725883483887\n",
+      "  time_total_s: 63.11474633216858\n",
+      "  timers:\n",
+      "    learn_throughput: 11492.021\n",
+      "    learn_time_ms: 14078.638\n",
+      "    sample_throughput: 23568.631\n",
+      "    sample_time_ms: 6864.718\n",
+      "    update_time_ms: 36.686\n",
+      "  timestamp: 1604233664\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      3 |          63.1147 | 485376 |  37.6345 |              43.6289 |              15.1237 |            114.661 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1387.3099946552645\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.46689093484419\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 38.66655836570194\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1512\n",
+      "  episodes_total: 5648\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0769410530726116\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0091951551536719\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014317200764101775\n",
+      "        total_loss: 4.537634372711182\n",
+      "        vf_explained_var: 0.9580438733100891\n",
+      "        vf_loss: 4.550650993982951\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.513043478260872\n",
+      "    gpu_util_percent0: 0.4282608695652175\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5173913043478255\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16103675868646175\n",
+      "    mean_env_wait_ms: 0.6593645086787177\n",
+      "    mean_inference_ms: 4.8577089246646405\n",
+      "    mean_raw_obs_processing_ms: 0.42820753933909217\n",
+      "  time_since_restore: 82.97024512290955\n",
+      "  time_this_iter_s: 19.855498790740967\n",
+      "  time_total_s: 82.97024512290955\n",
+      "  timers:\n",
+      "    learn_throughput: 11507.373\n",
+      "    learn_time_ms: 14059.855\n",
+      "    sample_throughput: 24572.569\n",
+      "    sample_time_ms: 6584.253\n",
+      "    update_time_ms: 36.417\n",
+      "  timestamp: 1604233684\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      4 |          82.9702 | 647168 |  38.6666 |              43.6289 |              15.1237 |            113.467 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1372.565211247704\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.40185601799774\n",
+      "  episode_reward_max: 43.62886597938149\n",
+      "  episode_reward_mean: 39.44358453260353\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1464\n",
+      "  episodes_total: 7112\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.044628421465556\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009637930120031038\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015056621322097877\n",
+      "        total_loss: 3.0646530191103616\n",
+      "        vf_explained_var: 0.9720616936683655\n",
+      "        vf_loss: 3.0783043106396994\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.678260869565225\n",
+      "    gpu_util_percent0: 0.44782608695652176\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508695652173913\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15917782673985395\n",
+      "    mean_env_wait_ms: 0.6566410931470792\n",
+      "    mean_inference_ms: 4.748845539400791\n",
+      "    mean_raw_obs_processing_ms: 0.4219900698653993\n",
+      "  time_since_restore: 102.53243446350098\n",
+      "  time_this_iter_s: 19.56218934059143\n",
+      "  time_total_s: 102.53243446350098\n",
+      "  timers:\n",
+      "    learn_throughput: 11519.656\n",
+      "    learn_time_ms: 14044.863\n",
+      "    sample_throughput: 25439.401\n",
+      "    sample_time_ms: 6359.898\n",
+      "    update_time_ms: 36.623\n",
+      "  timestamp: 1604233704\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      5 |          102.532 | 808960 |  39.4436 |              43.6289 |              15.1237 |            112.402 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1360.8171568057655\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-28-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.4935170178282\n",
+      "  episode_reward_max: 43.628865979381494\n",
+      "  episode_reward_mean: 40.051285019680485\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1526\n",
+      "  episodes_total: 8638\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.008226936062177\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008314594083155194\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011961210014609\n",
+      "        total_loss: 2.176027218500773\n",
+      "        vf_explained_var: 0.9811684489250183\n",
+      "        vf_loss: 2.1868296464284263\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.013043478260872\n",
+      "    gpu_util_percent0: 0.3617391304347826\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.526086956521739\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1576901249282025\n",
+      "    mean_env_wait_ms: 0.6545619856913595\n",
+      "    mean_inference_ms: 4.661154625197678\n",
+      "    mean_raw_obs_processing_ms: 0.41690510698628513\n",
+      "  time_since_restore: 122.15152668952942\n",
+      "  time_this_iter_s: 19.619092226028442\n",
+      "  time_total_s: 122.15152668952942\n",
+      "  timers:\n",
+      "    learn_throughput: 11527.252\n",
+      "    learn_time_ms: 14035.609\n",
+      "    sample_throughput: 26007.896\n",
+      "    sample_time_ms: 6220.88\n",
+      "    update_time_ms: 34.802\n",
+      "  timestamp: 1604233724\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      6 |          122.152 | 970752 |  40.0513 |              43.6289 |              15.1237 |            111.494 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1351.9801127931137\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.74748570301716\n",
+      "  episode_reward_max: 43.628865979381494\n",
+      "  episode_reward_mean: 40.50685320002359\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1504\n",
+      "  episodes_total: 10142\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9799897919098536\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007559017394669354\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013409938372205943\n",
+      "        total_loss: 1.644661049048106\n",
+      "        vf_explained_var: 0.9860979914665222\n",
+      "        vf_loss: 1.657049189011256\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.617391304347827\n",
+      "    gpu_util_percent0: 0.4239130434782608\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5217391304347827\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15650830518376826\n",
+      "    mean_env_wait_ms: 0.6530945053208776\n",
+      "    mean_inference_ms: 4.592386951937845\n",
+      "    mean_raw_obs_processing_ms: 0.41293979722789786\n",
+      "  time_since_restore: 141.83420944213867\n",
+      "  time_this_iter_s: 19.682682752609253\n",
+      "  time_total_s: 141.83420944213867\n",
+      "  timers:\n",
+      "    learn_throughput: 11524.629\n",
+      "    learn_time_ms: 14038.804\n",
+      "    sample_throughput: 26444.386\n",
+      "    sample_time_ms: 6118.198\n",
+      "    update_time_ms: 34.8\n",
+      "  timestamp: 1604233744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      7 |          141.834 | 1132544 |  40.5069 |              43.6289 |              15.1237 |            110.747 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1344.8585277968427\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.01317252587461\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 40.877048782789124\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 11691\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9412155350049337\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007740705274045467\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012592456245329231\n",
+      "        total_loss: 1.2588910659154255\n",
+      "        vf_explained_var: 0.9897112846374512\n",
+      "        vf_loss: 1.2704059382279713\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.641666666666662\n",
+      "    gpu_util_percent0: 0.36375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15552725421090569\n",
+      "    mean_env_wait_ms: 0.6520038178299323\n",
+      "    mean_inference_ms: 4.534700600650504\n",
+      "    mean_raw_obs_processing_ms: 0.4096249844377919\n",
+      "  time_since_restore: 161.7805416584015\n",
+      "  time_this_iter_s: 19.946332216262817\n",
+      "  time_total_s: 161.7805416584015\n",
+      "  timers:\n",
+      "    learn_throughput: 11521.5\n",
+      "    learn_time_ms: 14042.616\n",
+      "    sample_throughput: 26651.946\n",
+      "    sample_time_ms: 6070.551\n",
+      "    update_time_ms: 35.676\n",
+      "  timestamp: 1604233764\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      8 |          161.781 | 1294336 |   40.877 |              43.6289 |              15.1237 |            110.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1339.0663941252176\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-29-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.368015705225\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.17822892762955\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1553\n",
+      "  episodes_total: 13244\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9079152892033259\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0072981525445356965\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010131318272518305\n",
+      "        total_loss: 0.949362243215243\n",
+      "        vf_explained_var: 0.9923892021179199\n",
+      "        vf_loss: 0.9584879080454508\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.282608695652176\n",
+      "    gpu_util_percent0: 0.4395652173913045\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15471153080234437\n",
+      "    mean_env_wait_ms: 0.6512233236906179\n",
+      "    mean_inference_ms: 4.486726941601045\n",
+      "    mean_raw_obs_processing_ms: 0.40688607613554295\n",
+      "  time_since_restore: 181.48901557922363\n",
+      "  time_this_iter_s: 19.708473920822144\n",
+      "  time_total_s: 181.48901557922363\n",
+      "  timers:\n",
+      "    learn_throughput: 11526.677\n",
+      "    learn_time_ms: 14036.31\n",
+      "    sample_throughput: 26886.791\n",
+      "    sample_time_ms: 6017.527\n",
+      "    update_time_ms: 34.242\n",
+      "  timestamp: 1604233784\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      9 |          181.489 | 1456128 |  41.1782 |              43.6289 |              15.1237 |            109.368 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1334.3752454465434\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.81228046473926\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.422618434137334\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 14804\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.869762510061264\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0075428458318735165\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009666072980811199\n",
+      "        total_loss: 0.7397742619117101\n",
+      "        vf_explained_var: 0.994184672832489\n",
+      "        vf_loss: 0.7483666588862737\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.833333333333332\n",
+      "    gpu_util_percent0: 0.31916666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15401087755433693\n",
+      "    mean_env_wait_ms: 0.6506167732676298\n",
+      "    mean_inference_ms: 4.4459608456017845\n",
+      "    mean_raw_obs_processing_ms: 0.4045366030538726\n",
+      "  time_since_restore: 201.30298805236816\n",
+      "  time_this_iter_s: 19.81397247314453\n",
+      "  time_total_s: 201.30298805236816\n",
+      "  timers:\n",
+      "    learn_throughput: 11523.296\n",
+      "    learn_time_ms: 14040.428\n",
+      "    sample_throughput: 27081.39\n",
+      "    sample_time_ms: 5974.287\n",
+      "    update_time_ms: 34.416\n",
+      "  timestamp: 1604233804\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     10 |          201.303 | 1617920 |  41.4226 |              43.6289 |              15.1237 |            108.812 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1330.5694061408346\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.33194716242662\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.6210186464785\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1548\n",
+      "  episodes_total: 16352\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8340491751829783\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006366107768068711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009178327105473727\n",
+      "        total_loss: 0.6055479943752289\n",
+      "        vf_explained_var: 0.9953274130821228\n",
+      "        vf_loss: 0.6138701190551122\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.46666666666667\n",
+      "    gpu_util_percent0: 0.37000000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15341006651547073\n",
+      "    mean_env_wait_ms: 0.650181832154063\n",
+      "    mean_inference_ms: 4.4112331201416435\n",
+      "    mean_raw_obs_processing_ms: 0.40254424691393875\n",
+      "  time_since_restore: 221.31696248054504\n",
+      "  time_this_iter_s: 20.01397442817688\n",
+      "  time_total_s: 221.31696248054504\n",
+      "  timers:\n",
+      "    learn_throughput: 11519.218\n",
+      "    learn_time_ms: 14045.398\n",
+      "    sample_throughput: 28288.316\n",
+      "    sample_time_ms: 5719.393\n",
+      "    update_time_ms: 33.239\n",
+      "  timestamp: 1604233825\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     11 |          221.317 | 1779712 |   41.621 |              43.6289 |              15.1237 |            108.332 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1327.2690156599554\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-30-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.91024281328495\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.79185500832971\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1563\n",
+      "  episodes_total: 17915\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8071108410755793\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006752079119905829\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009787990158656612\n",
+      "        total_loss: 0.4518005351225535\n",
+      "        vf_explained_var: 0.9965425133705139\n",
+      "        vf_loss: 0.46064166476329166\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.460869565217386\n",
+      "    gpu_util_percent0: 0.4491304347826087\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15287929224510746\n",
+      "    mean_env_wait_ms: 0.649859182584871\n",
+      "    mean_inference_ms: 4.38067919169665\n",
+      "    mean_raw_obs_processing_ms: 0.40078994113897726\n",
+      "  time_since_restore: 240.91183829307556\n",
+      "  time_this_iter_s: 19.594875812530518\n",
+      "  time_total_s: 240.91183829307556\n",
+      "  timers:\n",
+      "    learn_throughput: 11522.834\n",
+      "    learn_time_ms: 14040.99\n",
+      "    sample_throughput: 28801.969\n",
+      "    sample_time_ms: 5617.394\n",
+      "    update_time_ms: 31.109\n",
+      "  timestamp: 1604233844\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     12 |          240.912 | 1941504 |  41.7919 |              43.6289 |              15.1237 |             107.91 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1324.5485464368408\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.57801746276323\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 41.93343711446106\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 19470\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7690616647402445\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0065094192589943605\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010228886812304458\n",
+      "        total_loss: 0.3978396902481715\n",
+      "        vf_explained_var: 0.9969910979270935\n",
+      "        vf_loss: 0.4071512247125308\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.712500000000002\n",
+      "    gpu_util_percent0: 0.40458333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15241252197920177\n",
+      "    mean_env_wait_ms: 0.6496173991986937\n",
+      "    mean_inference_ms: 4.353964505075953\n",
+      "    mean_raw_obs_processing_ms: 0.3992612917500714\n",
+      "  time_since_restore: 260.9479441642761\n",
+      "  time_this_iter_s: 20.03610587120056\n",
+      "  time_total_s: 260.9479441642761\n",
+      "  timers:\n",
+      "    learn_throughput: 11495.402\n",
+      "    learn_time_ms: 14074.497\n",
+      "    sample_throughput: 29007.895\n",
+      "    sample_time_ms: 5577.516\n",
+      "    update_time_ms: 31.578\n",
+      "  timestamp: 1604233865\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     13 |          260.948 | 2103296 |  41.9334 |              43.6289 |              15.1237 |            107.578 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1322.226\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.29351081530783\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.054489449346825\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1565\n",
+      "  episodes_total: 21035\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7336616019407908\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0064004862603421015\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008804643754653322\n",
+      "        total_loss: 0.3278699740767479\n",
+      "        vf_explained_var: 0.9975385069847107\n",
+      "        vf_loss: 0.33576134343942005\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.491666666666664\n",
+      "    gpu_util_percent0: 0.32416666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15199672808495696\n",
+      "    mean_env_wait_ms: 0.6494243284753675\n",
+      "    mean_inference_ms: 4.330132256006824\n",
+      "    mean_raw_obs_processing_ms: 0.39788879446265113\n",
+      "  time_since_restore: 280.836660861969\n",
+      "  time_this_iter_s: 19.88871669769287\n",
+      "  time_total_s: 280.836660861969\n",
+      "  timers:\n",
+      "    learn_throughput: 11490.563\n",
+      "    learn_time_ms: 14080.424\n",
+      "    sample_throughput: 29086.085\n",
+      "    sample_time_ms: 5562.523\n",
+      "    update_time_ms: 31.329\n",
+      "  timestamp: 1604233885\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     14 |          280.837 | 2265088 |  42.0545 |              43.6289 |              15.1237 |            107.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1320.1891843971632\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-31-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.05496791325514\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.16018734187611\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 22595\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7067601482073466\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006438710144720972\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010162829411759352\n",
+      "        total_loss: 0.2576701765259107\n",
+      "        vf_explained_var: 0.9980695843696594\n",
+      "        vf_loss: 0.26689864446719486\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.404347826086955\n",
+      "    gpu_util_percent0: 0.3060869565217391\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15162840674833306\n",
+      "    mean_env_wait_ms: 0.6492838913939692\n",
+      "    mean_inference_ms: 4.308869472451551\n",
+      "    mean_raw_obs_processing_ms: 0.3966675681414554\n",
+      "  time_since_restore: 300.50964164733887\n",
+      "  time_this_iter_s: 19.672980785369873\n",
+      "  time_total_s: 300.50964164733887\n",
+      "  timers:\n",
+      "    learn_throughput: 11490.394\n",
+      "    learn_time_ms: 14080.631\n",
+      "    sample_throughput: 29052.047\n",
+      "    sample_time_ms: 5569.04\n",
+      "    update_time_ms: 29.544\n",
+      "  timestamp: 1604233905\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     15 |           300.51 | 2426880 |  42.1602 |              43.6289 |              15.1237 |            107.055 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1318.4346780546457\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.84805829262234\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.2515568060273\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 24154\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6743296881516775\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006636352161876857\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00975274900944593\n",
+      "        total_loss: 0.23658680294950804\n",
+      "        vf_explained_var: 0.9982344508171082\n",
+      "        vf_loss: 0.2453494481742382\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.991666666666664\n",
+      "    gpu_util_percent0: 0.33416666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15129670825904046\n",
+      "    mean_env_wait_ms: 0.6491675546769002\n",
+      "    mean_inference_ms: 4.289756257599939\n",
+      "    mean_raw_obs_processing_ms: 0.39556396298388297\n",
+      "  time_since_restore: 320.2244436740875\n",
+      "  time_this_iter_s: 19.714802026748657\n",
+      "  time_total_s: 320.2244436740875\n",
+      "  timers:\n",
+      "    learn_throughput: 11483.06\n",
+      "    learn_time_ms: 14089.624\n",
+      "    sample_throughput: 29083.807\n",
+      "    sample_time_ms: 5562.958\n",
+      "    update_time_ms: 30.273\n",
+      "  timestamp: 1604233926\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     16 |          320.224 | 2588672 |  42.2516 |              43.6289 |              15.1237 |            106.848 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1316.8612322791712\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.6750029170394\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.333070966857214\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1557\n",
+      "  episodes_total: 25711\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6487419108549753\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006434203319561978\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010461925092386082\n",
+      "        total_loss: 0.18015940859913826\n",
+      "        vf_explained_var: 0.9986326694488525\n",
+      "        vf_loss: 0.1896588665743669\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.604347826086954\n",
+      "    gpu_util_percent0: 0.4843478260869565\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15099532910883745\n",
+      "    mean_env_wait_ms: 0.6490596721671469\n",
+      "    mean_inference_ms: 4.272450859355698\n",
+      "    mean_raw_obs_processing_ms: 0.3945623850682107\n",
+      "  time_since_restore: 339.8860158920288\n",
+      "  time_this_iter_s: 19.661572217941284\n",
+      "  time_total_s: 339.8860158920288\n",
+      "  timers:\n",
+      "    learn_throughput: 11488.521\n",
+      "    learn_time_ms: 14082.927\n",
+      "    sample_throughput: 29093.385\n",
+      "    sample_time_ms: 5561.127\n",
+      "    update_time_ms: 30.118\n",
+      "  timestamp: 1604233946\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     17 |          339.886 | 2750464 |  42.3331 |              43.6289 |              15.1237 |            106.675 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1315.4772084481176\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-32-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.53646368305209\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.40514405004122\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1549\n",
+      "  episodes_total: 27260\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6147788117329279\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006190092225248615\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00844319449000371\n",
+      "        total_loss: 0.15160012369354567\n",
+      "        vf_explained_var: 0.9988699555397034\n",
+      "        vf_loss: 0.15911269187927246\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.108333333333334\n",
+      "    gpu_util_percent0: 0.40958333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15072186700405005\n",
+      "    mean_env_wait_ms: 0.6489589654205459\n",
+      "    mean_inference_ms: 4.256776083733925\n",
+      "    mean_raw_obs_processing_ms: 0.3936520268695803\n",
+      "  time_since_restore: 359.4751284122467\n",
+      "  time_this_iter_s: 19.589112520217896\n",
+      "  time_total_s: 359.4751284122467\n",
+      "  timers:\n",
+      "    learn_throughput: 11502.311\n",
+      "    learn_time_ms: 14066.043\n",
+      "    sample_throughput: 29213.386\n",
+      "    sample_time_ms: 5538.283\n",
+      "    update_time_ms: 28.725\n",
+      "  timestamp: 1604233966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     18 |          359.475 | 2912256 |  42.4051 |              43.6289 |              15.1237 |            106.536 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1314.2216509171762\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.39508657482911\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.47027859269532\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1559\n",
+      "  episodes_total: 28819\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5793089667956034\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005601404506402711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009277280846921107\n",
+      "        total_loss: 0.12121031371255715\n",
+      "        vf_explained_var: 0.9990783333778381\n",
+      "        vf_loss: 0.1296569655338923\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.066666666666663\n",
+      "    gpu_util_percent0: 0.3979166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1504690836889304\n",
+      "    mean_env_wait_ms: 0.6488696992500765\n",
+      "    mean_inference_ms: 4.242361495701079\n",
+      "    mean_raw_obs_processing_ms: 0.39280933914753613\n",
+      "  time_since_restore: 379.6264307498932\n",
+      "  time_this_iter_s: 20.151302337646484\n",
+      "  time_total_s: 379.6264307498932\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.051\n",
+      "    learn_time_ms: 14097.001\n",
+      "    sample_throughput: 29213.738\n",
+      "    sample_time_ms: 5538.216\n",
+      "    update_time_ms: 30.107\n",
+      "  timestamp: 1604233987\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     19 |          379.626 | 3074048 |  42.4703 |              43.6289 |              15.1237 |            106.395 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1313.0996867271228\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.30233860342555\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.528634054575335\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1541\n",
+      "  episodes_total: 30360\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5525011867284775\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005483048929211994\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009698755030209819\n",
+      "        total_loss: 0.09727698999146621\n",
+      "        vf_explained_var: 0.9992494583129883\n",
+      "        vf_loss: 0.10615538681546847\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.075\n",
+      "    gpu_util_percent0: 0.43416666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15023976063883285\n",
+      "    mean_env_wait_ms: 0.6487841053204015\n",
+      "    mean_inference_ms: 4.22926206402729\n",
+      "    mean_raw_obs_processing_ms: 0.3920470315060969\n",
+      "  time_since_restore: 399.4815435409546\n",
+      "  time_this_iter_s: 19.8551127910614\n",
+      "  time_total_s: 399.4815435409546\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.093\n",
+      "    learn_time_ms: 14096.949\n",
+      "    sample_throughput: 29223.589\n",
+      "    sample_time_ms: 5536.349\n",
+      "    update_time_ms: 30.052\n",
+      "  timestamp: 1604234007\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     20 |          399.482 | 3235840 |  42.5286 |              43.6289 |              15.1237 |            106.302 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1312.0721969578171\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-33-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.19890350877193\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.58196716016847\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1560\n",
+      "  episodes_total: 31920\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5238876193761826\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005134576039078335\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009323944701463915\n",
+      "        total_loss: 0.0834660033384959\n",
+      "        vf_explained_var: 0.9993599057197571\n",
+      "        vf_loss: 0.09202497576673825\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.617391304347823\n",
+      "    gpu_util_percent0: 0.4456521739130434\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5739130434782598\n",
+      "    vram_util_percent0: 0.10109872089209576\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15002456451472287\n",
+      "    mean_env_wait_ms: 0.6487047149986278\n",
+      "    mean_inference_ms: 4.2170315233202755\n",
+      "    mean_raw_obs_processing_ms: 0.3913318433017469\n",
+      "  time_since_restore: 419.1035006046295\n",
+      "  time_this_iter_s: 19.621957063674927\n",
+      "  time_total_s: 419.1035006046295\n",
+      "  timers:\n",
+      "    learn_throughput: 11505.071\n",
+      "    learn_time_ms: 14062.668\n",
+      "    sample_throughput: 29282.333\n",
+      "    sample_time_ms: 5525.243\n",
+      "    update_time_ms: 30.159\n",
+      "  timestamp: 1604234027\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     21 |          419.104 | 3397632 |   42.582 |              43.6289 |              15.1237 |            106.199 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1311.1479420914095\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.12468999312756\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.630005430799805\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1547\n",
+      "  episodes_total: 33467\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49701932817697525\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005340795614756644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010354490535974037\n",
+      "        total_loss: 0.07194800892223914\n",
+      "        vf_explained_var: 0.9994434714317322\n",
+      "        vf_loss: 0.0814828487734\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.325\n",
+      "    gpu_util_percent0: 0.37458333333333327\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14982882739957487\n",
+      "    mean_env_wait_ms: 0.6486235678612109\n",
+      "    mean_inference_ms: 4.205782708358309\n",
+      "    mean_raw_obs_processing_ms: 0.39066600076646296\n",
+      "  time_since_restore: 438.92495369911194\n",
+      "  time_this_iter_s: 19.821453094482422\n",
+      "  time_total_s: 438.92495369911194\n",
+      "  timers:\n",
+      "    learn_throughput: 11494.245\n",
+      "    learn_time_ms: 14075.914\n",
+      "    sample_throughput: 29271.325\n",
+      "    sample_time_ms: 5527.321\n",
+      "    update_time_ms: 31.246\n",
+      "  timestamp: 1604234048\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     22 |          438.925 | 3559424 |    42.63 |              43.6289 |              15.1237 |            106.125 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1310.3136940853449\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.08285951027172\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.67351320494282\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1532\n",
+      "  episodes_total: 34999\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4672253554066022\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005037993270282944\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00685786875934961\n",
+      "        total_loss: 0.06014314107596874\n",
+      "        vf_explained_var: 0.9995446801185608\n",
+      "        vf_loss: 0.06622702504197757\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.15416666666667\n",
+      "    gpu_util_percent0: 0.3633333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1496488629333257\n",
+      "    mean_env_wait_ms: 0.6485461766268289\n",
+      "    mean_inference_ms: 4.195418444138528\n",
+      "    mean_raw_obs_processing_ms: 0.3900530056382457\n",
+      "  time_since_restore: 458.79926347732544\n",
+      "  time_this_iter_s: 19.8743097782135\n",
+      "  time_total_s: 458.79926347732544\n",
+      "  timers:\n",
+      "    learn_throughput: 11517.323\n",
+      "    learn_time_ms: 14047.709\n",
+      "    sample_throughput: 29258.763\n",
+      "    sample_time_ms: 5529.694\n",
+      "    update_time_ms: 32.041\n",
+      "  timestamp: 1604234068\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     23 |          458.799 | 3721216 |  42.6735 |              43.6289 |              15.1237 |            106.083 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1309.5558966207143\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-34-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.0737637588303\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.71301353738489\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1523\n",
+      "  episodes_total: 36522\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4321850041548411\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0057120353837187094\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009051567967010973\n",
+      "        total_loss: 0.05148738451922933\n",
+      "        vf_explained_var: 0.9995923042297363\n",
+      "        vf_loss: 0.059612637696166836\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.6125\n",
+      "    gpu_util_percent0: 0.35374999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14948084784143242\n",
+      "    mean_env_wait_ms: 0.6484509328204054\n",
+      "    mean_inference_ms: 4.185812792415693\n",
+      "    mean_raw_obs_processing_ms: 0.38947414275749065\n",
+      "  time_since_restore: 478.84203243255615\n",
+      "  time_this_iter_s: 20.042768955230713\n",
+      "  time_total_s: 478.84203243255615\n",
+      "  timers:\n",
+      "    learn_throughput: 11501.58\n",
+      "    learn_time_ms: 14066.937\n",
+      "    sample_throughput: 29276.676\n",
+      "    sample_time_ms: 5526.31\n",
+      "    update_time_ms: 31.839\n",
+      "  timestamp: 1604234089\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     24 |          478.842 | 3883008 |   42.713 |              43.6289 |              15.1237 |            106.074 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1308.854354630823\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.09423946178913\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.74960796999439\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1530\n",
+      "  episodes_total: 38052\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.40411561727523804\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004467884932334225\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007561299067068224\n",
+      "        total_loss: 0.0415184999195238\n",
+      "        vf_explained_var: 0.9996755123138428\n",
+      "        vf_loss: 0.0483882799744606\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.00833333333333\n",
+      "    gpu_util_percent0: 0.3670833333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14932390485994398\n",
+      "    mean_env_wait_ms: 0.6483514849496743\n",
+      "    mean_inference_ms: 4.176778186793073\n",
+      "    mean_raw_obs_processing_ms: 0.38892542131807273\n",
+      "  time_since_restore: 498.6148178577423\n",
+      "  time_this_iter_s: 19.772785425186157\n",
+      "  time_total_s: 498.6148178577423\n",
+      "  timers:\n",
+      "    learn_throughput: 11493.615\n",
+      "    learn_time_ms: 14076.686\n",
+      "    sample_throughput: 29308.484\n",
+      "    sample_time_ms: 5520.313\n",
+      "    update_time_ms: 31.941\n",
+      "  timestamp: 1604234109\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:10,587\tWARNING util.py:136 -- The `process_trial` operation took 0.5158097743988037 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     25 |          498.615 | 4044800 |  42.7496 |              43.6289 |              15.1237 |            106.094 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1308.2223065826438\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.13998179427531\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.78251353698859\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1496\n",
+      "  episodes_total: 39548\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3710899030168851\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005478878777163724\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008370831223146524\n",
+      "        total_loss: 0.03866795807455977\n",
+      "        vf_explained_var: 0.9996917843818665\n",
+      "        vf_loss: 0.04667644730458657\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.104166666666668\n",
+      "    gpu_util_percent0: 0.3454166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14918014489593562\n",
+      "    mean_env_wait_ms: 0.6482521101593612\n",
+      "    mean_inference_ms: 4.168509263007074\n",
+      "    mean_raw_obs_processing_ms: 0.38842351941405706\n",
+      "  time_since_restore: 518.4228372573853\n",
+      "  time_this_iter_s: 19.808019399642944\n",
+      "  time_total_s: 518.4228372573853\n",
+      "  timers:\n",
+      "    learn_throughput: 11494.237\n",
+      "    learn_time_ms: 14075.924\n",
+      "    sample_throughput: 29292.382\n",
+      "    sample_time_ms: 5523.347\n",
+      "    update_time_ms: 32.345\n",
+      "  timestamp: 1604234130\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:31,149\tWARNING util.py:136 -- The `process_trial` operation took 0.5663919448852539 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     26 |          518.423 | 4206592 |  42.7825 |              43.6289 |              15.1237 |             106.14 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1307.6298878595808\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-35-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.21381074168798\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.81325152203418\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1507\n",
+      "  episodes_total: 41055\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3422661249836286\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004864616707588236\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008692707876131559\n",
+      "        total_loss: 0.03158797137439251\n",
+      "        vf_explained_var: 0.9997386336326599\n",
+      "        vf_loss: 0.03996535111218691\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.462500000000002\n",
+      "    gpu_util_percent0: 0.33499999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14904403737255034\n",
+      "    mean_env_wait_ms: 0.6481460554960611\n",
+      "    mean_inference_ms: 4.160632746558721\n",
+      "    mean_raw_obs_processing_ms: 0.38794815762152746\n",
+      "  time_since_restore: 538.5130481719971\n",
+      "  time_this_iter_s: 20.090210914611816\n",
+      "  time_total_s: 538.5130481719971\n",
+      "  timers:\n",
+      "    learn_throughput: 11475.693\n",
+      "    learn_time_ms: 14098.67\n",
+      "    sample_throughput: 29224.222\n",
+      "    sample_time_ms: 5536.23\n",
+      "    update_time_ms: 32.82\n",
+      "  timestamp: 1604234151\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:35:52,001\tWARNING util.py:136 -- The `process_trial` operation took 0.5398478507995605 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     27 |          538.513 | 4368384 |  42.8133 |              43.6289 |              15.1237 |            106.214 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1307.0917562892712\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.31207674943566\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.841272069147415\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1473\n",
+      "  episodes_total: 42528\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.31406934062639874\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00531899471146365\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006233617905915405\n",
+      "        total_loss: 0.027707914200921852\n",
+      "        vf_explained_var: 0.9997760653495789\n",
+      "        vf_loss: 0.0338326171040535\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.541666666666668\n",
+      "    gpu_util_percent0: 0.38791666666666663\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14891911374014252\n",
+      "    mean_env_wait_ms: 0.6480333835817965\n",
+      "    mean_inference_ms: 4.153395707395419\n",
+      "    mean_raw_obs_processing_ms: 0.38750819763907707\n",
+      "  time_since_restore: 558.2239861488342\n",
+      "  time_this_iter_s: 19.710937976837158\n",
+      "  time_total_s: 558.2239861488342\n",
+      "  timers:\n",
+      "    learn_throughput: 11465.354\n",
+      "    learn_time_ms: 14111.382\n",
+      "    sample_throughput: 29254.98\n",
+      "    sample_time_ms: 5530.409\n",
+      "    update_time_ms: 31.925\n",
+      "  timestamp: 1604234171\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:12,490\tWARNING util.py:136 -- The `process_trial` operation took 0.5777196884155273 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     28 |          558.224 | 4530176 |  42.8413 |              43.6289 |              15.1237 |            106.312 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1306.5912378872663\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.44389390185694\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.86740122159219\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1469\n",
+      "  episodes_total: 43997\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2867726534605026\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005043890094384551\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007655571622308344\n",
+      "        total_loss: 0.01982968676990519\n",
+      "        vf_explained_var: 0.999823808670044\n",
+      "        vf_loss: 0.027376449356476467\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.208333333333332\n",
+      "    gpu_util_percent0: 0.3120833333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.148801680479015\n",
+      "    mean_env_wait_ms: 0.6479110446105578\n",
+      "    mean_inference_ms: 4.146556745190422\n",
+      "    mean_raw_obs_processing_ms: 0.3870915915108458\n",
+      "  time_since_restore: 578.142192363739\n",
+      "  time_this_iter_s: 19.918206214904785\n",
+      "  time_total_s: 578.142192363739\n",
+      "  timers:\n",
+      "    learn_throughput: 11477.643\n",
+      "    learn_time_ms: 14096.274\n",
+      "    sample_throughput: 29295.707\n",
+      "    sample_time_ms: 5522.72\n",
+      "    update_time_ms: 31.506\n",
+      "  timestamp: 1604234192\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:33,192\tWARNING util.py:136 -- The `process_trial` operation took 0.567206621170044 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     29 |          578.142 | 4691968 |  42.8674 |              43.6289 |              15.1237 |            106.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1306.1297474625158\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-36-52\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.60159721916663\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.89145908926165\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1457\n",
+      "  episodes_total: 45454\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.25657347589731216\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004977851562822859\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0074265640663118875\n",
+      "        total_loss: 0.020246487848150235\n",
+      "        vf_explained_var: 0.999823272228241\n",
+      "        vf_loss: 0.02755244541913271\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.96666666666667\n",
+      "    gpu_util_percent0: 0.34375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1486911615858267\n",
+      "    mean_env_wait_ms: 0.647780786364401\n",
+      "    mean_inference_ms: 4.140117442125262\n",
+      "    mean_raw_obs_processing_ms: 0.3867002477159633\n",
+      "  time_since_restore: 597.9215953350067\n",
+      "  time_this_iter_s: 19.7794029712677\n",
+      "  time_total_s: 597.9215953350067\n",
+      "  timers:\n",
+      "    learn_throughput: 11482.292\n",
+      "    learn_time_ms: 14090.567\n",
+      "    sample_throughput: 29325.187\n",
+      "    sample_time_ms: 5517.169\n",
+      "    update_time_ms: 29.907\n",
+      "  timestamp: 1604234212\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:36:53,780\tWARNING util.py:136 -- The `process_trial` operation took 0.5981490612030029 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     30 |          597.922 | 4853760 |  42.8915 |              43.6289 |              15.1237 |            106.602 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7b004_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1845\n",
+      "    time_step_mean: 1305.6988838856996\n",
+      "    time_step_min: 1292\n",
+      "  date: 2020-11-01_12-37-13\n",
+      "  done: true\n",
+      "  episode_len_mean: 106.77159124834733\n",
+      "  episode_reward_max: 43.6288659793815\n",
+      "  episode_reward_mean: 42.91394806184951\n",
+      "  episode_reward_min: 15.123711340206203\n",
+      "  episodes_this_iter: 1440\n",
+      "  episodes_total: 46894\n",
+      "  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.22576802472273508\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0045362276723608375\n",
+      "        model: {}\n",
+      "        policy_loss: -0.005217552456694345\n",
+      "        total_loss: 0.01427166493764768\n",
+      "        vf_explained_var: 0.9998777508735657\n",
+      "        vf_loss: 0.01948869600892067\n",
+      "    num_steps_sampled: 5015552\n",
+      "    num_steps_trained: 5015552\n",
+      "  iterations_since_restore: 31\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.72083333333333\n",
+      "    gpu_util_percent0: 0.36166666666666664\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.570833333333333\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34519\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14858768250616303\n",
+      "    mean_env_wait_ms: 0.6476419244786176\n",
+      "    mean_inference_ms: 4.134089086382151\n",
+      "    mean_raw_obs_processing_ms: 0.3863330350642181\n",
+      "  time_since_restore: 617.738039970398\n",
+      "  time_this_iter_s: 19.816444635391235\n",
+      "  time_total_s: 617.738039970398\n",
+      "  timers:\n",
+      "    learn_throughput: 11472.012\n",
+      "    learn_time_ms: 14103.193\n",
+      "    sample_throughput: 29323.896\n",
+      "    sample_time_ms: 5517.411\n",
+      "    update_time_ms: 29.881\n",
+      "  timestamp: 1604234233\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 5015552\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 7b004_00000\n",
+      "  \n",
+      "2020-11-01 12:37:14,609\tWARNING util.py:136 -- The `process_trial` operation took 0.7420144081115723 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1101 12:37:14.976943 34403 34403 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34338\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_122629-fdb3wrbz/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_122629-fdb3wrbz/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1292\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 646\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604234235\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1845\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1305.69888\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 43.62887\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 15.12371\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 42.91395\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 46894\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 31\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpretty-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/fdb3wrbz\u001b[0m\n",
+      "2020-11-01 12:37:24,612 - wandb.wandb_agent - INFO - Cleaning up finished run: fdb3wrbz\n",
+      "2020-11-01 12:37:24,941 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-01 12:37:24,941 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/la/la15.txt\n",
+      "2020-11-01 12:37:24,943 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/la/la15.txt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-01 12:37:29,961 - wandb.wandb_agent - INFO - Running runs: ['pq2fv3jo']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdifferent-sweep-5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/9xhkl8my\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pq2fv3jo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201101_123726-pq2fv3jo\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-11-01 12:37:30,609\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=67571)\u001b[0m 2020-11-01 12:37:33,413\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=67560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67547)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67547)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67540)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67540)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67469)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67469)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67515)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67515)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67512)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67512)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67537)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67537)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67525)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67525)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67530)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67530)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67465)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67465)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=67559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=67559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1540.9259259259259\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 118.22310126582279\n",
+      "  episode_reward_max: 44.242424242424256\n",
+      "  episode_reward_mean: 32.03126997826365\n",
+      "  episode_reward_min: 13.989898989898997\n",
+      "  episodes_this_iter: 1264\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1447077592213948\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005619530449621379\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007155387702672063\n",
+      "        total_loss: 40.47618579864502\n",
+      "        vf_explained_var: 0.7891119122505188\n",
+      "        vf_loss: 40.48278999328613\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.218518518518522\n",
+      "    gpu_util_percent0: 0.36629629629629634\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.440740740740741\n",
+      "    vram_util_percent0: 0.08366130971903357\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16496450454226685\n",
+      "    mean_env_wait_ms: 0.6576280720479034\n",
+      "    mean_inference_ms: 4.788716243497749\n",
+      "    mean_raw_obs_processing_ms: 0.4281524023401697\n",
+      "  time_since_restore: 22.09221601486206\n",
+      "  time_this_iter_s: 22.09221601486206\n",
+      "  time_total_s: 22.09221601486206\n",
+      "  timers:\n",
+      "    learn_throughput: 10922.862\n",
+      "    learn_time_ms: 14812.235\n",
+      "    sample_throughput: 22479.319\n",
+      "    sample_time_ms: 7197.371\n",
+      "    update_time_ms: 46.828\n",
+      "  timestamp: 1604234280\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      1 |          22.0922 | 161792 |  32.0313 |              44.2424 |              13.9899 |            118.223 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1531.6367083807356\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 117.54839910647803\n",
+      "  episode_reward_max: 44.242424242424256\n",
+      "  episode_reward_mean: 32.54738374060787\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1422\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1255147556463878\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009991972551991543\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012213830874922374\n",
+      "        total_loss: 10.040241003036499\n",
+      "        vf_explained_var: 0.9008758068084717\n",
+      "        vf_loss: 10.051019430160522\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.98846153846154\n",
+      "    gpu_util_percent0: 0.4046153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.511538461538462\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16294808968714042\n",
+      "    mean_env_wait_ms: 0.6564847478917705\n",
+      "    mean_inference_ms: 4.782872969782969\n",
+      "    mean_raw_obs_processing_ms: 0.42698163136099937\n",
+      "  time_since_restore: 43.73459029197693\n",
+      "  time_this_iter_s: 21.642374277114868\n",
+      "  time_total_s: 43.73459029197693\n",
+      "  timers:\n",
+      "    learn_throughput: 10992.045\n",
+      "    learn_time_ms: 14719.008\n",
+      "    sample_throughput: 22905.576\n",
+      "    sample_time_ms: 7063.433\n",
+      "    update_time_ms: 38.41\n",
+      "  timestamp: 1604234302\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      2 |          43.7346 | 323584 |  32.5474 |              44.2424 |              13.0808 |            117.548 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1510.1358481262328\n",
+      "    time_step_min: 1302\n",
+      "  date: 2020-11-01_12-38-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 116.32862362971986\n",
+      "  episode_reward_max: 44.79797979797981\n",
+      "  episode_reward_mean: 33.70579116376925\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1419\n",
+      "  episodes_total: 4105\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1123215953509014\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00993400338726739\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013690461909087995\n",
+      "        total_loss: 6.506547371546428\n",
+      "        vf_explained_var: 0.9344742298126221\n",
+      "        vf_loss: 6.518807013829549\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.468000000000004\n",
+      "    gpu_util_percent0: 0.36560000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.508\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16101849961752382\n",
+      "    mean_env_wait_ms: 0.6546024350645249\n",
+      "    mean_inference_ms: 4.701779084784631\n",
+      "    mean_raw_obs_processing_ms: 0.4230887594071475\n",
+      "  time_since_restore: 64.32173490524292\n",
+      "  time_this_iter_s: 20.58714461326599\n",
+      "  time_total_s: 64.32173490524292\n",
+      "  timers:\n",
+      "    learn_throughput: 11037.784\n",
+      "    learn_time_ms: 14658.015\n",
+      "    sample_throughput: 24159.746\n",
+      "    sample_time_ms: 6696.759\n",
+      "    update_time_ms: 34.468\n",
+      "  timestamp: 1604234323\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      3 |          64.3217 | 485376 |  33.7058 |               44.798 |              13.0808 |            116.329 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1488.4381143065161\n",
+      "    time_step_min: 1270\n",
+      "  date: 2020-11-01_12-39-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 114.89247699801551\n",
+      "  episode_reward_max: 46.01010101010102\n",
+      "  episode_reward_mean: 34.80499565381399\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1438\n",
+      "  episodes_total: 5543\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0760109821955364\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010554853981981674\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017120405255506437\n",
+      "        total_loss: 4.882782578468323\n",
+      "        vf_explained_var: 0.9524574279785156\n",
+      "        vf_loss: 4.898330052693685\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.83076923076923\n",
+      "    gpu_util_percent0: 0.33230769230769225\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5076923076923077\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15936923843872866\n",
+      "    mean_env_wait_ms: 0.6531312998927246\n",
+      "    mean_inference_ms: 4.622904338928759\n",
+      "    mean_raw_obs_processing_ms: 0.4189887193273442\n",
+      "  time_since_restore: 85.05826711654663\n",
+      "  time_this_iter_s: 20.73653221130371\n",
+      "  time_total_s: 85.05826711654663\n",
+      "  timers:\n",
+      "    learn_throughput: 11028.796\n",
+      "    learn_time_ms: 14669.96\n",
+      "    sample_throughput: 24936.84\n",
+      "    sample_time_ms: 6488.071\n",
+      "    update_time_ms: 46.059\n",
+      "  timestamp: 1604234343\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      4 |          85.0583 | 647168 |   34.805 |              46.0101 |              13.0808 |            114.892 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1466.4215029231427\n",
+      "    time_step_min: 1237\n",
+      "  date: 2020-11-01_12-39-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 113.48583970546588\n",
+      "  episode_reward_max: 47.52525252525255\n",
+      "  episode_reward_mean: 35.910843066747915\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1519\n",
+      "  episodes_total: 7062\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0269921322663624\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010993095813319087\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013592622436893484\n",
+      "        total_loss: 3.9119317531585693\n",
+      "        vf_explained_var: 0.9633958339691162\n",
+      "        vf_loss: 3.923839290936788\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.444000000000006\n",
+      "    gpu_util_percent0: 0.41679999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.516\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1580018213167273\n",
+      "    mean_env_wait_ms: 0.6519685995559447\n",
+      "    mean_inference_ms: 4.555161635142564\n",
+      "    mean_raw_obs_processing_ms: 0.41520922328594023\n",
+      "  time_since_restore: 105.7582585811615\n",
+      "  time_this_iter_s: 20.699991464614868\n",
+      "  time_total_s: 105.7582585811615\n",
+      "  timers:\n",
+      "    learn_throughput: 11021.266\n",
+      "    learn_time_ms: 14679.983\n",
+      "    sample_throughput: 25435.818\n",
+      "    sample_time_ms: 6360.794\n",
+      "    update_time_ms: 44.668\n",
+      "  timestamp: 1604234364\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      5 |          105.758 | 808960 |  35.9108 |              47.5253 |              13.0808 |            113.486 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1447.9500235183443\n",
+      "    time_step_min: 1237\n",
+      "  date: 2020-11-01_12-39-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 112.33274874313106\n",
+      "  episode_reward_max: 47.52525252525255\n",
+      "  episode_reward_mean: 36.86168359616273\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1491\n",
+      "  episodes_total: 8553\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.987803190946579\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010113457528253397\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014161262234362463\n",
+      "        total_loss: 3.0733113487561545\n",
+      "        vf_explained_var: 0.9713076949119568\n",
+      "        vf_loss: 3.0859439174334207\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.396\n",
+      "    gpu_util_percent0: 0.3632000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5239999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15689234927636098\n",
+      "    mean_env_wait_ms: 0.651134098255352\n",
+      "    mean_inference_ms: 4.500464998774646\n",
+      "    mean_raw_obs_processing_ms: 0.4120524597642815\n",
+      "  time_since_restore: 126.29982709884644\n",
+      "  time_this_iter_s: 20.541568517684937\n",
+      "  time_total_s: 126.29982709884644\n",
+      "  timers:\n",
+      "    learn_throughput: 11029.447\n",
+      "    learn_time_ms: 14669.094\n",
+      "    sample_throughput: 25808.454\n",
+      "    sample_time_ms: 6268.954\n",
+      "    update_time_ms: 43.186\n",
+      "  timestamp: 1604234385\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      6 |            126.3 | 970752 |  36.8617 |              47.5253 |              13.0808 |            112.333 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1430.1320079522864\n",
+      "    time_step_min: 1228\n",
+      "  date: 2020-11-01_12-40-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 111.28944504896627\n",
+      "  episode_reward_max: 48.48484848484849\n",
+      "  episode_reward_mean: 37.7558351344087\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1556\n",
+      "  episodes_total: 10109\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9375320275624593\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008831425181900462\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014223781297914684\n",
+      "        total_loss: 2.650870760281881\n",
+      "        vf_explained_var: 0.9759369492530823\n",
+      "        vf_loss: 2.6637970407803855\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.449999999999996\n",
+      "    gpu_util_percent0: 0.35692307692307695\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15594457790714622\n",
+      "    mean_env_wait_ms: 0.6505920718367179\n",
+      "    mean_inference_ms: 4.453229425218937\n",
+      "    mean_raw_obs_processing_ms: 0.409256308610765\n",
+      "  time_since_restore: 146.91562390327454\n",
+      "  time_this_iter_s: 20.6157968044281\n",
+      "  time_total_s: 146.91562390327454\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.377\n",
+      "    learn_time_ms: 14661.212\n",
+      "    sample_throughput: 26039.628\n",
+      "    sample_time_ms: 6213.299\n",
+      "    update_time_ms: 41.221\n",
+      "  timestamp: 1604234406\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      7 |          146.916 | 1132544 |  37.7558 |              48.4848 |              13.0808 |            111.289 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1413.9141553297743\n",
+      "    time_step_min: 1219\n",
+      "  date: 2020-11-01_12-40-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 110.37700420132042\n",
+      "  episode_reward_max: 49.040404040404056\n",
+      "  episode_reward_mean: 38.58040665594469\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1554\n",
+      "  episodes_total: 11663\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8849463810523351\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00801295922913899\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012614224765760204\n",
+      "        total_loss: 2.1787688732147217\n",
+      "        vf_explained_var: 0.9803922772407532\n",
+      "        vf_loss: 2.190222958723704\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.924000000000007\n",
+      "    gpu_util_percent0: 0.3896\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15514960562097774\n",
+      "    mean_env_wait_ms: 0.650196011864452\n",
+      "    mean_inference_ms: 4.41380605191362\n",
+      "    mean_raw_obs_processing_ms: 0.40683273492153127\n",
+      "  time_since_restore: 167.58297491073608\n",
+      "  time_this_iter_s: 20.667351007461548\n",
+      "  time_total_s: 167.58297491073608\n",
+      "  timers:\n",
+      "    learn_throughput: 11046.514\n",
+      "    learn_time_ms: 14646.43\n",
+      "    sample_throughput: 26162.052\n",
+      "    sample_time_ms: 6184.224\n",
+      "    update_time_ms: 41.682\n",
+      "  timestamp: 1604234427\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      8 |          167.583 | 1294336 |  38.5804 |              49.0404 |              13.0808 |            110.377 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1399.354544764219\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-40-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 109.57285519745801\n",
+      "  episode_reward_max: 49.04040404040408\n",
+      "  episode_reward_mean: 39.3178455763567\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1555\n",
+      "  episodes_total: 13218\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8404552837212881\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007818623019071916\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011729774332100837\n",
+      "        total_loss: 1.9283219973246257\n",
+      "        vf_explained_var: 0.9828620553016663\n",
+      "        vf_loss: 1.9389082888762157\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.368000000000002\n",
+      "    gpu_util_percent0: 0.39\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15447110974777709\n",
+      "    mean_env_wait_ms: 0.6499648656278564\n",
+      "    mean_inference_ms: 4.380306434888785\n",
+      "    mean_raw_obs_processing_ms: 0.4047426878747494\n",
+      "  time_since_restore: 188.20489048957825\n",
+      "  time_this_iter_s: 20.621915578842163\n",
+      "  time_total_s: 188.20489048957825\n",
+      "  timers:\n",
+      "    learn_throughput: 11046.003\n",
+      "    learn_time_ms: 14647.108\n",
+      "    sample_throughput: 26334.762\n",
+      "    sample_time_ms: 6143.667\n",
+      "    update_time_ms: 40.969\n",
+      "  timestamp: 1604234448\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |      9 |          188.205 | 1456128 |  39.3178 |              49.0404 |              13.0808 |            109.573 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1385.9825049162541\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.85056772100567\n",
+      "  episode_reward_max: 49.04040404040408\n",
+      "  episode_reward_mean: 40.00051201389402\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1578\n",
+      "  episodes_total: 14796\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7908046692609787\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007631780773711701\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011734772803417096\n",
+      "        total_loss: 1.5385288000106812\n",
+      "        vf_explained_var: 0.9865396022796631\n",
+      "        vf_loss: 1.5491326252619426\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.732000000000006\n",
+      "    gpu_util_percent0: 0.38040000000000007\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15388031735599098\n",
+      "    mean_env_wait_ms: 0.6498212598888915\n",
+      "    mean_inference_ms: 4.351027781645246\n",
+      "    mean_raw_obs_processing_ms: 0.40287986554113797\n",
+      "  time_since_restore: 208.505108833313\n",
+      "  time_this_iter_s: 20.30021834373474\n",
+      "  time_total_s: 208.505108833313\n",
+      "  timers:\n",
+      "    learn_throughput: 11056.477\n",
+      "    learn_time_ms: 14633.233\n",
+      "    sample_throughput: 26549.982\n",
+      "    sample_time_ms: 6093.865\n",
+      "    update_time_ms: 40.654\n",
+      "  timestamp: 1604234469\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     10 |          208.505 | 1617920 |  40.0005 |              49.0404 |              13.0808 |            108.851 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1373.7871090163433\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 108.19760771390212\n",
+      "  episode_reward_max: 49.040404040404084\n",
+      "  episode_reward_mean: 40.61680826327476\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1590\n",
+      "  episodes_total: 16386\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7443548093239466\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007289290855017801\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011087999266843932\n",
+      "        total_loss: 1.2828177213668823\n",
+      "        vf_explained_var: 0.9888736605644226\n",
+      "        vf_loss: 1.2928200562795003\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.136\n",
+      "    gpu_util_percent0: 0.3856\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15335957704686504\n",
+      "    mean_env_wait_ms: 0.6497293652386255\n",
+      "    mean_inference_ms: 4.325424204249887\n",
+      "    mean_raw_obs_processing_ms: 0.4011955359649914\n",
+      "  time_since_restore: 229.01598072052002\n",
+      "  time_this_iter_s: 20.51087188720703\n",
+      "  time_total_s: 229.01598072052002\n",
+      "  timers:\n",
+      "    learn_throughput: 11068.877\n",
+      "    learn_time_ms: 14616.84\n",
+      "    sample_throughput: 27216.446\n",
+      "    sample_time_ms: 5944.641\n",
+      "    update_time_ms: 39.857\n",
+      "  timestamp: 1604234489\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     11 |          229.016 | 1779712 |  40.6168 |              49.0404 |              13.0808 |            108.198 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1362.7848496680983\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-41-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.6175456163774\n",
+      "  episode_reward_max: 49.040404040404084\n",
+      "  episode_reward_mean: 41.17096364175804\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1590\n",
+      "  episodes_total: 17976\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7057946672042211\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006505049881525338\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011637478950433433\n",
+      "        total_loss: 1.0556738674640656\n",
+      "        vf_explained_var: 0.9909140467643738\n",
+      "        vf_loss: 1.066363235314687\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.067999999999998\n",
+      "    gpu_util_percent0: 0.38120000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15290224314841672\n",
+      "    mean_env_wait_ms: 0.6497100863030586\n",
+      "    mean_inference_ms: 4.30291912913981\n",
+      "    mean_raw_obs_processing_ms: 0.3997009547743406\n",
+      "  time_since_restore: 249.53435850143433\n",
+      "  time_this_iter_s: 20.518377780914307\n",
+      "  time_total_s: 249.53435850143433\n",
+      "  timers:\n",
+      "    learn_throughput: 11067.812\n",
+      "    learn_time_ms: 14618.246\n",
+      "    sample_throughput: 27784.289\n",
+      "    sample_time_ms: 5823.147\n",
+      "    update_time_ms: 40.514\n",
+      "  timestamp: 1604234510\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     12 |          249.534 | 1941504 |   41.171 |              49.0404 |              13.0808 |            107.618 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1352.7341357234316\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 107.1025339736385\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 41.67515040050036\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1598\n",
+      "  episodes_total: 19574\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6686889827251434\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0063633088720962405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01186193727577726\n",
+      "        total_loss: 0.8905991663535436\n",
+      "        vf_explained_var: 0.9923557639122009\n",
+      "        vf_loss: 0.9015227903922399\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.288461538461544\n",
+      "    gpu_util_percent0: 0.38153846153846155\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15249499620405588\n",
+      "    mean_env_wait_ms: 0.6497364450001253\n",
+      "    mean_inference_ms: 4.282874551579647\n",
+      "    mean_raw_obs_processing_ms: 0.39836613551654754\n",
+      "  time_since_restore: 270.1388850212097\n",
+      "  time_this_iter_s: 20.60452651977539\n",
+      "  time_total_s: 270.1388850212097\n",
+      "  timers:\n",
+      "    learn_throughput: 11056.406\n",
+      "    learn_time_ms: 14633.327\n",
+      "    sample_throughput: 27887.324\n",
+      "    sample_time_ms: 5801.632\n",
+      "    update_time_ms: 41.993\n",
+      "  timestamp: 1604234531\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     13 |          270.139 | 2103296 |  41.6752 |              49.0404 |              13.0808 |            107.103 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1343.4148870685165\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.65310846560847\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.142787951319704\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1594\n",
+      "  episodes_total: 21168\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6273181239763895\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006019947739938895\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009247757125801096\n",
+      "        total_loss: 0.7534371664126714\n",
+      "        vf_explained_var: 0.9935855865478516\n",
+      "        vf_loss: 0.7617945869763693\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.48\n",
+      "    gpu_util_percent0: 0.3504\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15213206388671544\n",
+      "    mean_env_wait_ms: 0.6497940000882954\n",
+      "    mean_inference_ms: 4.2649850452281735\n",
+      "    mean_raw_obs_processing_ms: 0.39716794855089166\n",
+      "  time_since_restore: 290.5424859523773\n",
+      "  time_this_iter_s: 20.403600931167603\n",
+      "  time_total_s: 290.5424859523773\n",
+      "  timers:\n",
+      "    learn_throughput: 11072.943\n",
+      "    learn_time_ms: 14611.472\n",
+      "    sample_throughput: 27934.424\n",
+      "    sample_time_ms: 5791.85\n",
+      "    update_time_ms: 35.766\n",
+      "  timestamp: 1604234552\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     14 |          290.542 | 2265088 |  42.1428 |              49.0404 |              13.0808 |            106.653 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1334.9958170049756\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-42-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 106.25092267135325\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.566322273703655\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1592\n",
+      "  episodes_total: 22760\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.593339666724205\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052832565270364285\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007287261697153251\n",
+      "        total_loss: 0.6348467022180557\n",
+      "        vf_explained_var: 0.994635820388794\n",
+      "        vf_loss: 0.6413739621639252\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.588\n",
+      "    gpu_util_percent0: 0.3836\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1518110809879511\n",
+      "    mean_env_wait_ms: 0.6498897805634568\n",
+      "    mean_inference_ms: 4.248940110401404\n",
+      "    mean_raw_obs_processing_ms: 0.39609601756717205\n",
+      "  time_since_restore: 311.00591683387756\n",
+      "  time_this_iter_s: 20.463430881500244\n",
+      "  time_total_s: 311.00591683387756\n",
+      "  timers:\n",
+      "    learn_throughput: 11097.5\n",
+      "    learn_time_ms: 14579.139\n",
+      "    sample_throughput: 27995.833\n",
+      "    sample_time_ms: 5779.146\n",
+      "    update_time_ms: 35.119\n",
+      "  timestamp: 1604234573\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     15 |          311.006 | 2426880 |  42.5663 |              49.0404 |              13.0808 |            106.251 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1327.4121421520238\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.89524239563237\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 42.95161292328897\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 24361\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5610497693220774\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005239539352866511\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008563858728545407\n",
+      "        total_loss: 0.5433527330557505\n",
+      "        vf_explained_var: 0.9954302906990051\n",
+      "        vf_loss: 0.5511491994063059\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.983999999999995\n",
+      "    gpu_util_percent0: 0.37079999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15151777280002335\n",
+      "    mean_env_wait_ms: 0.6499960724887209\n",
+      "    mean_inference_ms: 4.234304826550604\n",
+      "    mean_raw_obs_processing_ms: 0.39511468708048586\n",
+      "  time_since_restore: 331.8462426662445\n",
+      "  time_this_iter_s: 20.840325832366943\n",
+      "  time_total_s: 331.8462426662445\n",
+      "  timers:\n",
+      "    learn_throughput: 11077.938\n",
+      "    learn_time_ms: 14604.884\n",
+      "    sample_throughput: 28012.835\n",
+      "    sample_time_ms: 5775.638\n",
+      "    update_time_ms: 35.504\n",
+      "  timestamp: 1604234594\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     16 |          331.846 | 2588672 |  42.9516 |              49.0404 |              13.0808 |            105.895 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1320.4339440694312\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.57168707168707\n",
+      "  episode_reward_max: 49.04040404040409\n",
+      "  episode_reward_mean: 43.304979416090546\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1613\n",
+      "  episodes_total: 25974\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.5246386776367823\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005194058952232202\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010037654642170915\n",
+      "        total_loss: 0.3729574630657832\n",
+      "        vf_explained_var: 0.9968838095664978\n",
+      "        vf_loss: 0.3822186241547267\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.15\n",
+      "    gpu_util_percent0: 0.34961538461538466\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1512500032596141\n",
+      "    mean_env_wait_ms: 0.6501069321395831\n",
+      "    mean_inference_ms: 4.2209558905247935\n",
+      "    mean_raw_obs_processing_ms: 0.3942088287210041\n",
+      "  time_since_restore: 352.6941442489624\n",
+      "  time_this_iter_s: 20.847901582717896\n",
+      "  time_total_s: 352.6941442489624\n",
+      "  timers:\n",
+      "    learn_throughput: 11060.738\n",
+      "    learn_time_ms: 14627.595\n",
+      "    sample_throughput: 28046.143\n",
+      "    sample_time_ms: 5768.779\n",
+      "    update_time_ms: 36.388\n",
+      "  timestamp: 1604234616\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     17 |          352.694 | 2750464 |   43.305 |              49.0404 |              13.0808 |            105.572 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1314.0839173535712\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-43-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.28088299260548\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 43.62569621105941\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1614\n",
+      "  episodes_total: 27588\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.49088098108768463\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004925240180455148\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007551613341396053\n",
+      "        total_loss: 0.27305928741892177\n",
+      "        vf_explained_var: 0.997745931148529\n",
+      "        vf_loss: 0.27987127751111984\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.076923076923077\n",
+      "    gpu_util_percent0: 0.35576923076923084\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5730769230769224\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510024924486738\n",
+      "    mean_env_wait_ms: 0.6502222563745731\n",
+      "    mean_inference_ms: 4.208793894567712\n",
+      "    mean_raw_obs_processing_ms: 0.3933811392042326\n",
+      "  time_since_restore: 373.5547993183136\n",
+      "  time_this_iter_s: 20.860655069351196\n",
+      "  time_total_s: 373.5547993183136\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.452\n",
+      "    learn_time_ms: 14661.112\n",
+      "    sample_throughput: 28141.143\n",
+      "    sample_time_ms: 5749.304\n",
+      "    update_time_ms: 34.956\n",
+      "  timestamp: 1604234637\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     18 |          373.555 | 2912256 |  43.6257 |              49.0404 |              13.0808 |            105.281 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1308.3422956891525\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-44-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 105.01201725554643\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 43.913729876137445\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1620\n",
+      "  episodes_total: 29208\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4603450372815132\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0052619769315545755\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007839118620419564\n",
+      "        total_loss: 0.24682058518131575\n",
+      "        vf_explained_var: 0.9979783892631531\n",
+      "        vf_loss: 0.25436367591222125\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.90384615384615\n",
+      "    gpu_util_percent0: 0.3811538461538462\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1507749922403882\n",
+      "    mean_env_wait_ms: 0.6503503182530888\n",
+      "    mean_inference_ms: 4.197625625739776\n",
+      "    mean_raw_obs_processing_ms: 0.3926215964880014\n",
+      "  time_since_restore: 394.43259143829346\n",
+      "  time_this_iter_s: 20.87779211997986\n",
+      "  time_total_s: 394.43259143829346\n",
+      "  timers:\n",
+      "    learn_throughput: 11025.644\n",
+      "    learn_time_ms: 14674.154\n",
+      "    sample_throughput: 28102.66\n",
+      "    sample_time_ms: 5757.177\n",
+      "    update_time_ms: 33.741\n",
+      "  timestamp: 1604234658\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     19 |          394.433 | 3074048 |  43.9137 |              49.0404 |              13.0808 |            105.012 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1303.1952154976273\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-44-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.77212396560117\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 44.17383145096922\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1607\n",
+      "  episodes_total: 30815\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.43477704375982285\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004907564221260448\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007642344086586188\n",
+      "        total_loss: 0.17235680421193442\n",
+      "        vf_explained_var: 0.998579740524292\n",
+      "        vf_loss: 0.17972578232487044\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.568\n",
+      "    gpu_util_percent0: 0.3516\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15056551159545464\n",
+      "    mean_env_wait_ms: 0.650477071010486\n",
+      "    mean_inference_ms: 4.187399168266206\n",
+      "    mean_raw_obs_processing_ms: 0.39192218046315624\n",
+      "  time_since_restore: 415.2149660587311\n",
+      "  time_this_iter_s: 20.782374620437622\n",
+      "  time_total_s: 415.2149660587311\n",
+      "  timers:\n",
+      "    learn_throughput: 11005.002\n",
+      "    learn_time_ms: 14701.678\n",
+      "    sample_throughput: 28031.542\n",
+      "    sample_time_ms: 5771.784\n",
+      "    update_time_ms: 33.384\n",
+      "  timestamp: 1604234680\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     20 |          415.215 | 3235840 |  44.1738 |              49.0404 |              13.0808 |            104.772 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1298.6048573988814\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.55760212267062\n",
+      "  episode_reward_max: 49.0404040404041\n",
+      "  episode_reward_mean: 44.4073915135559\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1597\n",
+      "  episodes_total: 32412\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.4088049481312434\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0050367383907238645\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004726681110696518\n",
+      "        total_loss: 0.15046600687007108\n",
+      "        vf_explained_var: 0.9988059401512146\n",
+      "        vf_loss: 0.15514524901906648\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.25769230769231\n",
+      "    gpu_util_percent0: 0.3230769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5692307692307685\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15037307743519757\n",
+      "    mean_env_wait_ms: 0.6506021265347358\n",
+      "    mean_inference_ms: 4.177989463073186\n",
+      "    mean_raw_obs_processing_ms: 0.39127952344764305\n",
+      "  time_since_restore: 436.0554406642914\n",
+      "  time_this_iter_s: 20.840474605560303\n",
+      "  time_total_s: 436.0554406642914\n",
+      "  timers:\n",
+      "    learn_throughput: 10991.518\n",
+      "    learn_time_ms: 14719.713\n",
+      "    sample_throughput: 27990.599\n",
+      "    sample_time_ms: 5780.226\n",
+      "    update_time_ms: 33.786\n",
+      "  timestamp: 1604234701\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     21 |          436.055 | 3397632 |  44.4074 |              49.0404 |              13.0808 |            104.558 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1294.3254164459356\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.35706938607576\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 44.62349862987593\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 34027\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.38861273725827533\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004962532625844081\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006052409371477552\n",
+      "        total_loss: 0.10335199224452178\n",
+      "        vf_explained_var: 0.9991534352302551\n",
+      "        vf_loss: 0.1093505813429753\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.088461538461537\n",
+      "    gpu_util_percent0: 0.34846153846153843\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15019358290939233\n",
+      "    mean_env_wait_ms: 0.6507335363952385\n",
+      "    mean_inference_ms: 4.169147396856916\n",
+      "    mean_raw_obs_processing_ms: 0.39067463008215425\n",
+      "  time_since_restore: 456.7496886253357\n",
+      "  time_this_iter_s: 20.69424796104431\n",
+      "  time_total_s: 456.7496886253357\n",
+      "  timers:\n",
+      "    learn_throughput: 10986.132\n",
+      "    learn_time_ms: 14726.93\n",
+      "    sample_throughput: 28004.762\n",
+      "    sample_time_ms: 5777.303\n",
+      "    update_time_ms: 33.873\n",
+      "  timestamp: 1604234723\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     22 |           456.75 | 3559424 |  44.6235 |              49.0404 |              13.0808 |            104.357 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1290.3840622454425\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-45-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.17307152875175\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 44.82170512983978\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1623\n",
+      "  episodes_total: 35650\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.36651041358709335\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006440783229966958\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007153725775424391\n",
+      "        total_loss: 0.08216805756092072\n",
+      "        vf_explained_var: 0.999314546585083\n",
+      "        vf_loss: 0.0893440234164397\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.088\n",
+      "    gpu_util_percent0: 0.3868\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15002367096031743\n",
+      "    mean_env_wait_ms: 0.6508575565151\n",
+      "    mean_inference_ms: 4.160903003774551\n",
+      "    mean_raw_obs_processing_ms: 0.3901072062383884\n",
+      "  time_since_restore: 477.2431552410126\n",
+      "  time_this_iter_s: 20.49346661567688\n",
+      "  time_total_s: 477.2431552410126\n",
+      "  timers:\n",
+      "    learn_throughput: 11006.978\n",
+      "    learn_time_ms: 14699.039\n",
+      "    sample_throughput: 27941.378\n",
+      "    sample_time_ms: 5790.409\n",
+      "    update_time_ms: 31.7\n",
+      "  timestamp: 1604234744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     23 |          477.243 | 3721216 |  44.8217 |              49.0404 |              13.0808 |            104.173 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1286.7964535196131\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 104.00566154176393\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.00310735680616\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 37269\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.3446768522262573\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006010537773060302\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006810000515542924\n",
+      "        total_loss: 0.05681590953220924\n",
+      "        vf_explained_var: 0.9995128512382507\n",
+      "        vf_loss: 0.06364798328528802\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.616\n",
+      "    gpu_util_percent0: 0.42919999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1498672084151353\n",
+      "    mean_env_wait_ms: 0.6509884510617694\n",
+      "    mean_inference_ms: 4.153243452307446\n",
+      "    mean_raw_obs_processing_ms: 0.38958140467964614\n",
+      "  time_since_restore: 497.40847873687744\n",
+      "  time_this_iter_s: 20.165323495864868\n",
+      "  time_total_s: 497.40847873687744\n",
+      "  timers:\n",
+      "    learn_throughput: 11023.912\n",
+      "    learn_time_ms: 14676.46\n",
+      "    sample_throughput: 27996.068\n",
+      "    sample_time_ms: 5779.097\n",
+      "    update_time_ms: 33.775\n",
+      "  timestamp: 1604234764\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     24 |          497.408 | 3883008 |  45.0031 |              49.0404 |              13.0808 |            104.006 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1283.5285511912427\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.8526007099861\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.16817737492225\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1605\n",
+      "  episodes_total: 38874\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.32262827704350155\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005610594448323051\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004409408691572025\n",
+      "        total_loss: 0.04963509986797968\n",
+      "        vf_explained_var: 0.9995853304862976\n",
+      "        vf_loss: 0.054065559059381485\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.457692307692305\n",
+      "    gpu_util_percent0: 0.4265384615384616\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14972028928263528\n",
+      "    mean_env_wait_ms: 0.6511154433665545\n",
+      "    mean_inference_ms: 4.146093777194914\n",
+      "    mean_raw_obs_processing_ms: 0.3890936155505342\n",
+      "  time_since_restore: 517.5921437740326\n",
+      "  time_this_iter_s: 20.18366503715515\n",
+      "  time_total_s: 517.5921437740326\n",
+      "  timers:\n",
+      "    learn_throughput: 11035.673\n",
+      "    learn_time_ms: 14660.819\n",
+      "    sample_throughput: 28000.79\n",
+      "    sample_time_ms: 5778.123\n",
+      "    update_time_ms: 32.664\n",
+      "  timestamp: 1604234785\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:46:26,652\tWARNING util.py:136 -- The `process_trial` operation took 0.5261285305023193 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     25 |          517.592 | 4044800 |  45.1682 |              49.0404 |              13.0808 |            103.853 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1280.5338148716173\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-46-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.71221741815936\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.319422763771136\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1601\n",
+      "  episodes_total: 40475\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2999122018615405\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0053110466881965595\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006303349079341085\n",
+      "        total_loss: 0.05139423534274101\n",
+      "        vf_explained_var: 0.9995618462562561\n",
+      "        vf_loss: 0.0577147655809919\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.96\n",
+      "    gpu_util_percent0: 0.4584\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14958343418475262\n",
+      "    mean_env_wait_ms: 0.6512359147663624\n",
+      "    mean_inference_ms: 4.139411227315708\n",
+      "    mean_raw_obs_processing_ms: 0.38863613088367416\n",
+      "  time_since_restore: 537.769278049469\n",
+      "  time_this_iter_s: 20.1771342754364\n",
+      "  time_total_s: 537.769278049469\n",
+      "  timers:\n",
+      "    learn_throughput: 11085.459\n",
+      "    learn_time_ms: 14594.975\n",
+      "    sample_throughput: 28023.358\n",
+      "    sample_time_ms: 5773.469\n",
+      "    update_time_ms: 30.886\n",
+      "  timestamp: 1604234806\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:46:47,593\tWARNING util.py:136 -- The `process_trial` operation took 0.5515177249908447 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     26 |          537.769 | 4206592 |  45.3194 |              49.0404 |              13.0808 |            103.712 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1277.717564514211\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.58062906827577\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.461481590264796\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1619\n",
+      "  episodes_total: 42094\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.2697679474949837\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005566679639741778\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006809816346503794\n",
+      "        total_loss: 0.03190007215986649\n",
+      "        vf_explained_var: 0.9997119307518005\n",
+      "        vf_loss: 0.038705606323977314\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.436000000000003\n",
+      "    gpu_util_percent0: 0.3812\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14945344756304582\n",
+      "    mean_env_wait_ms: 0.6513545610993874\n",
+      "    mean_inference_ms: 4.133051412280412\n",
+      "    mean_raw_obs_processing_ms: 0.38819843216626215\n",
+      "  time_since_restore: 557.9500815868378\n",
+      "  time_this_iter_s: 20.180803537368774\n",
+      "  time_total_s: 557.9500815868378\n",
+      "  timers:\n",
+      "    learn_throughput: 11129.942\n",
+      "    learn_time_ms: 14536.644\n",
+      "    sample_throughput: 28097.666\n",
+      "    sample_time_ms: 5758.201\n",
+      "    update_time_ms: 30.627\n",
+      "  timestamp: 1604234827\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:08,513\tWARNING util.py:136 -- The `process_trial` operation took 0.5479977130889893 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     27 |           557.95 | 4368384 |  45.4615 |              49.0404 |              13.0808 |            103.581 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1275.0976458734085\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.45904339273052\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.59383551183082\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1623\n",
+      "  episodes_total: 43717\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025000000000000005\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.23974776516358057\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004747193811150889\n",
+      "        model: {}\n",
+      "        policy_loss: -0.004243802364120104\n",
+      "        total_loss: 0.02101877443298387\n",
+      "        vf_explained_var: 0.999813973903656\n",
+      "        vf_loss: 0.025263771259536345\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.936\n",
+      "    gpu_util_percent0: 0.364\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5679999999999996\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14933083667741634\n",
+      "    mean_env_wait_ms: 0.6514677609541502\n",
+      "    mean_inference_ms: 4.127067697966748\n",
+      "    mean_raw_obs_processing_ms: 0.3877881594254328\n",
+      "  time_since_restore: 578.1908588409424\n",
+      "  time_this_iter_s: 20.240777254104614\n",
+      "  time_total_s: 578.1908588409424\n",
+      "  timers:\n",
+      "    learn_throughput: 11182.422\n",
+      "    learn_time_ms: 14468.421\n",
+      "    sample_throughput: 28093.626\n",
+      "    sample_time_ms: 5759.029\n",
+      "    update_time_ms: 30.485\n",
+      "  timestamp: 1604234848\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:29,582\tWARNING util.py:136 -- The `process_trial` operation took 0.5904042720794678 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     28 |          578.191 | 4530176 |  45.5938 |              49.0404 |              13.0808 |            103.459 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1272.6863282026368\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-47-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 103.34723815406335\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.71580313859499\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1615\n",
+      "  episodes_total: 45332\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.012500000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.21396022414167723\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00464061457508554\n",
+      "        model: {}\n",
+      "        policy_loss: -0.003965421337246274\n",
+      "        total_loss: 0.02320340438745916\n",
+      "        vf_explained_var: 0.9998058676719666\n",
+      "        vf_loss: 0.027217798711111147\n",
+      "    num_steps_sampled: 4691968\n",
+      "    num_steps_trained: 4691968\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.857692307692307\n",
+      "    gpu_util_percent0: 0.34076923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.565384615384615\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14921483484635445\n",
+      "    mean_env_wait_ms: 0.6515697684351597\n",
+      "    mean_inference_ms: 4.121446270442373\n",
+      "    mean_raw_obs_processing_ms: 0.38740127780397765\n",
+      "  time_since_restore: 598.5525875091553\n",
+      "  time_this_iter_s: 20.36172866821289\n",
+      "  time_total_s: 598.5525875091553\n",
+      "  timers:\n",
+      "    learn_throughput: 11221.151\n",
+      "    learn_time_ms: 14418.485\n",
+      "    sample_throughput: 28165.983\n",
+      "    sample_time_ms: 5744.234\n",
+      "    update_time_ms: 31.72\n",
+      "  timestamp: 1604234869\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4691968\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:47:50,804\tWARNING util.py:136 -- The `process_trial` operation took 0.6144161224365234 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | RUNNING  | 172.17.0.4:67571 |     29 |          598.553 | 4691968 |  45.7158 |              49.0404 |              13.0808 |            103.347 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_02bc6_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 1901\n",
+      "    time_step_mean: 1270.4485656393304\n",
+      "    time_step_min: 1207\n",
+      "  date: 2020-11-01_12-48-10\n",
+      "  done: true\n",
+      "  episode_len_mean: 103.24400221587761\n",
+      "  episode_reward_max: 49.040404040404106\n",
+      "  episode_reward_mean: 45.82882130203902\n",
+      "  episode_reward_min: 13.080808080808094\n",
+      "  episodes_this_iter: 1602\n",
+      "  episodes_total: 46934\n",
+      "  experiment_id: 6c8ebffc261a4cedb67adf4d1763a8dd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.006250000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.19203581909338632\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004001018533017486\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0069229137285825955\n",
+      "        total_loss: 0.009018626738300858\n",
+      "        vf_explained_var: 0.9998963475227356\n",
+      "        vf_loss: 0.01601255312561989\n",
+      "    num_steps_sampled: 4853760\n",
+      "    num_steps_trained: 4853760\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.076000000000004\n",
+      "    gpu_util_percent0: 0.4292\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.571999999999999\n",
+      "    vram_util_percent0: 0.10109872089209578\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 67571\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14910530030356728\n",
+      "    mean_env_wait_ms: 0.6516595301622415\n",
+      "    mean_inference_ms: 4.116169102966147\n",
+      "    mean_raw_obs_processing_ms: 0.3870328506532899\n",
+      "  time_since_restore: 618.7089035511017\n",
+      "  time_this_iter_s: 20.15631604194641\n",
+      "  time_total_s: 618.7089035511017\n",
+      "  timers:\n",
+      "    learn_throughput: 11261.529\n",
+      "    learn_time_ms: 14366.788\n",
+      "    sample_throughput: 28251.677\n",
+      "    sample_time_ms: 5726.81\n",
+      "    update_time_ms: 31.9\n",
+      "  timestamp: 1604234890\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4853760\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 02bc6_00000\n",
+      "  \n",
+      "2020-11-01 12:48:11,852\tWARNING util.py:136 -- The `process_trial` operation took 0.6959054470062256 seconds to complete, which may be a performance bottleneck.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_02bc6_00000 | TERMINATED |       |     30 |          618.709 | 4853760 |  45.8288 |              49.0404 |              13.0808 |            103.244 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 67339\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201101_123726-pq2fv3jo/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201101_123726-pq2fv3jo/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 1207\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 646\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1604234892\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 1901\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 1270.44857\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 49.0404\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 13.08081\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 45.82882\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 46934\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 30\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdifferent-sweep-5\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pq2fv3jo\u001b[0m\n",
+      "2020-11-01 12:48:21,592 - wandb.wandb_agent - INFO - Cleaning up finished run: pq2fv3jo\n",
+      "2020-11-01 12:48:21,916 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-11-01 12:48:21,916 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent 1x8v92mc"
+    "!wandb agent 9xhkl8my"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
index c3d10c3..6d201e1 100644
--- a/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Random-checkpoint.ipynb
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'random_loop.py',\n",
+    "        'program': 'CP.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta71', '/JSS/JSS/env/instances/ta72', '/JSS/JSS/env/instances/ta73', '/JSS/JSS/env/instances/ta74',\n",
+    "                           '/JSS/JSS/env/instances/ta75', '/JSS/JSS/env/instances/ta76', '/JSS/JSS/env/instances/ta77', '/JSS/JSS/env/instances/ta78',\n",
+    "                           '/JSS/JSS/env/instances/ta79', '/JSS/JSS/env/instances/ta80']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -81,8 +81,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: kitgghxj\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kitgghxj\n"
+      "Create sweep with ID: kkxvg8te\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\n"
      ]
     }
    ],
@@ -92,7 +92,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -100,239 +100,102 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-13 12:32:48,579 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-13 12:32:48,906 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-13 12:32:48,906 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-11-03 17:48:30,968 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-03 17:48:31,522 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 17:48:31,522 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-13 12:32:48,908 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-03 17:48:31,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta51\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdrawn-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kitgghxj\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7zjyogzl\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201013_123250-7zjyogzl\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/quk2usr5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_174832-quk2usr5\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-13 12:32:53,926 - wandb.wandb_agent - INFO - Running runs: ['7zjyogzl']\n",
-      "2020-10-13 12:32:54,468\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_3851e_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-03 17:48:36,541 - wandb.wandb_agent - INFO - Running runs: ['quk2usr5']\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24629\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201103_174832-quk2usr5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201103_174832-quk2usr5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2762.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 603\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604426315\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/quk2usr5\u001b[0m\n",
+      "2020-11-03 17:58:41,416 - wandb.wandb_agent - INFO - Cleaning up finished run: quk2usr5\n",
+      "2020-11-03 17:58:41,795 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 17:58:41,795 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
+      "2020-11-03 17:58:41,799 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l0rsmjin\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_175842-l0rsmjin\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-03 17:58:46,817 - wandb.wandb_agent - INFO - Running runs: ['l0rsmjin']\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24731\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201103_175842-l0rsmjin/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201103_175842-l0rsmjin/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2799.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 603\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604426925\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l0rsmjin\u001b[0m\n",
+      "2020-11-03 18:08:52,752 - wandb.wandb_agent - INFO - Cleaning up finished run: l0rsmjin\n",
+      "2020-11-03 18:08:53,460 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-03 18:08:53,460 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
+      "2020-11-03 18:08:53,462 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta53\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/kkxvg8te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/dy77i2y1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201103_180854-dy77i2y1\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m F1013 12:32:56.746781   308   308 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c66ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c784c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c63c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29941c65e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f299417d789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec11ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec12ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec1491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993ec3801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m F1013 12:32:56.731905   318   318 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d36ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d484c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d33c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d8d35e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d88a789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5ce491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d5d0801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d4df7a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914d450a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9dcc98a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5cb08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de76a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5dde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de7baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d5dde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de76a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9de8454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e76bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e76c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9ea8d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d71625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d71a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9d728cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9eab829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x7f914ebd8840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=318)\u001b[0m     @     0x55b7d9e3bb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m F1013 12:32:56.749399   329   329 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef6ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddf084c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef3c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245ddef5e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245dda6789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daea491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245daec801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245d9fb7a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m F1013 12:32:56.749487   437   437 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36026ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f360384c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36023c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f36025e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f35b9789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32fd491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f32ff801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3280ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m F1013 12:32:56.749395   401   401 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f536ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f5484c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f533c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f535e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253f0a789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c4e491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253c50801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd1ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m F1013 12:32:56.749400   363   363 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35371\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m *** Check failure stack trace: ***\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba6ed  google::LogMessage::Fail()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549bb84c  google::LogMessage::SendToLog()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba3c9  google::LogMessage::Flush()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42549ba5e1  google::LogMessage::~LogMessage()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4254971789  ray::RayLog::~RayLog()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b51ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b52ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b5491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f42546b7801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4254638ed6  ray::CoreWorker::CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993dd27a8  ray::gcs::GlobalStateAccessor::Connect()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f2993d43a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c48b98a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41bb08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a66a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41cde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a6baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c41cde6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a66a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4a7454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c535bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c535c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c567d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c430625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c430a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4318cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c56a829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245d96ca2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f167698a  method_vectorcall_NOARGS\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1606b08  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16916a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692a20  method_vectorcall\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1607de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1691baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1607de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16916a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1692454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1720bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1720c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3284c14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f3285e82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd5c14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd6e82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463cc14  ray::CoreWorkerProcess::CreateWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463de82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x7f29954cb840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=308)\u001b[0m     @     0x563b5c4fab33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1752d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161b625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161ba0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f161c8cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f1755829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x7f245f0f4840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=329)\u001b[0m     @     0x55d7f16e5b33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f328684b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f31c4448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f31c5ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253bd784b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253b15448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1253b16ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425463e84b  ray::CoreWorkerProcess::Initialize()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425457c448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f425457dba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad7337d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1cb37d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d253d09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d218baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d219643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d18ede6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2186a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d219454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2a7bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2a7c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2d9d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a2625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a2a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f801b37d  _PyObject_MakeTpCall\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80a3d09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8068baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8069643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7fdede6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80686a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8069454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80f7bbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80f7c64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f8129d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff2625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff2a0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadfbd09  _PyEval_EvalFrameDefault\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc0baf  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc1643  _PyFunction_Vectorcall.localalias.353\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad36de6  _PyEval_EvalFrameDefault.cold.2792\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc06a2  _PyEval_EvalCodeWithName\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fadc1454  PyEval_EvalCodeEx\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae4fbbc  PyEval_EvalCode\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae4fc64  run_eval_code_obj\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae81d14  run_mod\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4a625  PyRun_FileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4aa0a  PyRun_SimpleFileExFlags\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fad4b8cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d1a38cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d2dc829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x7f92f4907840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=437)\u001b[0m     @     0x55917d26cb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f7ff38cf  Py_RunMain.cold.2911\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f812c829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x7f1255258840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=401)\u001b[0m     @     0x55c7f80bcb33  (unknown)\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae84829  Py_BytesMain\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x7f4255cbf840  __libc_start_main\n",
-      "\u001b[2m\u001b[36m(pid=363)\u001b[0m     @     0x5609fae14b33  (unknown)\n",
-      "2020-10-13 12:32:56,926\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffdf5a1a8201000000.\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.915767   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.929625   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
-      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1013 12:32:56.932425   265   265 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n"
+      "2020-11-03 18:08:58,480 - wandb.wandb_agent - INFO - Running runs: ['dy77i2y1']\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent kitgghxj"
+    "!wandb agent kkxvg8te"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index 46f4d10..4729210 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -6,7 +6,7 @@ default_config = {
     'env': 'jss_env',
     'seed': 0,
     'framework': 'torch',
-    'log_level': 'INFO',
+    'log_level': 'WARN',
     'num_gpus': 1,
     'instance_path': '/JSS/JSS/env/instances/ta51',
     'num_envs_per_worker': 2,
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index d4ac941..85598f6 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -50,7 +50,7 @@ def train_func():
     ray.init()
 
     stop = {
-        "time_total_s": 60 * 60,
+        "time_total_s": 10 * 60,
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
diff --git a/JSS/MTWR.py b/JSS/MTWR.py
index 1b7b946..37944ef 100644
--- a/JSS/MTWR.py
+++ b/JSS/MTWR.py
@@ -21,11 +21,11 @@ def MTWR_worker(default_config):
         real_state = np.copy(state['real_obs'])
         legal_actions = state['action_mask'][:-1]
         reshaped = np.reshape(real_state, (env.jobs, 7))
-        remaining_time = reshaped[:, 3]
+        remaining_time = (reshaped[:, 3] * env.max_time_jobs) / env.jobs_length
         illegal_actions = np.invert(legal_actions)
-        mask = illegal_actions * -1e8
+        mask = illegal_actions * 1e8
         remaining_time += mask
-        MTWR_action = np.argmax(remaining_time)
+        MTWR_action = np.argmin(remaining_time)
         assert legal_actions[MTWR_action]
         state, reward, done, _ = env.step(MTWR_action)
     env.reset()
diff --git a/JSS/PPO.ipynb b/JSS/PPO.ipynb
index 23b572b..c5ab352 100644
--- a/JSS/PPO.ipynb
+++ b/JSS/PPO.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 17,
    "metadata": {},
    "outputs": [
     {
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'MTWR.py',\n",
+    "        'program': 'train.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 18,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: po3ygyxo\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\n"
+      "Create sweep with ID: 1ke874jl\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/1ke874jl\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -100,425 +100,17471 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-14 20:43:27,735 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-14 20:43:31,145 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:31,145 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-14 20:43:31,147 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-05 10:06:11,479 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-05 10:06:11,801 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:06:11,801 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta40\n",
+      "2020-11-05 10:06:11,803 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta40\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:06:16,821 - wandb.wandb_agent - INFO - Running runs: ['6xs3d5g9']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9bbl2cxc\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204333-9bbl2cxc\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfluent-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/1ke874jl\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/6xs3d5g9\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_100613-6xs3d5g9\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:06:17,420\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_8c57e_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3282\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:36,159 - wandb.wandb_agent - INFO - Running runs: ['9bbl2cxc']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204333-9bbl2cxc/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204333-9bbl2cxc/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 197.38384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 197.38384\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3753\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708214\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9bbl2cxc\u001b[0m\n",
-      "2020-10-14 20:43:41,380 - wandb.wandb_agent - INFO - Cleaning up finished run: 9bbl2cxc\n",
-      "2020-10-14 20:43:41,772 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:41,772 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-14 20:43:41,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta52\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/frw3hck3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204343-frw3hck3\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m 2020-11-05 10:06:20,239\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m *** SIGSEGV (@0x0) received by PID 34526 (TID 0x7fc120d26700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7fc1208ff390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f9220774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fe9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m *** SIGSEGV (@0x0) received by PID 34535 (TID 0x7f71379cf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f71375a8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f423754df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236c787db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236c7b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m *** SIGSEGV (@0x0) received by PID 34536 (TID 0x7f598e0dc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f598dcb5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8dc51f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d37c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m *** SIGSEGV (@0x0) received by PID 34541 (TID 0x7f8d2924b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f8d28e24390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e28da4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e284cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m *** SIGSEGV (@0x0) received by PID 34559 (TID 0x7f3307d94700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f330796d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f04078def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f04070097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040700c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m *** SIGSEGV (@0x0) received by PID 34558 (TID 0x7f65445c1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f654419a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f364401cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f36437477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f364374a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m *** SIGSEGV (@0x0) received by PID 34561 (TID 0x7f2c27b9f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7f2c27778390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd2761ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m *** SIGSEGV (@0x0) received by PID 34507 (TID 0x7f62f2054700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f62f1c2d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f1becf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f13177db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m *** SIGSEGV (@0x0) received by PID 34556 (TID 0x7f420fc5d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f420f836390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130f7cef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eef97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m *** SIGSEGV (@0x0) received by PID 34516 (TID 0x7fc4af683700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7fc4af25c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95af124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae84f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m *** SIGSEGV (@0x0) received by PID 34514 (TID 0x7ff6316ae700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7ff631287390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc731225f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7309507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m *** SIGSEGV (@0x0) received by PID 34560 (TID 0x7ff7f76b6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7ff7f728f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f7229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f69547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m *** SIGSEGV (@0x0) received by PID 34531 (TID 0x7f94f6ac3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f94f669c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f64f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f5c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m *** SIGSEGV (@0x0) received by PID 34562 (TID 0x7fcd0a916700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7fcd0a4ef390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0a365f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09a907db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m *** SIGSEGV (@0x0) received by PID 34525 (TID 0x7f26566f7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7f26562d0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef756255f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef7559807db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef7559838f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef755983ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m *** SIGSEGV (@0x0) received by PID 34574 (TID 0x7f445ffe7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f445fbc0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f9c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f0f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f0f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f0f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f9220785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f92207a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fc4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fc48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236c7bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236c7bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f423755eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4237581c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236a23a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236a21388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d37f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d37fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d37fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8dc62b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8dc85c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e284d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e284d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040700cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040700cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f04078efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f0407912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f0406db4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f0406db2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f364374aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f364374ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f364402db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f3644050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f36434f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f36434f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd27630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd27653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f131a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f131aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f131ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f1bfdb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f1c20c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eefc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eefcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m *** SIGSEGV (@0x0) received by PID 34540 (TID 0x7f7d33366700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m *** SIGSEGV (@0x0) received by PID 34552 (TID 0x7f62284af700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m *** SIGSEGV (@0x0) received by PID 34449 (TID 0x7fe1389ae700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m *** SIGSEGV (@0x0) received by PID 34529 (TID 0x7fb60f918700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m *** SIGSEGV (@0x0) received by PID 34484 (TID 0x7fad7663d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m *** SIGSEGV (@0x0) received by PID 34483 (TID 0x7fa4f2e3e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m *** SIGSEGV (@0x0) received by PID 34539 (TID 0x7fb81f1e9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7fb81edc2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae8528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95af135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95af158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m *** SIGSEGV (@0x0) received by PID 34532 (TID 0x7f7bd5f27700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f7bd5b00390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd57f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7309538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc730953ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc730953d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc731236b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc731259c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m *** SIGSEGV (@0x0) received by PID 34460 (TID 0x7f98afeb5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m *** SIGSEGV (@0x0) received by PID 34521 (TID 0x7f1d773da700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7f1d76fb3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76e62f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m *** SIGSEGV (@0x0) received by PID 34458 (TID 0x7fbf48f82700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m *** SIGSEGV (@0x0) received by PID 34463 (TID 0x7fb7bdc32700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m *** SIGSEGV (@0x0) received by PID 34566 (TID 0x7faec3f15700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7faec3aee390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f69578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f6957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f6957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f723ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f725dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m *** SIGSEGV (@0x0) received by PID 34527 (TID 0x7fe82dfa1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fe82db7a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m *** SIGSEGV (@0x0) received by PID 34466 (TID 0x7f47421c3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f4741d9c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841d52f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f184147d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m *** SIGSEGV (@0x0) received by PID 34518 (TID 0x7f1f8ff4d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f5c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f5c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f5c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f59cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f59cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09a938f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09a93ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09a93d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0a376b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0a399c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m *** SIGSEGV (@0x0) received by PID 34530 (TID 0x7f247bf37700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m *** SIGSEGV (@0x0) received by PID 34464 (TID 0x7fc33844c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7fc338025390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m *** SIGSEGV (@0x0) received by PID 34553 (TID 0x7f045b66b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7f045b244390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55b115f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a8407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m *** SIGSEGV (@0x0) received by PID 34448 (TID 0x7f633f7c5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f633f39e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343f340f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m *** SIGSEGV (@0x0) received by PID 34477 (TID 0x7fd22bbd4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m *** SIGSEGV (@0x0) received by PID 34485 (TID 0x7f5b1245c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f5b12035390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c11e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m *** SIGSEGV (@0x0) received by PID 34502 (TID 0x7fa85f613700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7fa85f1ec390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795f124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef755983d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef756266b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef756289c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef75572ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m *** SIGSEGV (@0x0) received by PID 34468 (TID 0x7f326a1f3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f0f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f9d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f9f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155ee9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155ee99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m *** SIGSEGV (@0x0) received by PID 34546 (TID 0x7f17683e5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7f1767fbe390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee867d2cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee8674577db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m *** SIGSEGV (@0x0) received by PID 34446 (TID 0x7f9ea8c8b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m *** SIGSEGV (@0x0) received by PID 34452 (TID 0x7fb231167700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m *** SIGSEGV (@0x0) received by PID 34506 (TID 0x7f6724264700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f6723e3d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f3823ddef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f38235097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m *** SIGSEGV (@0x0) received by PID 34549 (TID 0x7fee6e622700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fee6e1fb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6e13af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d8657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m *** SIGSEGV (@0x0) received by PID 34545 (TID 0x7f7a0aed8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f7a0aab1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0aa24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a14f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m *** SIGSEGV (@0x0) received by PID 34475 (TID 0x7ff2c375c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m *** SIGSEGV (@0x0) received by PID 34522 (TID 0x7fad39422700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7fad38ffb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m *** SIGSEGV (@0x0) received by PID 34528 (TID 0x7f8b84a04700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m *** SIGSEGV (@0x0) received by PID 34509 (TID 0x7fabdb85a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7fabdb433390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f921fc4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f92203354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f4236a235a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f423710e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d127a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d125388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d1275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e284d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e28db5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e28dd8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e2827aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f0406db45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f04099728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f36434f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd26af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f10c2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f10c0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f10c25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eefcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130f7dfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130f802c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eca4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f7d32f3f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32ed3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e325fe7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e326018f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m *** SIGSEGV (@0x0) received by PID 34447 (TID 0x7f2cc33e3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7f2cc2fbc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc263e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f6228088390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3327eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f33275e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f33275e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fe138587390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb238521f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb237c4c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7fb60f4f1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870f48ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870ebba7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870ebbd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m *** SIGSEGV (@0x0) received by PID 34455 (TID 0x7f00f147c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7f00f1055390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m *** SIGSEGV (@0x0) received by PID 34459 (TID 0x7fb988fa5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7fb988b7e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m *** SIGSEGV (@0x0) received by PID 34480 (TID 0x7f0858dc1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7f085899a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed958825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m *** SIGSEGV (@0x0) received by PID 34524 (TID 0x7f6b2e80e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f6b2e3e7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2e34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2da767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m *** SIGSEGV (@0x0) received by PID 34454 (TID 0x7f548d366700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f548cf3f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258cea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c5cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7fad76216390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e7613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e758657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e758688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7fa4f2a17390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f299ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f20ca7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m *** SIGSEGV (@0x0) received by PID 34476 (TID 0x7f7097308700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f7096ee1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196e93f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891ecfcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e4277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e42a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae5faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae5f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95ae5fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7306fba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7306f9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7306fb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f98afa8e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69afa42f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af16d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af1708f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee7658d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee765908f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m *** SIGSEGV (@0x0) received by PID 34467 (TID 0x7fd0b9120700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7fbf48b5b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9048b0ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904823a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904823d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7fb7bd80b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bd6f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bce1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bce228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m *** SIGSEGV (@0x0) received by PID 34474 (TID 0x7f6b6ac7f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f6b6a858390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6a70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69e357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69e388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m *** SIGSEGV (@0x0) received by PID 34511 (TID 0x7f9171dcb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f91719a4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f62717f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m *** SIGSEGV (@0x0) received by PID 34453 (TID 0x7fe05a20b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fe059de4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb159d77f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1594a27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1594a58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc3a88f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc31b37db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc31b68f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f66ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f66fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f66ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m *** SIGSEGV (@0x0) received by PID 34503 (TID 0x7f734b119700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f734acf2390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444ac8ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a3ba7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a3bd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92da0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d1357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d1388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f18414808f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841480ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7f1f8fb26390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f9c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f0f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f0f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m *** SIGSEGV (@0x0) received by PID 34462 (TID 0x7fac0706e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7fac06c47390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d06ad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d061fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d061ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f59cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0983ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09839388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0983b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m *** SIGSEGV (@0x0) received by PID 34457 (TID 0x7fb4ebb0d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7fb4eb6e6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eb61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85ead4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85ead4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7f247bb10390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57bab5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b1e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b1e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9437eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f94375e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f94375e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f94375e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a8438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a843ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a843d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m *** SIGSEGV (@0x0) received by PID 34461 (TID 0x7fbc27b14700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7fbc276ed390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d2761ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ea6b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ea6e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ea6ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m *** SIGSEGV (@0x0) received by PID 34533 (TID 0x7eff865d1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fd22b7ad390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32b61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32ad4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32ad4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c1154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c115528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c11552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e84f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e8528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef755729388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef75572b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef755e164f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef7582e98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m *** SIGSEGV (@0x0) received by PID 34450 (TID 0x7f45f6a4c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f45f6625390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f65a4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5ccf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5cd28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f3269dcc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369d52f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f036947d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f03694808f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155ee9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f1561a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m *** SIGSEGV (@0x0) received by PID 34555 (TID 0x7f9c13380700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f9c12f59390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d12cfcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d124277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d1242a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m *** SIGSEGV (@0x0) received by PID 34570 (TID 0x7f1c21b7e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7f1c21757390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed216f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee86745a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee86745aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m *** SIGSEGV (@0x0) received by PID 34451 (TID 0x7f59122e7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f5911ec0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a11e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a1154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a115528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m *** SIGSEGV (@0x0) received by PID 34564 (TID 0x7f2dba24d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7f2db9e26390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb9db7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb94e27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb94e58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m *** SIGSEGV (@0x0) received by PID 34519 (TID 0x7ff8ee637700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7ff8ee210390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ee13af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed8657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m *** Aborted at 1604570785 (unix time) try \"date -d @1604570785\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m *** SIGSEGV (@0x0) received by PID 34520 (TID 0x7f5f0938e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f5f08f67390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f30085cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f9ea8864390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa874cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7e777db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m *** SIGSEGV (@0x0) received by PID 34550 (TID 0x7ff456cca700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7ff4568a3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc5567bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7fb230d40390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f8330c74f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f833039f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83303a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f382350c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f382350cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m *** SIGSEGV (@0x0) received by PID 34544 (TID 0x7f7877d3e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m *** SIGSEGV (@0x0) received by PID 34471 (TID 0x7fdc52142700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fdc51d1b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad51c0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad513387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d8688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a1528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a152ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a152d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0aa35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0aa58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7ff2c3335390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c3229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c29547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m *** SIGSEGV (@0x0) received by PID 34523 (TID 0x7f0fcb22d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7f0fcae06390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0caa13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca13e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca1418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38f4ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3867a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3867d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3867dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f8b845dd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c84339f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83a647db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83a678f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m *** SIGSEGV (@0x0) received by PID 34554 (TID 0x7f9d7928e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f9d78e67390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e78dd2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e784fd7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdb229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda9547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda9578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f92228088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f92203354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x7f92263e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11269fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f1124fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11250a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f1124fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f1124fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f1124fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f1124fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f11250643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34526)\u001b[0m     @     0x560f111c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f42395e18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f423710e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x7f423d1b979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743908fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743863b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438efa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743863bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x5637438ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34535)\u001b[0m     @     0x563743864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d8124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8fce58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a8d8124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x7f2a938bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x5605132adfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513208b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513294a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513208bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e28278388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e2827a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e289654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e2ae388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x7f040d54a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x5565854a9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585404b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x55658548fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585490a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585404bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x55658548fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585490643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585405689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x55658548fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585490643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585405689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x55658548fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585490643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585405689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x55658548fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585490643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34559)\u001b[0m     @     0x556585405689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f3643bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f36460b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f3643bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x7f3649c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d22fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d09a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376d09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34558)\u001b[0m     @     0x55d376c7e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd296b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x7efd2d28b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad95afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad940baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad941a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad940baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad941643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad940baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad941643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad940baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad941643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad940baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad941643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34561)\u001b[0m     @     0x5568ad8b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f17ad4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f3c808de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f17ad4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x7f33f785879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf565fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eca2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130eca45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130f38f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f13118628de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32601ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32601d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32ee4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32f07c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc26418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f33275e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f33275e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3327ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3327eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb237c4f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb237c4fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb237c4fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb238532b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb238555c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870ebbdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870ebbdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870f4a0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870f4c3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870e965a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f05cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f05d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f05d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a889e8f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a881137db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a881168f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a88116ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m *** SIGSEGV (@0x0) received by PID 34547 (TID 0x7ff1ab3bc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7ff1aaf95390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aaf13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2da798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2da79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2da79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c5d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c5d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c5d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258ceb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e75868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e75868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e7614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e7616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f20cd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f20cdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f20cdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f29b0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f41965be7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f41965c18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f41965c1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e42aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e42ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891ed0db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891ed30c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95aece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95b11b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95aece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x7f95b4d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bf0bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be66b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be66bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43bef2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34516)\u001b[0m     @     0x55b43be67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc730de64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc7332b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc730de64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x7fc736e9179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e907fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e862b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8edbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8eea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e862bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8edbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8ee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e863689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8edbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8ee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e863689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8edbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8ee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e863689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af170ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af170d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69afa53b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69afa76c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76590ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76590d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76e73b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76e96c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76338a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fd0b8cf9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b8bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b82fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904823dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904823dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9048b20b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bce22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bce22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bd705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bd728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69e38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69e38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1594a5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1594a5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc31b6ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc31b6d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc3a99b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc3abcc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f92bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8f6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x7fc8fce9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166c8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816623b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166afa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816623bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816624689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a3bdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92da1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92da3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841480d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841d63b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841d86c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841228a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1841226388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f0f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f0f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f9d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f9f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d061ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65f60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x7f65fc16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ad1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46ab8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34531)\u001b[0m     @     0x559e46a2d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09f264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0c3f98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e09f264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x7f9e0ffd179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d9701fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85ead4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b1e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b1e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57bac6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57bae9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f94375e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9437ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9437eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55b126b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55b149c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a5eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a5e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d27630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ea6ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343f351b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343f374c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343e816a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7eff861aa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed08613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed0858657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32ad4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32ad4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32b630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c11552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c11e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c11e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795f135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795f158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef755e164f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x7ef75bec179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3ccb4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc0fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc0fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34525)\u001b[0m     @     0x564f3cc10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5cd2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5cd2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369480ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369480d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369d63b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369d86c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f155f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x7f156563179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb36cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb353a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb352baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb353643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34574)\u001b[0m     @     0x563bdb2c8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d1242aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d1242ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee86745ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee867d3db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee867d60c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee867202a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee867200388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a11552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a11552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb94e5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb94e5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb9dc8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb9debc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed8688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f30085d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f30085d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f30085d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7e7a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc5567ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83303a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83303a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f8330c85b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f8330ca8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f382350cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f3823defb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f3823e12c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f38232b4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f38232b2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f7877917390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49778b1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976fdc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad5133b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad5133bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad5133bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6e14bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6e16ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b09efaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b09ef8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b09efa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c29578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca141ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca141d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83a67ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83a67d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c8434ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdb23ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdb25dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513293baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513294643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34536)\u001b[0m     @     0x560513209689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e289654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x7f5e2ea1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2908fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2863b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28efa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2863bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e28ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34541)\u001b[0m     @     0x55d6e2864689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf54c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34507)\u001b[0m     @     0x559ddf4c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f130f38f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x7f131543a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d88fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e323a9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e323a7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc23e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc23e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f332738ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f332738a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f332738c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb2379f7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb2379f5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb2379f75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870e963388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870e9655a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870f0504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f87115238de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f05d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f037aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a88116d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a889f9b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a88a1cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a87ebea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a87ebc388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aaf24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aaf47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed958836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed958859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2e35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2e37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2d821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2d81f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2d8215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258ced8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c37aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258c37a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e75610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e7560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e756105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f29d3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f1e75a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f1e73388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f1e755a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f41965c1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196ea4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196ec7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196369a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196367388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e1d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e1d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e1d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd4ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8edbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e8ee643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34514)\u001b[0m     @     0x56042e863689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69aef18a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69aef16388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69aef185a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76336388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee763385a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76a234f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b82ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9048b43c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9047fe5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9047fe3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f9047fe55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bcbcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bcbc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bcbca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6a71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6a73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69be0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69bde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f627180ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f627182dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb159d88b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb159dabc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb15924da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb15924b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc2f5ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc2f5c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc2f5e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816624689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816624689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166aebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c8166af643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34560)\u001b[0m     @     0x55c816624689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a3bdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444aca0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444acc3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a165a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a163388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92cee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92cede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92cee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f18412285a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f18419134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f1843de68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08ee9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08ee99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08ee9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d061ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d06ae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d06b05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d05fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d05fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d96e8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34562)\u001b[0m     @     0x5622d965d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85ead4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eb630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eb653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eaaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eaaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57af8ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57af89388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57af8b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f943738ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f943738a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f943738c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55a5eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55acd64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55d1a98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d27653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d26af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343e814388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343e8165a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ef014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed0858688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32b653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32aaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32aaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32aaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c112faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c112f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c112fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e5faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e5f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795e5fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795ece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f65b5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f65d8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5a7aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5a78388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369228a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f0369226388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f03692285a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d12d0db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d12d30c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d121d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d121d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d121d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed21705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed21728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed20bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee8672025a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee8678ed4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a11e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a11e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a112faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a112f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb928da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb928b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb928d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ee14bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ee16ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed60e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f300837aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7e7aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc5567efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f833014aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f8330148388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f833014a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f38232b45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f382399f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f3825e728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976fdf8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976fdfad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad51c1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad51c41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad510e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad510e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad510e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d60e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6d6105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6dcfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf701ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a5e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0cab88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b0a5e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x7f4b1069079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015bbbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b16b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b16bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015ba2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34545)\u001b[0m     @     0x55f015b17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c2957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c2957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0caa24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0caa47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0c9ee9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0c9ee7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0c9ee95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3867dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38f60b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38f83c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38425a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38423388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e384255a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c8436dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c8380fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c8380d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c8380f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e785008f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda6ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda6fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cda6ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34556)\u001b[0m     @     0x55d6c1ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e323a95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32a944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e34f678de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc23e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc4fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3327a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3329f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f3327a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x7f332db2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x5615047a7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504702b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504702bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb2380e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb23a5b58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f870f0504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x7f87150fb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa40ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa3f6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34529)\u001b[0m     @     0x5606fa36b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f037a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a87ebe5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a885a94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aa3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed957cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed9583e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c303df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258ca654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258ef388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f258ca654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x7f2592b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560609fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560564b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605efbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605f0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560564bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605efbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605f0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560565689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605efbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e75cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e781ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e75cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f25604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f4a338de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f41963695a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196a544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e8bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f8920d908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f891e8bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x7f892496879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc70fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc57a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc56baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfc57643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34539)\u001b[0m     @     0x55f9bfbcc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cd53ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x7f4cdb46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d38afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d370baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d371a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d370baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d371643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d370baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d371643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d370baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d371643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d370baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d371643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34532)\u001b[0m     @     0x55750d2e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af6034f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69b1ad68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69af6034f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x7f69b56ae79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fdefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee78ef68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee76a234f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x7eee7cace79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa102fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa0e9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34521)\u001b[0m     @     0x55faaa05e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b82ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f90486d04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904aba38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bd2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bf7888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88bd2b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c69be05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6a2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6c79e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f6270ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f62713ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb15924d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1599384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb15be0b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc36494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc5b1c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc36494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a1655a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a8504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444cd238de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92fa9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb92d5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x7fb93367679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d74fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0ccfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f18419134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x7f18479be79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef91fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeecb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef78a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeecbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821ef78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34466)\u001b[0m     @     0x55821eeed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef091a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef08f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x7ef09563179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d05fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d066924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d08b658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eaaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eb1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85ed6b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b6764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57db498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef57b6764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9437a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9439f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f9437a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x7f943db2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51083fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa5106aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa5106a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa5106a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa5106a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa51069baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa5106a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34464)\u001b[0m     @     0x55aa50fdf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed55acd64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x7ed560d8179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056decfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d47b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d47bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d48689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d48689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d48689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056dd3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34553)\u001b[0m     @     0x559056d48689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d296b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f34413d48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f343ef014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x7f3444fac79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff333fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff31aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34448)\u001b[0m     @     0x55f7ff28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed085868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed085868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32d6b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c13eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x7f2c17a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a8475fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a845c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34485)\u001b[0m     @     0x55f2a83d1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f79611b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f795ece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x7f7964d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c743fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c729baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c72aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c729baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c72a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c729baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c72a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c729baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c72a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c729baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c72a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34502)\u001b[0m     @     0x56359c69f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f5a7a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f61654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f86388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16f61654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x7f16fc21079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65c4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe651fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe651fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe6520689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe6520689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f03699134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f036bde68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f03699134f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x7f036f9be79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61f4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b614fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b614fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61db643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b6150689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61db643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b6150689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61db643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b6150689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61dabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b61db643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34468)\u001b[0m     @     0x5567b6150689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d128bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d14d908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d128bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x7f6d1896879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ec3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55eaaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed212b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed237888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed212b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x7eed2736079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f27fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e82b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e82bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e83689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e83689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee869dc08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee8678ed4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x7ee86d99879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b6bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b52a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b51baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329b52643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34546)\u001b[0m     @     0x55e329ac7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a112fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a13eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a119e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x7f2a17a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x56310029efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001f9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100284baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100285a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001f9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100284baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100285643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100284baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100285643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb99784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efebbe4b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efeb99784f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x7efebfa2379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28453fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283aeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9ed6105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9edcfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9f01ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f300837a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f300af388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f3008a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7e7ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa875db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa8780c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc555c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc55637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc55884f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc55637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83308354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f8332d088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83308354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x7f83368e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593841fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593827baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593828a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593827baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593828643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593827baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593828643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f382399f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x7f3829a4a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a499fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a47fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a480a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a47fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a480643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a47fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a480643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a47fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a480643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a47fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a480643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34506)\u001b[0m     @     0x562d4a3f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976fdfd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad517ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad53ca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf6dcfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x7fbf73da679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e63dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e598b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e624a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e598bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e623baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e624643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34549)\u001b[0m     @     0x55af6e599689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c26ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c26fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca5d44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ccaa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0ca5d44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38b104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3afe38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e38b104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83efa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c863cd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e78500ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e78500d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdd2bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7cdadea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x7f7ce0e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddd09fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc64b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcefbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcf0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc64bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcefbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcf0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc65689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcefbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcf0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc65689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcefbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcf0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc65689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcefbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddcf0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34509)\u001b[0m     @     0x5622ddc65689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e32a944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x7f4e38b3f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da4dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da33baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da34a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da33baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da34643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da33baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da34643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da33baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da34643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da33baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3da34643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34540)\u001b[0m     @     0x557e3d9a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc2ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x7efdc8b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e88448fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e8842f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34447)\u001b[0m     @     0x561e883a4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504703689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504703689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504703689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x56150478e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34552)\u001b[0m     @     0x561504703689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb2380e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x7fb23e18d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bf2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862bd9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34449)\u001b[0m     @     0x55f862b4e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f2f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f0a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x7ed1f6b1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda22fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda09a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda08baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cda09643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34455)\u001b[0m     @     0x5609cd97e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a8aa7c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a885a94f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x7f8a8e65479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c26bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c251baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c252a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c251baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c252643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c251baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c252643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c251baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c252643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c251baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c252643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34459)\u001b[0m     @     0x55ff9c1c7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aaad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2acfa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2aaad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x7fc2b0b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d88fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31d6f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34547)\u001b[0m     @     0x559d31ce4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed95a8b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed9583e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x7ed95e49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dd0bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc66b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc66bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dcf2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34480)\u001b[0m     @     0x55fa1dc67689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c2df0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x7f3c33fb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2dd0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2db7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34524)\u001b[0m     @     0x55efd2d2c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605f0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560565689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605efbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605f0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560565689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605efbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a5605f0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34454)\u001b[0m     @     0x55a560565689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x7f7e7bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a282fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1ddb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a268baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a269a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1ddbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a268baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a269643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1de689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a268baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a269643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1de689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a268baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a269643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1de689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a268baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a269643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34484)\u001b[0m     @     0x56149a1de689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f25604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x7f75f860b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c45fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6c2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34483)\u001b[0m     @     0x558dd6ba1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4198f278de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f4196a544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x7f419caff79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c24fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b7fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b7fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f39b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f39bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f3a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f3a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f3a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43fc5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34460)\u001b[0m     @     0x560e43f3a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b82ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b8be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b8c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b80a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b80a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f90486d04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x7f904e77b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb20efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb169b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb169bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb16a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb16a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb16a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb1f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34458)\u001b[0m     @     0x55bedb16a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x7f88c336079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2df08fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de63b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deefa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de63bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2deef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34463)\u001b[0m     @     0x557a2de64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c6a2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x7f3c7037679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d84dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d833baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d834a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d833baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d834643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d833baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d834643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d833baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d834643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d833baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d834643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34474)\u001b[0m     @     0x55e50d7a9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f627388d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f62713ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x7f627746579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512f7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851252b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512dea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851252bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851253689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851253689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851253689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512ddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x5598512de643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34511)\u001b[0m     @     0x559851253689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb1599384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x7fb15f9e379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a5a5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a500b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a500bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a501689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a501689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a501689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a58c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34453)\u001b[0m     @     0x560b4a501689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x7f7fc96f479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5c7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d522b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5aea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d522bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d523689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d523689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d523689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d5ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34566)\u001b[0m     @     0x564a2d523689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f444a8504f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x7f44508fb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7438fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7393b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7393bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7394689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7394689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7394689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be741f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34503)\u001b[0m     @     0x561be7394689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0ccfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0cd0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0cd0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0cd0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0d5b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34527)\u001b[0m     @     0x55faa0cd0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54869fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad5484fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54850a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad5484fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad5484fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad5484fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad5484fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad54850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34518)\u001b[0m     @     0x55ad547c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d066924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x7f7d0c73d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965943fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965929baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96592aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965929baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96592a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965929baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96592a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965929baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96592a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d965929baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96592a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34462)\u001b[0m     @     0x55d96589f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85eb1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x7f85f128b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba5214fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba516fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba516fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba5170689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba5170689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba5170689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba51fb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34457)\u001b[0m     @     0x55aba5170689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x7ef58172179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06dbbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d16b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d16bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06da2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34530)\u001b[0m     @     0x55bb06d17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d271e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x7f8d2d28b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x56412486dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124853baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124854a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124853baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124854643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124853baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124854643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124853baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124854643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124853baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x564124854643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34461)\u001b[0m     @     0x5641247c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed08614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed08616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed085610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed08560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed0856105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa32b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x7fa33128b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287e8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028743b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028743bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028744689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028744689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028744689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x5570287cf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34477)\u001b[0m     @     0x557028744689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe6520689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe65ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34450)\u001b[0m     @     0x560fe6520689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55ea9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55eaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34555)\u001b[0m     @     0x561d55e1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e83689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98f0e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34570)\u001b[0m     @     0x558c98e83689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100284baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100285643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100284baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x563100285643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34451)\u001b[0m     @     0x5631001fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e2843aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283aebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e2843a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e2843a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e2843a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e28439baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e2843a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34564)\u001b[0m     @     0x562e283af689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9edcfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x7fc9f3da679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c46ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c455baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c456a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c455baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c456643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c455baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c456643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c455baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c456643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c455baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c456643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34519)\u001b[0m     @     0x55717c3cb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x7f300eb1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebcbffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebca6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34520)\u001b[0m     @     0x55a6ebc1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7c22a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7c20388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x7fc55c42779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c236fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c191b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c191bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c192689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c192689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c192689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c21d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34550)\u001b[0m     @     0x55fa3c192689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593827baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593828643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593827baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x559593828643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34452)\u001b[0m     @     0x55959379d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49778c2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49778e5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976d87a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976d85388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f4976d875a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad517ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x7fad5787979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf46fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaf2d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34471)\u001b[0m     @     0x55d8aaea2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c26ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c52bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x7ee0d047779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd869fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd84fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd850a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd84fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd84fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd84fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd84fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd850643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34523)\u001b[0m     @     0x55d2fd7c5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x7f7e3ebbb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e68bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e671baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e672a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e671baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e672643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e671baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e672643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e671baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e672643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e671baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e672643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34522)\u001b[0m     @     0x55656e5e7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c83efa4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x7f5c89fa579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb40fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb26baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb27a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb26baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb27643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb26baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb27643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb26baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb27643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb26baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fb27643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34528)\u001b[0m     @     0x56274fa9c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e78de3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e78e06c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e782a8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e782a6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e782a85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487c0b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34476)\u001b[0m     @     0x556487b80689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b80a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b87924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed085cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed0881ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed085cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x7ed08bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd34fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc8fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa7c225a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa830d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6faa7e08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49774724f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49799458de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x7fc3c8e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c91bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c876b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c901baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c902a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c876bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c901baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c902643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c877689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c901baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c902643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c877689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c901baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c902643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c877689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c901baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c902643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34475)\u001b[0m     @     0x560b3c877689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e789934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e7ae668de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e789934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1bac658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1b87924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x7fa1be83d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0af4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a4fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a4fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a50689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a50689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a50689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0adb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34467)\u001b[0m     @     0x558de0a50689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc8fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc90689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc90689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc90689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dd1b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34533)\u001b[0m     @     0x560e5dc90689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fa830d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x7f6fae3b879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac76efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6c9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac754baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac755a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6c9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac754baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac755643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6ca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac754baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac755643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6ca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac754baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac755643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6ca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac754baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac755643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34446)\u001b[0m     @     0x5562ac6ca689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f49774724f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x7f497d51d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f61942cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619387b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619412baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619413a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619387bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619412baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619413643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619388689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619412baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619413643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619388689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619412baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619413643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619388689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619412baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619413643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34544)\u001b[0m     @     0x55f619388689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x7f6e7ea3e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e273fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1ceb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e259baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e25aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1cebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e259baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e25a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e259baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e25a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e259baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e25a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e259baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e25a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=34554)\u001b[0m     @     0x55c04e1cf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:06:25,970\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:06:25,998\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.\n",
+      "2020-11-05 10:06:25,999\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.\n",
+      "2020-11-05 10:06:25,999\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.\n",
+      "2020-11-05 10:06:25,999\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "2020-11-05 10:06:26,019\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff091d563401000000.\n",
+      "2020-11-05 10:06:26,020\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:06:26,030\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff90aded9101000000.\n",
+      "2020-11-05 10:06:26,031\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "2020-11-05 10:06:26,051\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:06:26,051\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.\n",
+      "2020-11-05 10:06:26,054\tERROR trial_runner.py:567 -- Trial PPO_jss_env_8c57e_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=34568, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 20.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_8c57e_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_8c57e_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_8c57e_00000_0_2020-11-05_10-06-18/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048283 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=d984ee9d41b92c534100f4fd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048418 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048475 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048625 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c41da4ee8b0b4d04100f4fd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048743 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048810 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1e9c16c25b494a4a43fb47bd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048866 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.048974 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=61afdfe40390d0a343fb47bd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049086 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=7dd3b2683d323ffd31c3fed901000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049144 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=0a51bbe8b791810831c3fed901000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049249 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8b485cbbeaa005a559d91ef301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "2020-11-05 10:06:26,062\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049304 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "2020-11-05 10:06:26,063\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049355 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ca546fa1af7e507159d91ef301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=59d91ef301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049455 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=5cf29c5b7b7ed08d56c9ec1501000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049553 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=f4d9d8a5e202b0910314ce3001000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049616 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=8b0b449b9f08d0430314ce3001000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049716 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049783 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049888 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.049944 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.0== Status ==\n",
+      "Memory usage on this node: 20.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_8c57e_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_8c57e_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_8c57e_00000_0_2020-11-05_10-06-18/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "50058 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=726b8519c6d92b8e8168b55d01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050107 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e8fef079b20e071c8168b55d01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050204 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1f6f5417a7b065f9091d563401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050256 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e76b5820fbdeb0f2091d563401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050357 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=efaf5dbfabc208739f3cc57a01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050426 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=b3b45bae970c41729f3cc57a01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050531 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=37f0cff2c5fdc1c790aded9101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050586 34568 35650 task_manager.cc:323] Task f\n",
+      "ailed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=ff02fc67a478da9090aded9101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050680 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=bf6cd9795b8b23124e242e9f01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050729 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c5da4173a1c517cf4e242e9f01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050827 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=3e4916e36cb3ce60252160a301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050880 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c2d663ba592886f5252160a301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.050979 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9ecf84e34eb8e61dc2621d1401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.051035 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f3cba62d4c01820bc2621d1401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:25.967126 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:25.986599 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:25.987879 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:25.993906 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:25.995369 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.012833 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.014303 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.014788 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.016731 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.018128 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.018208 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.018252 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.018616 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.020604 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.023252 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:26.040598 34405 34405 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_8c57e_00000])\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.057854 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.057962 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=eb0057ff902d31287ef9157101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=7ef9157101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058038 34568 35650 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c72f258bb1224db7ef9157101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=7ef9157101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058202 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058391 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=37f711ca0d66f5bd4100f4fd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4100f4fd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058578 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3372\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:46,790 - wandb.wandb_agent - INFO - Running runs: ['frw3hck3']\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058769 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=10a4a4113c6c36ea43fb47bd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34340\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.058946 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d7b1ed864d13e17f31c3fed901000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=31c3fed901000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059301 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=457f03c785986c89252160a301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=252160a301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059365 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=4f22c19b5f703db99f3cc57a01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=9f3cc57a01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059480 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=626c71df3976eafd4e242e9f01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059653 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=7249131d8582b825091d563401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=091d563401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059824 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.059988 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=575b3faf45c7d0bd8168b55d01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.060155 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=ad47e6e6a1a1660b0314ce3001000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=0314ce3001000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[36m(pid=34568)\u001b[0m E1105 10:06:26.060376 34568 35650 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=6b6365ef3364d41390aded9101000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=90aded9101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error --- 2.09MB of 2.09MB uploaded (0.00MB deduped)\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204343-frw3hck3/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204343-frw3hck3/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 163.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 163.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3871\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 2\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708225\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_100613-6xs3d5g9/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_100613-6xs3d5g9/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/frw3hck3\u001b[0m\n",
-      "2020-10-14 20:43:52,006 - wandb.wandb_agent - INFO - Cleaning up finished run: frw3hck3\n",
-      "2020-10-14 20:43:52,326 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:43:52,327 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
-      "2020-10-14 20:43:52,329 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta53\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfluent-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/6xs3d5g9\u001b[0m\n",
+      "2020-11-05 10:06:37,699 - wandb.wandb_agent - INFO - Cleaning up finished run: 6xs3d5g9\n",
+      "2020-11-05 10:06:38,027 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:06:38,027 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta41\n",
+      "2020-11-05 10:06:38,029 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta41\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:06:43,047 - wandb.wandb_agent - INFO - Running runs: ['d7n056b5']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/o0hyb863\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204354-o0hyb863\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdulcet-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/1ke874jl\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/d7n056b5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_100639-d7n056b5\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:06:43,676\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_9bf91_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:43:57,342 - wandb.wandb_agent - INFO - Running runs: ['o0hyb863']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204354-o0hyb863/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204354-o0hyb863/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 180.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 180.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3790\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708235\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/o0hyb863\u001b[0m\n",
-      "2020-10-14 20:44:02,563 - wandb.wandb_agent - INFO - Cleaning up finished run: o0hyb863\n",
-      "2020-10-14 20:44:02,910 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:02,911 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta54\n",
-      "2020-10-14 20:44:02,913 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta54\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/802owiob\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204405-802owiob\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m 2020-11-05 10:06:46,485\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m *** SIGSEGV (@0x0) received by PID 36143 (TID 0x7f63a8291700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m *** SIGSEGV (@0x0) received by PID 36101 (TID 0x7fc316570700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m *** SIGSEGV (@0x0) received by PID 36088 (TID 0x7ffb1fc3e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m *** SIGSEGV (@0x0) received by PID 36014 (TID 0x7f5cc62c8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m *** SIGSEGV (@0x0) received by PID 36132 (TID 0x7fd9967ee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m *** SIGSEGV (@0x0) received by PID 36094 (TID 0x7f040bfbb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7f040bb94390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m *** SIGSEGV (@0x0) received by PID 36063 (TID 0x7fbc1cd3c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7fbc1c915390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1c56af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m *** SIGSEGV (@0x0) received by PID 36079 (TID 0x7f80312d1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m *** SIGSEGV (@0x0) received by PID 36026 (TID 0x7fd976518700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m *** SIGSEGV (@0x0) received by PID 36097 (TID 0x7f4463599700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m *** SIGSEGV (@0x0) received by PID 36118 (TID 0x7fa5e16f1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m *** SIGSEGV (@0x0) received by PID 36074 (TID 0x7fb30e9b7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7fb30e590390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840e4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840dc247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m *** SIGSEGV (@0x0) received by PID 36093 (TID 0x7fd4c1e90700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fd4c1a69390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c17f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m *** SIGSEGV (@0x0) received by PID 36127 (TID 0x7fdc21faa700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fdc21b83390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad21a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad211357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m *** SIGSEGV (@0x0) received by PID 36137 (TID 0x7f04fd069700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7f04fcc42390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fcb3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc2667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc2698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m *** SIGSEGV (@0x0) received by PID 36109 (TID 0x7f799d25c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f799ce35390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9cdc9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c4f47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m *** SIGSEGV (@0x0) received by PID 36140 (TID 0x7f81380f4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f8137ccd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5237af5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f52372207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m *** SIGSEGV (@0x0) received by PID 36092 (TID 0x7f53cf166700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f53ced3f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24cecfcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce4277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m *** SIGSEGV (@0x0) received by PID 36135 (TID 0x7fd239aed700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fd2396c6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa339674f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338d9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338da28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m *** SIGSEGV (@0x0) received by PID 36114 (TID 0x7faa2b0a9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7faa2ac82390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2abcef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a2f97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f63a7e6a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a7dc3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a74ee7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a74f18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7fc316149390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94160faf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94158257db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7ffb1f817390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1f7c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1eef07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f5cc5ea1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc5e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc554f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7fd9963c7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa9634bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m *** SIGSEGV (@0x0) received by PID 36110 (TID 0x7f8a1e29d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f8a1de76390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50baf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1bc957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1bc988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m *** SIGSEGV (@0x0) received by PID 36095 (TID 0x7f4ec4687700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f4ec4260390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f8030eaa390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5130e37f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f51305627db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7fd9760f1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa760a8f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa757d37db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f4463172390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15630f7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15628227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7fa5e12ca390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e124af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e09757db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m *** SIGSEGV (@0x0) received by PID 36011 (TID 0x7f641fc1b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f641f7f4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351f751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ee7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ee7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m *** SIGSEGV (@0x0) received by PID 36002 (TID 0x7f1db9758700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7f1db9331390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb92cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb89f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb89fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m *** SIGSEGV (@0x0) received by PID 36082 (TID 0x7ff892058700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7ff891c31390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc991becf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9913177db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc99131a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840dc278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840dc27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840dc27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840e50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840e52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840d9cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840d9cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840d9cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c180ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c182dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c0ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c13ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c388d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad211388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad21138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad21138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad21a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad21a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad20ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad20ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad20ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad215cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad23a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fcb4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fcb6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc00f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc0115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc6fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5febcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c4f78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c4f7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c4f7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9cddab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9cdfdc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c29fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c29d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c29f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c98a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9ee5d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f52372238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5237223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5237223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5237b06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5237b29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5236fcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5236fc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5236fcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce42a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce42aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce42ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ced0db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ced30c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce1d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce1d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce1d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce8bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24d0d908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338da2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338da2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa339685b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa3396a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338b4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338b48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa338b4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa3392354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa33b7088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a2fc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a2fcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a2fcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2abdfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2ac02c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a0a4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a0a2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a0a45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a78f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2cc628de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m *** SIGSEGV (@0x0) received by PID 36004 (TID 0x7f5ac06b8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f5ac0291390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bc00c0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf7eb7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf7ee8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m *** SIGSEGV (@0x0) received by PID 36030 (TID 0x7f0a747e7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7f0a743c0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb74363f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73a8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73a918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m *** SIGSEGV (@0x0) received by PID 36089 (TID 0x7f7dd522c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f7dd4e05390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed4d89f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed44b47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed44b78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m *** SIGSEGV (@0x0) received by PID 36133 (TID 0x7fa485123700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7fa484cfc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f7584bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75842fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m *** SIGSEGV (@0x0) received by PID 36075 (TID 0x7f4dc8372700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f4dc7f4b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec7e0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec75367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec75398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m *** SIGSEGV (@0x0) received by PID 36024 (TID 0x7fe626714700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fe6262ed390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb726279f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb7259a47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb7259a78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m *** SIGSEGV (@0x0) received by PID 36017 (TID 0x7f97bda55700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f97bd62e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bd5e4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcd0f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcd128f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcd12ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m *** SIGSEGV (@0x0) received by PID 36037 (TID 0x7fb5c4aa8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7fb5c4681390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c4563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a74f1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a74f1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a7dd4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a7df7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a7299a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a7297388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a72995a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a79844f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a9e578de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34a79844f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94158288f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f9415828ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f9415828d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f941610bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f941612ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94155d0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94155ce388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f94155d05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f9415cbb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f941818e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1eef38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1eef3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1eef3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1f7d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1f7f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1ec9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1ec99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1ec9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m *** SIGSEGV (@0x0) received by PID 36020 (TID 0x7fc01968c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7fc019265390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9119166f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f91188917db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f91188948f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9118894ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc55528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc5552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc5552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc5e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc5e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc52faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc52f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc52fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc59e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc7eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa9635cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa9637fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa9581f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa958215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa983df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1ddf7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d5227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d5258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d525ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d525d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1de08b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1de2bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d2cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d2cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d2cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50bb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50bb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50afcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50afc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50afcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50db898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1bc98ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1bc98d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1c57bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1c59ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1ba40a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1ba3e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1ba405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1c12b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1e5fe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d1c12b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x7f8d221d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f256155fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m *** SIGSEGV (@0x0) received by PID 36058 (TID 0x7fc105624700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7fc1051fd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92050b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92047e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92047e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92047e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92047e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92050c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92050e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc401cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc37477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc374a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc374aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc374ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc402db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc4050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc34f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc34f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc34f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m *** SIGSEGV (@0x0) received by PID 36103 (TID 0x7fd9a6dbc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7fd9a6995390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa67bbf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5ee67db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5ee98f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5ee9ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m *** SIGSEGV (@0x0) received by PID 36016 (TID 0x7f6d89393700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f6d88f6c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e885cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e885d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m *** SIGSEGV (@0x0) received by PID 36068 (TID 0x7fcd2858e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7fcd28167390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e27eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e275e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e275e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m *** SIGSEGV (@0x0) received by PID 36066 (TID 0x7f6a0a1ea700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f6a09dc3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b09d1df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b094487db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b0944b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m *** SIGSEGV (@0x0) received by PID 36099 (TID 0x7f1b1437a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7f1b13f53390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec13e0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec135367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m *** SIGSEGV (@0x0) received by PID 36077 (TID 0x7fd0c197f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fd0c1558390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c14e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m *** SIGSEGV (@0x0) received by PID 36023 (TID 0x7f392f26f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f392ee48390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2edf0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e51b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e51e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e51ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m *** SIGSEGV (@0x0) received by PID 36126 (TID 0x7fcd56343700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7fcd55f1c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e55e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e5554f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e555528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e55552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e55552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e55e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f51305658f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5130565ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5130565d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5130e48b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5130e6bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f513030da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f513030b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f513030d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f51309f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m *** SIGSEGV (@0x0) received by PID 36028 (TID 0x7f7c2d8da700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f7c2d4b3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2d3ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2caf77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2cafa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2cafaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2cafad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2d3ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2d400c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa757d68f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa757d6ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa757d6d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa760b9b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa760dcc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa7557ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa7557c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa7557e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15628258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1562825ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1562825d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1563108b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f156312bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15625cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15625cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f15625cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1562cb84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f156518b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m *** SIGSEGV (@0x0) received by PID 36013 (TID 0x7f130c073700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7f130bc4c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40baf5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b2207db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b2238f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b223ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b223d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40bb06b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m *** SIGSEGV (@0x0) received by PID 36080 (TID 0x7f9def83e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f9def417390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eef3cdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeeaf87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeeafb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeeafbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m *** SIGSEGV (@0x0) received by PID 36012 (TID 0x7f980a8fc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f980a4d5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690a467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f6909b927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f6909b958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f6909b95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m *** SIGSEGV (@0x0) received by PID 36081 (TID 0x7f430737b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f4306f54390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406ed3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f14065fe7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f14066018f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406601ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e09788f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e0978ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e0978d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e125bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e127ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e0720a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e071e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e07205a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e0e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e32de8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e0e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x7f76e6eb679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8b9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e814b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8a0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e814bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m *** SIGSEGV (@0x0) received by PID 36007 (TID 0x7f1538958700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7f1538531390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee6383e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637b0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637b118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637b11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m *** SIGSEGV (@0x0) received by PID 36027 (TID 0x7fc7575ac700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7fc757185390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9857124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f985684f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f98568528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9856852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m *** SIGSEGV (@0x0) received by PID 36085 (TID 0x7fe1b4e15700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fe1b49ee390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b4825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m *** SIGSEGV (@0x0) received by PID 36083 (TID 0x7f4de2474700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f4de204d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee1e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee15528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m *** SIGSEGV (@0x0) received by PID 36009 (TID 0x7f2a3d4da700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7f2a3d0b3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3cf4ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c67a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c67d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m *** SIGSEGV (@0x0) received by PID 36003 (TID 0x7fd28124f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fd280e28390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa380dd0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3804fb7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3804fe8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3804fead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m *** SIGSEGV (@0x0) received by PID 36070 (TID 0x7f1257d84700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7f125795d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee3578def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee3570097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35700c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m *** SIGSEGV (@0x0) received by PID 36102 (TID 0x7f1b6b4bc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7f1b6b095390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6b041f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a76c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a76f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m *** SIGSEGV (@0x0) received by PID 36078 (TID 0x7f90645fe700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f90641d7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6164101f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f616382c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m *** SIGSEGV (@0x0) received by PID 36005 (TID 0x7f3f39fd8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f3f39bb1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f1039b5ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103928a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103928d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103928dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m *** SIGSEGV (@0x0) received by PID 36021 (TID 0x7fb4ab303700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7fb4aaedc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aae66f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa5917db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa5948f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa594ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa594d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aae77b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m *** SIGSEGV (@0x0) received by PID 36104 (TID 0x7fef6cfc2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fef6cb9b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06cb3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c2667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c2698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06cb4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06cb6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m *** SIGSEGV (@0x0) received by PID 36090 (TID 0x7fe63d277700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fe63ce50390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73cdd2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c4fd7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c5008f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c500ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c500d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m *** SIGSEGV (@0x0) received by PID 36064 (TID 0x7fa364e2b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7fa364a04390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7464774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463e9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463ea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463ea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463ea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7464785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f74647a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463c4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m *** SIGSEGV (@0x0) received by PID 36025 (TID 0x7fde0439f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7fde03f78390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf03eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf035e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf035e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf035e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf035e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m *** SIGSEGV (@0x0) received by PID 36010 (TID 0x7fa442387700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7fa441f60390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7541e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f754154f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75415528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7541552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7541552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7541e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m *** SIGSEGV (@0x0) received by PID 36086 (TID 0x7f249f463700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7f249f03c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59efd4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e6ff7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e7028f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e702ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e702d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m *** SIGSEGV (@0x0) received by PID 36056 (TID 0x7fcc57b8e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7fcc57767390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d5761ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m *** SIGSEGV (@0x0) received by PID 36008 (TID 0x7f2277452700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7f227702b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376f92f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3766bd7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3766c08f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3766c0ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3766c0d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376fa3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m *** SIGSEGV (@0x0) received by PID 36015 (TID 0x7fd44a272700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fd449e4b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa549df7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m *** SIGSEGV (@0x0) received by PID 36059 (TID 0x7fee5dc94700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fee5d86d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5d7f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cf247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cf278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cf27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m *** SIGSEGV (@0x0) received by PID 36076 (TID 0x7f689c9db700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f689c5b4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399c53cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399bc677db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399bc6a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399bc6aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399bc6ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399c54db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m *** SIGSEGV (@0x0) received by PID 36006 (TID 0x7f7ea3452700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f7ea302b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2faff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa26da7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa26dd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa26ddad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa26ddd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m *** SIGSEGV (@0x0) received by PID 36022 (TID 0x7f886ad5d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f886a936390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596a8d1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969ffc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969fff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969fffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969fffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m *** SIGSEGV (@0x0) received by PID 36033 (TID 0x7fdcb120c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fdcb0de5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0b42f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb026d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb02708f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0270ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0270d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0b53b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m *** SIGSEGV (@0x0) received by PID 36117 (TID 0x7f3cbf34f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f3cbef28390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbeed3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe5fe7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe6018f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe601ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe601d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m *** SIGSEGV (@0x0) received by PID 36120 (TID 0x7f19339ee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7f19335c7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea33572f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32c9d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32ca08f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32ca0ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32ca0d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m *** SIGSEGV (@0x0) received by PID 36029 (TID 0x7f09a5fca700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7f09a5ba3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa5b2df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa52587db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa525b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa525bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa525bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa5b3eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m *** SIGSEGV (@0x0) received by PID 36087 (TID 0x7fc1484b3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7fc14808c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247f2ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f924765a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f924765d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f924765dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m *** SIGSEGV (@0x0) received by PID 36084 (TID 0x7f49d1b1a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f49d16f3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad1687f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0db27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0db58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0db5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0db5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad1698b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad16bbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m *** Aborted at 1604570811 (unix time) try \"date -d @1604570811\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m *** SIGSEGV (@0x0) received by PID 36019 (TID 0x7fb61742f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7fb617008390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716f94f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f87166bf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f87166c28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f87166c2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f87166c2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716fa5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716fc8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ee7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ee7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351f762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351f785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb89fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb89fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb92deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc99131aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc99131ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc991bfdb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc991c20c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f841058d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f840e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x7f841416579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c13ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x7fa5c746579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3752fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36adb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3739a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36adbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c3739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36093)\u001b[0m     @     0x5568c36ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad215cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x7fad2767679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1851fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17acb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1837baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1838a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17acbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1837baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1838643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1837baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1838643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1837baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1838643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1837baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff1838643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36127)\u001b[0m     @     0x55bff17ad689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed5fc6fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x7ed6027a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7bc3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7ba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7baaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7ba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7baa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7ba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7baa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7ba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7baa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7ba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7baa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36137)\u001b[0m     @     0x55d5c7b1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4a9c98a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x7f4aa2a3579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x55635998afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359970baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359971a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359970baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359971643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359970baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359971643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359970baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359971643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359970baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x556359971643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36109)\u001b[0m     @     0x5563598e6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f52376b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f5239b898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f52376b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x7f523d76179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f87516dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875153baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875154a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875153baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875154643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875153baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875154643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875153baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875154643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24ce8bd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x7f24d496879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b2bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a86b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b12a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a86bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050b12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36092)\u001b[0m     @     0x556050a87689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa3392354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x7fa33f2e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da808fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da763b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7efa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da763bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da764689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da764689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da764689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da7ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36135)\u001b[0m     @     0x5633da764689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b2a78f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x7f7b3083a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a0aafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a005b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a090baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a091a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a005bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a090baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a091643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a006689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a090baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a091643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a006689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a090baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a091643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a006689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a090baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a091643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36114)\u001b[0m     @     0x55675a006689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf7eead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf7eed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bc00d1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73a91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73a91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb74374b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb74397c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73839a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed44b7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed44b7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed4d9ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed4dbdc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75842ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75842ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75842ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec7539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec7539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec7e1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec7e3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb7259a7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb7259a7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72628ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb7262adc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcd12d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bd5f5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bd618c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcabaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcab8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c4574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c4597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x7f34ada2f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b3efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a99b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b24baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b25a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a99bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b24baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b25643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a9a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b24baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b25643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a9a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b24baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b25643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a9a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b24baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867b25643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36143)\u001b[0m     @     0x559867a9a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f9415cbb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x7f941bd6679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860cffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb860b6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36101)\u001b[0m     @     0x55cb8602b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1f3864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc218598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc1f3864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x7fcc2543179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cccdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc28b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc28bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9118894d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9119177b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911919ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911863ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dc59e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x7f2dcba9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c4ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7baab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c36a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7baabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7bab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7bab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7bab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c35baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7c36643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36014)\u001b[0m     @     0x561ca7bab689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa95f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x7faa9bfb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc968fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc94f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36132)\u001b[0m     @     0x55bacc8c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d9b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1fe8b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b1d9b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed50b6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x7ed51176179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957edfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95748b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95748bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95749689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95749689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95749689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f957d4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36094)\u001b[0m     @     0x558f95749689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f25613c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36063)\u001b[0m     @     0x55f2560b1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f920458ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f9204589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f920458b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc3bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc60b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc3bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5ee9d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa67ccb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa67efc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5c91a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5c8f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e885d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e885d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e275e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e275e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e27ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e27eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b0944bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b0944bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b09d2eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b09d51c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec135398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec13539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c0c0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c0c118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c0c11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e51ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2ee01b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2ee24c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e2c6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e2c4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e55e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e552faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e552f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e552fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e559e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5132ecb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f51309f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x7f5136aa379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838eb4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e0fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e0fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36079)\u001b[0m     @     0x562838e10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2c8a2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2c8a0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2c8a25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2cf8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa75c694f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa7813c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa75c694f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x7faa7bd1479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x559303885fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x55930386c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36026)\u001b[0m     @     0x5593037e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1562cb84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x7f1568d6379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede2aafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede205b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede290baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede291a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede205bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede290baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede291643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede206689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede290baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede291643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede206689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede290baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede291643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede206689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede290baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede291643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36097)\u001b[0m     @     0x559ede206689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40bb29c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40afcba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40afc9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40afcb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40db898de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeeafbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eef3deb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eef401c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eee8a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eee8a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eee8a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f6909b95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690a478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690a49bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690993da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690993b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690993d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406601d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406ee4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406f07c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f14063a9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f14063a7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f14063a95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36118)\u001b[0m     @     0x55b86e815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637b11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee6383f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee638417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee6378b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee6378b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9856852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9857135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9857158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f98565faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f98565f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b4836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b4859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee1552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee1552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee1e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c67dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c67dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3cf60b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3cf83c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c425a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3804fed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa380de1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa380e04c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3802a6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3802a4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35700cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35700cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee3578efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee357912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee356db4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee356db2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a76fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a76fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6b052b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6b075c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a517a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f616382f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f616382fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f616382fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6164112b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6164135c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103928dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f1039b70b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f1039b93c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f1039035a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f1039033388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f10390355a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aae9ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa33ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa33a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aa33c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c00f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c0115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73cde3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73ce06c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c2a8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c2a6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c2a85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463c48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f7463c4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f74643354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f74668088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf03ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf03eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf0338ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf0338a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf0338c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7541e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75412faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75412f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75412fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59efe5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59f008c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e4aaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e4a8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59e4aa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d57630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d57653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376fc6c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376468a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376466388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3764685a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5495227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cf27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5d80ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5d82dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399c570c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399ba12a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399ba10388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399ba125a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2fc0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2fe3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2485a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2483388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa24855a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596a8e2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596a905c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969da7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969da5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0b76c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0018a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb0016388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb00185a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb07034f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbeee4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbef07c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe3a9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe3a7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbe3a95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea33583b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea335a6c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32a48a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32a46388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea32a485a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa5b61c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa5003a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa5001388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa50035a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa56ee4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0b5da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0b5b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad0b5d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad12484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f871646aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716468388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f871646a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716b554f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ec27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ec25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351ec275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351f3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f35217e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb9301c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb87a3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb87a1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb87a35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb8e8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9910c2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9910c0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9910c25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9917ad4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf768fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf74f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36074)\u001b[0m     @     0x558ecf6c4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875153baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f875154643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36140)\u001b[0m     @     0x55f8750c9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bc00f4c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf596a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf594388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbf5965a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbfc814f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73837388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb738395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73f244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb763f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb73f244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x7edb79fcf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe2978fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed425fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed425d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed425f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed494a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed6e1d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f7584be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f7584c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75840a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75840a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75840a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec72e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec72df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec72e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec79cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72574fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72574d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72574f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb725e3a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72830d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bcaba5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bd1a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bf6788de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68bd1a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x7f68c325079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e98efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8e9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e974baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e975a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8e9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e974baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e975643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e974baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e975643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e974baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e975643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c3a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c41244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56ccb4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36088)\u001b[0m     @     0x55b56cc29689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911863a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911863c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9118d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911b1fa8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x7f5b23a6379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da765afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7640baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7641a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7640baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7641643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7640baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7641643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7640baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7641643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7640baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da7641643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36110)\u001b[0m     @     0x563da75b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f9204c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f92071498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f9204c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x7f920ad2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631971fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318ccb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631957baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631958a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318ccbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631957baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631958643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631957baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631958643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631957baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631958643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631957baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f631958643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36058)\u001b[0m     @     0x55f6318cd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x7f1fc9c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dafdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da58b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da58bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7dae4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36095)\u001b[0m     @     0x556e7da59689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa5c915a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa884f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaa637c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e8837aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e8837a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e8af388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e2738ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e2738a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e2738c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e27a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e29f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b091f3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b091f1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b091f35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b098de4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec13539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec13e1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec13e3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec132e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec132df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec132e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c0c11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c14f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c1517c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c09b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c09b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e2c65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e9b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a30e848de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e57eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e559e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x7f9e5ba9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd50287fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd5026e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36126)\u001b[0m     @     0x55cd501e3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2f4608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d2cf8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x7f4d3303879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc4095fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc407c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36028)\u001b[0m     @     0x55abc3ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee40b6b64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x7ee41176179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113d4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e21132fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113bba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e21132fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e211330689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e211330689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e211330689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113babaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e2113bb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36013)\u001b[0m     @     0x55e211330689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeef8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6ef14618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6eeef8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690a0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690c4fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f690a0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406a944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1408f678de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f1406a944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee6378b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee63a4778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f98565fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9856ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f98591b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b3cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b43e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b68b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2b43e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee1e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee12faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee12f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee12fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c423388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3c4255a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3cb104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3efe38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3802a65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3809914f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa382e648de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa3809914f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee356db45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee3599728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x7ee35d54a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d96098fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a515388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6a5175a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6ac024f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f61635d7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f61635d5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f61635d75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6163cc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f61661958de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f10397204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103bbf38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f10397204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x7f103f7cb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d38fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c93b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c93bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8d1f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36005)\u001b[0m     @     0x55f5d8c94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aaa274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85acefa8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85aaa274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x7f85b0ad279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f44fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5e9fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5e9fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5ea0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5ea0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5ea0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5f2b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36021)\u001b[0m     @     0x561ef5ea0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c6fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06ebcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc06c6fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x7fc0727a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67f0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f67d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36104)\u001b[0m     @     0x55e7f674c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c9934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73ee668de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb73c9934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x7fb742a3e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743ae7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a42b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a42bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743ace643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743ace643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f74643354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x7f746a3e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef276fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef25d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36064)\u001b[0m     @     0x5652ef1d2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf03a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf05f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf03a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x7faf09b2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f7295bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72941baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72942a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72941baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72942643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72941baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72942643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72941baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72942643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75419e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7543eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f75419e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x7f7547a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018816fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018771b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018771bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018772689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018772689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018772689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x5610187fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36010)\u001b[0m     @     0x561018772689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59eb954f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef5a10688de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef59eb954f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x7ef5a4c4079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x55603837afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038360baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038361a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038360baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038361643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038360baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038361643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d56af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d571e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d596b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d571e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x7f9d5d28b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec04dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec033baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec034a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376b534f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef3790268de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef376b534f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x7ef37cbfe79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5240fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5226baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5227a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5226baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5227643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5226baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5227643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5226baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5227643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5226baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f5227643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36008)\u001b[0m     @     0x5578f519c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5495258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa549525ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa549525d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5cccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5d3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5f88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399c0fd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399e5d08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f399c0fd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x7f39a21a879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda75cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda742baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda743a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda742baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda743643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda742baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda743643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda742baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda743643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda742baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda743643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36076)\u001b[0m     @     0x564dda6b8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2b704f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa50438de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa2b704f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x7f4fa8c1b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d32fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d18baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d19a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d18baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d19643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d18baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d19643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f5969da75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596a4924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596c9658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f596a4924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x7f597053d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d93fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403ceeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d7aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403ceebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403cef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb2bd68de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb07034f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x7fadb67ae79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39f0ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39ef6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36033)\u001b[0m     @     0x55ed39e6b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbea944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dc0f678de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dbea944f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x7f0dc4b3f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a45fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea331334f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea356068de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea331334f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x7eea391de79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x55980953efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809499b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809524baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809525a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809499bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa7bc18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaa56ee4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x7edaab79979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d829fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d784b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d80fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d810a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d784bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d80fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d810643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d785689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d80fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d810643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d785689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d80fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d810643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d785689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d80fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d810643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36029)\u001b[0m     @     0x55776d785689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f924765dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247f40b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247f63c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad371b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad12484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x7f1ad72f379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x558391486fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x55839146d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36084)\u001b[0m     @     0x5583913e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f87190288de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f8716b554f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x7f871cc0079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611c6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61121b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611ada20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61121bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61122689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61122689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61122689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d611ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36019)\u001b[0m     @     0x563d61122689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f351f3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x7f35253bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a935fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a890b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a890bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a891689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a891689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a891689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a91c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36011)\u001b[0m     @     0x55707a891689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeebb3618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeeb8e8e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x7eeebef3979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b076fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230b05d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36002)\u001b[0m     @     0x56230afd2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc993c808de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc9917ad4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x7fc99785879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e20fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e07a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bc21548de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bbfc814f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x7f2bc5d2c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60aa1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a87baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a88a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a87baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a88643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a87baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a88643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a87baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a88643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a87baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff60a88643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe295f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36030)\u001b[0m     @     0x564fe28d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4ed494a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x7f4eda9f579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185199fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a18517fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185180a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a18517fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185180643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a18517fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185180643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a18517fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185180643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a18517fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a185180643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36089)\u001b[0m     @     0x55a1850f5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75847924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f7586c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f75847924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x7f758a83d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c85fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec9e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ec79cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb725e3a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x7fb72bee579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbca2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfdb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc88baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc89a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfdbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc88baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc89643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc88baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc89643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc88baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc89643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc88baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbc89643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36024)\u001b[0m     @     0x55adbbbfe689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e974baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e975643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36017)\u001b[0m     @     0x56441e8ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c65f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86c41244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x7f86ca1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38960fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38946baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38947a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38946baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38947643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38946baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38947643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38946baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38947643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38946baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b38947643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36037)\u001b[0m     @     0x564b388bc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f9118d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x7f911edd279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db679fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db65fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db660a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db65fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db660643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db65fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db660643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db65fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db660643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db65fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db660643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36020)\u001b[0m     @     0x5567db5d5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x7faaac42779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282e6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28241b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282cda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28241bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28242689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28242689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28242689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282ccbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d282cd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36103)\u001b[0m     @     0x563d28242689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e88a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x7f3e8eb1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b6b5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b610b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b610bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b611689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b611689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b611689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b69c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36016)\u001b[0m     @     0x55854b611689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e27a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x7f9e2db2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcd4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc2fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc2fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dcbb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36068)\u001b[0m     @     0x556c6dc30689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b0bdb18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b098de4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x7f3b0f98979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493f2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x5596493d9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36066)\u001b[0m     @     0x55964934e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec139cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec15e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec139cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x7eec19a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b778fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c09b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c10a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c35778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a2e9b14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x7f0a34a5c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6dbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e636b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e636bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e637689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e637689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e637689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e6c2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36023)\u001b[0m     @     0x55630e637689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x7f6ef503979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbc3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbaaa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bba9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bbaa643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36080)\u001b[0m     @     0x563e2bb1f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x7f69100d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38da4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38cffb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38cffbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d8b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36012)\u001b[0m     @     0x558e38d00689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x7f140cb3f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d8710efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d87069b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d87069bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d8706a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d8706a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d8706a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d870f5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36081)\u001b[0m     @     0x564d8706a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee637fa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x7ee63e04f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba159fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba13fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba140a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba13fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba140643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba13fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba140643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba13fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba140643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba13fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba140643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36007)\u001b[0m     @     0x555dba0b5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f9856ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x7f985cd9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b623774fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236cfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236cfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b62375b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36027)\u001b[0m     @     0x55b6236d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x7fb2ba49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bebcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be17b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be17bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be18689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be18689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be18689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30bea3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36085)\u001b[0m     @     0x55a30be18689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee3eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee19e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x7f1ee7a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a738fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb3cb104f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x7efb42bbb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c938a00fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c9389e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36009)\u001b[0m     @     0x55c93895c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x7fa386a3c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f126fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f081b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f081bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f10d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36003)\u001b[0m     @     0x56418f082689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d9607f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36070)\u001b[0m     @     0x559d95ff4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6d0d58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec6ac024f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x7eec70cad79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471eafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47145b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47145bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6163cc24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x7f6169d6d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f276765fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f27674c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36078)\u001b[0m     @     0x55f2766c1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743ace643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743acdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743ace643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36090)\u001b[0m     @     0x563743a43689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72941baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f72942643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36025)\u001b[0m     @     0x564f728b7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038360baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038361643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038360baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x556038361643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36086)\u001b[0m     @     0x5560382d6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec033baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec034643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec033baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec034643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec033baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec034643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec033baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ec034643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36056)\u001b[0m     @     0x55e3ebfa9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa549e08b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa549e2bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5492cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5492cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5492cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf5d3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x7fbf6346579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977be4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b3fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b3fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b40689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b40689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b40689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977bcb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m     @     0x55f977b40689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d18baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d19643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d18baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155d19643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36006)\u001b[0m     @     0x565155c8e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403cef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403cef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d79baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403d7a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36022)\u001b[0m     @     0x564403cef689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x564853a2c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36117)\u001b[0m     @     0x5648539a1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809524baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809525643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x55980949a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809524baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809525643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x55980949a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809524baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809525643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x55980949a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809524baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x559809525643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36120)\u001b[0m     @     0x55980949a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247405a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247403388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f92474055a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e06baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64e07643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36082)\u001b[0m     @     0x556c64d7c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36004)\u001b[0m     @     0x55ff609fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619c6c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36133)\u001b[0m     @     0x563619be1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x7f1ecda7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59082fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fddb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59068baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59069a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fddbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59068baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59069643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59068baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59069643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59068baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59069643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59068baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa59069643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36075)\u001b[0m     @     0x55aa58fde689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b75f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36099)\u001b[0m     @     0x564b8b6d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c10a44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x7fa1c714f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657f08fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e63b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eefa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e63bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eeebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657eef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36077)\u001b[0m     @     0x562657e64689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a693b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a693bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a694689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a694689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a694689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a71f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36083)\u001b[0m     @     0x55810a694689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47146689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47146689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47146689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e471d1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36102)\u001b[0m     @     0x561e47146689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5499b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa54be8b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247af04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9249fc38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa5499b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x7fa54fa6379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c81afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c775b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c800baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c801a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c775bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c800baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c801643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c776689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c800baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c801643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c776689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c800baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c801643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c776689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c800baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c801643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36015)\u001b[0m     @     0x555b2c776689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f9247af04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x7f924db9b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a84fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59dfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59dfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d5a6b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=36087)\u001b[0m     @     0x55f2d59e0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:06:52,200\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.\n",
+      "2020-11-05 10:06:52,201\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:06:52,207\tERROR trial_runner.py:567 -- Trial PPO_jss_env_9bf91_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=36107, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 22.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_9bf91_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_9bf91_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_9bf91_00000_0_2020-11-05_10-06-44/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3552\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:07,929 - wandb.wandb_agent - INFO - Running runs: ['802owiob']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204405-802owiob/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204405-802owiob/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 201.68687\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 201.68687\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3601\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708246\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/802owiob\u001b[0m\n",
-      "2020-10-14 20:44:13,147 - wandb.wandb_agent - INFO - Cleaning up finished run: 802owiob\n",
-      "2020-10-14 20:44:13,451 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:13,451 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta55\n",
-      "2020-10-14 20:44:13,453 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta55\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ix8moovg\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204415-ix8moovg\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "2020-11-05 10:06:52,223\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff091d563401000000.\n",
+      "2020-11-05 10:06:52,223\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.\n",
+      "2020-11-05 10:06:52,224\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.\n",
+      "2020-11-05 10:06:52,224\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "2020-11-05 10:06:52,224\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.\n",
+      "2020-11-05 10:06:52,224\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff252160a301000000.\n",
+      "2020-11-05 10:06:52,224\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 22.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_9bf91_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_9bf91_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_9bf91_00000_0_2020-11-05_10-06-44/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_9bf91_00000])\n",
+      "2020-11-05 10:06:52,235\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "2020-11-05 10:06:52,235\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.228685 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=170fdfd5d34985a7e0497dac01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.228801 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=89f63fee54d6858ee0497dac01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.228881 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=c6f8a2750fad0b0de0497dac01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=e0497dac01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.230479 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=eb0057ff902d31287ef9157101000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=7ef9157101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.230823 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=6c72f258bb1224db7ef9157101000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=7ef9157101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=36107)\u001b[0m E1105 10:06:52.230952 36107 37247 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=db864355021abf067ef9157101000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=7ef9157101000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.230523 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.235877 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.236886 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3642\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:18,469 - wandb.wandb_agent - INFO - Running runs: ['ix8moovg']\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.238452 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.241946 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 35902\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffbdff035801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):09MB uploaded (0.00MB deduped)\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa97540c201000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.246706 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.264009 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.283356 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.284910 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.300863 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.305044 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.314386 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.322131 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.327162 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.332408 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.341799 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.345430 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.350364 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.354562 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.360404 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.362756 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.363675 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.364166 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.364950 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.368077 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.369668 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.369885 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.370070 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.371389 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.373176 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.373919 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.375170 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.376034 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.376513 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.377329 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.377599 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.379487 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.379751 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.381050 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.381126 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.382010 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.382050 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.382319 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.383761 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.384661 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:06:52.385108 35961 35961 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204415-ix8moovg/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204415-ix8moovg/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 224.37374\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 224.37374\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3435\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708256\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_100639-d7n056b5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_100639-d7n056b5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ix8moovg\u001b[0m\n",
-      "2020-10-14 20:44:23,694 - wandb.wandb_agent - INFO - Cleaning up finished run: ix8moovg\n",
-      "2020-10-14 20:44:24,023 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:24,023 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta56\n",
-      "2020-10-14 20:44:24,025 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta56\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdulcet-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/d7n056b5\u001b[0m\n",
+      "2020-11-05 10:07:03,909 - wandb.wandb_agent - INFO - Cleaning up finished run: d7n056b5\n",
+      "2020-11-05 10:07:04,244 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:07:04,244 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta42\n",
+      "2020-11-05 10:07:04,246 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta42\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:07:09,264 - wandb.wandb_agent - INFO - Running runs: ['phnfkvio']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zda8eskt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204426-zda8eskt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/1ke874jl\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/phnfkvio\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_100706-phnfkvio\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:07:09,883\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ab943_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3726\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:29,037 - wandb.wandb_agent - INFO - Running runs: ['zda8eskt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204426-zda8eskt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204426-zda8eskt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 178.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 178.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3881\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708267\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zda8eskt\u001b[0m\n",
-      "2020-10-14 20:44:34,252 - wandb.wandb_agent - INFO - Cleaning up finished run: zda8eskt\n",
-      "2020-10-14 20:44:36,273 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:36,273 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta57\n",
-      "2020-10-14 20:44:36,275 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta57\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/uz9lk4hk\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204438-uz9lk4hk\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m 2020-11-05 10:07:12,633\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m *** SIGSEGV (@0x0) received by PID 37642 (TID 0x7feed7989700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m *** SIGSEGV (@0x0) received by PID 37564 (TID 0x7f7d830ee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f7d82cc7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e82c51f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e8237c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m *** SIGSEGV (@0x0) received by PID 37638 (TID 0x7fea77d00700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fea778d9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb77871f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m *** SIGSEGV (@0x0) received by PID 37641 (TID 0x7f07510eb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m *** SIGSEGV (@0x0) received by PID 37557 (TID 0x7fb495d36700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7fb49590f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f85957f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m *** SIGSEGV (@0x0) received by PID 37560 (TID 0x7f57a5fb0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f57a5b89390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m *** SIGSEGV (@0x0) received by PID 37676 (TID 0x7f71f1ba5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f71f177e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f16f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m *** SIGSEGV (@0x0) received by PID 37568 (TID 0x7f6c424e2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f6c420bb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d4204df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m *** SIGSEGV (@0x0) received by PID 37562 (TID 0x7f61d988b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f61d9464390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m *** Aborted at 1604570837 (unix time) try \"date -d @1604570837\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m *** SIGSEGV (@0x0) received by PID 37623 (TID 0x7f234d289700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7f234ce62390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44cdd2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c4fd7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m *** SIGSEGV (@0x0) received by PID 37583 (TID 0x7f1ba83a6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7f1ba7f7f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m *** SIGSEGV (@0x0) received by PID 37652 (TID 0x7f018b8e2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7f018b4bb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28ac15f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a3407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m *** SIGSEGV (@0x0) received by PID 37684 (TID 0x7f9abce6b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f9abca44390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbc825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbf507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m *** SIGSEGV (@0x0) received by PID 37572 (TID 0x7f935dd1a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f935d8f3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645d7f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cf247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m *** SIGSEGV (@0x0) received by PID 37580 (TID 0x7f4c3970b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f4c392e4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3924af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d389757db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d389788f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m *** SIGSEGV (@0x0) received by PID 37672 (TID 0x7f4abe3cf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f4abdfa8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbde24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd54f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd5528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbde35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m *** SIGSEGV (@0x0) received by PID 37634 (TID 0x7fbe9f8fd700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7fbe9f4d6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9f46af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9eb957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9eb988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9eb98ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m *** SIGSEGV (@0x0) received by PID 37616 (TID 0x7fb8480ca700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7fb847ca3390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89479c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89470f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89470f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m *** SIGSEGV (@0x0) received by PID 37645 (TID 0x7fda370bf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fda36c98390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab36a21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab3614c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab3614f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m *** SIGSEGV (@0x0) received by PID 37629 (TID 0x7fcc0a412700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7fcc09feb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d09e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d0954f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d095528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m *** SIGSEGV (@0x0) received by PID 37628 (TID 0x7f9af446f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f9af4048390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3ed8f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf36037db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf36068f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3606ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3606d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m *** SIGSEGV (@0x0) received by PID 37635 (TID 0x7f654eba6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f654e77f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364e4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364dc247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364dc278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364dc27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m *** SIGSEGV (@0x0) received by PID 37660 (TID 0x7fbf0ed35700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7fbf0e90e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900e70af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900de357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900de388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900de38ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m *** SIGSEGV (@0x0) received by PID 37653 (TID 0x7fe1dc294700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fe1dbe6d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2dbbf7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db3227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db3258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m *** SIGSEGV (@0x0) received by PID 37671 (TID 0x7f4270bc2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f427079b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f1370563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fc8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fc918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m *** SIGSEGV (@0x0) received by PID 37640 (TID 0x7f603e261700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f603de3a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313dde4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d50f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d5128f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d512ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m *** SIGSEGV (@0x0) received by PID 37636 (TID 0x7fb39c8a3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7fb39c47c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849c333f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849ba5e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849ba618f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849ba61ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m *** SIGSEGV (@0x0) received by PID 37610 (TID 0x7ff198298700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7ff197e71390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc297ddef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc2975097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29750c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m *** SIGSEGV (@0x0) received by PID 37549 (TID 0x7efde5126700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7efde4cff390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee4c87f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee43b27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee43b58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m *** SIGSEGV (@0x0) received by PID 37582 (TID 0x7fef05648700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fef05221390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0050b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0047e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0047e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0047e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m *** SIGSEGV (@0x0) received by PID 37677 (TID 0x7f95009a9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f9500582390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f66003e3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ffb0e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m *** SIGSEGV (@0x0) received by PID 37650 (TID 0x7feafbe6a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7feafba43390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfb751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfae7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfae7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m *** SIGSEGV (@0x0) received by PID 37574 (TID 0x7fa99d8b3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7fa99d48c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9d3ccf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9caf77db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9cafa8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m *** SIGSEGV (@0x0) received by PID 37571 (TID 0x7f215beb2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7f215ba8b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25ba23f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b14e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7feed7562390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd6c15f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd63407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd63438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd6343ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m *** SIGSEGV (@0x0) received by PID 37556 (TID 0x7f8a5c331700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f8a5bf0a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5beb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b5e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b5e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m *** SIGSEGV (@0x0) received by PID 37631 (TID 0x7f4d16b1c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f4d166f5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e164f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e15c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e15c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e15c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m *** SIGSEGV (@0x0) received by PID 37575 (TID 0x7ffb90746700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7ffb9031f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc90290f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f9bb7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f9be8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m *** SIGSEGV (@0x0) received by PID 37675 (TID 0x7f920a8cf700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f920a4a8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630a34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e8237f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e8237fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e8237fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76f9c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76f9f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7f0750cc4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed850bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8502fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8502ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a5a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a51357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a51388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d417787db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d4177b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d940ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8b3a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8b3d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c5008f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c500ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c500d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44cde3b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca7eb6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca75e17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca75e48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a3438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a343ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbf538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbf53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cf278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cf27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m *** SIGSEGV (@0x0) received by PID 37693 (TID 0x7f6c210f2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f6c20ccb390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d20bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m *** SIGSEGV (@0x0) received by PID 37586 (TID 0x7f1043978700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m *** SIGSEGV (@0x0) received by PID 37559 (TID 0x7f31e881f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m *** SIGSEGV (@0x0) received by PID 37566 (TID 0x7f7d2d06b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m *** SIGSEGV (@0x0) received by PID 37637 (TID 0x7fb4295ee700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m *** SIGSEGV (@0x0) received by PID 37588 (TID 0x7feb77c60700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7feb77839390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d38978ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d38978d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3925bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3927ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbde58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd2faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd2f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd2fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9eb98d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9f47bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9f49ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9e940a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9e93e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89470f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89470f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89479d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89479f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab3614fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab3614fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab36a32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab36a55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d09552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d09552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d09e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3ee9b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3f0cc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf33aea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf33ac388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364dc27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364e50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364e52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364d9cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364d9cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900de38d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900e71bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900e73ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900dbe0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900dbde388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db325ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db325d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fc91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fc91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f1370574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f1370597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d512d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313ddf5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313de18c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d2baa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d2b8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849ba61d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849c344b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849c367c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849b809a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849b807388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m *** SIGSEGV (@0x0) received by PID 37553 (TID 0x7f586c778700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f586c351390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296c2f3f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296ba1e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296ba218f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29750cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29750cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc297defb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc297e12c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc2972b4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee43b5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee43b5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee4c98b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee4cbbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0047e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0050c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0050e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc00458ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc004589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ffb118f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ffb11ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ffb11d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f66003f4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f6600417c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ff8b9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfae7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfae7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfb762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfb785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfac27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfac25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m *** SIGSEGV (@0x0) received by PID 37569 (TID 0x7f4833685700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f483325e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1933124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f193284f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m *** SIGSEGV (@0x0) received by PID 37570 (TID 0x7f0ba8669700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7f0ba8242390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca801cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca77477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca774a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca774aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m *** SIGSEGV (@0x0) received by PID 37678 (TID 0x7f24f6bb3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7f24f678c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f64f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f5c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f5c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9cafaad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9cafad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9d3ddb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9d400c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9c8a2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9c8a0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b1518f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b151ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b151d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25ba34b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25ba57c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd6343d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd6c26b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd6c49c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd60eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd60e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b5e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b5e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5bec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5beeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b38ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b38a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e15c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e1650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e1652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e159cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e159cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e159cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e160ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f9bead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f9bed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc902a1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc902c4c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f766a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f764388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630a35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630a37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630981f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f63098215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e82c62b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e82c85c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e82127a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e82125388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e821275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e828124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m *** SIGSEGV (@0x0) received by PID 37567 (TID 0x7f6690ad0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f66906a9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f379065ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fd8a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fd8d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m *** SIGSEGV (@0x0) received by PID 37550 (TID 0x7f7370b55700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f737072e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f44706dff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fe0a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76f9fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76f9fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb77882b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb778a5c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76d47a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76d45388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8502ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8502ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed850be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed850c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m *** SIGSEGV (@0x0) received by PID 37626 (TID 0x7fb87913b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7fb878d14390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f8978c1ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897834a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897834d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m *** SIGSEGV (@0x0) received by PID 37552 (TID 0x7f9de9125700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f9de8cfe390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee8940f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee806b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee806e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f859580ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f859582dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m *** SIGSEGV (@0x0) received by PID 37647 (TID 0x7fdc08194700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fdc07d6d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad07cf9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad074247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m *** SIGSEGV (@0x0) received by PID 37674 (TID 0x7fc26333f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7fc262f18390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362e93f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f93625be7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f93625c18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f93625c1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a5138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a5138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a5a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a5a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a4ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a4ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m *** SIGSEGV (@0x0) received by PID 37551 (TID 0x7f6ce64c5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m *** SIGSEGV (@0x0) received by PID 37554 (TID 0x7f850359e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f8503177390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5603124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f560284f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f56028528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f1705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f1728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f0bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d4177bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d4177bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d4205eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d42081c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d41523a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d41521388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8b3dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8b3dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d9420b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d9443c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d88e5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d88e3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44ce06c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c2a8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c2a6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c2a85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c9934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44ee668de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca75e4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca75e4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca7ec7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca7eeac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca738ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca738a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a343d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28ac26b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28ac49c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a0eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a0e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a0eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbf53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbc836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbc859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbbcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m *** SIGSEGV (@0x0) received by PID 37632 (TID 0x7f3b4a62f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f3b4a208390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4a13af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c498657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c498688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m *** SIGSEGV (@0x0) received by PID 37639 (TID 0x7fd98817b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m *** SIGSEGV (@0x0) received by PID 37630 (TID 0x7ff1f7f9a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7ff1f7b73390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f79c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f70f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m *** SIGSEGV (@0x0) received by PID 37621 (TID 0x7f0ee6b37700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m *** SIGSEGV (@0x0) received by PID 37565 (TID 0x7f9c04103700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f9c03cdc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d03bc7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d032f27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d032f58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m *** SIGSEGV (@0x0) received by PID 37624 (TID 0x7f142bac7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7f142b6a0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52b61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52ad4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52ad4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m *** SIGSEGV (@0x0) received by PID 37555 (TID 0x7fcfb4f55700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fcfb4b2e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b4acdf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b41f87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b41fb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m *** SIGSEGV (@0x0) received by PID 37613 (TID 0x7ff99cc41700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7ff99c81a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9c73ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9be697db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9be6c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m *** SIGSEGV (@0x0) received by PID 37618 (TID 0x7f5432920700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f54324f9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2532467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2531b927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2531b958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m *** SIGSEGV (@0x0) received by PID 37619 (TID 0x7f8aadd90700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f8aad969390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bad7f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacf247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacf278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m *** SIGSEGV (@0x0) received by PID 37617 (TID 0x7f882cb8f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f882c768390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592c563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592bc8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592bc918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m *** SIGSEGV (@0x0) received by PID 37620 (TID 0x7fb43a91f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7fb43a4f8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853a467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f8539b927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m *** SIGSEGV (@0x0) received by PID 37667 (TID 0x7fc1bef0b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7fc1beae4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bea21f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be14c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m *** SIGSEGV (@0x0) received by PID 37662 (TID 0x7f947c8a5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f947c47e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657c333f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657ba5e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657ba618f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657ba61ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m *** SIGSEGV (@0x0) received by PID 37665 (TID 0x7fcb11145700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7fcb10d1e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c10bd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c102fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c102ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c102ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cf27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645d80ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645d82dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645cccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645d3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m *** SIGSEGV (@0x0) received by PID 37611 (TID 0x7feb58441700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7feb5801a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc57e0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc575367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc575398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m *** SIGSEGV (@0x0) received by PID 37625 (TID 0x7f6850d30700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f6850909390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f3950825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394ff507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394ff538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m *** SIGSEGV (@0x0) received by PID 37680 (TID 0x7f0471da2700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7f047197b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed5717f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d202fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d202ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d202ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d202ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d20be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7f1043551390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1434eaf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee142c157db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee142c188f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee142c18ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee142c18d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1434fbb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f31e83f8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e8333f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7a5e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7a618f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7a61ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f7d2cc44390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2cbd1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c2fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c2ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c2ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c2ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2cbe2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2cc05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m *** SIGSEGV (@0x0) received by PID 37561 (TID 0x7f0dcfbde700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7f0dcf7b7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edecf61ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeced4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeced4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeced4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7fb4291c7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85290b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85287e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85287e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85287e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85287e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc777cef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76ef97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76efc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76efcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76efcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc777dfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m *** SIGSEGV (@0x0) received by PID 37573 (TID 0x7fe5a6335700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fe5a5f0e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a5e24f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a554f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a55528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a5552ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d38720a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3871e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d387205a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d38e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3b2de8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m *** Aborted at 1604570838 (unix time) try \"date -d @1604570838\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m *** SIGSEGV (@0x0) received by PID 37627 (TID 0x7fb3cba54700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7fb3cb62d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cb5f2f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cad1d7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd9e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbfeb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bbd9e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x7f1bc3a9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c911ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9106a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c9106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37672)\u001b[0m     @     0x55e8c907b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9e9405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9f02b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8fa14fe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8f9f02b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x7f8fa50d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d408affd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40895baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40896a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40895baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40896643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40895baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40896643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40895baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40896643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40895baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d40896643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37634)\u001b[0m     @     0x561d4080b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f8946e9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f8946e99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f8946e9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89475864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f8949a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab35ef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab35ef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab35ef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab365e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab38ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d09e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d092faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d092f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d092fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d099e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d0beb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf33ae5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3a994f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf5f6c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf3a994f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x7f6bf9b4479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3883fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37deb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3869baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e386aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37debfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3869baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e386a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3869baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e386a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3869baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e386a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e3869baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e386a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37628)\u001b[0m     @     0x55e4e37df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m *** SIGSEGV (@0x0) received by PID 37622 (TID 0x7f4d84f3d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f4d84b16390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e84825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83f507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83f538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83f53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364d9cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f365058d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f364e0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x7f365416579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7338fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7293b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7293bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7294689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7294689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7294689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900dbe05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f901079e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f900e2cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x7f901437679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a892065fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a89204c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37660)\u001b[0m     @     0x55a891fc1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2dbc08b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2dbc2bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db0cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db0cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db0cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db7b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2ddc8b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fa39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fa37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f136fa395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f13701244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f13725f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d2ba5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d9a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313fe788de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f313d9a54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x7f3143a5079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e939fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e894b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e920a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e894bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849b8095a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849bef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849e3c78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296ba21ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296ba21d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296c304b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296c327c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc2972b2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc2972b45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29799f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc299e728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee415da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee415b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee415d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee48484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee6d1b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc00458b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc004c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc0071498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ff8b7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65ff8b95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65fffa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f66024778de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfac275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfb3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfd7e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f19328528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1932852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca774ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca802db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca8050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca74f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f5c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f5c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9c8a25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9cf8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9f4608de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25aef9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25aef7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25aef95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b5e44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m *** SIGSEGV (@0x0) received by PID 37633 (TID 0x7f5f6bbef700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f5f6b7c8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306b6aef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306add97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd60eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd67d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd8ca98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5b38c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5ba774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5df4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e1858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e160ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x7f1e1c16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371ecffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371eb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37631)\u001b[0m     @     0x564371e2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8f7665a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8fe514f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc923248de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630c3df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f6309f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x7f630ffb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4c0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e84ce58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e828124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x7f4e888bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f54fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eafb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eafbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531f3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37564)\u001b[0m     @     0x559531eb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fd8dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fd8dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f3790670b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f3790693c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fe0d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fe0dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fe0dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb76d475a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb774324f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb799058de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8500a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8500a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8500a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8507924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897834dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897834dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f8978c30b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f8978c53c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee806ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee806ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee8951b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f8594ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f85953ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f859788d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad074278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad07427ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f93625c1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362ea4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362ec7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362369a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a4ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a55cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f6ce609e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de604af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de57757db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de57788f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5602852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5602852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5603135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f37888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x7f42f736079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a088cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0872baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0873a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0872baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0873643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0872baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0873643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0872baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0873643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d415235a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d41c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d440e18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d88e55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8fd04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef44c9934f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x7ef452a3e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870da8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d03b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d03bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d04689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d04689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d04689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d8f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37623)\u001b[0m     @     0x55d870d04689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca738c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca7a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a7d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28cca98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed28a7d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbc3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbe8b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bbc3e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x7f6bc249179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a4efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89a9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a34baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a35a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89a9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a34baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a35643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a34baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a35643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a34baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a35643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a34baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea8a35643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37684)\u001b[0m     @     0x55dea89aa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c49868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c49868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4a14bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4a16ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c49610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7fd987d54390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa87ce0f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa8740b7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa8740e8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa8740ead3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f70f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f70f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f70f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f79d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f79f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7f0ee6710390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe64f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe5c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d032f5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d032f5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d03bd8b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d03bfbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d0309da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d0309b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52ad4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52ad4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52b630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52b653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52aaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b41fbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b41fbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b4adeb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b4b01c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9be6cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9be6cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9c74fb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9c772c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2531b95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2531b95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f2532478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f253249bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacf27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacf27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bad80ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bad82dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592bc91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592bc91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f8539b958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f8539b95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be14f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be14fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be14fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657ba61d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657c344b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657c367c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c102ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c10be2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c10c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c100a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645f88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f645d3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc57539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc57539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394ff53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394ff53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f3950836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f3950859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394fcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed57180ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed57182dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d20c05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d200a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d200a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee14351ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1429c0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1429be388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7a61d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e8344b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e8367c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7809a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7807388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c0a7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c0a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c0a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeced4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edecf630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edecf653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeceaf5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85290c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f85290e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f852858ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f8528589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc77802c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76ca4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76ca2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc76ca45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc7738f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a5552d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a5e35b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a5e58c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a52faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a52f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a52fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d38e0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x7f1d3eeb679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a52fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69adb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a38baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a39a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69adbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a38baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a39643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a38baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a39643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a38baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a39643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a38baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee6a39643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37580)\u001b[0m     @     0x55fee69ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cad208f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cad20ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f89475864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x7f894d63179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aee0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98aec7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37616)\u001b[0m     @     0x55f98ae3c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab365e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x7fab3c68d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0ccfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce027b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce027bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce0b3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37645)\u001b[0m     @     0x5557ce028689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d099e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x7f9d0fa9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc800fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc7e7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37629)\u001b[0m     @     0x5586cc75c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83f53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e84836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e84859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83cfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83cf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae731f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37635)\u001b[0m     @     0x564ae7294689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2db7b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x7fb2e186379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f76fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95f5d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37653)\u001b[0m     @     0x55db95ed2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f13701244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x7f13761cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbf7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb52b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbdea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb52bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbde643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb53689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbde643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb53689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbde643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb53689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbddbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bbde643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37671)\u001b[0m     @     0x55914bb53689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e91fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37640)\u001b[0m     @     0x560e2e895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f849bef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x7f84a1f9f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec418fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec373b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3ffa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec373bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec374689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec374689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec374689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3febaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec3ff643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37636)\u001b[0m     @     0x555cec374689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296b7c9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296b7c7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296b7c95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296beb44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29799f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x7fc29da4a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc5dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc43baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc44a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc43baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc44643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc43baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc44643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc43baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc44643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc43baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfc44643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37610)\u001b[0m     @     0x55bddfbb9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7ecee48484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x7eceea8f379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d8adfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d808b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d893baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d894a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d808bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d893baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d894643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d809689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d893baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d894643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d809689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d893baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d894643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d809689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d893baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d894643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37549)\u001b[0m     @     0x55f41d809689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc004c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x7fc00ad2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae5087ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507dab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50866a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507dabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50865baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae50866643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37582)\u001b[0m     @     0x55ae507db689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f65fffa44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x7f660604f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb8cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb72baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb73a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb72baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb73643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb72baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb73643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb72baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb73643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb72baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cb73643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37677)\u001b[0m     @     0x55bd0cae8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbbfb3124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x7fbc013bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb557dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5563baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5564a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5563baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5564643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5563baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5564643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5563baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5564643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5563baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb5564643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37650)\u001b[0m     @     0x55cfb54d9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1932852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1933135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1933158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f19325faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f19325f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f19325fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca74f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca74f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca7bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edcaa0b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edca7bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f59cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f59cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f59cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7a9cf8d4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x7f7aa303879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fda6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd01b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd01bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd8d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37574)\u001b[0m     @     0x562f0fd02689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25dab78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef25b5e44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x7ef26168f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x5637036a7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703602b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703602bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703603689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703603689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703603689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x56370368e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37571)\u001b[0m     @     0x563703603689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306addc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306addcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306addcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306b6bfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306b6e2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfd67d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x7fbfdc47779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4526fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4481b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4481bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4482689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4482689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4482689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a450d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37642)\u001b[0m     @     0x55b4a4482689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b5ba774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x7f5b61b2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2c14fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b6fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b6fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2bfb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37556)\u001b[0m     @     0x5570e2b70689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc8fe514f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x7fcc95efc79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213256b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213256bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x5642132e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37575)\u001b[0m     @     0x564213257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f4a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37675)\u001b[0m     @     0x558e1f41c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fb35a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fb33388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f378fb355a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f37902204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f37926f38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f44706f0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f4470713c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fbb5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fbb3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f446fbb55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f44702a04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb774324f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x7fbb7d4dd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c75fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4c5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37638)\u001b[0m     @     0x5583b4bd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed852c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed8507924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x7ed85683d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfb9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf14b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfa0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf14bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bfa0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37641)\u001b[0m     @     0x56182bf15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f89780f5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f89780f3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f89780f55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f89787e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897acb38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee8974c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee7e16a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee7e14388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee7e165a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee85014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f85953ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x7f859b46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38761fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38747baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38748a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38747baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38748643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38747baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38748643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38747baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38748643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38747baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f38748643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37557)\u001b[0m     @     0x561f386bd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad07427d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad07d0ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad07d2dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad071cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad071cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad071cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362367388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f93623695a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362a544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9364f278de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9362a544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a7a9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28a55cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x7f28ab67679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7f06fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e61b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eeda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e61bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e62689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e62689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e62689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7eed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37560)\u001b[0m     @     0x5589c7e62689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de5778ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de5778d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de605bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de607ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de5520a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de551e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5603158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f56025faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f56025f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f56025fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5602ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0872baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a0873643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37676)\u001b[0m     @     0x55c1a07e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d41c0e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x7f3d47cb979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b48abfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4806b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4891baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4892a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4806bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4891baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4892643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4807689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4891baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4892643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4807689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4891baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4892643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4807689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4891baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4892643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37568)\u001b[0m     @     0x5597b4807689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32db4a38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32d8fd04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x7f32df07b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x5567100b1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710097baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710098a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710097baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710098643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710097baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710098643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710097baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710098643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710097baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x556710098643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37562)\u001b[0m     @     0x55671000d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca9f4a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eeca7a774f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x7eecadb2279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371cc4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c1fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c1fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371cab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c20689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371cab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c20689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371cab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c20689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371caabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371cab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37583)\u001b[0m     @     0x562371c20689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x7ed29047779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0940fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0926baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0927a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0926baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0927643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0926baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0927643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0926baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0927643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0926baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c0927643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37652)\u001b[0m     @     0x5621c089c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4960e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c496105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c49cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4c1ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa8740ed91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa87cf1b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa87d14c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa871b6a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa871b4388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f6e9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f6e99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f6e9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f75864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe5c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe5c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe5c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d0309d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d037884f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d05c5b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52aaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52aaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52d6b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b3fa3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b3fa1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b3fa35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b468e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9bc14a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9bc12388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9bc145a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9c2ff4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9e7d28de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fca9c2ff4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x7fcaa21a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa2bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f986b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa12a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f986bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f987689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f253193da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f253193b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f253193d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f25320284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f25344fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bacccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bad3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5baf88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592c574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592c597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592ba39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592ba37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592ba395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592c1244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f8539b95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853a478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853a49bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853993da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853993b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853993d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bea32b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bea55c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bdef7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bdef5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92bdef75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657b809a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657b807388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657b8095a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657bef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657e3c78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c100a5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c100a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c107924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c12c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c107924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x7f646346579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd108fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd063b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0efa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd063bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd064689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd064689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd064689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0eebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd0ef643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37572)\u001b[0m     @     0x55eddd064689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc57e1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc57e3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc572e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc572df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc572e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc579cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394fcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f394fcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f39503e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f39528b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f39503e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed570ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed5713ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d200a75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d207924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d22c658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d207924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x7f3d2683d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc60fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc47a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc46baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecc47643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1429c05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1430ab4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee14557e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee1430ab4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x7ee14915679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b946fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b92d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37586)\u001b[0m     @     0x55622b8a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e78095a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7ef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02ea3c78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c7924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2ec658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e2c7924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x7f4e3283d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a60afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a565b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a565bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a566689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a566689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a566689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a5f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37566)\u001b[0m     @     0x55932a566689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeceaf3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edeceaf55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edecf1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7eded16b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f852858b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f8528c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f852b1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f8528c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x7f852ed2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8effd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc798628de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc7738f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x7fbc7d43a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b485afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4840baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4841a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4840baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4841643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4840baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4841643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4840baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4841643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4840baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b4841643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37588)\u001b[0m     @     0x5573b47b6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a59e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a7eb88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cad20d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cb603b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cb626c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e83cfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e843e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e868b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296e3878de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f296beb44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x7f2971f5f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be7484cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74832baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74833a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74832baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74833643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74832baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74833643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74832baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74833643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74832baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be74833643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37553)\u001b[0m     @     0x55be747a8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1932ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f19351b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x7edcadc8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503449fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a50342fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503430a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a50342fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503430643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a50342fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503430643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a50342fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503430643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a50342fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a503430643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37570)\u001b[0m     @     0x55a5033a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5f60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x7ef5fc16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ebbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e16b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e16bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678ea2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37678)\u001b[0m     @     0x559678e17689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306ab84a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306ab82388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306ab845a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f37902204f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x7f37962cb79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa80afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa765b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa765bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa766689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa766689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa766689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa7f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37567)\u001b[0m     @     0x562daa766689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f44727738de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f44702a04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x7f447634b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d1478fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d145f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37550)\u001b[0m     @     0x5650d13d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f89787e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x7f897e88b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce43efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce399b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce424baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce425a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce399bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce424baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce425643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce39a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce424baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce425643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce39a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce424baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce425643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce39a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce424baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce425643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37626)\u001b[0m     @     0x5620ce39a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6eea9d48de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6ee85014f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x7f6eee1a279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aecffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484aeb6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37552)\u001b[0m     @     0x56484ae2b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad078ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad09d8d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad078ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x7fad0d96579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2eb9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e14b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2ea0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e14bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2ea0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2ea0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2ea0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e9fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2ea0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37647)\u001b[0m     @     0x556ed2e15689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x7f9368aff79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71939fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71894b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c7191fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71920a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71894bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c7191fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c7191fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c7191fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c7191fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71920643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37674)\u001b[0m     @     0x562c71895689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de55205a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de5c0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de80de8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3de5c0b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x7f3debcb679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f216fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f171b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f171bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f56051b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5602ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x7f5608d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a13efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a099b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a124baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a125a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a099bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a124baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a125643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a09a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a124baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a125643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a09a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a124baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a125643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a09a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a124baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a125643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37554)\u001b[0m     @     0x55635a09a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c49cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x7f0c4fda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cf0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8cd7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37632)\u001b[0m     @     0x5612a8c4c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa871b65a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa878a14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa89d748de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa878a14f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f9a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2f75864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x7fc2fd63179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bdafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b35b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b35bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b36689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b36689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b36689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2bc1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37630)\u001b[0m     @     0x55b4e2b36689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe59cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe59cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe59cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d037884f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x7f6d0983379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c35fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b90b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b90bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6c1c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37565)\u001b[0m     @     0x561ae6b91689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee52b1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x7ee53128b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597cd012fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccff9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37624)\u001b[0m     @     0x5597ccf6e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b6b618de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0b468e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x7fa0ba73979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3ddfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec338b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec338bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec339689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec339689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec339689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec3c4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37555)\u001b[0m     @     0x5597ec339689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f987689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f987689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa11baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9fa12643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37613)\u001b[0m     @     0x561f9f987689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f25320284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x7f25380d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263cdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926328b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926328bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926329689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926329689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926329689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x5569263b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37618)\u001b[0m     @     0x556926329689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bad3ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x7f5bb346579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3d0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a3b7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37619)\u001b[0m     @     0x55bd9a32c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592e5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f592c1244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x7f59321cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea86fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853a0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853c4fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f853a0284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x7f85400d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8b9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa814b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8a0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa814bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92c0ab58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92be5e24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x7f92c468d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330ec5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e20b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eaca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e20bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330eac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37667)\u001b[0m     @     0x558330e21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f657bef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x7f6581f9f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bd9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b34b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bbfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bc0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b34bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bbfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bc0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b35689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bbfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bc0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b35689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bbfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bc0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b35689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bbfbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0bc0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37662)\u001b[0m     @     0x55fce0b35689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x7f9c1683d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6c4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe61fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe61fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe620689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe620689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe620689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe6ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37665)\u001b[0m     @     0x555abe620689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc59e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc579cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x7fbc5da7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fed2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x7f395649179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6956b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6956bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6957689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6957689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6957689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc69e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37625)\u001b[0m     @     0x55bbc6957689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed57388d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed5713ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x7ed57746579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc6dfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc8b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc54a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc8bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc53baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdc54643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37680)\u001b[0m     @     0x55d3fdbc9689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37693)\u001b[0m     @     0x5597ecbbc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02e7ef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x7f02edf9f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7eedfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e48b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e48bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7ed4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37559)\u001b[0m     @     0x560ee7e49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7edecf1e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x7eded528b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495e4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d4953fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d4953fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d49540689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d49540689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d49540689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d495cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37561)\u001b[0m     @     0x564d49540689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e8d6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37637)\u001b[0m     @     0x55873e84b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6a59e54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x7fb6aba9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564778038fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f93b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f93bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x56477801f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37573)\u001b[0m     @     0x564777f94689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84caac8a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84caac6388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84caac85a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cb1b34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e843e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x7f1e8a49179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afdf8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd53b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd53bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afddf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37622)\u001b[0m     @     0x5622afd54689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1932ce54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x7f1938d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244c0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e8244a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37569)\u001b[0m     @     0x55e82441c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306b26f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306d7428de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f306b26f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x7f307131a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d6a1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fcb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d687baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d688a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fcbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d687baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d688643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d687baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d688643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d687baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d688643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f172689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f172689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f172689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fcbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f1fd643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37551)\u001b[0m     @     0x55f36f172689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x7faa8d94c79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be201aefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20109b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20194baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20195a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20109bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20194baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20195643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be2010a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20194baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20195643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be2010a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20194baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20195643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be2010a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20194baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be20195643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37639)\u001b[0m     @     0x55be2010a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30ea6d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37617)\u001b[0m     @     0x55a30e9e2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa89fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa8a0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37620)\u001b[0m     @     0x5573fa815689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074feb9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37611)\u001b[0m     @     0x56074fe2e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cd6868de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d687baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d688643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37633)\u001b[0m     @     0x55cc0d5fd689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfe60ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x7edfec16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191422fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191408baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191409a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191408baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191409643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191408baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191409643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191408baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191409643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191408baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d191409643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37621)\u001b[0m     @     0x55d19137e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84cb1b34f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x7f84d125e79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93e7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9342b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9342bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9343689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9343689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9343689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d93ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=37627)\u001b[0m     @     0x5610d9343689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "2020-11-05 10:07:18,345\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.\n",
+      "2020-11-05 10:07:18,347\tERROR trial_runner.py:567 -- Trial PPO_jss_env_ab943_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=37688, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 23.9/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ab943_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_ab943_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_ab943_00000_0_2020-11-05_10-07-11/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.339879 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=137dbd5547ea6deabdff035801000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3824\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:41,292 - wandb.wandb_agent - INFO - Running runs: ['uz9lk4hk']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204438-uz9lk4hk/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204438-uz9lk4hk/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 209.43434\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 209.43434\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3742\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708279\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/uz9lk4hk\u001b[0m\n",
-      "2020-10-14 20:44:46,515 - wandb.wandb_agent - INFO - Cleaning up finished run: uz9lk4hk\n",
-      "2020-10-14 20:44:46,834 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:46,834 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta58\n",
-      "2020-10-14 20:44:46,836 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta58\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/i1pzxngg\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204448-i1pzxngg\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.340052 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=3f75a43fb9f70f24bdff035801000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.340174 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=726b8519c6d92b8e8168b55d01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.340237 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=e8fef079b20e071c8168b55d01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.339663 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.348565 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "2020-11-05 10:07:18,372\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffbdff035801000000.\n",
+      "2020-11-05 10:07:18,373\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 23.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ab943_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_ab943_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_ab943_00000_0_2020-11-05_10-07-11/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
       "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_ab943_00000])\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.355484 37688 38786 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=575b3faf45c7d0bd8168b55d01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=8168b55d01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.358621 37688 38786 task_manager.cc:323] Task failed: IOError: 14: failed to connect to all addresses: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=150a9d56b40e3700bdff035801000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=bdff035801000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.368407 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=bf6cd9795b8b23124e242e9f01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.368507 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=c5da4173a1c517cf4e242e9f01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=37688)\u001b[0m E1105 10:07:18.368592 37688 38786 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=626c71df3976eafd4e242e9f01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=4e242e9f01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3912\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:44:51,849 - wandb.wandb_agent - INFO - Running runs: ['i1pzxngg']\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.368371 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.374328 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 37449\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.380496 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error --- 2.09MB of 2.09MB uploaded (0.00MB deduped)\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff091d563401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0314ce3001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4100f4fd01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.398025 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.403740 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.408936 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.410506 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.417423 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.418872 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.420966 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.422003 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.435156 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.460924 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.474542 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.481526 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.481829 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.482877 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.487709 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.492220 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.496332 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.505857 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.506453 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.506624 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.507773 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.508775 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.512436 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.516341 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.516407 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.516860 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.516995 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.517253 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.519479 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.521167 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.523342 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.524055 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.524757 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.527154 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff252160a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.528190 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.529613 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.531947 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.533715 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.535359 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.536332 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.536576 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.539386 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.539686 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa97540c201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.542917 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.544206 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.545106 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.545445 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.547315 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.548048 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.549109 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.549212 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.549736 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.550320 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.550449 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.551002 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.552634 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.553782 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.554188 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.554746 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.555704 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.556077 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.556381 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.556708 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.556804 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.556874 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.557425 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.557840 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.557932 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.558014 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.558739 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.559217 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.560585 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.561875 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:18.562985 37508 37508 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204448-i1pzxngg/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204448-i1pzxngg/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 209.89899\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 209.89899\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3826\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708290\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201105_100706-phnfkvio/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201105_100706-phnfkvio/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/i1pzxngg\u001b[0m\n",
-      "2020-10-14 20:44:57,073 - wandb.wandb_agent - INFO - Cleaning up finished run: i1pzxngg\n",
-      "2020-10-14 20:44:57,383 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:44:57,384 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta59\n",
-      "2020-10-14 20:44:57,386 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta59\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgood-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/phnfkvio\u001b[0m\n",
+      "2020-11-05 10:07:30,132 - wandb.wandb_agent - INFO - Cleaning up finished run: phnfkvio\n",
+      "2020-11-05 10:07:30,521 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-05 10:07:30,522 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta43\n",
+      "2020-11-05 10:07:30,525 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta43\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.9 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "2020-11-05 10:07:35,543 - wandb.wandb_agent - INFO - Running runs: ['7uauk61u']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3kcee9dt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204459-3kcee9dt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwoven-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/1ke874jl\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/7uauk61u\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201105_100732-7uauk61u\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-05 10:07:36,245\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 12.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_bb4dc_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 3998\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:45:02,401 - wandb.wandb_agent - INFO - Running runs: ['3kcee9dt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204459-3kcee9dt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204459-3kcee9dt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 211.84848\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 211.84848\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3517\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708300\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/3kcee9dt\u001b[0m\n",
-      "2020-10-14 20:45:07,613 - wandb.wandb_agent - INFO - Cleaning up finished run: 3kcee9dt\n",
-      "2020-10-14 20:45:10,058 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 20:45:10,059 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta60\n",
-      "2020-10-14 20:45:10,061 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python MTWR.py --instance_path=/JSS/JSS/env/instances/ta60\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMTWR\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/po3ygyxo\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/kkype8ue\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_204512-kkype8ue\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m 2020-11-05 10:07:38,988\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m *** SIGSEGV (@0x0) received by PID 39219 (TID 0x7f4a5c71c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f4a5c2f5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5c29ef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b9c97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m *** SIGSEGV (@0x0) received by PID 39214 (TID 0x7fb606831700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7fb60640a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f8706193f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87058be7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87058c18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m *** SIGSEGV (@0x0) received by PID 39215 (TID 0x7fadd7042700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7fadd6c1b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed6badf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m *** SIGSEGV (@0x0) received by PID 39128 (TID 0x7f09c7738700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m *** SIGSEGV (@0x0) received by PID 39229 (TID 0x7f28946b6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7f289428f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m *** SIGSEGV (@0x0) received by PID 39216 (TID 0x7f5dd07f7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f5dd03d0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ed0333f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfa5e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m *** SIGSEGV (@0x0) received by PID 39202 (TID 0x7f1aa7770700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7f1aa7349390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m *** SIGSEGV (@0x0) received by PID 39212 (TID 0x7f2ed5631700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7f2ed520a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd5166f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd48917db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd48948f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m *** SIGSEGV (@0x0) received by PID 39129 (TID 0x7f70f660b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m *** SIGSEGV (@0x0) received by PID 39190 (TID 0x7f66912cc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f6690ea5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3790e37f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f37905627db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m *** SIGSEGV (@0x0) received by PID 39097 (TID 0x7eff7b06c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7eff7ac45390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m *** SIGSEGV (@0x0) received by PID 39209 (TID 0x7f8248c8b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f8248864390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5348774f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347e9f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m *** SIGSEGV (@0x0) received by PID 39167 (TID 0x7ff7ace69700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m *** SIGSEGV (@0x0) received by PID 39116 (TID 0x7fd40af00700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fd40aad9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m *** SIGSEGV (@0x0) received by PID 39184 (TID 0x7ff44a98f700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7ff44a568390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54a4f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc549c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc549c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m *** SIGSEGV (@0x0) received by PID 39126 (TID 0x7f29428e3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7f29424bc390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m *** SIGSEGV (@0x0) received by PID 39172 (TID 0x7f739660b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f73961e4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f449613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f44958657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m *** SIGSEGV (@0x0) received by PID 39207 (TID 0x7fa8bc31b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7fa8bbef4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bbe0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb5367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m *** SIGSEGV (@0x0) received by PID 39171 (TID 0x7f5b5ebab700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f5b5e784390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m *** SIGSEGV (@0x0) received by PID 39221 (TID 0x7fa4d1c3d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7fa4d1816390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d16f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m *** SIGSEGV (@0x0) received by PID 39162 (TID 0x7f9f49ca3700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f9f4987c390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f70497f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048f247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m *** SIGSEGV (@0x0) received by PID 39224 (TID 0x7ffa37e60700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7ffa37a39390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m *** SIGSEGV (@0x0) received by PID 39187 (TID 0x7f6eb295e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f6eb2537390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb2193f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb18be7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m *** SIGSEGV (@0x0) received by PID 39179 (TID 0x7f7d37b5c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f7d37735390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e376aef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m *** SIGSEGV (@0x0) received by PID 39112 (TID 0x7f99ff587700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m *** SIGSEGV (@0x0) received by PID 39196 (TID 0x7f7dbbdfb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f7dbb9d4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m *** SIGSEGV (@0x0) received by PID 39223 (TID 0x7f5ea9f30700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f5ea9b09390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa9a0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa91357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m *** SIGSEGV (@0x0) received by PID 39163 (TID 0x7fca45b20700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7fca456f9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b45687f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m *** SIGSEGV (@0x0) received by PID 39191 (TID 0x7f95c4491700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f95c406a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m *** SIGSEGV (@0x0) received by PID 39194 (TID 0x7fd2f0d51700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fd2f092a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b9cc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b9ccad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87058c1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed62d87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed62db8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7f09c7311390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac7229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac69547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef994223f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef99394e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfa618f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba7229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba69547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd4894ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f70f61e4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f613af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f58657db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f37905658f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3790565ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07aad1f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a1fc7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a1ff8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347ea28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347ea2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7ff7aca42390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac911f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac03c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50aa9ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a1ca7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a1cd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a1cdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc549c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc549c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54a50ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54a52dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa42467f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa41b927db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa41b958f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa41b95ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f44958688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f4495868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f4495868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f449614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb5398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bbe1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5e729f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5de547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5de578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5de57ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d1705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048f278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048f27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb378def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb370097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3700c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m *** SIGSEGV (@0x0) received by PID 39183 (TID 0x7f5463c42700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb18c18f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb18c1ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb18c1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb21a4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb21c7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36dd97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36ddc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36ddcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f99ff160390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6aff0f7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe8227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe8258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa91388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa9138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa9138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa9a1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa9a3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44db27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44db58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44db5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c401cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c37477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c374a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m *** SIGSEGV (@0x0) received by PID 39122 (TID 0x7fc5cf625700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7fc5cf1fe390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96cf124f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m *** SIGSEGV (@0x0) received by PID 39110 (TID 0x7f73d56b0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f0825f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3eff507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3eff538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3eff53ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m *** SIGSEGV (@0x0) received by PID 39200 (TID 0x7f6537b8a700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f6537763390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m *** SIGSEGV (@0x0) received by PID 39233 (TID 0x7f5bf8a7b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f5bf8654390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf8563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m *** SIGSEGV (@0x0) received by PID 39108 (TID 0x7feeaa820700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7feeaa3f9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfaa34bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m *** SIGSEGV (@0x0) received by PID 39168 (TID 0x7f230026b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7f22ffe44390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ffddef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff5097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m *** SIGSEGV (@0x0) received by PID 39096 (TID 0x7f0cad7be700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7f0cad397390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m *** SIGSEGV (@0x0) received by PID 39127 (TID 0x7ff7d5328700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7ff7d4f01390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m *** SIGSEGV (@0x0) received by PID 39117 (TID 0x7f5e7decb700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f5e7daa4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m *** SIGSEGV (@0x0) received by PID 39111 (TID 0x7f16302c1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7f162fe9a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72fe0bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b9ccd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5c2afb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5c2d2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b774a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b772388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5b7745a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87058c1d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87061a4b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87061c7c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f8705669a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f8705667388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87056695a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed62dbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed62dbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed6bbeb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed6be1c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac69578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac6957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac6957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac723ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef9939518f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef993951ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef993951d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef994234b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef994257c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfa61ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfa61d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ed0344b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ed0367c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecf809a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba69578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba6957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba6957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba723ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba725dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd4894d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd5177b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd519ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd463ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd463a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd463c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f58688f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f5868ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f5868d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f614bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3790565d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3790e48b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3790e6bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f379030da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f379030b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f379030d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m *** SIGSEGV (@0x0) received by PID 39120 (TID 0x7fd5ff0f1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fd5fecca390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fec6af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe3957db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a1ffad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a1ffd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07aae2b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07ab05c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed079fa7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed079fa5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed079fa75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m *** SIGSEGV (@0x0) received by PID 39103 (TID 0x7fcc99de1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7fcc999ba390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d995f7f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98d227db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m *** SIGSEGV (@0x0) received by PID 39124 (TID 0x7ff3e68f4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7ff3e64cd390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e6365f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5a907db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m *** SIGSEGV (@0x0) received by PID 39114 (TID 0x7fd055562700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fd05513b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1550b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1547e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m *** SIGSEGV (@0x0) received by PID 39192 (TID 0x7fb477405700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7fb476fde390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576f13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m *** SIGSEGV (@0x0) received by PID 39113 (TID 0x7f7dd7fd8700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m *** SIGSEGV (@0x0) received by PID 39164 (TID 0x7f7c1940c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m *** SIGSEGV (@0x0) received by PID 39177 (TID 0x7f615bdef700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m *** SIGSEGV (@0x0) received by PID 39173 (TID 0x7eff753d5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347ea2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5348785b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f53487a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347c4aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347c48388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f5347c4a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac03f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac03fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac03fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac922b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac945c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a1cdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50aab0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50aad3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa509f75a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa509f73388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc5499cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc5499cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc5499cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa41b95d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa42478b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa4249bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa4193da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa4193b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f449616ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f4495610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f449560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f44956105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bbe3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb2e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb2df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb2e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5de57d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5e73ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5e75dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5dbffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5dbfd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d1728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d0bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m *** SIGSEGV (@0x0) received by PID 39105 (TID 0x7f4f8250b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f4f820e4390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081f8df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20816b87db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048f27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f704980ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f704982dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048ccfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048ccd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3700cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3700cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb378efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb37912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m *** SIGSEGV (@0x0) received by PID 39203 (TID 0x7f76d8bd7700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f76d87b0390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d8563f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7c8e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m *** SIGSEGV (@0x0) received by PID 39176 (TID 0x7fb9153d5700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7fb914fae390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a145cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a145d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f546381b390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f25637a9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562ed47db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562ed78f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb1669a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb1667388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb16695a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36ddcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e376bfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e376e2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36b84a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe825ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe825d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6aff108b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6aff12bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebadb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebadb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebadb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa8ee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa8ede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa8ee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44db5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b45698b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b456bbc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44b5da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44b5b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c374aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c374ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c402db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c4050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce84f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce8528f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce852ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f73d5289390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d5225f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d49507db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d49538f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3eff53d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f0836b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f0859c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3efcfba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3efcf9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m *** SIGSEGV (@0x0) received by PID 39166 (TID 0x7fa6f7770700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7fa6f7349390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f72e6f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m *** SIGSEGV (@0x0) received by PID 39188 (TID 0x7fb33e49b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7fb33e074390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843e005f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d7307db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d7338f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m *** SIGSEGV (@0x0) received by PID 39178 (TID 0x7fd4269a9700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fd426582390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa526537f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525c627db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525c658f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m *** SIGSEGV (@0x0) received by PID 39119 (TID 0x7f4857e28700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f4857a01390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1957751f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956e7c7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m *** SIGSEGV (@0x0) received by PID 39226 (TID 0x7f4915848700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f4915421390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a1539ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14aca7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m *** SIGSEGV (@0x0) received by PID 39107 (TID 0x7ff0b1006700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7ff0b0bdf390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0b3bf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b02667db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b02698f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m *** SIGSEGV (@0x0) received by PID 39118 (TID 0x7f75e3f1e700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f75e3af7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e3a88f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e31b37db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m *** SIGSEGV (@0x0) received by PID 39158 (TID 0x7f2bb39b1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7f2bb358a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb2c15f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m *** SIGSEGV (@0x0) received by PID 39234 (TID 0x7ff339790700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7ff339369390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc4392fcf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438a277db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438a2a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438a2aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m *** SIGSEGV (@0x0) received by PID 39115 (TID 0x7fb3c956b700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7fb3c9144390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c90b5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c87e07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m *** SIGSEGV (@0x0) received by PID 39175 (TID 0x7fec3852c700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fec38105390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3801cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd377477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3774a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m *** SIGSEGV (@0x0) received by PID 39186 (TID 0x7f5cb3865700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f5cb343e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db3229f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db29547db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db29578f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db2957ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m *** SIGSEGV (@0x0) received by PID 39198 (TID 0x7fae56bdc700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7fae567b5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f564f9f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f55c247db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m *** SIGSEGV (@0x0) received by PID 39104 (TID 0x7f6df58f0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f6df54c9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef5476f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef4ba17db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m *** SIGSEGV (@0x0) received by PID 39099 (TID 0x7fe9fd5e0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fe9fd1b9390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafd174f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc89f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc8a28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc8a2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m *** SIGSEGV (@0x0) received by PID 39181 (TID 0x7f5c8c6a6700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f5c8c27f390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8c01cf90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b7477db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b74a8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m *** SIGSEGV (@0x0) received by PID 39165 (TID 0x7f5513b65700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f551373e390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f26136aef90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612dd97db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612ddc8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m *** SIGSEGV (@0x0) received by PID 39100 (TID 0x7f3e0e139700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f3e0dd12390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0dc0df90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d3387db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d33b8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m *** SIGSEGV (@0x0) received by PID 39130 (TID 0x7f2955c2d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7f2955806390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa556f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m *** Aborted at 1604570864 (unix time) try \"date -d @1604570864\" if you are using GNU date ***\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m *** SIGSEGV (@0x0) received by PID 39170 (TID 0x7fa4006fe700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7fa4002d7390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74fff2ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff65a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff65d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m *** SIGSEGV (@0x0) received by PID 39102 (TID 0x7f01d5008700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7f01d4be1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4b64f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d428f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d42928f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4292ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f363761ff90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636d4a7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636d4d8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636d4dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m *** SIGSEGV (@0x0) received by PID 39174 (TID 0x7f4aaf40d700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f4aaefe6390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1baef13f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae63e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m *** SIGSEGV (@0x0) received by PID 39161 (TID 0x7f3a5b2a4700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f3a5ae7d390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5ae26f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a5517db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m *** SIGSEGV (@0x0) received by PID 39101 (TID 0x7f5f700b0700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f5f6fc89390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f9c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f0f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7c918f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9a767db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9a798f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9a79ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff50c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff50cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddad347f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddaca727db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddaca758f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddaca75ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m *** SIGSEGV (@0x0) received by PID 39169 (TID 0x7fa425ba1700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7fa42577a390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f75256f4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524e1f7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524e228f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d4e77f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d45a27db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d45a58f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d45a5ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7da0af90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d1357db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d1388f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d138ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f5367db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f5398f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f539ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5be5f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5e3328de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b5be5f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f8705d544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f87082278de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f8705d544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x7f870bdff79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50cdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5028b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5028bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5029689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5029689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5029689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade50b4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39214)\u001b[0m     @     0x55ade5029689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed6083a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed6081388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed60835a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac725dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac66ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac66fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac66ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef9936f9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef9936f7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef9936f95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef993de44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef9962b78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecf807388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecf8095a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ed23c78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba66ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba66fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba66ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd4d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd71fa8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effd4d274f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x7effdadd279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4dbffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4da6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39212)\u001b[0m     @     0x55b3c4d1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f5610a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f560e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f56105a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f5cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f37909f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3792ecb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f37909f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x7f3796aa379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c0778fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d3b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075fa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d3bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075ebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c075f643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39190)\u001b[0m     @     0x5622c06d4689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe3988f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe398ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe398d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fec7bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fec9ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07cb658de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed07a6924f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x7ed08073d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c91fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0becb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c78a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0becbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0bed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0bed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0bed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0c78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39097)\u001b[0m     @     0x559ca0bed689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98d258f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98d25ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98d25d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d99608b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d9962bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5a938f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5a93ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5a93d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e6376b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e6399c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1547e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1547e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1547e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1550c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f857663e7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f85766418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f7dd7bb1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed79c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed70f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed70f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed70f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f7c18fe5390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d185cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d185d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f615b9c8390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b8def90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b0097db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b00c8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7eff74fae390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074ea4f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed0745cf7db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed0745d28f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m PC: @                0x0 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m *** SIGSEGV (@0x0) received by PID 39098 (TID 0x7f564ff08700) from PID 0; stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f564fae1390 (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f9c5f90 _ZN3c1012function_refIFvPPcPKllEE11callback_fnIZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNSA_L11copy_kernelERNS8_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNSA_L11copy_kernelESD_bENKSE_clEvENKSF_clEvEUlNS8_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvSD_OT0_OT1_EUlS2_S4_lE0_EEvlS2_S4_l\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f0f07db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f53483354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f534a8088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f53483354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x7f534e3e079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d46afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c5b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d450baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d451a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c5bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d450baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d451643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d450baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d451643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d450baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d451643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d450baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d451643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39209)\u001b[0m     @     0x561c5d3c6689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8abde7a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8abde5388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8abde75a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac4d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa509f755a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a6604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50cb338de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa50a6604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54c58d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc54a0ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x7fc55016579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ee8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e43b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecfa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e43bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e44689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e44689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e44689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6ecf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39184)\u001b[0m     @     0x560fd6e44689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa4193d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa420284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa444fb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa420284f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x7efa480d379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x56196778efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676e9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967774baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967775a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676e9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967774baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967775643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f4495cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f44981ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f4495cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x7f449bda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb75fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbb5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39172)\u001b[0m     @     0x55d6bbad1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bde9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79bb9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x7f79c1a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1c0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e1a7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39207)\u001b[0m     @     0x564e4e11c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5dbff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5e2ea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c607bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c5e2ea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x7f2c6439579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abc8fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab23b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abafa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab23bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d37888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d12b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20816bb8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20816bbad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20816bbd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081f9eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081fc1c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f7048ccf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f70493ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f704b88d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f70493ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x7f704f46579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442cbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb36db4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb36db2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb36db45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb399728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7c91ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d8574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d8597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a145d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a145d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562ed7ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562ed7d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f25637bab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f25637ddc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562c7fa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb1d544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb42278de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb1d544f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x7f3fb7dff79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0abc2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba9a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba8baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0aba9643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39187)\u001b[0m     @     0x55fa0ab1e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36b82388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e36b845a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e3726f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e397428de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe5cda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe5cb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afe5cd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afecb84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebd9728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ebb49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x7f4ec154a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503c7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50322b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503aea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50322bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50323689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50323689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50323689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503adbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab503ae643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39196)\u001b[0m     @     0x55ab50323689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa95cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2faba9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2fa95cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x7f2faf67679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab54fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aaafb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aaafbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aab0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aab0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aab0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547ab3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39223)\u001b[0m     @     0x56547aab0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b44b5d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b452484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b4771b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c34f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c34f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c34f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c3bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c60b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce852d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96cf135b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96cf158c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce5faa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce5f8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96ce5fa5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d4953ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d4953d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d5236b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d5259c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d46fba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3efcfb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f03e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f28b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f03e64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x7fa3f649179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88483fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883deb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88469baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d8846aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883debfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6a117db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6a148f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6a14ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d733ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d733d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525c65ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525c65d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa526548b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa52656bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956e7f8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956e7fad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14acd8f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14acdad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0269ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0269d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0b4cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e31b68f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e31b6ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb23407db _ZN3c1012function_refIFvPPcPKlllEE11callback_fnIZN2at14TensorIterator8for_eachENS0_IFvS2_S4_lEEElEUlS2_S4_llE_EEvlS2_S4_ll\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb23438f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438a2ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc43930db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc439330c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c87e38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c87e3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3774aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3774ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3802db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd38050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db2957d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db323ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db325dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db26ffa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db26fd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f55c278f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f55c27ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f55c27d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f5650ab22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef4ba48f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef4ba4ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef4ba4d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef5487b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef54aac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc8a2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafd185b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafd1a8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc64aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc648388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b74aad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b74ad91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8c02db22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8c050c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612ddcad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612ddcd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f26136bfb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d33bad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d33bd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0dc1eb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0dc41c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d0e3a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d0e1388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa55705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa55728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff65dad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff65dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74fff40b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74fff63c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff405a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4292d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4b75b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4b98c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d403aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d4038388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636d4dd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3637630b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3637653c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636af5a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636af3388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f3636af55a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae6418f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae641ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae641d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1baef24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1baef47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a5548f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a554ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a554d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5ae37b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5ae5ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f0f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f0f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f0f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7c91d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf8574b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf8597c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf7a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9a79d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfaa35cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfaa37fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9821a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa981f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff50cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ffdefb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ffe12c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff2b4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff2b2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff2b45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddaca75d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddad358b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddad37bc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddac81da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddac81b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524e22ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524e22d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7525705b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7525728c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d45a5d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d4e88b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d4eabc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d434da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d434b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d138d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7da1bb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7da3ec1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7cee0a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7cede388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f539d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72fe1cb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72fe3fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f2e1a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f2df388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f2e15a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x7f1b61f0a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca474fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3cfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3cfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca45b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39219)\u001b[0m     @     0x5598ca3d0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed676e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed8c418de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7ed676e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x7f7edc81979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fedfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f48b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f48bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2fd4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39215)\u001b[0m     @     0x55bbf2f49689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac92bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edac6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x7edacce9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed30afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed265b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed265bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed266689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed266689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed266689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef993de44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x7ef999e8f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907e4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x56349073fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x56349073fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x563490740689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x563490740689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x563490740689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x5634907cb643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39229)\u001b[0m     @     0x563490740689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ecfef44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x7f2ed5f9f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de83fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddeb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de6aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3de6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39216)\u001b[0m     @     0x562a3dddf689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba92bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eeba6dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x7eebace9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddc010fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbff7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39202)\u001b[0m     @     0x556ddbf6c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f81ce8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41f5cfb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x7f41fbda679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebe5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb40b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb40bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb41689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb41689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb41689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcbbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5ebcc643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39129)\u001b[0m     @     0x55aa5eb41689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe140a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe13e388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe1405a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98acda93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98acb388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d98acd5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e583ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5839388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e583b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1550e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa15458ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa154589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa15458b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576f24b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576f47c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f85763e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f85763e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed70f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed79d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed79f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed6e9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed6e99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d185d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d185d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b00cad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b00cd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b8efb22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed0745d2ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed0745d2d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074eb5b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074ed8c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f0f38f7 at::TensorIterator::serial_for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ae9a58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8ac4d24f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x7fc8b257d79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775f0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d7a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d6baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d7775d7643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39167)\u001b[0m     @     0x55d77754c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x7fa51070b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc9a9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc904b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc98fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc990a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc904bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc98fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc990643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc905689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc98fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc990643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc905689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc98fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc990643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc905689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc98fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc990643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39116)\u001b[0m     @     0x562fcc905689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967774baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967775643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967774baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967775643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967774baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x561967775643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39126)\u001b[0m     @     0x5619676ea689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaebaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68abaf643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39171)\u001b[0m     @     0x55d68ab24689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x7f75d736079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b1afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a75b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b00baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b01a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a75bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b00baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b01643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b00baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b01643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b00baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b01643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b00baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852b01643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39221)\u001b[0m     @     0x55c852a76689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081463a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081461388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20814635a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144226b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144226bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144227689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144227689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144227689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d1442b2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39162)\u001b[0m     @     0x55d144227689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3749f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x7fcb3d54a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb04385fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb0436c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39224)\u001b[0m     @     0x55fb042e1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7a39a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7a37388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d7a395a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a1437aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a1437a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562c7d388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f2562c7f5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f256336a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e3726f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x7f4e3d31a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6f3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6d9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6daa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6d9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6da643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6d9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6da643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6d9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6da643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6d9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c6da643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39179)\u001b[0m     @     0x56490c64f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6b0118b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6afecb84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x7f6b04d6379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad91fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5acecb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad78a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5acecbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5aced689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5aced689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5aced689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad77baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5ad78643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39112)\u001b[0m     @     0x557a5aced689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b452484f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x7f9b4b2f379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a376057fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb2b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb2bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a37603e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39163)\u001b[0m     @     0x55a375fb3689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c3bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x7f66c9c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef54fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeafb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeafbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603cef3b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39191)\u001b[0m     @     0x5603ceeb0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96cece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96d11b88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96cece54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d46f9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d46fb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d4de64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d72b98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88469baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d8846a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88469baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d8846a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88469baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d8846a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d88469baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d8846a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39194)\u001b[0m     @     0x561d883df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6a14d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f72f7b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f731ac1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f67bca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f67ba388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f67bc5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843e016b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843e039c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d4dba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d4d9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843d4db5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525a0da93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525a0b388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa525a0d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa5260f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa5285cb8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14acdd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a153b0b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a153d3c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14875a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14873388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0b6fc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b0011a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b000f388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b00115a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e31b6d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e3a99b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e3abcc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e2f5ea93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e2f5c388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb2343ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb2343d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb2c26b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb2c49c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb20eba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb20e9388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc4387d2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc4387d0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc4387d25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438ebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc43b3908de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c87e3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c90c6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c90e9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c858ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c8589388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd374f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd374f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd374f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db26ff5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f5652dc1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f559cfa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f559cd388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef494ca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef494a388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef494c5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafc64a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafcd354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbaff2088de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b4f2a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b4f0388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8b4f25a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f26136e2c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612b84a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612b82388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d0e35a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d7ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa54bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa552b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff403388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ff4055a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d403a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d47254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f36371e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f36396b38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f36371e04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae3e9a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae3e7388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bae3e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a2fca93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a2fa388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a2fc5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f9d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f9f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306ee9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306ee99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cfa5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cf81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x7f2cfe1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2c9fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b224b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2afbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2b0a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b224bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2afbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2b0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b225689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2afbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2b0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b225689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2afbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2b0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b225689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2afbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b2b0643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39233)\u001b[0m     @     0x55ff5b225689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa98215a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfac3df8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfa9f0c4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff99f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef401e728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef3ff99f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x7ef405a4a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0bffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb0a6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39168)\u001b[0m     @     0x5645eb01b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddac81d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddacf084f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddaf3db8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524bcaa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524bc8388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f7524bca5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f75252b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f75277888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d434d5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d4a384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d6f0b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8d4a384f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7cee05a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7fa9e8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f7d5cb4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee731e9f8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee72f9cc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x7ee735a7779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f34437efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442d9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344364baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344365a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442d9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344364baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344365643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442da689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344364baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344365643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed2f1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39128)\u001b[0m     @     0x55a0ed266689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe82b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa700cfe8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa6fe82b4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x7fa7048d679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7926fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7881b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7881bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7882689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7882689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7882689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d790d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39120)\u001b[0m     @     0x55f4d7882689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d991b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d9b68b8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9d991b84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x7f9dc035979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449dcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344937b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344937bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344938689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344938689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344938689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x5653449c3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39103)\u001b[0m     @     0x565344938689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5f264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e83f98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4e5f264f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x7fc4ebfd179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8daefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d09b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d95a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d09bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d94baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d95643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39124)\u001b[0m     @     0x5607c8d0a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa154c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa1571498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa154c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x7fa15ad2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d752fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6adb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d739a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6adbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f85763e95a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8578fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed6e9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed75864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed9a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d1837aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d1837a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b912c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325adb4a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325adb2388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325adb45a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed07437aa93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074378388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed07437a5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f0f3ad3 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f0f3d91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f9d6b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f9f9c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081b4e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f20840218de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2081b4e4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x7f2087bf979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb2792bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27886b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27911baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27912a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27886bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27911baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47da5f78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47d81244f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x7f47de1cf79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bcea7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce02b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce02bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce03689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce03689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce03689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce8e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39203)\u001b[0m     @     0x5566bce03689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a16f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a14a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x7f8a1ab1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcdbefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd19b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd19bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcda5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39176)\u001b[0m     @     0x561dfcd1a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f256583d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f256336a4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x7f256941579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e51afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e475b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e501a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e475bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e500baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e501643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39183)\u001b[0m     @     0x55657e476689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x7f96d4d9079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9327fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9282b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930ea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9282bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930dbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa930e643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39122)\u001b[0m     @     0x55eaa9283689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44d4de64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x7f44dae9179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f7718cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e7b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77172baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77173a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e7bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77172baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77173643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77172baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77173643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77172baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77173643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77172baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f77173643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39110)\u001b[0m     @     0x561f770e8689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6ea74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f937a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77f6ea74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x7f77fcf5279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc59efd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4f9b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc584baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc585a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4f9bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc584baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843dbc64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f84400998de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f843dbc64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa5260f84f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x7fa52c1a379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c9bfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf6b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c81baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c82a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf6bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c81baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c82643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c81baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c82643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c81baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c82643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c81baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678c82643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39178)\u001b[0m     @     0x55d678bf7689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956e7fd91 at::TensorIterator::for_each()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1957762b22 _ZN2at6native12_GLOBAL__N_114cpu_kernel_vecILb1EZZZNS1_L11copy_kernelERNS_14TensorIteratorEbENKUlvE3_clEvENKUlvE2_clEvEUlfE_ZZZNS1_L11copy_kernelES4_bENKS5_clEvENKS6_clEvEUlNS_6vec25612_GLOBAL__N_16Vec256IfEEE0_EEvS4_OT0_OT1_\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a148755a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14f604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a174338de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b06fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b2bcf8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e2f5e5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e36494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb20eb5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc438ebd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x7fc43ef6879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681511ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815106a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815105baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x556815106643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39234)\u001b[0m     @     0x55681507b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c858b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c8c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd37bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3a0b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd37bdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x7fbd3dc8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482db2fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0db08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d98baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d99a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0dbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d98baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d99643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d98baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d99643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d98baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d99643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d98baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d99643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39175)\u001b[0m     @     0x565482d0e689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db52bd8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db2dea4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x7f2db8e9579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a83fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249deb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a6aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249debfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a69baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c24a6a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39186)\u001b[0m     @     0x561c249df689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f559cf5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f560ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f5858d8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f560ba4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef50374f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef750a8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbafcd354f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x7fbb02de079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae949fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a4b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae92fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae930a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a4bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae92fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae930643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae92fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae930643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae92fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae930643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae92fbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae930643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39099)\u001b[0m     @     0x5616ae8a5689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8bbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8e0b08de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d8bbdd4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x7f2d91c8879f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adc5fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad20b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adaca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad20bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adabbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97adac643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39181)\u001b[0m     @     0x55a97ad21689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f2612b845a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f261326f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f26157428de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f261326f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x7f261931a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6356b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0fca18de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f0d7ce4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x7f0f1387979f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc80fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdbb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc66baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc67a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdbbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc66baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc67643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc66baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc67643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc66baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc67643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc66baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cc67643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39100)\u001b[0m     @     0x56384cbdc689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa577888de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa552b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x7efa5b36079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f553b0fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530bb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55396baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55397a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530bbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55396baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55397643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55396baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55397643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55396baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55397643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55396baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f55397643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39130)\u001b[0m     @     0x561f5530c689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ffaf04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f7501fc38de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f74ffaf04f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x7f7505b9b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de36fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd91b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd91bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d6bf88de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2d47254f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x7ed2da7d079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a25095fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a2507c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39102)\u001b[0m     @     0x557a24ff1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x7f363d28b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721d7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872132b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872132bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721be643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872133689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721be643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872133689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721be643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872133689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721bdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x5648721be643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39200)\u001b[0m     @     0x564872133689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1baead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bb0fa78de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1baead44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x7f1bb4b7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435f1fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d8a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d7baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x5596435d8643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a9e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5ceba8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b5a9e74f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x7f0b60a9279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c521fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47cb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c507baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c508a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47cbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306ee9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f3071a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x7fbfaffb779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e11cfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e077b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e102baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e103a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e077bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e102baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e103643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e078689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e102baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e103643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e078689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e102baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e103643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e078689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e102baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e103643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39108)\u001b[0m     @     0x561f3e078689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddacf084f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x7eddb2fb379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1e3fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1c9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1caa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1c9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1ca643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1c9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1ca643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1c9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1ca643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1c9baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b1ca643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39096)\u001b[0m     @     0x55637b13f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f75252b54f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x7f752b36079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0c4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb01fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb01fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb020689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb020689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb020689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0aabaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb0ab643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39169)\u001b[0m     @     0x55c3bb020689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x7fc8daae379f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5c6fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c521b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5ada20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c521bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c522689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c522689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c522689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5acbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c5ad643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39127)\u001b[0m     @     0x55804c522689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x7f2f8367679f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e75fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd0b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5ca20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd0bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5bbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82e5c643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39117)\u001b[0m     @     0x560b82dd1689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442da689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344364baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344365643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442da689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344364baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f344365643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39111)\u001b[0m     @     0x55f3442da689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d738baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d739643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39114)\u001b[0m     @     0x56286d6ae689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f8576ad44f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x7f857cb7f79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4edcfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e37b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec3a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e37bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec2baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4ec3643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39192)\u001b[0m     @     0x5618c4e38689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4ed75864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x7f4edd63179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2fbfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed256b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e2a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed256bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed2e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39113)\u001b[0m     @     0x55f0ed257689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d1af388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d18a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x7f4d1eb1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f3aefd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f309b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f394baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f395a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f309bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f394baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f395643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325d9728de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed076f388de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed074a654f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274ee9ba93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274ee99388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274ee9b5a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27912643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27887689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27911baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27912643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27887689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27911baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27912643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27887689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27911baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27912643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39105)\u001b[0m     @     0x55eb27887689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc585643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc584baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc585643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc584baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc585643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc584baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc585643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39166)\u001b[0m     @     0x562afc4fa689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x7f8443c7179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4dafd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba435b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c1a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba435bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba436689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba436689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba436689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c0baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba4c1643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39188)\u001b[0m     @     0x560bba436689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1957785c1d at::native::(anonymous namespace)::copy_kernel()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956c27a93 at::native::DispatchStub<>::operator()<>()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956c25388 at::native::copy_impl()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a14f604f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x7f1a1b00b79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de746fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a1b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72da20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a1bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de72d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39226)\u001b[0m     @     0x5631de6a2689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b06fc4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x7fc1b67a779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x56358343afd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583395b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583420baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583421a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583395bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e5b1c8de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e36494f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x7f46e96f479f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39e7fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3942b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cea20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3942bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3943689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3943689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3943689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39cdbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e39ce643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39118)\u001b[0m     @     0x5589e3943689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb27d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb4ca98de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb27d64f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x7efcb847779f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ebffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413ea6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39158)\u001b[0m     @     0x564413e1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84cb1498de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84c8c764f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x7f84ced2179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e6ffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e55baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e56a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcabfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e55baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e56643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e55baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e56643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e55baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e56643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e55baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13e56643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39115)\u001b[0m     @     0x559b13dcb689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x7f7f5c16579f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae333fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28eb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae31aa20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28ebfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae319baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae31a643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39198)\u001b[0m     @     0x55f3ae28f689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3ef50374f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x7f3efb0e279f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511506fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511461b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114eda20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511461bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511462689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511462689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511462689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ecbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f5114ed643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39104)\u001b[0m     @     0x55f511462689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6356bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6357689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6357689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6357689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e1baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c63e2643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39165)\u001b[0m     @     0x5646c6357689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1cbaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70de1d643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39170)\u001b[0m     @     0x55b70dd92689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39174)\u001b[0m     @     0x55964354d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c507baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c508643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c507baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c508643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c507baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c508643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c507baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c508643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39161)\u001b[0m     @     0x56026c47d689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f306f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x7f307563179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1bbffd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1ab08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba6a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1abfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba5baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1ba6643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39101)\u001b[0m     @     0x55f1c1b1b689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f30a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f394baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f395643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f30a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f394baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f395643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f30a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f394baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f395643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39164)\u001b[0m     @     0x55562f30a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f325b49f4f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x7f326154a79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd64fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcbfb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcbfbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcc0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcc0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcc0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dd4b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39177)\u001b[0m     @     0x55632dcc0689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x7ed07ab1079f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8befd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b819b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a5a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b819bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b81a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b81a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b81a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a4baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b8a5643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39173)\u001b[0m     @     0x55c51b81a689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f2751a598de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f1956c275a4 at::native::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f19573124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583420baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583421643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583396689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583420baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583421643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583396689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583420baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583421643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583396689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583420baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583421643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39107)\u001b[0m     @     0x563583396689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "== Status ==\n",
+      "Memory usage on this node: 24.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 ERROR)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_bb4dc_00000 | ERROR    |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "Number of errored trials: 1\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "| Trial name              |   # failures | error file                                                                        |\n",
+      "|-------------------------+--------------+-----------------------------------------------------------------------------------|\n",
+      "| PPO_jss_env_bb4dc_00000 |            1 | /root/ray_results/ppo-jss/PPO_jss_env_bb4dc_00000_0_2020-11-05_10-07-37/error.txt |\n",
+      "+-------------------------+--------------+-----------------------------------------------------------------------------------+\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f274f5864f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x7f275563179f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119ab4fd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a0fb08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9ba20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a0fbfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9abaf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a9b643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39098)\u001b[0m     @     0x55f119a10689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f19597e58de torch::autograd::VariableType::(anonymous namespace)::copy_()\n",
+      "2020-11-05 10:07:44,803\tERROR trial_runner.py:567 -- Trial PPO_jss_env_bb4dc_00000: Error processing event.\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
+      "    result = self.trial_executor.fetch_result(trial)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
+      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
+      "    raise value.as_instanceof_cause()\n",
+      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=39242, ip=172.17.0.4)\n",
+      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
+      "    raise e\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
+      "    result = Trainable.train(self)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
+      "    result = self.step()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
+      "    res = next(self.train_exec_impl)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
+      "    return next(self.built_iterator)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 876, in apply_flatten\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 828, in add_wait_hooks\n",
+      "    item = next(it)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
+      "    for item in it:\n",
+      "  [Previous line repeated 1 more time]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 466, in base_iterator\n",
+      "    actor_set.init_actors()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1238, in init_actors\n",
+      "    ray.get([a.par_iter_init.remote(self.transforms) for a in self.actors])\n",
+      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
+      "2020-11-05 10:07:44,807\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff821ddf4301000000.\n",
+      "2020-11-05 10:07:44,807\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff43fb47bd01000000.\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f19573124f5 at::Tensor::copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x7f195d3bd79f torch::autograd::THPVariable_copy_()\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5bdfd7 method_vectorcall_VARARGS_KEYWORDS\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b518b08 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a4a20 method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b518bfd _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b519689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b519689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b519689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a3baf _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b5a4643 _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=39119)\u001b[0m     @     0x56439b519689 _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.795258 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.796500 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "2020-11-05 10:07:44,818\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffc2621d1401000000.\n",
+      "2020-11-05 10:07:44,818\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffa97540c201000000.\n",
+      "2020-11-05 10:07:44,818\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff56c9ec1501000000.\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.796416 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=1e9c16c25b494a4a43fb47bd01000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.796594 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=61afdfe40390d0a343fb47bd01000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.796761 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=8e79ac7e91b36714821ddf4301000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.796834 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=428a4b4025d91890821ddf4301000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.807859 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=9ecf84e34eb8e61dc2621d1401000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.808137 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Socket closed: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=f3cba62d4c01820bc2621d1401000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.808488 39242 40373 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=10a4a4113c6c36ea43fb47bd01000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=43fb47bd01000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.809252 39242 40373 task_manager.cc:323] Task failed: IOError: cancelling all pending tasks of dead actor: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=38e2d2d27b716bfb821ddf4301000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=821ddf4301000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.812713 39242 40373 task_manager.cc:323] Task failed: IOError: 14: failed to connect to all addresses: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=8fbf1bd7de98d288c2621d1401000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=c2621d1401000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 74, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 56, in train_func\n",
+      "    analysis = tune.run(PPOTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
+      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
+      "ray.tune.error.TuneError: ('Trials did not complete', [PPO_jss_env_bb4dc_00000])\n",
+      "2020-11-05 10:07:44,829\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe0497dac01000000.\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.807876 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.815104 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.815445 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.820873 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.815107 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=fde3d5eda9f525d7a97540c201000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=0}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.815239 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=par_iter_init, function_hash=}, task_id=d16c21eef3935840a97540c201000000, task_name=RolloutWorker.par_iter_init(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=1}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.815429 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=stop, function_hash=}, task_id=d88ec84d5baca957a97540c201000000, task_name=RolloutWorker.stop(), job_id=01000000, num_args=0, num_returns=2, actor_task_spec={actor_id=a97540c201000000, actor_caller_id=ffffffffffffffffdf5a1a8201000000, actor_counter=2}\n",
+      "\u001b[2m\u001b[36m(pid=39242)\u001b[0m E1105 10:07:44.815793 39242 40373 task_manager.cc:323] Task failed: IOError: 14: Connection reset by peer: Type=ACTOR_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.rllib.evaluation.rollout_worker, class_name=RolloutWorker, function_name=set_weights, function_hash=}, task_id=4db1cba171d56c3356c9ec1501000000, task_name=RolloutWorker.set_weights(), job_id=01000000, num_args=2, num_returns=2, actor_task_spec={actor_id=56c9ec1501000000, actor_caller_id=ffffffffffffffffdf--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff31c3fed901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 4096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "2020-10-14 20:45:15,074 - wandb.wandb_agent - INFO - Running runs: ['kkype8ue']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_204512-kkype8ue/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_204512-kkype8ue/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result 197.64646\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode 197.64646\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep 3735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step 0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime 1\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp 1602708313\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:       nb_episodes ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   avg_best_result ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:      best_episode ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:     best_timestep ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:             _step ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:          _runtime ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        _timestamp ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mMTWR\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/kkype8ue\u001b[0m\n",
-      "2020-10-14 20:45:20,294 - wandb.wandb_agent - INFO - Cleaning up finished run: kkype8ue\n",
-      "2020-10-14 20:45:20,607 - wandb.wandb_agent - INFO - Agent received command: exit\n",
-      "2020-10-14 20:45:20,607 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
+      "Call stack:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 38996\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb2413f7201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffbdff035801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff252160a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error --- 2.09MB of 2.09MB uploaded (0.00MB deduped)\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4e242e9f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff90aded9101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff091d563401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7f7c936001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0d557f6601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7ef9157101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9f3cc57a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff19fd5b4901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff58dd50c101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffeca600ef01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.855248 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.858098 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.862875 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.865669 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.866950 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.869575 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.881582 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.883808 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.884388 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.884492 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "ValueError: I/O operation on closed file.\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.889406 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "Call stack:\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.894985 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.901394 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff59d91ef301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5cc87e2501000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.910544 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8cd168e101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8edbbd3001000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.923193 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.927239 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff41e0fbff01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff9d526f0201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0fae11b201000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.931519 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.936708 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.937791 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.940845 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8168b55d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa4f7314201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff120020c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd784bf0601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff1e7ae67b01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff257d30801000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.944075 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.945669 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff302122d001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff2d1a71ea01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffc3083e0c01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3a9488b101000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff018c9dac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8f9a5fc701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff04668d8f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffef1af81501000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff61dc472601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffb3cace0801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7b2861ac01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffee8852f401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff20d842ad01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff5843697701000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff50168bc201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff99d0343201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff51728d3301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff34cbbac201000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff3166f9e301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff8d06128001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff80993fa801000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff4f9bfece01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffdd5654aa01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff244a7d1001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff452e714401000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffd989d1f001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff392716d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff310e963d01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffda2cd21f01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff71ca01c001000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff0aeae6a301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffccf343cc01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff358dd45601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task fffffffffffffffff0f72e3901000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff10f667b001000000.'\n",
+      "Arguments: ()\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.954448 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.955423 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.964993 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.984345 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.991227 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.991828 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.994192 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.997316 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:44.999085 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1105 10:07:45.010207 39055 39055 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Connection reset by peer\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff702ed69e01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff75f329e601000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff7a508a7a01000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffffa7ad1db301000000.'\n",
+      "Arguments: ()\n",
+      "--- Logging error ---\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1085, in emit\n",
+      "    self.flush()\n",
+      "  File \"/root/miniconda3/lib/python3.8/logging/__init__.py\", line 1065, in flush\n",
+      "    self.stream.flush()\n",
+      "ValueError: I/O operation on closed file.\n",
+      "Call stack:\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 890, in _bootstrap\n",
+      "    self._bootstrap_inner()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
+      "    self.run()\n",
+      "  File \"/root/miniconda3/lib/python3.8/threading.py\", line 870, in run\n",
+      "    self._target(*self._args, **self._kwargs)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1072, in listen_error_messages_raylet\n",
+      "    logger.warning(error_message)\n",
+      "Message: 'A worker died or was killed while executing task ffffffffffffffff14da135201000000.'\n",
+      "Arguments: ()\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent po3ygyxo"
+    "!wandb agent 1ke874jl"
    ]
   },
   {
diff --git a/JSS/Random.ipynb b/JSS/Random.ipynb
index a16b1ba..30632e8 100644
--- a/JSS/Random.ipynb
+++ b/JSS/Random.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
@@ -56,7 +56,7 @@
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
     "    os.environ[\"WANDB_API_KEY\"] = '3487a01956bf67cc7882bca2a38f70c8c95f8463'\n",
     "    sweep_config = {\n",
-    "        'program': 'random_loop.py',\n",
+    "        'program': 'CP.py',\n",
     "        'method': 'grid',\n",
     "        'metric': {\n",
     "            'name': 'time_step_min',\n",
@@ -64,9 +64,9 @@
     "        },\n",
     "        'parameters': {\n",
     "            'instance_path': {\n",
-    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
-    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
-    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
+    "                'values': ['/JSS/JSS/env/instances/ta40', '/JSS/JSS/env/instances/ta41', '/JSS/JSS/env/instances/ta42', '/JSS/JSS/env/instances/ta43', '/JSS/JSS/env/instances/ta44',\n",
+    "                           '/JSS/JSS/env/instances/ta45', '/JSS/JSS/env/instances/ta46', '/JSS/JSS/env/instances/ta47', '/JSS/JSS/env/instances/ta48',\n",
+    "                           '/JSS/JSS/env/instances/ta49', '/JSS/JSS/env/instances/ta50']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -74,25 +74,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: lh9x5rb9\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\n"
+      "Create sweep with ID: wnc8ihq1\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\n"
      ]
     }
    ],
    "source": [
-    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
+    "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_3\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
@@ -100,1977 +100,422 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-14 18:51:58,915 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-14 18:51:59,229 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:51:59,229 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
-      "2020-10-14 18:51:59,231 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta51\n",
+      "2020-11-04 21:27:40,508 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-11-04 21:27:40,953 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:27:40,953 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta40\n",
+      "2020-11-04 21:27:40,955 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta40\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-14 18:52:04,245 - wandb.wandb_agent - INFO - Running runs: ['bgm3l5ts']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meffortless-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/bgm3l5ts\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185201-bgm3l5ts\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/h3u61381\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_212741-h3u61381\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:52:04,834\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-04 21:27:45,971 - wandb.wandb_agent - INFO - Running runs: ['h3u61381']\n",
       "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=25130)\u001b[0m 2020-10-14 18:52:07,658\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-11\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 72.94000000000001\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.247757911682129\n",
-      "  time_this_iter_s: 3.247757911682129\n",
-      "  time_total_s: 3.247757911682129\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701531\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |      1 |          3.24776 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-16\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 12000\n",
-      "  iterations_since_restore: 30\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.3\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 8.01456618309021\n",
-      "  time_this_iter_s: 0.16585516929626465\n",
-      "  time_total_s: 8.01456618309021\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701536\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 12000\n",
-      "  training_iteration: 30\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     30 |          8.01457 | 12000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-21\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 23600\n",
-      "  iterations_since_restore: 59\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.782260656356812\n",
-      "  time_this_iter_s: 0.1621565818786621\n",
-      "  time_total_s: 12.782260656356812\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701541\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 23600\n",
-      "  training_iteration: 59\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     59 |          12.7823 | 23600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |     87 |          17.4055 | 34800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-26\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 35200\n",
-      "  iterations_since_restore: 88\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.567854166030884\n",
-      "  time_this_iter_s: 0.16233396530151367\n",
-      "  time_total_s: 17.567854166030884\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701546\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 35200\n",
-      "  training_iteration: 88\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |    116 |          22.0842 | 46400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-31\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 46800\n",
-      "  iterations_since_restore: 117\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 22.268078804016113\n",
-      "  time_this_iter_s: 0.18388056755065918\n",
-      "  time_total_s: 22.268078804016113\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701551\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 46800\n",
-      "  training_iteration: 117\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "2020-10-14 18:52:32,975\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=25093, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 2.46153846e-01,\n",
-      "       6.26262626e-01, 5.02564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.77948718e-01, 4.44444444e-01,\n",
-      "       8.88205128e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 6.85128205e-01, 3.73737374e-01, 8.00000000e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.07692308e-01, 3.43434343e-01, 9.21025641e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.27272727e-01, 6.00000000e-01, 4.10256410e-01,\n",
-      "       1.21212121e-01, 7.73333333e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.91919192e-01, 7.33333333e-01, 3.82564103e-01, 2.22222222e-01,\n",
-      "       3.95897436e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.54871795e-01, 1.31313131e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.72727273e-01, 8.00000000e-01,\n",
-      "       6.23589744e-01, 3.23232323e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 2.94358974e-01,\n",
-      "       2.02020202e-01, 2.35897436e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.34343434e-01,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 1.31313131e-01,\n",
-      "       4.00000000e-01, 2.28717949e-01, 7.57575758e-01, 5.10769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.41025641e-01, 4.54545455e-01, 1.76410256e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.23232323e-01, 6.00000000e-01, 6.53333333e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 2.02020202e-02,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.25128205e-01, 1.91919192e-01, 3.85641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.20512821e-01, 3.23232323e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.78787879e-01, 6.00000000e-01, 5.18974359e-01,\n",
-      "       7.07070707e-02, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.83076923e-01, 2.72727273e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 2.92929293e-01, 2.56410256e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.00000000e-01,\n",
-      "       5.85641026e-01, 2.32323232e-01, 2.44102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       4.24242424e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.48205128e-01, 8.68686869e-01,\n",
-      "       1.76410256e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.94949495e-01, 4.51282051e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.61025641e-01, 8.08080808e-02, 6.17435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.02564103e-01,\n",
-      "       8.08080808e-01, 1.94871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 1.21212121e-01,\n",
-      "       7.97948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.33333333e-01, 9.74358974e-02, 3.03030303e-01, 8.41025641e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 4.04040404e-01, 3.24102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 4.66666667e-01, 3.84615385e-01,\n",
-      "       8.18181818e-01, 1.66153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       2.17435897e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.37435897e-01, 1.00000000e+00, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.32820513e-01, 3.43434343e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.04040404e-02, 4.66666667e-01, 4.81025641e-01,\n",
-      "       5.35353535e-01, 1.08717949e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 1.91794872e-01, 2.02020202e-02,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 5.85858586e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.70769231e-01, 2.92929293e-01, 3.28205128e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.14871795e-01,\n",
-      "       6.66666667e-01, 5.10769231e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-02, 4.66666667e-01, 4.77948718e-01, 6.66666667e-01,\n",
-      "       4.18461538e-03, 0.00000000e+00, 0.00000000e+00, 2.52525253e-01,\n",
-      "       5.33333333e-01, 5.51794872e-01, 3.83838384e-01, 1.70256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.20000000e-01, 7.27272727e-01, 1.23076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.43434343e-01, 6.66666667e-01, 5.40512821e-01,\n",
-      "       2.72727273e-01, 3.01538462e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 4.94949495e-01,\n",
-      "       7.79487179e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.68717949e-01, 7.57575758e-01, 3.50769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.33333333e-01,\n",
-      "       8.01025641e-01, 1.41414141e-01, 1.08717949e-03, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.54871795e-01, 5.05050505e-02,\n",
-      "       9.02564103e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 6.22564103e-01, 4.54545455e-01, 8.82051282e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 4.04040404e-01, 3.07692308e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.30256410e-01,\n",
-      "       7.07070707e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 2.77948718e-01, 3.93939394e-01,\n",
-      "       1.64102564e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | RUNNING  | 172.17.0.4:25130 |    145 |           26.762 | 58000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_5afa5_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-52-37\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 1d2b23a635304ca6bea1e0ffde98d7ee\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 58800\n",
-      "  iterations_since_restore: 147\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 25130\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 27.082104921340942\n",
-      "  time_this_iter_s: 0.1581122875213623\n",
-      "  time_total_s: 27.082104921340942\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701557\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 58800\n",
-      "  training_iteration: 147\n",
-      "  trial_id: 5afa5_00000\n",
-      "  \n",
-      "2020-10-14 18:52:41,582\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_5afa5_00000: Error processing event.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
-      "    result = self.trial_executor.fetch_result(trial)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
-      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
-      "    raise value.as_instanceof_cause()\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RandomMasked.train()\u001b[39m (pid=25130, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
-      "    raise e\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
-      "    result = Trainable.train(self)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
-      "    result = self.step()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
-      "    res = next(self.train_exec_impl)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
-      "    return next(self.built_iterator)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 551, in base_iterator\n",
-      "    batch = ray.get(obj_ref)\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=25093, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 2.46153846e-01,\n",
-      "       6.26262626e-01, 5.02564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.77948718e-01, 4.44444444e-01,\n",
-      "       8.88205128e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 6.85128205e-01, 3.73737374e-01, 8.00000000e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.07692308e-01, 3.43434343e-01, 9.21025641e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.27272727e-01, 6.00000000e-01, 4.10256410e-01,\n",
-      "       1.21212121e-01, 7.73333333e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.91919192e-01, 7.33333333e-01, 3.82564103e-01, 2.22222222e-01,\n",
-      "       3.95897436e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.54871795e-01, 1.31313131e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.72727273e-01, 8.00000000e-01,\n",
-      "       6.23589744e-01, 3.23232323e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 2.94358974e-01,\n",
-      "       2.02020202e-01, 2.35897436e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.34343434e-01,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 1.31313131e-01,\n",
-      "       4.00000000e-01, 2.28717949e-01, 7.57575758e-01, 5.10769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.41025641e-01, 4.54545455e-01, 1.76410256e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.23232323e-01, 6.00000000e-01, 6.53333333e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 2.02020202e-02,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.25128205e-01, 1.91919192e-01, 3.85641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.20512821e-01, 3.23232323e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.78787879e-01, 6.00000000e-01, 5.18974359e-01,\n",
-      "       7.07070707e-02, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.83076923e-01, 2.72727273e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 2.92929293e-01, 2.56410256e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.00000000e-01,\n",
-      "       5.85641026e-01, 2.32323232e-01, 2.44102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       4.24242424e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.48205128e-01, 8.68686869e-01,\n",
-      "       1.76410256e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.94949495e-01, 4.51282051e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.61025641e-01, 8.08080808e-02, 6.17435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.02564103e-01,\n",
-      "       8.08080808e-01, 1.94871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 1.21212121e-01,\n",
-      "       7.97948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.33333333e-01, 9.74358974e-02, 3.03030303e-01, 8.41025641e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 4.04040404e-01, 3.24102564e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 4.66666667e-01, 3.84615385e-01,\n",
-      "       8.18181818e-01, 1.66153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       2.17435897e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.37435897e-01, 1.00000000e+00, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.32820513e-01, 3.43434343e-01, 6.56410256e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.04040404e-02, 4.66666667e-01, 4.81025641e-01,\n",
-      "       5.35353535e-01, 1.08717949e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 1.91794872e-01, 2.02020202e-02,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 5.85858586e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.70769231e-01, 2.92929293e-01, 3.28205128e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.14871795e-01,\n",
-      "       6.66666667e-01, 5.10769231e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-02, 4.66666667e-01, 4.77948718e-01, 6.66666667e-01,\n",
-      "       4.18461538e-03, 0.00000000e+00, 0.00000000e+00, 2.52525253e-01,\n",
-      "       5.33333333e-01, 5.51794872e-01, 3.83838384e-01, 1.70256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.20000000e-01, 7.27272727e-01, 1.23076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.43434343e-01, 6.66666667e-01, 5.40512821e-01,\n",
-      "       2.72727273e-01, 3.01538462e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 4.94949495e-01,\n",
-      "       7.79487179e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.68717949e-01, 7.57575758e-01, 3.50769231e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.33333333e-01,\n",
-      "       8.01025641e-01, 1.41414141e-01, 1.08717949e-03, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.54871795e-01, 5.05050505e-02,\n",
-      "       9.02564103e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 6.22564103e-01, 4.54545455e-01, 8.82051282e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 4.04040404e-01, 3.07692308e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 5.30256410e-01,\n",
-      "       7.07070707e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 2.77948718e-01, 3.93939394e-01,\n",
-      "       1.64102564e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.13 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 ERROR)\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc   |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 | ERROR    |       |    172 |          31.1614 | 68800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "Number of errored trials: 1\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "| Trial name                       |   # failures | error file                                                                                 |\n",
-      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
-      "| RandomMasked_jss_env_5afa5_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_5afa5_00000_0_2020-10-14_18-52-06/error.txt |\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"random_loop.py\", line 73, in <module>\n",
-      "    rand_func()\n",
-      "  File \"random_loop.py\", line 55, in rand_func\n",
-      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
-      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
-      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_5afa5_00000])\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24896\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32790\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_185201-bgm3l5ts/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_185201-bgm3l5ts/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_212741-h3u61381/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_212741-h3u61381/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1775.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604525862\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meffortless-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/bgm3l5ts\u001b[0m\n",
-      "2020-10-14 18:52:51,177 - wandb.wandb_agent - INFO - Cleaning up finished run: bgm3l5ts\n",
-      "2020-10-14 18:52:51,692 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:52:51,693 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta52\n",
-      "2020-10-14 18:52:51,700 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta52\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/h3u61381\u001b[0m\n",
+      "2020-11-04 21:37:51,376 - wandb.wandb_agent - INFO - Cleaning up finished run: h3u61381\n",
+      "2020-11-04 21:37:51,696 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:37:51,696 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta41\n",
+      "2020-11-04 21:37:51,698 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta41\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msuper-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ezglujb0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185253-ezglujb0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/c18o79jq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_213752-c18o79jq\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:52:56,719 - wandb.wandb_agent - INFO - Running runs: ['ezglujb0']\n",
-      "2020-10-14 18:52:57,270\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=26894)\u001b[0m 2020-10-14 18:53:00,066\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-03\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 71.17999999999999\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.277367115020752\n",
-      "  time_this_iter_s: 3.277367115020752\n",
-      "  time_total_s: 3.277367115020752\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701583\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |      1 |          3.27737 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-08\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 11600\n",
-      "  iterations_since_restore: 29\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.1\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 7.904330253601074\n",
-      "  time_this_iter_s: 0.16050171852111816\n",
-      "  time_total_s: 7.904330253601074\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701588\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 11600\n",
-      "  training_iteration: 29\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     29 |          7.90433 | 11600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "2020-11-04 21:37:56,716 - wandb.wandb_agent - INFO - Running runs: ['c18o79jq']\n",
       "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33712\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_213752-c18o79jq/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_213752-c18o79jq/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2137.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604526473\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/c18o79jq\u001b[0m\n",
+      "2020-11-04 21:48:02,339 - wandb.wandb_agent - INFO - Cleaning up finished run: c18o79jq\n",
+      "2020-11-04 21:48:02,711 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:48:02,712 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta42\n",
+      "2020-11-04 21:48:02,713 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta42\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sb79yg44\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_214803-sb79yg44\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-13\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 22400\n",
-      "  iterations_since_restore: 56\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.449386596679688\n",
-      "  time_this_iter_s: 0.16517019271850586\n",
-      "  time_total_s: 12.449386596679688\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701593\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 22400\n",
-      "  training_iteration: 56\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     56 |          12.4494 | 22400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-18\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 33600\n",
-      "  iterations_since_restore: 84\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.05783486366272\n",
-      "  time_this_iter_s: 0.1567375659942627\n",
-      "  time_total_s: 17.05783486366272\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701598\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 33600\n",
-      "  training_iteration: 84\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |     84 |          17.0578 | 33600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-24\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 45200\n",
-      "  iterations_since_restore: 113\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 4.5\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 21.754982709884644\n",
-      "  time_this_iter_s: 0.16276907920837402\n",
-      "  time_total_s: 21.754982709884644\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701604\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 45200\n",
-      "  training_iteration: 113\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |    113 |           21.755 | 45200 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "2020-10-14 18:53:25,585\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26854, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       5.05050505e-01, 6.72820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.07070707e-02, 4.00000000e-01, 3.89743590e-01, 7.47474747e-01,\n",
-      "       1.20205128e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 7.47692308e-01, 3.43434343e-01, 5.82564103e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 5.33333333e-01,\n",
-      "       5.48717949e-01, 6.76767677e-01, 1.37435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.56923077e-01,\n",
-      "       1.51515152e-01, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 2.81025641e-01, 2.42424242e-01,\n",
-      "       1.47692308e-03, 0.00000000e+00, 0.00000000e+00, 7.07070707e-02,\n",
-      "       6.66666667e-01, 5.47692308e-01, 0.00000000e+00, 6.66666667e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.66666667e-01,\n",
-      "       1.79487179e-01, 7.17171717e-01, 1.95076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       1.71717172e-01, 1.12205128e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.04040404e-02,\n",
-      "       2.58461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.48717949e-01, 4.34343434e-01, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 1.01010101e-01, 5.90769231e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.82564103e-01,\n",
-      "       6.86868687e-01, 1.25128205e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.06060606e-02, 6.66666667e-01, 5.57948718e-01, 2.62626263e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 4.02051282e-01, 9.69696970e-01, 5.53846154e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.22051282e-01, 1.51515152e-01, 1.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.08080808e-02, 8.00000000e-01, 7.04615385e-01,\n",
-      "       5.65656566e-01, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.01538462e-01, 6.66666667e-01,\n",
-      "       6.25641026e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 6.36363636e-01, 1.12410256e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.40512821e-01, 1.51515152e-01, 1.43589744e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       3.33333333e-01, 5.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.86868687e-01, 7.33333333e-01, 5.47692308e-01, 8.58585859e-01,\n",
-      "       1.74358974e-03, 0.00000000e+00, 0.00000000e+00, 2.02020202e-01,\n",
-      "       5.33333333e-01, 4.80000000e-01, 3.63636364e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.86153846e-01, 3.83838384e-01, 6.35897436e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.00000000e-01,\n",
-      "       6.26262626e-01, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 8.72820513e-01, 1.00000000e+00,\n",
-      "       8.20512821e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 4.98461538e-01, 6.76767677e-01, 2.07179487e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.51515152e-01, 4.00000000e-01,\n",
-      "       4.74871795e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.13131313e-01, 8.00000000e-01, 6.59487179e-01,\n",
-      "       8.58585859e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.07692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.58974359e-01, 3.03030303e-02, 5.21025641e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.84615385e-01, 5.65656566e-01, 1.25538462e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 7.68205128e-01,\n",
-      "       1.00000000e+00, 3.36410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 6.26666667e-01, 1.00000000e+00,\n",
-      "       1.24923077e-02, 0.00000000e+00, 0.00000000e+00, 6.06060606e-02,\n",
-      "       5.33333333e-01, 4.31794872e-01, 4.54545455e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
-      "       9.70256410e-01, 1.00000000e+00, 9.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.58974359e-01,\n",
-      "       1.01010101e-02, 8.41025641e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 9.33333333e-01, 8.36923077e-01, 4.04040404e-02,\n",
-      "       1.15487179e-02, 0.00000000e+00, 0.00000000e+00, 6.96969697e-01,\n",
-      "       6.00000000e-01, 5.84615385e-01, 2.92929293e-01, 1.07282051e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       4.65641026e-01, 0.00000000e+00, 3.38461538e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.02564103e-01,\n",
-      "       7.07070707e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.66666667e-01, 6.17435897e-01, 1.51515152e-01,\n",
-      "       3.38461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 2.02020202e-02, 4.59487179e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 5.33333333e-01,\n",
-      "       5.09743590e-01, 1.71717172e-01, 2.93333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       4.94949495e-01, 6.97435897e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.62564103e-01, 3.23232323e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.33333333e-01, 7.80512821e-01, 2.62626263e-01, 3.69230769e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.52525253e-01, 9.33333333e-01,\n",
-      "       8.87179487e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       6.26262626e-01, 6.40000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 1.11111111e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n",
-      "2020-10-14 18:53:27,586\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26840, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.80512821e-01,\n",
-      "       2.12121212e-01, 3.26153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.96923077e-01, 6.56565657e-01,\n",
-      "       1.82564103e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 6.07179487e-01, 4.84848485e-01, 1.02564103e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.35353535e-01, 4.66666667e-01,\n",
-      "       4.53333333e-01, 1.71717172e-01, 3.48717949e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.44444444e-01, 8.00000000e-01, 6.14358974e-01,\n",
-      "       4.34343434e-01, 8.82051282e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-01, 6.66666667e-01, 3.46666667e-01, 2.72727273e-01,\n",
-      "       1.90769231e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.00000000e-01, 3.28205128e-01, 5.35353535e-01, 6.35897436e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.08080808e-02, 5.33333333e-01,\n",
-      "       3.95897436e-01, 1.41414141e-01, 2.87179487e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.06060606e-02, 6.00000000e-01, 3.89743590e-01,\n",
-      "       3.33333333e-01, 4.94358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.33333333e-01, 5.87692308e-01, 5.15151515e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.33333333e-01, 8.48484848e-01, 1.72307692e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 9.09090909e-02, 6.83076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.92820513e-01,\n",
-      "       8.08080808e-02, 2.46153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 5.33333333e-01, 4.10256410e-01, 7.87878788e-01,\n",
-      "       4.51282051e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.43589744e-01, 1.61616162e-01, 4.82051282e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.24615385e-01, 4.64646465e-01, 5.33333333e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.08205128e-01,\n",
-      "       6.56565657e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 6.03076923e-01, 1.21212121e-01,\n",
-      "       9.47692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.62051282e-01, 4.34343434e-01, 6.76923077e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.01538462e-01, 2.02020202e-01, 1.43589744e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 8.71794872e-01,\n",
-      "       1.00000000e+00, 1.98974359e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.02020202e-01, 7.33333333e-01, 5.96923077e-01, 1.01010101e-01,\n",
-      "       8.41025641e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.00000000e+00, 7.61025641e-01, 1.00000000e+00, 1.51794872e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       3.95897436e-01, 5.05050505e-02, 6.15384615e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 5.81538462e-01,\n",
-      "       6.86868687e-01, 2.03076923e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.29292929e-01, 5.33333333e-01, 5.00512821e-01, 6.86868687e-01,\n",
-      "       1.82564103e-03, 0.00000000e+00, 0.00000000e+00, 4.34343434e-01,\n",
-      "       4.66666667e-01, 4.54358974e-01, 2.62626263e-01, 5.33333333e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       4.90256410e-01, 7.77777778e-01, 5.29230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.14141414e-01, 8.00000000e-01, 6.49230769e-01,\n",
-      "       1.01010101e-02, 2.05128205e-05, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.69230769e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 3.24102564e-01, 3.23232323e-01, 1.16923077e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       5.93846154e-01, 6.56565657e-01, 3.13846154e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.98461538e-01,\n",
-      "       1.71717172e-01, 2.64615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.31313131e-01, 8.00000000e-01, 5.05641026e-01, 4.84848485e-01,\n",
-      "       3.44615385e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.89743590e-01, 2.62626263e-01, 2.33846154e-03,\n",
-      "       0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.53846154e-01, 4.04040404e-02, 8.20512821e-05, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.10256410e-01,\n",
-      "       3.33333333e-01, 8.88205128e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 7.21025641e-01, 6.76767677e-01,\n",
-      "       4.10256410e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.00000000e-01, 3.36410256e-01, 4.04040404e-02, 8.10256410e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       5.74358974e-01, 7.07070707e-02, 1.31282051e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.35897436e-01,\n",
-      "       2.82828283e-01, 2.37948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 5.33333333e-01, 7.77777778e-01,\n",
-      "       1.16923077e-03, 0.00000000e+00, 0.00000000e+00, 6.56565657e-01,\n",
-      "       4.66666667e-01, 2.40000000e-01, 1.81818182e-01, 2.29743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       4.27692308e-01, 1.51515152e-01, 8.51282051e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.10256410e-01,\n",
-      "       1.71717172e-01, 8.20512821e-05, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.22222222e-01, 3.33333333e-01, 2.95384615e-01, 7.87878788e-01,\n",
-      "       3.54871795e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 5.16923077e-01, 3.63636364e-01, 7.79487179e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       6.00000000e-01, 1.31313131e-01, 3.48717949e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 6.70769231e-01,\n",
-      "       1.61616162e-01, 2.62564103e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 2.42424242e-01,\n",
-      "       3.32307692e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False,  True, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False,  True,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False])})\n",
-      "Result for RandomMasked_jss_env_7a318_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-29\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: a0d7abda875641ee8277cfe989ce99c0\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 56800\n",
-      "  iterations_since_restore: 142\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 26894\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 26.409894704818726\n",
-      "  time_this_iter_s: 0.16816067695617676\n",
-      "  time_total_s: 26.409894704818726\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701609\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 56800\n",
-      "  training_iteration: 142\n",
-      "  trial_id: 7a318_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | RUNNING  | 172.17.0.4:26894 |    142 |          26.4099 | 56800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
+      "2020-11-04 21:48:07,725 - wandb.wandb_agent - INFO - Running runs: ['sb79yg44']\n",
       "\n",
-      "2020-10-14 18:53:30,587\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26878, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 3.03030303e-01, 4.66666667e-01, 3.36410256e-01,\n",
-      "       6.46464646e-01, 1.31282051e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 3.96923077e-01, 0.00000000e+00,\n",
-      "       1.84615385e-04, 0.00000000e+00, 0.00000000e+00, 1.91919192e-01,\n",
-      "       4.66666667e-01, 5.66153846e-01, 2.72727273e-01, 2.78974359e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       6.01025641e-01, 7.77777778e-01, 1.18974359e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.20000000e-01,\n",
-      "       7.57575758e-01, 1.38051282e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 5.82564103e-01, 1.00000000e+00,\n",
-      "       6.97435897e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.95897436e-01, 1.61616162e-01, 3.05641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       2.87179487e-01, 7.07070707e-02, 3.89743590e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       5.25252525e-01, 6.46153846e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.22222222e-01, 6.00000000e-01, 4.82051282e-01, 1.01010101e-02,\n",
-      "       1.57948718e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.33333333e-01, 3.63636364e-01, 1.49743590e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 4.66666667e-01,\n",
-      "       3.54871795e-01, 3.43434343e-01, 3.01538462e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 7.41538462e-01,\n",
-      "       1.41414141e-01, 2.74871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.00000000e-01, 1.98974359e-01, 4.34343434e-01,\n",
-      "       7.67179487e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 5.43589744e-01, 2.02020202e-02, 8.61538462e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       4.24615385e-01, 4.34343434e-01, 2.46153846e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.03030303e-02, 4.66666667e-01, 4.87179487e-01,\n",
-      "       1.01010101e-01, 5.04615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 7.33333333e-01, 6.37948718e-01, 1.21212121e-01,\n",
-      "       2.42051282e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.00000000e-01, 9.94871795e-02, 4.04040404e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 6.66666667e-01,\n",
-      "       5.08717949e-01, 3.33333333e-01, 2.03076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 8.71794872e-01,\n",
-      "       1.00000000e+00, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 4.81025641e-01, 6.36363636e-01,\n",
-      "       2.46153846e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 5.50769231e-01, 3.63636364e-01, 3.91794872e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.23232323e-01, 6.00000000e-01,\n",
-      "       4.53333333e-01, 1.01010101e-01, 2.99487179e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 2.32323232e-01, 6.00000000e-01, 4.78974359e-01,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.33333333e-01, 3.64102564e-01, 4.94949495e-01,\n",
-      "       3.83589744e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.04615385e-01, 1.21212121e-01, 9.43589744e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       5.65128205e-01, 5.75757576e-01, 4.92307692e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.50769231e-01,\n",
-      "       3.83838384e-01, 1.92820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       1.06666667e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.82564103e-01, 2.02020202e-01, 5.80512821e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       6.98461538e-01, 6.76767677e-01, 1.06666667e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.98461538e-01,\n",
-      "       7.27272727e-01, 8.20512821e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 3.65128205e-01, 5.05050505e-02,\n",
-      "       1.88717949e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 5.88717949e-01, 6.96969697e-01, 7.58974359e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       4.34871795e-01, 1.01010101e-01, 2.13333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.25252525e-01, 6.66666667e-01, 5.46666667e-01,\n",
-      "       0.00000000e+00, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       1.51515152e-01, 6.00000000e-01, 6.16410256e-01, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.23232323e-01,\n",
-      "       7.33333333e-01, 7.24102564e-01, 8.08080808e-01, 3.05641026e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.31313131e-01, 4.66666667e-01,\n",
-      "       3.29230769e-01, 1.11111111e-01, 6.83076923e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.35897436e-01,\n",
-      "       3.03030303e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.84615385e-01, 6.06060606e-02,\n",
-      "       1.78461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.06666667e-01, 2.12121212e-01, 9.08717949e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       4.44102564e-01, 2.42424242e-01, 2.42051282e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.66666667e-01, 6.10256410e-01,\n",
-      "       3.03030303e-02, 2.52307692e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.01025641e-01, 3.13131313e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       8.00000000e-01, 6.66666667e-01, 1.01010101e-01, 3.26153846e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.04040404e-02, 6.00000000e-01,\n",
-      "       6.83076923e-01, 6.06060606e-02, 1.23076923e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       2.32323232e-01, 3.22051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 6.66666667e-01, 4.91282051e-01, 1.01010101e-02,\n",
-      "       1.37435897e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False,  True, False, False, False,  True])})\n",
-      "2020-10-14 18:53:33,891\tERROR trial_runner.py:567 -- Trial RandomMasked_jss_env_7a318_00000: Error processing event.\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 515, in _process_trial\n",
-      "    result = self.trial_executor.fetch_result(trial)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 488, in fetch_result\n",
-      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1428, in get\n",
-      "    raise value.as_instanceof_cause()\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RandomMasked.train()\u001b[39m (pid=26894, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 516, in train\n",
-      "    raise e\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\", line 505, in train\n",
-      "    result = Trainable.train(self)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py\", line 336, in train\n",
-      "    result = self.step()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\", line 134, in step\n",
-      "    res = next(self.train_exec_impl)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 756, in __next__\n",
-      "    return next(self.built_iterator)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 843, in apply_filter\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 783, in apply_foreach\n",
-      "    for item in it:\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 551, in base_iterator\n",
-      "    batch = ray.get(obj_ref)\n",
-      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=26854, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       5.05050505e-01, 6.72820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.07070707e-02, 4.00000000e-01, 3.89743590e-01, 7.47474747e-01,\n",
-      "       1.20205128e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.33333333e-01, 7.47692308e-01, 3.43434343e-01, 5.82564103e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.15151515e-01, 5.33333333e-01,\n",
-      "       5.48717949e-01, 6.76767677e-01, 1.37435897e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 5.56923077e-01,\n",
-      "       1.51515152e-01, 1.12820513e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 2.81025641e-01, 2.42424242e-01,\n",
-      "       1.47692308e-03, 0.00000000e+00, 0.00000000e+00, 7.07070707e-02,\n",
-      "       6.66666667e-01, 5.47692308e-01, 0.00000000e+00, 6.66666667e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.66666667e-01,\n",
-      "       1.79487179e-01, 7.17171717e-01, 1.95076923e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       1.71717172e-01, 1.12205128e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.12820513e-01, 4.04040404e-02,\n",
-      "       2.58461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.48717949e-01, 4.34343434e-01, 1.14256410e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.75897436e-01, 1.01010101e-01, 5.90769231e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.82564103e-01,\n",
-      "       6.86868687e-01, 1.25128205e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.06060606e-02, 6.66666667e-01, 5.57948718e-01, 2.62626263e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 4.02051282e-01, 9.69696970e-01, 5.53846154e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       5.22051282e-01, 1.51515152e-01, 1.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.08080808e-02, 8.00000000e-01, 7.04615385e-01,\n",
-      "       5.65656566e-01, 1.14871795e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 9.33333333e-01, 7.01538462e-01, 6.66666667e-01,\n",
-      "       6.25641026e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.92307692e-01, 6.36363636e-01, 1.12410256e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.40512821e-01, 1.51515152e-01, 1.43589744e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 7.33333333e-01, 6.56410256e-01,\n",
-      "       3.33333333e-01, 5.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.86868687e-01, 7.33333333e-01, 5.47692308e-01, 8.58585859e-01,\n",
-      "       1.74358974e-03, 0.00000000e+00, 0.00000000e+00, 2.02020202e-01,\n",
-      "       5.33333333e-01, 4.80000000e-01, 3.63636364e-01, 7.38461538e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.66666667e-01,\n",
-      "       4.86153846e-01, 3.83838384e-01, 6.35897436e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.00000000e-01,\n",
-      "       6.26262626e-01, 3.69230769e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 8.72820513e-01, 1.00000000e+00,\n",
-      "       8.20512821e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 4.98461538e-01, 6.76767677e-01, 2.07179487e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.51515152e-01, 4.00000000e-01,\n",
-      "       4.74871795e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 3.13131313e-01, 8.00000000e-01, 6.59487179e-01,\n",
-      "       8.58585859e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       3.07692308e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       2.66666667e-01, 1.58974359e-01, 3.03030303e-02, 5.21025641e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.00000000e-01,\n",
-      "       3.84615385e-01, 5.65656566e-01, 1.25538462e-02, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 7.68205128e-01,\n",
-      "       1.00000000e+00, 3.36410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 6.26666667e-01, 1.00000000e+00,\n",
-      "       1.24923077e-02, 0.00000000e+00, 0.00000000e+00, 6.06060606e-02,\n",
-      "       5.33333333e-01, 4.31794872e-01, 4.54545455e-01, 9.23076923e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
-      "       9.70256410e-01, 1.00000000e+00, 9.84615385e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 3.58974359e-01,\n",
-      "       1.01010101e-02, 8.41025641e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.44444444e-01, 9.33333333e-01, 8.36923077e-01, 4.04040404e-02,\n",
-      "       1.15487179e-02, 0.00000000e+00, 0.00000000e+00, 6.96969697e-01,\n",
-      "       6.00000000e-01, 5.84615385e-01, 2.92929293e-01, 1.07282051e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       4.65641026e-01, 0.00000000e+00, 3.38461538e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 7.02564103e-01,\n",
-      "       7.07070707e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.66666667e-01, 6.17435897e-01, 1.51515152e-01,\n",
-      "       3.38461538e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 2.02020202e-02, 4.59487179e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.13131313e-01, 5.33333333e-01,\n",
-      "       5.09743590e-01, 1.71717172e-01, 2.93333333e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.66666667e-01, 7.94871795e-01,\n",
-      "       4.94949495e-01, 6.97435897e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 4.62564103e-01, 3.23232323e-01,\n",
-      "       1.43589744e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       9.33333333e-01, 7.80512821e-01, 2.62626263e-01, 3.69230769e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.52525253e-01, 9.33333333e-01,\n",
-      "       8.87179487e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.10769231e-01,\n",
-      "       6.26262626e-01, 6.40000000e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.94871795e-01, 1.11111111e-01,\n",
-      "       2.21538462e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 ERROR)\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc   |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 | ERROR    |       |    171 |          30.8067 | 68400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+-------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "Number of errored trials: 1\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
-      "| Trial name                       |   # failures | error file                                                                                 |\n",
-      "|----------------------------------+--------------+--------------------------------------------------------------------------------------------|\n",
-      "| RandomMasked_jss_env_7a318_00000 |            1 | /root/ray_results/ppo-jss/RandomMasked_jss_env_7a318_00000_0_2020-10-14_18-52-58/error.txt |\n",
-      "+----------------------------------+--------------+--------------------------------------------------------------------------------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33800\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_214803-sb79yg44/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_214803-sb79yg44/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2071.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604527084\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/sb79yg44\u001b[0m\n",
+      "2020-11-04 21:58:08,292 - wandb.wandb_agent - INFO - Cleaning up finished run: sb79yg44\n",
+      "2020-11-04 21:58:08,653 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 21:58:08,653 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta43\n",
+      "2020-11-04 21:58:08,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta43\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/p3hdb6ys\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_215809-p3hdb6ys\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"random_loop.py\", line 73, in <module>\n",
-      "    rand_func()\n",
-      "  File \"random_loop.py\", line 55, in rand_func\n",
-      "    analysis = tune.run(RandomMaskedTrainer, config=config, stop=stop, name=\"ppo-jss\")\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/tune.py\", line 427, in run\n",
-      "    raise TuneError(\"Trials did not complete\", incomplete_trials)\n",
-      "ray.tune.error.TuneError: ('Trials did not complete', [RandomMasked_jss_env_7a318_00000])\n",
+      "2020-11-04 21:58:13,672 - wandb.wandb_agent - INFO - Running runs: ['p3hdb6ys']\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 26647\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33846\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201014_185253-ezglujb0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201014_185253-ezglujb0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_215809-p3hdb6ys/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_215809-p3hdb6ys/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1967.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604527690\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msuper-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ezglujb0\u001b[0m\n",
-      "2020-10-14 18:53:43,767 - wandb.wandb_agent - INFO - Cleaning up finished run: ezglujb0\n",
-      "2020-10-14 18:53:44,146 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-14 18:53:44,146 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tinstance_path: /JSS/JSS/env/instances/ta53\n",
-      "2020-10-14 18:53:44,148 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python random_loop.py --instance_path=/JSS/JSS/env/instances/ta53\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/p3hdb6ys\u001b[0m\n",
+      "2020-11-04 22:08:18,999 - wandb.wandb_agent - INFO - Cleaning up finished run: p3hdb6ys\n",
+      "2020-11-04 22:08:19,334 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:08:19,334 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta44\n",
+      "2020-11-04 22:08:19,336 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta44\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/lh9x5rb9\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gx7ht69p\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201014_185345-gx7ht69p\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/q6lvwcdf\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_220820-q6lvwcdf\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-14 18:53:49,166 - wandb.wandb_agent - INFO - Running runs: ['gx7ht69p']\n",
-      "2020-10-14 18:53:49,662\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+-------+\n",
-      "| Trial name                       | status   | loc   |\n",
-      "|----------------------------------+----------+-------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  |       |\n",
-      "+----------------------------------+----------+-------+\n",
+      "2020-11-04 22:08:24,353 - wandb.wandb_agent - INFO - Running runs: ['q6lvwcdf']\n",
       "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33892\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_220820-q6lvwcdf/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_220820-q6lvwcdf/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2091.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604528301\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/q6lvwcdf\u001b[0m\n",
+      "2020-11-04 22:18:29,584 - wandb.wandb_agent - INFO - Cleaning up finished run: q6lvwcdf\n",
+      "2020-11-04 22:18:29,915 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:18:29,916 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta45\n",
+      "2020-11-04 22:18:29,917 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta45\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/60frjwtk\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_221830-60frjwtk\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=28631)\u001b[0m 2020-10-14 18:53:52,367\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-53-56\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 400\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 68.7\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.3600000000000003\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 3.336198329925537\n",
-      "  time_this_iter_s: 3.336198329925537\n",
-      "  time_total_s: 3.336198329925537\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 400\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |      1 |           3.3362 |  400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
+      "2020-11-04 22:18:34,933 - wandb.wandb_agent - INFO - Running runs: ['60frjwtk']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-01\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 11600\n",
-      "  iterations_since_restore: 29\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 5.2\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 7.95437479019165\n",
-      "  time_this_iter_s: 0.16468524932861328\n",
-      "  time_total_s: 7.95437479019165\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701641\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 11600\n",
-      "  training_iteration: 29\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 21.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     29 |          7.95437 | 11600 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33938\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_221830-60frjwtk/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_221830-60frjwtk/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2032.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604528911\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/60frjwtk\u001b[0m\n",
+      "2020-11-04 22:28:39,901 - wandb.wandb_agent - INFO - Cleaning up finished run: 60frjwtk\n",
+      "2020-11-04 22:28:40,319 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:28:40,320 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta46\n",
+      "2020-11-04 22:28:40,321 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta46\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/4w63mxn5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_222841-4w63mxn5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:28:45,337 - wandb.wandb_agent - INFO - Running runs: ['4w63mxn5']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-06\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 23200\n",
-      "  iterations_since_restore: 58\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 12.706214427947998\n",
-      "  time_this_iter_s: 0.1642756462097168\n",
-      "  time_total_s: 12.706214427947998\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701646\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 23200\n",
-      "  training_iteration: 58\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     58 |          12.7062 | 23200 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33984\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_222841-4w63mxn5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_222841-4w63mxn5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2070.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604529522\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/4w63mxn5\u001b[0m\n",
+      "2020-11-04 22:38:45,728 - wandb.wandb_agent - INFO - Cleaning up finished run: 4w63mxn5\n",
+      "2020-11-04 22:38:46,210 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:38:46,210 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta47\n",
+      "2020-11-04 22:38:46,212 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta47\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/qpbtop8x\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_223847-qpbtop8x\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:38:51,228 - wandb.wandb_agent - INFO - Running runs: ['qpbtop8x']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-11\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 34800\n",
-      "  iterations_since_restore: 87\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 17.468780755996704\n",
-      "  time_this_iter_s: 0.15766501426696777\n",
-      "  time_total_s: 17.468780755996704\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701651\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 34800\n",
-      "  training_iteration: 87\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |     87 |          17.4688 | 34800 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34030\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_223847-qpbtop8x/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_223847-qpbtop8x/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 1991.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604530128\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/qpbtop8x\u001b[0m\n",
+      "2020-11-04 22:48:56,548 - wandb.wandb_agent - INFO - Cleaning up finished run: qpbtop8x\n",
+      "2020-11-04 22:48:56,937 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:48:56,937 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta48\n",
+      "2020-11-04 22:48:56,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta48\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/gsihk78x\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_224857-gsihk78x\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:49:01,955 - wandb.wandb_agent - INFO - Running runs: ['gsihk78x']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-16\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 46400\n",
-      "  iterations_since_restore: 116\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 4.3\n",
-      "    gpu_util_percent0: 0.0\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 2.9\n",
-      "    vram_util_percent0: 0.0\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 22.175960779190063\n",
-      "  time_this_iter_s: 0.1871342658996582\n",
-      "  time_total_s: 22.175960779190063\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701656\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 46400\n",
-      "  training_iteration: 116\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |    116 |           22.176 | 46400 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34076\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_224857-gsihk78x/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_224857-gsihk78x/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2052.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 602\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604530739\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/gsihk78x\u001b[0m\n",
+      "2020-11-04 22:59:07,301 - wandb.wandb_agent - INFO - Cleaning up finished run: gsihk78x\n",
+      "2020-11-04 22:59:07,606 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 22:59:07,606 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta49\n",
+      "2020-11-04 22:59:07,608 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta49\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pvt5040k\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_225908-pvt5040k\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 22:59:12,624 - wandb.wandb_agent - INFO - Running runs: ['pvt5040k']\n",
       "\n",
-      "Result for RandomMasked_jss_env_99699_00000:\n",
-      "  custom_metrics: {}\n",
-      "  date: 2020-10-14_18-54-21\n",
-      "  done: false\n",
-      "  episode_len_mean: .nan\n",
-      "  episode_reward_max: .nan\n",
-      "  episode_reward_mean: .nan\n",
-      "  episode_reward_min: .nan\n",
-      "  episodes_this_iter: 0\n",
-      "  episodes_total: 0\n",
-      "  experiment_id: 00d9f426bb89434f8ae7ff271eb43732\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    num_steps_sampled: 58000\n",
-      "  iterations_since_restore: 145\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf: {}\n",
-      "  pid: 28631\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf: {}\n",
-      "  time_since_restore: 26.801780700683594\n",
-      "  time_this_iter_s: 0.15772652626037598\n",
-      "  time_total_s: 26.801780700683594\n",
-      "  timers: {}\n",
-      "  timestamp: 1602701661\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 58000\n",
-      "  training_iteration: 145\n",
-      "  trial_id: '99699_00000'\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 22.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 0/3 GPUs, 0.0/557.08 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name                       | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
-      "| RandomMasked_jss_env_99699_00000 | RUNNING  | 172.17.0.4:28631 |    145 |          26.8018 | 58000 |      nan |                  nan |                  nan |                nan |\n",
-      "+----------------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34122\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_225908-pvt5040k/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_225908-pvt5040k/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2072.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604531349\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/pvt5040k\u001b[0m\n",
+      "2020-11-04 23:09:17,980 - wandb.wandb_agent - INFO - Cleaning up finished run: pvt5040k\n",
+      "2020-11-04 23:09:18,328 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-11-04 23:09:18,328 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta50\n",
+      "2020-11-04 23:09:18,330 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python CP.py --instance_path=/JSS/JSS/env/instances/ta50\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.8 is available!  To upgrade, please run:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/sweeps/wnc8ihq1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/7oeiazwm\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201104_230919-7oeiazwm\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
+      "2020-11-04 23:09:23,346 - wandb.wandb_agent - INFO - Running runs: ['7oeiazwm']\n",
       "\n",
-      "2020-10-14 18:54:21,879\tERROR worker.py:1018 -- Possible unhandled error from worker: \u001b[36mray::RolloutWorker.par_iter_next_batch()\u001b[39m (pid=28512, ip=172.17.0.4)\n",
-      "  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
-      "  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1158, in par_iter_next_batch\n",
-      "    batch.append(self.par_iter_next())\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/util/iter.py\", line 1152, in par_iter_next\n",
-      "    return next(self.local_it)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 288, in gen_rollouts\n",
-      "    yield self.sample()\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 579, in sample\n",
-      "    batches = [self.input_reader.next()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 93, in next\n",
-      "    batches = [self.get_data()]\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 209, in get_data\n",
-      "    item = next(self.rollout_provider)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 585, in _env_runner\n",
-      "    active_envs, to_eval, outputs = _process_observations(\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\", line 797, in _process_observations\n",
-      "    prep_obs: EnvObsType = _get_or_raise(preprocessors,\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 233, in transform\n",
-      "    self.check_shape(observation)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/rllib/models/preprocessors.py\", line 61, in check_shape\n",
-      "    raise ValueError(\n",
-      "ValueError: ('Observation outside expected value range', Dict(action_mask:Box(0.0, 1.0, (51,), float32), real_obs:Box(0.0, 1.0, (350,), float64)), {'real_obs': array([0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 3.67179487e-01,\n",
-      "       1.31313131e-01, 1.84615385e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 5.87692308e-01, 2.42424242e-01,\n",
-      "       1.16923077e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.66666667e-01, 8.18461538e-01, 1.71717172e-01, 1.84615385e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.56565657e-01, 6.66666667e-01,\n",
-      "       6.98461538e-01, 1.01010101e-02, 9.23076923e-04, 0.00000000e+00,\n",
-      "       1.00000000e+00, 0.00000000e+00, 6.66666667e-01, 4.84102564e-01,\n",
-      "       4.44444444e-01, 1.74358974e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       7.17171717e-01, 6.66666667e-01, 2.94358974e-01, 0.00000000e+00,\n",
-      "       1.02564103e-04, 0.00000000e+00, 0.00000000e+00, 4.04040404e-01,\n",
-      "       6.66666667e-01, 5.13846154e-01, 7.77777778e-01, 1.57948718e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.00000000e-01,\n",
-      "       1.30256410e-01, 5.35353535e-01, 7.20000000e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 3.72307692e-01,\n",
-      "       4.54545455e-01, 1.09333333e-02, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 8.00000000e-01, 6.25641026e-01, 5.45454545e-01,\n",
-      "       8.20512821e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.66666667e-01, 2.42051282e-01, 1.61616162e-01, 1.25128205e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.11794872e-01, 4.04040404e-02, 1.16923077e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 5.33333333e-01, 4.99487179e-01,\n",
-      "       6.56565657e-01, 8.61538462e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.33333333e-01, 3.83589744e-01, 2.22222222e-01,\n",
-      "       5.33333333e-04, 0.00000000e+00, 0.00000000e+00, 2.32323232e-01,\n",
-      "       6.00000000e-01, 4.54358974e-01, 3.13131313e-01, 7.58974359e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.66666667e-01,\n",
-      "       3.66153846e-01, 7.87878788e-01, 5.29230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.55384615e-01,\n",
-      "       0.00000000e+00, 2.66666667e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.08080808e-02, 8.00000000e-01, 6.92307692e-01, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 3.06666667e-01, 6.46464646e-01, 3.28205128e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       6.07179487e-01, 3.33333333e-01, 6.15384615e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.66666667e-01, 4.44102564e-01,\n",
-      "       9.09090909e-02, 1.57948718e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       8.08080808e-02, 6.66666667e-02, 8.00000000e-02, 7.07070707e-01,\n",
-      "       8.82051282e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.00512821e-01, 4.14141414e-01, 6.76923077e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.00000000e-01,\n",
-      "       3.95897436e-01, 1.51515152e-01, 8.41025641e-04, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 9.33333333e-01, 6.40000000e-01,\n",
-      "       7.17171717e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.05050505e-02, 6.66666667e-01, 6.82051282e-01, 5.05050505e-02,\n",
-      "       2.25641026e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 5.04615385e-01, 3.03030303e-02, 9.84615385e-04,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.41538462e-01, 9.79797980e-01, 5.68205128e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.33333333e-01, 2.86153846e-01,\n",
-      "       2.72727273e-01, 9.23076923e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
-      "       1.39487179e-03, 0.00000000e+00, 0.00000000e+00, 5.35353535e-01,\n",
-      "       8.66666667e-01, 5.94871795e-01, 5.45454545e-01, 3.63076923e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.68205128e-01, 6.66666667e-01, 3.69230769e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 2.66666667e-01, 2.67692308e-01,\n",
-      "       7.47474747e-01, 5.21025641e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.00000000e-01, 3.65128205e-01, 1.51515152e-01,\n",
-      "       7.69230769e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.66666667e-01, 4.74871795e-01, 1.21212121e-01, 2.95384615e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 8.66666667e-01,\n",
-      "       8.50256410e-01, 5.35353535e-01, 4.77948718e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 8.00000000e-01, 6.10256410e-01,\n",
-      "       5.45454545e-01, 6.35897436e-04, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 6.66666667e-01, 6.31794872e-01, 7.07070707e-01,\n",
-      "       7.15897436e-03, 0.00000000e+00, 0.00000000e+00, 5.05050505e-01,\n",
-      "       6.00000000e-01, 6.04102564e-01, 4.04040404e-01, 1.09128205e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 3.03030303e-02, 7.33333333e-01,\n",
-      "       5.03589744e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 1.11111111e-01, 7.33333333e-01, 5.93846154e-01,\n",
-      "       5.55555556e-01, 2.15384615e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 4.66666667e-01, 4.54358974e-01, 4.94949495e-01,\n",
-      "       4.26666667e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       6.00000000e-01, 3.81538462e-01, 1.71717172e-01, 3.26153846e-03,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.33333333e-01,\n",
-      "       5.88717949e-01, 1.71717172e-01, 6.07179487e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 6.00000000e-01, 5.88717949e-01,\n",
-      "       2.92929293e-01, 5.76410256e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       4.84848485e-01, 4.66666667e-01, 3.88717949e-01, 6.36363636e-01,\n",
-      "       1.29230769e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
-      "       5.33333333e-01, 5.16923077e-01, 6.06060606e-02, 1.61230769e-02,\n",
-      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 5.33333333e-01,\n",
-      "       5.47692308e-01, 6.16161616e-01, 4.94358974e-03, 0.00000000e+00,\n",
-      "       0.00000000e+00, 0.00000000e+00, 4.00000000e-01, 3.78461538e-01,\n",
-      "       2.52525253e-01, 8.82051282e-03, 0.00000000e+00, 0.00000000e+00,\n",
-      "       0.00000000e+00, 5.33333333e-01, 2.82051282e-01, 6.06060606e-01,\n",
-      "       4.43076923e-03, 0.00000000e+00]), 'action_mask': array([False, False, False, False,  True, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False, False, False, False, False,\n",
-      "       False, False, False, False, False,  True])})\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34168\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201104_230919-7oeiazwm/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201104_230919-7oeiazwm/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep 2010.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step 0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime 601\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp 1604531960\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   best_timestep ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:           _step ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        _runtime ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:      _timestamp ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mCP\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_3/runs/7oeiazwm\u001b[0m\n",
+      "2020-11-04 23:19:23,596 - wandb.wandb_agent - INFO - Cleaning up finished run: 7oeiazwm\n",
+      "2020-11-04 23:19:23,944 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-11-04 23:19:23,944 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent lh9x5rb9"
+    "!wandb agent wnc8ihq1"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index 14e0018..8fbfc47 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index 46f4d10..4729210 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -6,7 +6,7 @@ default_config = {
     'env': 'jss_env',
     'seed': 0,
     'framework': 'torch',
-    'log_level': 'INFO',
+    'log_level': 'WARN',
     'num_gpus': 1,
     'instance_path': '/JSS/JSS/env/instances/ta51',
     'num_envs_per_worker': 2,
diff --git a/JSS/env/__pycache__/JSS.cpython-38.pyc b/JSS/env/__pycache__/JSS.cpython-38.pyc
index b190093..143d813 100644
Binary files a/JSS/env/__pycache__/JSS.cpython-38.pyc and b/JSS/env/__pycache__/JSS.cpython-38.pyc differ
diff --git a/JSS/train.py b/JSS/train.py
index d4ac941..85598f6 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -50,7 +50,7 @@ def train_func():
     ray.init()
 
     stop = {
-        "time_total_s": 60 * 60,
+        "time_total_s": 10 * 60,
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index f73d8af..c4cadde 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201014_204512-kkype8ue/logs/debug-internal.log
\ No newline at end of file
+run-20201105_100917-bx5k1vyc/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index db2ed2e..9f3a486 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201014_204512-kkype8ue/logs/debug.log
\ No newline at end of file
+run-20201105_100917-bx5k1vyc/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index f19e5b0..7155b92 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201014_204512-kkype8ue
\ No newline at end of file
+run-20201105_100917-bx5k1vyc
\ No newline at end of file
diff --git a/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log b/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
index 62aefa0..a469c27 100644
--- a/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
+++ b/JSS/wandb/run-20201014_185459-4qedwvw4/logs/debug-internal.log
@@ -3791,3 +3791,60 @@
 2020-10-14 20:48:22,755 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
 2020-10-14 20:48:24,674 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
 2020-10-14 20:48:29,293 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:33,903 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:37,761 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:37,761 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:48:37,761 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:37,765 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:37,962 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:38,519 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:43,143 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:47,759 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:52,385 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:48:52,968 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:52,968 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:48:52,968 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:52,975 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:53,184 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:57,005 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:01,622 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:06,249 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:08,189 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:08,190 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:08,190 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:08,195 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:08,392 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:10,874 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:15,492 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:20,107 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:23,398 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:23,398 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:23,398 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:23,403 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:23,595 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:24,725 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:29,333 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:33,953 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:38,566 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:38,601 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:38,601 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:38,601 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:38,605 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:38,802 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:43,182 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:47,813 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:52,436 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:49:53,808 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:53,809 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:49:53,809 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:53,813 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:54,014 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:57,041 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:01,665 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:06,273 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
+2020-10-14 20:50:09,020 DEBUG   HandlerThread:30187 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:50:09,020 DEBUG   SenderThread:30187 [sender.py:send():88] send: request
+2020-10-14 20:50:09,020 DEBUG   SenderThread:30187 [sender.py:send_request():97] send_request: status
+2020-10-14 20:50:09,024 DEBUG   SenderThread:30187 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:50:09,226 DEBUG   SenderThread:30187 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:50:10,902 DEBUG   SenderThread:30187 [sender.py:send():88] send: stats
diff --git a/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb b/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb
index fe32750..a173876 100644
Binary files a/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb and b/JSS/wandb/run-20201014_185459-4qedwvw4/run-4qedwvw4.wandb differ
diff --git a/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log b/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
index 6c28b35..39056d1 100644
--- a/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
+++ b/JSS/wandb/run-20201014_185623-es6i30gb/logs/debug-internal.log
@@ -3766,3 +3766,55 @@
 2020-10-14 20:48:28,206 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
 2020-10-14 20:48:28,210 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
 2020-10-14 20:48:28,411 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:32,759 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:37,379 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:41,998 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:43,417 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:43,417 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:48:43,418 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:43,425 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:43,622 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:48:46,618 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:51,237 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:55,878 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:48:58,628 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:48:58,629 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:48:58,629 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:48:58,634 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:48:58,828 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:00,486 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:05,100 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:09,717 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:13,834 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:13,834 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:13,835 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:13,839 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:14,032 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:14,334 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:18,948 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:23,561 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:28,192 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:29,038 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:29,038 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:29,039 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:29,043 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:29,241 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:32,806 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:37,429 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:42,040 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:44,247 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:44,247 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:44,247 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:44,252 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:44,453 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:49:46,669 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:51,288 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:55,904 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:49:59,459 DEBUG   HandlerThread:34843 [handler.py:handle_request():54] handle_request: status
+2020-10-14 20:49:59,459 DEBUG   SenderThread:34843 [sender.py:send():88] send: request
+2020-10-14 20:49:59,460 DEBUG   SenderThread:34843 [sender.py:send_request():97] send_request: status
+2020-10-14 20:49:59,464 DEBUG   SenderThread:34843 [connectionpool.py:_new_conn():955] Starting new HTTPS connection (1): api.wandb.ai:443
+2020-10-14 20:49:59,667 DEBUG   SenderThread:34843 [connectionpool.py:_make_request():428] https://api.wandb.ai:443 "POST /graphql HTTP/1.1" 200 None
+2020-10-14 20:50:00,513 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:50:05,125 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
+2020-10-14 20:50:09,744 DEBUG   SenderThread:34843 [sender.py:send():88] send: stats
diff --git a/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb b/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb
index 6b25ef1..0114685 100644
Binary files a/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb and b/JSS/wandb/run-20201014_185623-es6i30gb/run-es6i30gb.wandb differ
