2020-10-11 01:07:12,725	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1919a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=13638)[0m 2020-10-11 01:07:15,615	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=13587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=13607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=13607)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_01-07-56
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.185312466961997
        entropy_coeff: 0.00010000000000000002
        kl: 0.0036130246673045413
        model: {}
        policy_loss: -0.003321010303417487
        total_loss: 660.8493172781808
        vf_explained_var: 0.0902143344283104
        vf_loss: 660.8520377022879
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.176744186046506
    gpu_util_percent0: 0.3190697674418605
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00023255813953488373
    ram_util_percent: 6.288372093023254
    vram_util_percent0: 0.19233908181866718
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17198500496327562
    mean_env_wait_ms: 1.1935906765011217
    mean_inference_ms: 5.848860326980728
    mean_raw_obs_processing_ms: 0.46055532598539645
  time_since_restore: 35.44934701919556
  time_this_iter_s: 35.44934701919556
  time_total_s: 35.44934701919556
  timers:
    learn_throughput: 6179.066
    learn_time_ms: 26183.894
    sample_throughput: 17586.808
    sample_time_ms: 9199.623
    update_time_ms: 27.578
  timestamp: 1602378476
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      1 |          35.4493 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3615.71875
    time_step_min: 3379
  date: 2020-10-11_01-08-30
  done: false
  episode_len_mean: 889.243670886076
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 218.11024805012124
  episode_reward_min: 139.6565656565651
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1563667144094194
        entropy_coeff: 0.00010000000000000002
        kl: 0.005588595988228917
        model: {}
        policy_loss: -0.005145243211050651
        total_loss: 309.6634434291295
        vf_explained_var: 0.5110005736351013
        vf_loss: 309.6681431361607
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.5375
    gpu_util_percent0: 0.39
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4674999999999985
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1674349191654332
    mean_env_wait_ms: 1.1892899823723322
    mean_inference_ms: 5.601307188290506
    mean_raw_obs_processing_ms: 0.44751355384655617
  time_since_restore: 69.23034644126892
  time_this_iter_s: 33.780999422073364
  time_total_s: 69.23034644126892
  timers:
    learn_throughput: 6232.243
    learn_time_ms: 25960.477
    sample_throughput: 18853.108
    sample_time_ms: 8581.715
    update_time_ms: 32.045
  timestamp: 1602378510
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      2 |          69.2303 | 323584 |   218.11 |              258.596 |              139.657 |            889.244 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3605.8004484304934
    time_step_min: 3307
  date: 2020-10-11_01-09-04
  done: false
  episode_len_mean: 883.9324894514768
  episode_reward_max: 273.1414141414139
  episode_reward_mean: 219.63067382687615
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1559785093579973
        entropy_coeff: 0.00010000000000000002
        kl: 0.005705334711819887
        model: {}
        policy_loss: -0.005416615699817028
        total_loss: 138.0080075945173
        vf_explained_var: 0.7535021901130676
        vf_loss: 138.0129677908761
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6175
    gpu_util_percent0: 0.341
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16457006687705705
    mean_env_wait_ms: 1.1886900608814899
    mean_inference_ms: 5.412446177591582
    mean_raw_obs_processing_ms: 0.4384565099146732
  time_since_restore: 102.59135174751282
  time_this_iter_s: 33.3610053062439
  time_total_s: 102.59135174751282
  timers:
    learn_throughput: 6222.247
    learn_time_ms: 26002.182
    sample_throughput: 19937.103
    sample_time_ms: 8115.121
    update_time_ms: 36.733
  timestamp: 1602378544
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      3 |          102.591 | 485376 |  219.631 |              273.141 |              108.444 |            883.932 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3597.865894039735
    time_step_min: 3299
  date: 2020-10-11_01-09-37
  done: false
  episode_len_mean: 879.9430379746835
  episode_reward_max: 273.1414141414139
  episode_reward_mean: 220.18950581767015
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.145553273814065
        entropy_coeff: 0.00010000000000000002
        kl: 0.006627164581524474
        model: {}
        policy_loss: -0.003294940252089873
        total_loss: 91.67672947474888
        vf_explained_var: 0.8346154093742371
        vf_loss: 91.67947714669364
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.57
    gpu_util_percent0: 0.42874999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16252447330189282
    mean_env_wait_ms: 1.1889641223200256
    mean_inference_ms: 5.275792922358907
    mean_raw_obs_processing_ms: 0.43156804221527534
  time_since_restore: 135.69621896743774
  time_this_iter_s: 33.10486721992493
  time_total_s: 135.69621896743774
  timers:
    learn_throughput: 6230.585
    learn_time_ms: 25967.386
    sample_throughput: 20585.899
    sample_time_ms: 7859.36
    update_time_ms: 36.934
  timestamp: 1602378577
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      4 |          135.696 | 647168 |   220.19 |              273.141 |              108.444 |            879.943 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3585.1535433070867
    time_step_min: 3248
  date: 2020-10-11_01-10-11
  done: false
  episode_len_mean: 875.8113924050633
  episode_reward_max: 273.89898989898956
  episode_reward_mean: 221.74824191279868
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1170965603419714
        entropy_coeff: 0.00010000000000000002
        kl: 0.0073127357422241145
        model: {}
        policy_loss: -0.004589947339679513
        total_loss: 69.63101359776088
        vf_explained_var: 0.8730839490890503
        vf_loss: 69.6349857875279
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.605
    gpu_util_percent0: 0.37425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16100623492954302
    mean_env_wait_ms: 1.1903030586084198
    mean_inference_ms: 5.172050990487806
    mean_raw_obs_processing_ms: 0.4261472606627905
  time_since_restore: 169.3882918357849
  time_this_iter_s: 33.69207286834717
  time_total_s: 169.3882918357849
  timers:
    learn_throughput: 6215.785
    learn_time_ms: 26029.216
    sample_throughput: 20864.729
    sample_time_ms: 7754.33
    update_time_ms: 33.415
  timestamp: 1602378611
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      5 |          169.388 | 808960 |  221.748 |              273.899 |              108.444 |            875.811 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3571.8727948003716
    time_step_min: 3248
  date: 2020-10-11_01-10-43
  done: false
  episode_len_mean: 866.4307692307692
  episode_reward_max: 273.89898989898956
  episode_reward_mean: 224.3235065588005
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1168718508311681
        entropy_coeff: 0.00010000000000000002
        kl: 0.006476998329162598
        model: {}
        policy_loss: -0.005510002674002733
        total_loss: 70.99435479300362
        vf_explained_var: 0.9086169004440308
        vf_loss: 70.99932970319476
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.39487179487179
    gpu_util_percent0: 0.37974358974358974
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487179487179487
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1590005400015443
    mean_env_wait_ms: 1.1946908983986995
    mean_inference_ms: 5.032622221489551
    mean_raw_obs_processing_ms: 0.41932028528327625
  time_since_restore: 202.209046125412
  time_this_iter_s: 32.820754289627075
  time_total_s: 202.209046125412
  timers:
    learn_throughput: 6221.584
    learn_time_ms: 26004.952
    sample_throughput: 21272.59
    sample_time_ms: 7605.656
    update_time_ms: 31.472
  timestamp: 1602378643
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      6 |          202.209 | 970752 |  224.324 |              273.899 |              108.444 |            866.431 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3563.0954692556634
    time_step_min: 3248
  date: 2020-10-11_01-11-17
  done: false
  episode_len_mean: 861.623417721519
  episode_reward_max: 273.89898989898956
  episode_reward_mean: 225.67317958061608
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1144772171974182
        entropy_coeff: 0.00010000000000000002
        kl: 0.006019386762220945
        model: {}
        policy_loss: -0.004305004408316953
        total_loss: 48.77932630266462
        vf_explained_var: 0.9047781229019165
        vf_loss: 48.78314045497349
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.97692307692308
    gpu_util_percent0: 0.37230769230769234
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492307692307692
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15826543949929003
    mean_env_wait_ms: 1.1965415732499598
    mean_inference_ms: 4.982316892658726
    mean_raw_obs_processing_ms: 0.41687404612013057
  time_since_restore: 235.3876667022705
  time_this_iter_s: 33.17862057685852
  time_total_s: 235.3876667022705
  timers:
    learn_throughput: 6223.487
    learn_time_ms: 25997.001
    sample_throughput: 21453.277
    sample_time_ms: 7541.598
    update_time_ms: 29.808
  timestamp: 1602378677
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      7 |          235.388 | 1132544 |  225.673 |              273.899 |              108.444 |            861.623 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3556.0050215208034
    time_step_min: 3164
  date: 2020-10-11_01-11-49
  done: false
  episode_len_mean: 856.9915611814346
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 226.63148361249608
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0986125894955225
        entropy_coeff: 0.00010000000000000002
        kl: 0.006170262183461871
        model: {}
        policy_loss: -0.0031930855329846963
        total_loss: 46.80305508204869
        vf_explained_var: 0.9096501469612122
        vf_loss: 46.80574062892369
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.982051282051287
    gpu_util_percent0: 0.4148717948717949
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48974358974359
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157653799142631
    mean_env_wait_ms: 1.1983594837973255
    mean_inference_ms: 4.939307110783967
    mean_raw_obs_processing_ms: 0.41474696584492715
  time_since_restore: 267.6087055206299
  time_this_iter_s: 32.221038818359375
  time_total_s: 267.6087055206299
  timers:
    learn_throughput: 6248.535
    learn_time_ms: 25892.79
    sample_throughput: 21652.643
    sample_time_ms: 7472.159
    update_time_ms: 28.426
  timestamp: 1602378709
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      8 |          267.609 | 1294336 |  226.631 |              286.626 |              108.444 |            856.992 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3548.5244845360826
    time_step_min: 3164
  date: 2020-10-11_01-12-22
  done: false
  episode_len_mean: 852.5284810126582
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 227.80865618207372
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0650508148329598
        entropy_coeff: 0.00010000000000000002
        kl: 0.006214145138593656
        model: {}
        policy_loss: -0.004704453990728196
        total_loss: 40.7940559387207
        vf_explained_var: 0.9207640290260315
        vf_loss: 40.79824583871024
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.510256410256414
    gpu_util_percent0: 0.3030769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492307692307692
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15713251705971767
    mean_env_wait_ms: 1.2002511170394472
    mean_inference_ms: 4.901912090638423
    mean_raw_obs_processing_ms: 0.4128331006356355
  time_since_restore: 300.6975691318512
  time_this_iter_s: 33.08886361122131
  time_total_s: 300.6975691318512
  timers:
    learn_throughput: 6248.945
    learn_time_ms: 25891.088
    sample_throughput: 21760.518
    sample_time_ms: 7435.117
    update_time_ms: 27.354
  timestamp: 1602378742
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |      9 |          300.698 | 1456128 |  227.809 |              286.626 |              108.444 |            852.528 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3537.0620985010705
    time_step_min: 3164
  date: 2020-10-11_01-12-55
  done: false
  episode_len_mean: 843.5205696202531
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 229.74231236414764
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.051774995667594
        entropy_coeff: 0.00010000000000000002
        kl: 0.005662505781011922
        model: {}
        policy_loss: -0.003457985136524907
        total_loss: 48.82970101492746
        vf_explained_var: 0.9392586946487427
        vf_loss: 48.83269691467285
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.94
    gpu_util_percent0: 0.40425000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.156298996026168
    mean_env_wait_ms: 1.204298743921151
    mean_inference_ms: 4.841484448924022
    mean_raw_obs_processing_ms: 0.40984096487230576
  time_since_restore: 333.8653209209442
  time_this_iter_s: 33.16775178909302
  time_total_s: 333.8653209209442
  timers:
    learn_throughput: 6247.685
    learn_time_ms: 25896.312
    sample_throughput: 21845.81
    sample_time_ms: 7406.089
    update_time_ms: 26.78
  timestamp: 1602378775
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     10 |          333.865 | 1617920 |  229.742 |              286.626 |              108.444 |            843.521 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3531.6599210266536
    time_step_min: 3164
  date: 2020-10-11_01-13-29
  done: false
  episode_len_mean: 839.4863680623174
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 230.84943396968697
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0536018099103654
        entropy_coeff: 0.00010000000000000002
        kl: 0.005740754938285265
        model: {}
        policy_loss: -0.004100227533074628
        total_loss: 26.738118852887833
        vf_explained_var: 0.9477106928825378
        vf_loss: 26.741749899727957
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.294871794871796
    gpu_util_percent0: 0.42000000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492307692307692
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15595879464453036
    mean_env_wait_ms: 1.2061132614285184
    mean_inference_ms: 4.816658473111363
    mean_raw_obs_processing_ms: 0.4086100683496072
  time_since_restore: 366.9830825328827
  time_this_iter_s: 33.11776161193848
  time_total_s: 366.9830825328827
  timers:
    learn_throughput: 6254.982
    learn_time_ms: 25866.101
    sample_throughput: 22464.514
    sample_time_ms: 7202.114
    update_time_ms: 26.227
  timestamp: 1602378809
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     11 |          366.983 | 1779712 |  230.849 |              286.626 |              108.444 |            839.486 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3524.2348901098903
    time_step_min: 3164
  date: 2020-10-11_01-14-02
  done: false
  episode_len_mean: 835.625226039783
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 231.93340274352917
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0263355714934213
        entropy_coeff: 0.00010000000000000002
        kl: 0.005388899939134717
        model: {}
        policy_loss: -0.0026694155676523224
        total_loss: 23.36897223336356
        vf_explained_var: 0.9493735432624817
        vf_loss: 23.371205057416642
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.852500000000003
    gpu_util_percent0: 0.33475
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5025
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15564879659874087
    mean_env_wait_ms: 1.2078834502027462
    mean_inference_ms: 4.794227234506592
    mean_raw_obs_processing_ms: 0.4074620779122181
  time_since_restore: 400.1100289821625
  time_this_iter_s: 33.126946449279785
  time_total_s: 400.1100289821625
  timers:
    learn_throughput: 6249.218
    learn_time_ms: 25889.961
    sample_throughput: 22745.298
    sample_time_ms: 7113.206
    update_time_ms: 24.91
  timestamp: 1602378842
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     12 |           400.11 | 1941504 |  231.933 |              286.626 |              108.444 |            835.625 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3515.1769199839164
    time_step_min: 3164
  date: 2020-10-11_01-14-35
  done: false
  episode_len_mean: 828.9916500994036
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 233.31564150450816
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 303
  episodes_total: 2515
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9795211979321071
        entropy_coeff: 0.00010000000000000002
        kl: 0.0054178747814148664
        model: {}
        policy_loss: -0.0039238286138113055
        total_loss: 30.990808623177664
        vf_explained_var: 0.9597876667976379
        vf_loss: 30.994288172040665
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.497435897435896
    gpu_util_percent0: 0.3425641025641025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492307692307692
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.155133224185923
    mean_env_wait_ms: 1.2114268746776067
    mean_inference_ms: 4.7571784947757685
    mean_raw_obs_processing_ms: 0.4055939201697233
  time_since_restore: 433.1842029094696
  time_this_iter_s: 33.07417392730713
  time_total_s: 433.1842029094696
  timers:
    learn_throughput: 6253.297
    learn_time_ms: 25873.071
    sample_throughput: 22782.838
    sample_time_ms: 7101.486
    update_time_ms: 22.616
  timestamp: 1602378875
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     13 |          433.184 | 2103296 |  233.316 |              286.626 |              108.444 |            828.992 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3508.1098570353647
    time_step_min: 3164
  date: 2020-10-11_01-15-09
  done: false
  episode_len_mean: 825.4769173492182
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 234.2829110163435
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 171
  episodes_total: 2686
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9803529466901507
        entropy_coeff: 0.00010000000000000002
        kl: 0.005972379951604775
        model: {}
        policy_loss: -0.004176166748428451
        total_loss: 17.37805720738002
        vf_explained_var: 0.9644187092781067
        vf_loss: 17.381734439304896
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.807499999999997
    gpu_util_percent0: 0.374
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15488600252796134
    mean_env_wait_ms: 1.213266281730378
    mean_inference_ms: 4.739018674572105
    mean_raw_obs_processing_ms: 0.40467723093890823
  time_since_restore: 466.72408056259155
  time_this_iter_s: 33.53987765312195
  time_total_s: 466.72408056259155
  timers:
    learn_throughput: 6240.886
    learn_time_ms: 25924.525
    sample_throughput: 22784.655
    sample_time_ms: 7100.919
    update_time_ms: 21.128
  timestamp: 1602378909
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     14 |          466.724 | 2265088 |  234.283 |              286.626 |              108.444 |            825.477 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3502.4282670454545
    time_step_min: 3164
  date: 2020-10-11_01-15-42
  done: false
  episode_len_mean: 822.6441631504923
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 235.0286408387673
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9680584498814174
        entropy_coeff: 0.00010000000000000002
        kl: 0.005360300386590617
        model: {}
        policy_loss: -0.004790830550648805
        total_loss: 18.844842229570663
        vf_explained_var: 0.9597339034080505
        vf_loss: 18.849193845476425
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.8875
    gpu_util_percent0: 0.3175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5025
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546702989109824
    mean_env_wait_ms: 1.2148416594113736
    mean_inference_ms: 4.723618220457118
    mean_raw_obs_processing_ms: 0.40387725993851503
  time_since_restore: 500.11237025260925
  time_this_iter_s: 33.3882896900177
  time_total_s: 500.11237025260925
  timers:
    learn_throughput: 6244.853
    learn_time_ms: 25908.057
    sample_throughput: 22829.907
    sample_time_ms: 7086.844
    update_time_ms: 21.62
  timestamp: 1602378942
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     15 |          500.112 | 2426880 |  235.029 |              286.626 |              108.444 |            822.644 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3492.8748790712675
    time_step_min: 3164
  date: 2020-10-11_01-16-15
  done: false
  episode_len_mean: 817.9776286353467
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 236.4300531683081
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 285
  episodes_total: 3129
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9243289147104535
        entropy_coeff: 0.00010000000000000002
        kl: 0.004941935418173671
        model: {}
        policy_loss: -0.002416406392252871
        total_loss: 20.494511468069895
        vf_explained_var: 0.9706491827964783
        vf_loss: 20.49652590070452
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.842499999999998
    gpu_util_percent0: 0.40225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15431225616843608
    mean_env_wait_ms: 1.2177112360643774
    mean_inference_ms: 4.698817116592263
    mean_raw_obs_processing_ms: 0.4025744667003437
  time_since_restore: 533.273514509201
  time_this_iter_s: 33.1611442565918
  time_total_s: 533.273514509201
  timers:
    learn_throughput: 6241.894
    learn_time_ms: 25920.336
    sample_throughput: 22761.64
    sample_time_ms: 7108.099
    update_time_ms: 21.574
  timestamp: 1602378975
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     16 |          533.274 | 2588672 |   236.43 |              286.626 |              108.444 |            817.978 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3487.0893617021275
    time_step_min: 3164
  date: 2020-10-11_01-16-49
  done: false
  episode_len_mean: 815.1965039180229
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 237.30890277092797
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 189
  episodes_total: 3318
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9251739297594342
        entropy_coeff: 0.00010000000000000002
        kl: 0.006876115321314761
        model: {}
        policy_loss: -0.004790381578329418
        total_loss: 13.003837585449219
        vf_explained_var: 0.9741474390029907
        vf_loss: 13.008376598358154
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.810000000000002
    gpu_util_percent0: 0.38575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15411358974204287
    mean_env_wait_ms: 1.2194353497051045
    mean_inference_ms: 4.684119724090247
    mean_raw_obs_processing_ms: 0.40182884935067564
  time_since_restore: 566.5171394348145
  time_this_iter_s: 33.2436249256134
  time_total_s: 566.5171394348145
  timers:
    learn_throughput: 6240.36
    learn_time_ms: 25926.711
    sample_throughput: 22783.553
    sample_time_ms: 7101.263
    update_time_ms: 27.353
  timestamp: 1602379009
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     17 |          566.517 | 2750464 |  237.309 |              286.626 |              108.444 |            815.197 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3482.2711716937356
    time_step_min: 3164
  date: 2020-10-11_01-17-22
  done: false
  episode_len_mean: 812.9841772151899
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 238.0127831828061
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9121834508010319
        entropy_coeff: 0.00010000000000000002
        kl: 0.005939339586932745
        model: {}
        policy_loss: -0.004666414274912053
        total_loss: 13.373389652797155
        vf_explained_var: 0.9706013798713684
        vf_loss: 13.377850464412145
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.894871794871797
    gpu_util_percent0: 0.3128205128205129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.505128205128205
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15395159617839463
    mean_env_wait_ms: 1.22079048317082
    mean_inference_ms: 4.672748414524507
    mean_raw_obs_processing_ms: 0.4012372788818238
  time_since_restore: 599.5571284294128
  time_this_iter_s: 33.03998899459839
  time_total_s: 599.5571284294128
  timers:
    learn_throughput: 6220.925
    learn_time_ms: 26007.707
    sample_throughput: 22784.488
    sample_time_ms: 7100.972
    update_time_ms: 27.541
  timestamp: 1602379042
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | RUNNING  | 172.17.0.4:13638 |     18 |          599.557 | 2912256 |  238.013 |              286.626 |              108.444 |            812.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1919a_00000:
  custom_metrics:
    time_step_max: 4134
    time_step_mean: 3475.192194600374
    time_step_min: 3164
  date: 2020-10-11_01-17-56
  done: true
  episode_len_mean: 809.212523215707
  episode_reward_max: 286.62626262626276
  episode_reward_mean: 239.1292173526187
  episode_reward_min: 108.44444444444453
  episodes_this_iter: 293
  episodes_total: 3769
  experiment_id: 2f305d5b800e4eeb9de71517f5f212b6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.854990520647594
        entropy_coeff: 0.00010000000000000002
        kl: 0.005603519800518241
        model: {}
        policy_loss: -0.005170247958241296
        total_loss: 17.128002847943986
        vf_explained_var: 0.9756284356117249
        vf_loss: 17.13297748565674
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.932499999999997
    gpu_util_percent0: 0.29799999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 13638
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15367776096376484
    mean_env_wait_ms: 1.2233040665224353
    mean_inference_ms: 4.65369731815133
    mean_raw_obs_processing_ms: 0.40025931282177796
  time_since_restore: 633.080274105072
  time_this_iter_s: 33.52314567565918
  time_total_s: 633.080274105072
  timers:
    learn_throughput: 6213.439
    learn_time_ms: 26039.04
    sample_throughput: 22749.239
    sample_time_ms: 7111.974
    update_time_ms: 27.979
  timestamp: 1602379076
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 1919a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | TERMINATED |       |     19 |           633.08 | 3074048 |  239.129 |              286.626 |              108.444 |            809.213 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.16 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1919a_00000 | TERMINATED |       |     19 |           633.08 | 3074048 |  239.129 |              286.626 |              108.444 |            809.213 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


