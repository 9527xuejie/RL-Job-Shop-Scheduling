2020-10-09 05:46:12,986	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_be451_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=8095)[0m 2020-10-09 05:46:16,063	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=7950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=7946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=7946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8043)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_05-47-28
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1626124948263168
        entropy_coeff: 0.0
        kl: 0.006706918065901846
        model: {}
        policy_loss: -0.02228336870903149
        total_loss: 477.6126174926758
        vf_explained_var: 0.5879462361335754
        vf_loss: 477.63355560302733
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.30131578947368
    gpu_util_percent0: 0.3253947368421052
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.857894736842105
    vram_util_percent0: 0.2614014948818422
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24320529397161844
    mean_env_wait_ms: 3.2368469032176885
    mean_inference_ms: 9.042758332170354
    mean_raw_obs_processing_ms: 0.8495380717245432
  time_since_restore: 66.00155878067017
  time_this_iter_s: 66.00155878067017
  time_total_s: 66.00155878067017
  timers:
    learn_throughput: 6449.247
    learn_time_ms: 50173.922
    sample_throughput: 20541.822
    sample_time_ms: 15752.449
    update_time_ms: 37.273
  timestamp: 1602222448
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      1 |          66.0016 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_05-48-32
  done: false
  episode_len_mean: 875.4193037974684
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.0434886843113
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1324275761842728
        entropy_coeff: 0.0
        kl: 0.00680690958397463
        model: {}
        policy_loss: -0.02705804833676666
        total_loss: 106.97557735443115
        vf_explained_var: 0.864749550819397
        vf_loss: 107.00127506256104
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.629333333333335
    gpu_util_percent0: 0.42253333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.161333333333335
    vram_util_percent0: 0.2694774242921177
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23854085931446142
    mean_env_wait_ms: 3.2244713175934834
    mean_inference_ms: 8.670552513201104
    mean_raw_obs_processing_ms: 0.8373663271884302
  time_since_restore: 130.7394895553589
  time_this_iter_s: 64.73793077468872
  time_total_s: 130.7394895553589
  timers:
    learn_throughput: 6442.466
    learn_time_ms: 50226.728
    sample_throughput: 21501.584
    sample_time_ms: 15049.31
    update_time_ms: 29.097
  timestamp: 1602222512
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      2 |          130.739 | 647168 |  228.043 |              284.798 |              147.061 |            875.419 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3212.0
  date: 2020-10-09_05-49-37
  done: false
  episode_len_mean: 875.5200421940929
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.06634914546288
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1226310700178146
        entropy_coeff: 0.0
        kl: 0.0072616024990566075
        model: {}
        policy_loss: -0.031810283684171735
        total_loss: 22.510703086853027
        vf_explained_var: 0.9619172811508179
        vf_loss: 22.541060876846313
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.84189189189189
    gpu_util_percent0: 0.36918918918918925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.19864864864865
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2357114791018242
    mean_env_wait_ms: 3.2171806149683877
    mean_inference_ms: 8.438811271468271
    mean_raw_obs_processing_ms: 0.8288684842768207
  time_since_restore: 195.09384155273438
  time_this_iter_s: 64.35435199737549
  time_total_s: 195.09384155273438
  timers:
    learn_throughput: 6435.754
    learn_time_ms: 50279.111
    sample_throughput: 22092.464
    sample_time_ms: 14646.804
    update_time_ms: 33.93
  timestamp: 1602222577
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      3 |          195.094 | 970752 |  228.066 |              284.798 |              147.061 |             875.52 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3212.0
  date: 2020-10-09_05-50-42
  done: false
  episode_len_mean: 873.5379746835443
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.90734081319505
  episode_reward_min: 142.51515151515105
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1102492332458496
        entropy_coeff: 0.0
        kl: 0.007186211971566081
        model: {}
        policy_loss: -0.03168159363558516
        total_loss: 16.155826020240784
        vf_explained_var: 0.970098614692688
        vf_loss: 16.186070251464844
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.314864864864866
    gpu_util_percent0: 0.2551351351351352
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.221621621621622
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23394856372625047
    mean_env_wait_ms: 3.215419037942573
    mean_inference_ms: 8.27851903507371
    mean_raw_obs_processing_ms: 0.8223220738006431
  time_since_restore: 259.6981143951416
  time_this_iter_s: 64.60427284240723
  time_total_s: 259.6981143951416
  timers:
    learn_throughput: 6432.168
    learn_time_ms: 50307.145
    sample_throughput: 22303.993
    sample_time_ms: 14507.896
    update_time_ms: 34.875
  timestamp: 1602222642
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      4 |          259.698 | 1294336 |  227.907 |              284.798 |              142.515 |            873.538 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3212.0
  date: 2020-10-09_05-51-46
  done: false
  episode_len_mean: 871.1600253004427
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 228.54734568966052
  episode_reward_min: 139.27272727272697
  episodes_this_iter: 317
  episodes_total: 1581
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0839314430952072
        entropy_coeff: 0.0
        kl: 0.007301237899810076
        model: {}
        policy_loss: -0.03422184691298753
        total_loss: 13.664916038513184
        vf_explained_var: 0.9771825671195984
        vf_loss: 13.697677731513977
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.72162162162162
    gpu_util_percent0: 0.2583783783783784
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.268918918918919
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23268997296980068
    mean_env_wait_ms: 3.216393396235953
    mean_inference_ms: 8.158934647605557
    mean_raw_obs_processing_ms: 0.816655004823409
  time_since_restore: 324.35747385025024
  time_this_iter_s: 64.65935945510864
  time_total_s: 324.35747385025024
  timers:
    learn_throughput: 6423.312
    learn_time_ms: 50376.5
    sample_throughput: 22499.62
    sample_time_ms: 14381.754
    update_time_ms: 36.218
  timestamp: 1602222706
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      5 |          324.357 | 1617920 |  228.547 |              284.798 |              139.273 |             871.16 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_05-52-51
  done: false
  episode_len_mean: 865.8226244343891
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.1262991910049
  episode_reward_min: 139.27272727272697
  episodes_this_iter: 629
  episodes_total: 2210
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0906235158443451
        entropy_coeff: 0.0
        kl: 0.007110288576222956
        model: {}
        policy_loss: -0.03357774175237864
        total_loss: 16.595123744010927
        vf_explained_var: 0.9779272079467773
        vf_loss: 16.627279210090638
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.239189189189187
    gpu_util_percent0: 0.3202702702702703
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.239189189189187
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23108875073226837
    mean_env_wait_ms: 3.2214037121219943
    mean_inference_ms: 8.00057494484264
    mean_raw_obs_processing_ms: 0.8094870962066137
  time_since_restore: 388.53843116760254
  time_this_iter_s: 64.1809573173523
  time_total_s: 388.53843116760254
  timers:
    learn_throughput: 6427.289
    learn_time_ms: 50345.335
    sample_throughput: 22639.978
    sample_time_ms: 14292.593
    update_time_ms: 38.061
  timestamp: 1602222771
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      6 |          388.538 | 1941504 |  230.126 |              284.798 |              139.273 |            865.823 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_05-53-55
  done: false
  episode_len_mean: 864.1467563291139
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.94678989259668
  episode_reward_min: 139.27272727272697
  episodes_this_iter: 318
  episodes_total: 2528
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0856800496578216
        entropy_coeff: 0.0
        kl: 0.0073434867546893655
        model: {}
        policy_loss: -0.036798591585829855
        total_loss: 9.396662044525147
        vf_explained_var: 0.9819757342338562
        vf_loss: 9.431991863250733
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.151351351351348
    gpu_util_percent0: 0.3268918918918919
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.260810810810806
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23047288919595554
    mean_env_wait_ms: 3.22311284441875
    mean_inference_ms: 7.942525544164549
    mean_raw_obs_processing_ms: 0.8068790806635697
  time_since_restore: 452.61541771888733
  time_this_iter_s: 64.07698655128479
  time_total_s: 452.61541771888733
  timers:
    learn_throughput: 6429.718
    learn_time_ms: 50326.312
    sample_throughput: 22768.405
    sample_time_ms: 14211.975
    update_time_ms: 38.719
  timestamp: 1602222835
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      7 |          452.615 | 2265088 |  230.947 |              284.798 |              139.273 |            864.147 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_05-54-59
  done: false
  episode_len_mean: 861.7232770745429
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.86313557516073
  episode_reward_min: 139.27272727272697
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.073272380232811
        entropy_coeff: 0.0
        kl: 0.007133169274311513
        model: {}
        policy_loss: -0.037717038835398856
        total_loss: 9.768660807609558
        vf_explained_var: 0.9807562828063965
        vf_loss: 9.804951190948486
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.41351351351351
    gpu_util_percent0: 0.2508108108108108
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.282432432432431
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22994964847562388
    mean_env_wait_ms: 3.2249089557603283
    mean_inference_ms: 7.892509349262596
    mean_raw_obs_processing_ms: 0.8047348827061724
  time_since_restore: 517.0086929798126
  time_this_iter_s: 64.3932752609253
  time_total_s: 517.0086929798126
  timers:
    learn_throughput: 6427.862
    learn_time_ms: 50340.84
    sample_throughput: 22845.665
    sample_time_ms: 14163.912
    update_time_ms: 38.009
  timestamp: 1602222899
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      8 |          517.009 | 2588672 |  231.863 |              284.798 |              139.273 |            861.723 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_05-56-03
  done: false
  episode_len_mean: 858.9927215189873
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 232.8904615778032
  episode_reward_min: 139.27272727272697
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0530591011047363
        entropy_coeff: 0.0
        kl: 0.0072512088110670446
        model: {}
        policy_loss: -0.03984947297722101
        total_loss: 9.665666818618774
        vf_explained_var: 0.9802690744400024
        vf_loss: 9.704066061973572
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.305479452054794
    gpu_util_percent0: 0.25369863013698635
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.26027397260274
    vram_util_percent0: 0.27164644145621514
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.229495885369768
    mean_env_wait_ms: 3.2269393718210795
    mean_inference_ms: 7.848863382169046
    mean_raw_obs_processing_ms: 0.8027596400942321
  time_since_restore: 581.1623816490173
  time_this_iter_s: 64.15368866920471
  time_total_s: 581.1623816490173
  timers:
    learn_throughput: 6428.117
    learn_time_ms: 50338.851
    sample_throughput: 22930.908
    sample_time_ms: 14111.26
    update_time_ms: 38.33
  timestamp: 1602222963
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | RUNNING  | 172.17.0.4:8095 |      9 |          581.162 | 2912256 |   232.89 |              284.798 |              139.273 |            858.993 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_be451_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3176.0
  date: 2020-10-09_05-57-08
  done: true
  episode_len_mean: 854.4958768554151
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 234.4237232134427
  episode_reward_min: 120.33333333333309
  episodes_this_iter: 478
  episodes_total: 3638
  experiment_id: 719a02d681af4169af6465ba24aeace6
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0234815418720244
        entropy_coeff: 0.0
        kl: 0.007023272383958101
        model: {}
        policy_loss: -0.038848224887624384
        total_loss: 14.087752199172973
        vf_explained_var: 0.9805647134780884
        vf_loss: 14.125195693969726
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.355405405405406
    gpu_util_percent0: 0.34283783783783783
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.260810810810808
    vram_util_percent0: 0.2716464414562152
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8095
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22888465252968493
    mean_env_wait_ms: 3.230956321217845
    mean_inference_ms: 7.792669841288822
    mean_raw_obs_processing_ms: 0.8000534908067115
  time_since_restore: 645.6390581130981
  time_this_iter_s: 64.47667646408081
  time_total_s: 645.6390581130981
  timers:
    learn_throughput: 6428.407
    learn_time_ms: 50336.58
    sample_throughput: 22945.763
    sample_time_ms: 14102.124
    update_time_ms: 38.924
  timestamp: 1602223028
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: be451_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | TERMINATED |       |     10 |          645.639 | 3235840 |  234.424 |              284.798 |              120.333 |            854.496 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1009 05:57:08.804618  7908  7908 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1009 05:57:08.804708  7908  7908 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
== Status ==
Memory usage on this node: 76.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_be451_00000 | TERMINATED |       |     10 |          645.639 | 3235840 |  234.424 |              284.798 |              120.333 |            854.496 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


