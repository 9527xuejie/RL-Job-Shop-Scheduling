2020-10-12 01:38:20,143	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_9c831_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=74879)[0m 2020-10-12 01:38:22,882	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=74911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74797)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_01-38-56
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823419034481049
        entropy_coeff: 0.0001
        kl: 0.006913263505945603
        model: {}
        policy_loss: -0.009153704750739658
        total_loss: 507.07541910807294
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.939393939393938
    gpu_util_percent0: 0.2545454545454546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.563636363636364
    vram_util_percent0: 0.08611616327260803
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16927850728566426
    mean_env_wait_ms: 1.1673912526501955
    mean_inference_ms: 5.702668605449943
    mean_raw_obs_processing_ms: 0.4541837657517435
  time_since_restore: 28.69399404525757
  time_this_iter_s: 28.69399404525757
  time_total_s: 28.69399404525757
  timers:
    learn_throughput: 8272.336
    learn_time_ms: 19558.2
    sample_throughput: 17836.841
    sample_time_ms: 9070.665
    update_time_ms: 24.781
  timestamp: 1602466736
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      1 |           28.694 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3617.4756944444443
    time_step_min: 3379
  date: 2020-10-12_01-39-24
  done: false
  episode_len_mean: 892.6835443037975
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.43370412990643
  episode_reward_min: 143.74747474747463
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1495513916015625
        entropy_coeff: 0.0001
        kl: 0.008068564774778983
        model: {}
        policy_loss: -0.011281727226257013
        total_loss: 126.03075726826985
        vf_explained_var: 0.8121792674064636
        vf_loss: 126.04054133097331
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.76875
    gpu_util_percent0: 0.314375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1653614097006659
    mean_env_wait_ms: 1.1624070294924285
    mean_inference_ms: 5.509512528842825
    mean_raw_obs_processing_ms: 0.4445929385634286
  time_since_restore: 55.997567653656006
  time_this_iter_s: 27.303573608398438
  time_total_s: 55.997567653656006
  timers:
    learn_throughput: 8311.04
    learn_time_ms: 19467.118
    sample_throughput: 19147.419
    sample_time_ms: 8449.807
    update_time_ms: 33.442
  timestamp: 1602466764
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      2 |          55.9976 | 323584 |  217.434 |              264.354 |              143.747 |            892.684 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4090
    time_step_mean: 3611.885650224215
    time_step_min: 3304
  date: 2020-10-12_01-39-50
  done: false
  episode_len_mean: 888.92194092827
  episode_reward_max: 265.41414141414145
  episode_reward_mean: 219.27138473340983
  episode_reward_min: 136.47474747474763
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1405511895815532
        entropy_coeff: 0.0001
        kl: 0.010281015497942766
        model: {}
        policy_loss: -0.012611954092183927
        total_loss: 57.214155197143555
        vf_explained_var: 0.8955041766166687
        vf_loss: 57.22482458750407
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.62903225806452
    gpu_util_percent0: 0.29935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16252335577200402
    mean_env_wait_ms: 1.1609036404121225
    mean_inference_ms: 5.337045549787707
    mean_raw_obs_processing_ms: 0.4359861156359756
  time_since_restore: 82.56119179725647
  time_this_iter_s: 26.563624143600464
  time_total_s: 82.56119179725647
  timers:
    learn_throughput: 8316.551
    learn_time_ms: 19454.219
    sample_throughput: 20260.182
    sample_time_ms: 7985.713
    update_time_ms: 32.204
  timestamp: 1602466790
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      3 |          82.5612 | 485376 |  219.271 |              265.414 |              136.475 |            888.922 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3604.7847682119204
    time_step_min: 3278
  date: 2020-10-12_01-40-17
  done: false
  episode_len_mean: 887.0933544303797
  episode_reward_max: 269.35353535353477
  episode_reward_mean: 220.7296381536886
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.125044176975886
        entropy_coeff: 0.0001
        kl: 0.008713830960914493
        model: {}
        policy_loss: -0.01281238537436972
        total_loss: 42.594160079956055
        vf_explained_var: 0.921076238155365
        vf_loss: 42.605342864990234
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.116129032258065
    gpu_util_percent0: 0.3696774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16047840605806665
    mean_env_wait_ms: 1.1604730718443403
    mean_inference_ms: 5.2067579189535085
    mean_raw_obs_processing_ms: 0.42905778331377753
  time_since_restore: 109.09626126289368
  time_this_iter_s: 26.535069465637207
  time_total_s: 109.09626126289368
  timers:
    learn_throughput: 8326.275
    learn_time_ms: 19431.499
    sample_throughput: 20840.775
    sample_time_ms: 7763.243
    update_time_ms: 30.468
  timestamp: 1602466817
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      4 |          109.096 | 647168 |   220.73 |              269.354 |              129.808 |            887.093 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3599.3018372703414
    time_step_min: 3278
  date: 2020-10-12_01-40-44
  done: false
  episode_len_mean: 882.8556962025316
  episode_reward_max: 269.95959595959573
  episode_reward_mean: 221.7850658483568
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0891432861487071
        entropy_coeff: 0.0001
        kl: 0.012039707663158575
        model: {}
        policy_loss: -0.014468279647796104
        total_loss: 34.90501435597738
        vf_explained_var: 0.9392260909080505
        vf_loss: 34.91718260447184
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.887096774193548
    gpu_util_percent0: 0.27580645161290324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15894197033962015
    mean_env_wait_ms: 1.1608867371285125
    mean_inference_ms: 5.107796714442251
    mean_raw_obs_processing_ms: 0.4234893518783444
  time_since_restore: 135.7074818611145
  time_this_iter_s: 26.611220598220825
  time_total_s: 135.7074818611145
  timers:
    learn_throughput: 8329.402
    learn_time_ms: 19424.205
    sample_throughput: 21180.694
    sample_time_ms: 7638.654
    update_time_ms: 28.984
  timestamp: 1602466844
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      5 |          135.707 | 808960 |  221.785 |               269.96 |              129.808 |            882.856 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3576.6360153256705
    time_step_min: 3249
  date: 2020-10-12_01-41-10
  done: false
  episode_len_mean: 874.0354477611941
  episode_reward_max: 276.7777777777778
  episode_reward_mean: 224.91535692748363
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 282
  episodes_total: 1072
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0584310293197632
        entropy_coeff: 0.0001
        kl: 0.00993667837853233
        model: {}
        policy_loss: -0.012500340701080859
        total_loss: 36.99903710683187
        vf_explained_var: 0.9552376866340637
        vf_loss: 37.00965595245361
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.433333333333337
    gpu_util_percent0: 0.29133333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15701217853020227
    mean_env_wait_ms: 1.1634658691331203
    mean_inference_ms: 4.982241788605034
    mean_raw_obs_processing_ms: 0.4164406826040074
  time_since_restore: 161.89525747299194
  time_this_iter_s: 26.18777561187744
  time_total_s: 161.89525747299194
  timers:
    learn_throughput: 8338.645
    learn_time_ms: 19402.672
    sample_throughput: 21564.096
    sample_time_ms: 7502.842
    update_time_ms: 27.536
  timestamp: 1602466870
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      6 |          161.895 | 970752 |  224.915 |              276.778 |              129.808 |            874.035 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3563.234627831715
    time_step_min: 3249
  date: 2020-10-12_01-41-36
  done: false
  episode_len_mean: 868.820411392405
  episode_reward_max: 276.7777777777778
  episode_reward_mean: 226.81002269530734
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 192
  episodes_total: 1264
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0695739388465881
        entropy_coeff: 0.0001
        kl: 0.01017006098603209
        model: {}
        policy_loss: -0.015108836193879446
        total_loss: 25.033511479695637
        vf_explained_var: 0.9567611813545227
        vf_loss: 25.046693483988445
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.98387096774194
    gpu_util_percent0: 0.4048387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15609835506358583
    mean_env_wait_ms: 1.164915133475011
    mean_inference_ms: 4.921641340528115
    mean_raw_obs_processing_ms: 0.41319393641671737
  time_since_restore: 188.31726551055908
  time_this_iter_s: 26.42200803756714
  time_total_s: 188.31726551055908
  timers:
    learn_throughput: 8339.607
    learn_time_ms: 19400.435
    sample_throughput: 21796.429
    sample_time_ms: 7422.867
    update_time_ms: 29.746
  timestamp: 1602466896
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      7 |          188.317 | 1132544 |   226.81 |              276.778 |              129.808 |             868.82 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3551.6083213773313
    time_step_min: 3241
  date: 2020-10-12_01-42-03
  done: false
  episode_len_mean: 864.3305203938115
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 228.58967310233115
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.049300491809845
        entropy_coeff: 0.0001
        kl: 0.00948797888122499
        model: {}
        policy_loss: -0.012509522377513349
        total_loss: 18.031604131062824
        vf_explained_var: 0.965584933757782
        vf_loss: 18.042320410410564
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.232258064516135
    gpu_util_percent0: 0.2206451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15544940286837064
    mean_env_wait_ms: 1.166205296804172
    mean_inference_ms: 4.87915572548922
    mean_raw_obs_processing_ms: 0.4108291211252382
  time_since_restore: 214.98990321159363
  time_this_iter_s: 26.672637701034546
  time_total_s: 214.98990321159363
  timers:
    learn_throughput: 8333.878
    learn_time_ms: 19413.771
    sample_throughput: 21918.672
    sample_time_ms: 7381.469
    update_time_ms: 28.525
  timestamp: 1602466923
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      8 |           214.99 | 1294336 |   228.59 |              278.444 |              129.808 |            864.331 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3540.101804123711
    time_step_min: 3203
  date: 2020-10-12_01-42-30
  done: false
  episode_len_mean: 859.4512658227848
  episode_reward_max: 280.71717171717177
  episode_reward_mean: 230.29571026722905
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0134407381216686
        entropy_coeff: 0.0001
        kl: 0.009283836542939147
        model: {}
        policy_loss: -0.012368955969577655
        total_loss: 17.686386903127033
        vf_explained_var: 0.9648472666740417
        vf_loss: 17.69700034459432
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.74838709677419
    gpu_util_percent0: 0.395483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15487873867969798
    mean_env_wait_ms: 1.1675650895674787
    mean_inference_ms: 4.84187523742498
    mean_raw_obs_processing_ms: 0.40871189212362863
  time_since_restore: 241.45888352394104
  time_this_iter_s: 26.468980312347412
  time_total_s: 241.45888352394104
  timers:
    learn_throughput: 8334.765
    learn_time_ms: 19411.704
    sample_throughput: 22046.32
    sample_time_ms: 7338.73
    update_time_ms: 27.523
  timestamp: 1602466950
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |      9 |          241.459 | 1456128 |  230.296 |              280.717 |              129.808 |            859.451 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3520.4086956521737
    time_step_min: 3187
  date: 2020-10-12_01-42-56
  done: false
  episode_len_mean: 850.8297644539615
  episode_reward_max: 283.14141414141403
  episode_reward_mean: 233.21481950122194
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 288
  episodes_total: 1868
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9686284810304642
        entropy_coeff: 0.0001
        kl: 0.009191953033829728
        model: {}
        policy_loss: -0.013561500377060534
        total_loss: 21.392618497212727
        vf_explained_var: 0.9707826972007751
        vf_loss: 21.404438972473145
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.720000000000002
    gpu_util_percent0: 0.30833333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540201517302602
    mean_env_wait_ms: 1.1705098798150193
    mean_inference_ms: 4.7856756433992045
    mean_raw_obs_processing_ms: 0.4055814012277992
  time_since_restore: 267.76593565940857
  time_this_iter_s: 26.30705213546753
  time_total_s: 267.76593565940857
  timers:
    learn_throughput: 8333.739
    learn_time_ms: 19414.096
    sample_throughput: 22209.441
    sample_time_ms: 7284.83
    update_time_ms: 27.163
  timestamp: 1602466976
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     10 |          267.766 | 1617920 |  233.215 |              283.141 |              129.808 |             850.83 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3507.2546890424483
    time_step_min: 3134
  date: 2020-10-12_01-43-22
  done: false
  episode_len_mean: 846.0447906523856
  episode_reward_max: 291.17171717171703
  episode_reward_mean: 235.21408830269573
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 186
  episodes_total: 2054
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9666833182175955
        entropy_coeff: 0.0001
        kl: 0.009547891871382793
        model: {}
        policy_loss: -0.013738454226465061
        total_loss: 12.241443475087484
        vf_explained_var: 0.9760217666625977
        vf_loss: 12.253368775049845
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.738709677419358
    gpu_util_percent0: 0.26064516129032256
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15357960483673547
    mean_env_wait_ms: 1.172159824055812
    mean_inference_ms: 4.756254633021019
    mean_raw_obs_processing_ms: 0.40393987799977293
  time_since_restore: 294.1156644821167
  time_this_iter_s: 26.34972882270813
  time_total_s: 294.1156644821167
  timers:
    learn_throughput: 8341.81
    learn_time_ms: 19395.31
    sample_throughput: 22893.018
    sample_time_ms: 7067.308
    update_time_ms: 28.266
  timestamp: 1602467002
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     11 |          294.116 | 1779712 |  235.214 |              291.172 |              129.808 |            846.045 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3497.9578754578756
    time_step_min: 3134
  date: 2020-10-12_01-43-49
  done: false
  episode_len_mean: 842.4163652802894
  episode_reward_max: 291.17171717171703
  episode_reward_mean: 236.73661113850974
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9434071083863577
        entropy_coeff: 0.0001
        kl: 0.008886806822071472
        model: {}
        policy_loss: -0.013857747412354607
        total_loss: 11.377227465311686
        vf_explained_var: 0.9759158492088318
        vf_loss: 11.389402151107788
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.212903225806453
    gpu_util_percent0: 0.26774193548387093
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935484
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15323711353589206
    mean_env_wait_ms: 1.1735504141926574
    mean_inference_ms: 4.733669941592836
    mean_raw_obs_processing_ms: 0.4026690031899588
  time_since_restore: 320.82109665870667
  time_this_iter_s: 26.705432176589966
  time_total_s: 320.82109665870667
  timers:
    learn_throughput: 8336.273
    learn_time_ms: 19408.194
    sample_throughput: 23128.278
    sample_time_ms: 6995.419
    update_time_ms: 27.424
  timestamp: 1602467029
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     12 |          320.821 | 1941504 |  236.737 |              291.172 |              129.808 |            842.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3486.6059196617334
    time_step_min: 3124
  date: 2020-10-12_01-44-16
  done: false
  episode_len_mean: 838.6017551190973
  episode_reward_max: 292.6868686868691
  episode_reward_mean: 238.48256066726591
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 181
  episodes_total: 2393
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8922233482201894
        entropy_coeff: 0.0001
        kl: 0.009549010079354048
        model: {}
        policy_loss: -0.01278734568040818
        total_loss: 13.555466810862223
        vf_explained_var: 0.9759069085121155
        vf_loss: 13.566433668136597
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.816129032258065
    gpu_util_percent0: 0.24225806451612905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528761658156167
    mean_env_wait_ms: 1.1752151362052337
    mean_inference_ms: 4.710304558333864
    mean_raw_obs_processing_ms: 0.4013476075641952
  time_since_restore: 347.2873511314392
  time_this_iter_s: 26.466254472732544
  time_total_s: 347.2873511314392
  timers:
    learn_throughput: 8333.376
    learn_time_ms: 19414.94
    sample_throughput: 23189.499
    sample_time_ms: 6976.951
    update_time_ms: 28.723
  timestamp: 1602467056
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     13 |          347.287 | 2103296 |  238.483 |              292.687 |              129.808 |            838.602 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3469.7535741158767
    time_step_min: 3113
  date: 2020-10-12_01-44-42
  done: false
  episode_len_mean: 833.5454206999256
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 240.81842625811342
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 293
  episodes_total: 2686
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8776892324288686
        entropy_coeff: 0.0001
        kl: 0.007773946427429716
        model: {}
        policy_loss: -0.010698449972551316
        total_loss: 15.110443512598673
        vf_explained_var: 0.9769299030303955
        vf_loss: 15.119674841562906
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.903225806451616
    gpu_util_percent0: 0.36
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15238817929144804
    mean_env_wait_ms: 1.17762736952472
    mean_inference_ms: 4.67765854883583
    mean_raw_obs_processing_ms: 0.39953469831128613
  time_since_restore: 373.74122190475464
  time_this_iter_s: 26.45387077331543
  time_total_s: 373.74122190475464
  timers:
    learn_throughput: 8324.858
    learn_time_ms: 19434.806
    sample_throughput: 23285.423
    sample_time_ms: 6948.21
    update_time_ms: 28.622
  timestamp: 1602467082
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     14 |          373.741 | 2265088 |  240.818 |              294.354 |              129.808 |            833.545 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3462.2837357954545
    time_step_min: 3113
  date: 2020-10-12_01-45-09
  done: false
  episode_len_mean: 830.8618143459915
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 241.84911349784755
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.863788440823555
        entropy_coeff: 0.0001
        kl: 0.007791075816688438
        model: {}
        policy_loss: -0.012327776794942716
        total_loss: 10.273081302642822
        vf_explained_var: 0.9786503911018372
        vf_loss: 10.283936818440756
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.03666666666667
    gpu_util_percent0: 0.2906666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521545485824182
    mean_env_wait_ms: 1.1788374818581504
    mean_inference_ms: 4.662251472715558
    mean_raw_obs_processing_ms: 0.3986710708763885
  time_since_restore: 400.09441328048706
  time_this_iter_s: 26.353191375732422
  time_total_s: 400.09441328048706
  timers:
    learn_throughput: 8324.353
    learn_time_ms: 19435.986
    sample_throughput: 23378.595
    sample_time_ms: 6920.519
    update_time_ms: 28.86
  timestamp: 1602467109
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     15 |          400.094 | 2426880 |  241.849 |              294.354 |              129.808 |            830.862 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3455.942876344086
    time_step_min: 3113
  date: 2020-10-12_01-45-35
  done: false
  episode_len_mean: 828.2247003994673
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 242.81659470873842
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.83723417421182
        entropy_coeff: 0.0001
        kl: 0.007628274809879561
        model: {}
        policy_loss: -0.012279657608208558
        total_loss: 12.01127060254415
        vf_explained_var: 0.9756709933280945
        vf_loss: 12.02210815747579
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.17096774193548
    gpu_util_percent0: 0.3774193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15193426898701937
    mean_env_wait_ms: 1.180047023580732
    mean_inference_ms: 4.647747463125278
    mean_raw_obs_processing_ms: 0.3978437797166443
  time_since_restore: 426.38201236724854
  time_this_iter_s: 26.287599086761475
  time_total_s: 426.38201236724854
  timers:
    learn_throughput: 8324.166
    learn_time_ms: 19436.422
    sample_throughput: 23349.767
    sample_time_ms: 6929.063
    update_time_ms: 28.991
  timestamp: 1602467135
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     16 |          426.382 | 2588672 |  242.817 |              294.354 |              129.808 |            828.225 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3444.122673176686
    time_step_min: 3094
  date: 2020-10-12_01-46-02
  done: false
  episode_len_mean: 823.5167927382753
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 244.61548923424857
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 301
  episodes_total: 3305
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113860189914703
        entropy_coeff: 0.0001
        kl: 0.007556577174303432
        model: {}
        policy_loss: -0.013141293660737574
        total_loss: 15.380037069320679
        vf_explained_var: 0.977569580078125
        vf_loss: 15.391748189926147
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.6
    gpu_util_percent0: 0.3459375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515618712490499
    mean_env_wait_ms: 1.1822779266661751
    mean_inference_ms: 4.623459172474917
    mean_raw_obs_processing_ms: 0.39648031902030656
  time_since_restore: 453.353483915329
  time_this_iter_s: 26.971471548080444
  time_total_s: 453.353483915329
  timers:
    learn_throughput: 8314.149
    learn_time_ms: 19459.838
    sample_throughput: 23273.959
    sample_time_ms: 6951.632
    update_time_ms: 29.073
  timestamp: 1602467162
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     17 |          453.353 | 2750464 |  244.615 |              297.232 |              129.808 |            823.517 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3438.5295823665892
    time_step_min: 3094
  date: 2020-10-12_01-46-29
  done: false
  episode_len_mean: 821.4971231300345
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 245.47900175518117
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 171
  episodes_total: 3476
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8175450464089712
        entropy_coeff: 0.0001
        kl: 0.008889387284095088
        model: {}
        policy_loss: -0.012165131881677857
        total_loss: 9.633394241333008
        vf_explained_var: 0.979500949382782
        vf_loss: 9.643863201141357
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.083333333333332
    gpu_util_percent0: 0.30833333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15138067305114777
    mean_env_wait_ms: 1.1834423109986942
    mean_inference_ms: 4.6111450325767676
    mean_raw_obs_processing_ms: 0.39579817484181906
  time_since_restore: 479.5601313114166
  time_this_iter_s: 26.206647396087646
  time_total_s: 479.5601313114166
  timers:
    learn_throughput: 8322.159
    learn_time_ms: 19441.109
    sample_throughput: 23372.591
    sample_time_ms: 6922.296
    update_time_ms: 29.684
  timestamp: 1602467189
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     18 |           479.56 | 2912256 |  245.479 |              297.232 |              129.808 |            821.497 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3433.6869975048517
    time_step_min: 3094
  date: 2020-10-12_01-46-55
  done: false
  episode_len_mean: 819.7515818431912
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 246.22265293929658
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8071245352427164
        entropy_coeff: 0.0001
        kl: 0.008481618443814417
        model: {}
        policy_loss: -0.012896277631322542
        total_loss: 10.852858781814575
        vf_explained_var: 0.9760850071907043
        vf_loss: 10.864139159520468
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.190322580645166
    gpu_util_percent0: 0.3067741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935475
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15121953726835777
    mean_env_wait_ms: 1.1844871979968323
    mean_inference_ms: 4.600407616337548
    mean_raw_obs_processing_ms: 0.3951927089616496
  time_since_restore: 505.95303225517273
  time_this_iter_s: 26.392900943756104
  time_total_s: 505.95303225517273
  timers:
    learn_throughput: 8321.716
    learn_time_ms: 19442.145
    sample_throughput: 23433.52
    sample_time_ms: 6904.298
    update_time_ms: 38.131
  timestamp: 1602467215
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     19 |          505.953 | 3074048 |  246.223 |              297.232 |              129.808 |            819.752 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3426.42053915276
    time_step_min: 3094
  date: 2020-10-12_01-47-22
  done: false
  episode_len_mean: 816.5918939587051
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 247.43319764043696
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 288
  episodes_total: 3923
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7764832923809687
        entropy_coeff: 0.0001
        kl: 0.006902001642932494
        model: {}
        policy_loss: -0.013880621010988156
        total_loss: 13.025757471720377
        vf_explained_var: 0.9806082844734192
        vf_loss: 13.03833532333374
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.712903225806457
    gpu_util_percent0: 0.3609677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509461134729382
    mean_env_wait_ms: 1.1863527789124912
    mean_inference_ms: 4.582500976018145
    mean_raw_obs_processing_ms: 0.3941842753056177
  time_since_restore: 532.657856464386
  time_this_iter_s: 26.704824209213257
  time_total_s: 532.657856464386
  timers:
    learn_throughput: 8311.031
    learn_time_ms: 19467.14
    sample_throughput: 23419.908
    sample_time_ms: 6908.311
    update_time_ms: 46.775
  timestamp: 1602467242
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     20 |          532.658 | 3235840 |  247.433 |              297.232 |              129.808 |            816.592 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3421.3232843137257
    time_step_min: 3094
  date: 2020-10-12_01-47-49
  done: false
  episode_len_mean: 814.9396299902629
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 248.11603867300065
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 185
  episodes_total: 4108
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7784419159094492
        entropy_coeff: 0.0001
        kl: 0.00804499420337379
        model: {}
        policy_loss: -0.014405049829899022
        total_loss: 8.84128741423289
        vf_explained_var: 0.9825008511543274
        vf_loss: 8.854161024093628
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.476666666666674
    gpu_util_percent0: 0.322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15079782306463546
    mean_env_wait_ms: 1.1874566403456555
    mean_inference_ms: 4.572195661446275
    mean_raw_obs_processing_ms: 0.3936225266965036
  time_since_restore: 559.012130022049
  time_this_iter_s: 26.354273557662964
  time_total_s: 559.012130022049
  timers:
    learn_throughput: 8306.818
    learn_time_ms: 19477.013
    sample_throughput: 23455.936
    sample_time_ms: 6897.7
    update_time_ms: 46.541
  timestamp: 1602467269
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     21 |          559.012 | 3397632 |  248.116 |              297.232 |              129.808 |             814.94 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3417.2550129747583
    time_step_min: 3090
  date: 2020-10-12_01-48-15
  done: false
  episode_len_mean: 813.5680806187016
  episode_reward_max: 297.8383838383839
  episode_reward_mean: 248.68299114889217
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 159
  episodes_total: 4267
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7700633853673935
        entropy_coeff: 0.0001
        kl: 0.007813045522198081
        model: {}
        policy_loss: -0.012473011311764518
        total_loss: 8.323536992073059
        vf_explained_var: 0.9814441204071045
        vf_loss: 8.334524432818094
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.516129032258068
    gpu_util_percent0: 0.32645161290322583
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1506723683565958
    mean_env_wait_ms: 1.188360228684807
    mean_inference_ms: 4.563775052195036
    mean_raw_obs_processing_ms: 0.39314874005916484
  time_since_restore: 585.4563698768616
  time_this_iter_s: 26.444239854812622
  time_total_s: 585.4563698768616
  timers:
    learn_throughput: 8309.9
    learn_time_ms: 19469.79
    sample_throughput: 23526.666
    sample_time_ms: 6876.963
    update_time_ms: 47.211
  timestamp: 1602467295
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | RUNNING  | 172.17.0.4:74879 |     22 |          585.456 | 3559424 |  248.683 |              297.838 |              129.808 |            813.568 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9c831_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3411.738772787906
    time_step_min: 3090
  date: 2020-10-12_01-48-42
  done: true
  episode_len_mean: 811.4891736632788
  episode_reward_max: 297.8383838383839
  episode_reward_mean: 249.50558613086224
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 259
  episodes_total: 4526
  experiment_id: 475de12bc68346f5a717b3d64cc0b38e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7288455019394556
        entropy_coeff: 0.0001
        kl: 0.007099877965326111
        model: {}
        policy_loss: -0.013382211055917045
        total_loss: 12.866562684377035
        vf_explained_var: 0.9804218411445618
        vf_loss: 12.878597736358643
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.183333333333334
    gpu_util_percent0: 0.406
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74879
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15047488198370554
    mean_env_wait_ms: 1.1898251072416721
    mean_inference_ms: 4.550969235688889
    mean_raw_obs_processing_ms: 0.3924321218757443
  time_since_restore: 611.7788410186768
  time_this_iter_s: 26.322471141815186
  time_total_s: 611.7788410186768
  timers:
    learn_throughput: 8313.28
    learn_time_ms: 19461.873
    sample_throughput: 23546.007
    sample_time_ms: 6871.314
    update_time_ms: 45.445
  timestamp: 1602467322
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 9c831_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | TERMINATED |       |     23 |          611.779 | 3721216 |  249.506 |              297.838 |              129.808 |            811.489 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9c831_00000 | TERMINATED |       |     23 |          611.779 | 3721216 |  249.506 |              297.838 |              129.808 |            811.489 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


