2020-10-11 16:15:19,401	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f5a8f_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=25709)[0m 2020-10-11 16:15:22,150	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=25645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25676)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25676)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25577)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25577)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=25654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=25654)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3604.8101265822784
    time_step_min: 3251
  date: 2020-10-11_16-15-48
  done: false
  episode_len_mean: 891.0759493670886
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 219.83684950773548
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 79
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1817580461502075
        entropy_coeff: 0.00010000000000000002
        kl: 0.0056662580796650475
        model: {}
        policy_loss: -0.012262638957638825
        total_loss: 530.9325648716518
        vf_explained_var: 0.42352813482284546
        vf_loss: 530.9438127790179
    num_steps_sampled: 80896
    num_steps_trained: 80896
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.49583333333333
    gpu_util_percent0: 0.2104166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.3333333333333335
    vram_util_percent0: 0.07734776429430414
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14321407295738187
    mean_env_wait_ms: 0.6565433153586462
    mean_inference_ms: 6.003179202737835
    mean_raw_obs_processing_ms: 0.3204385216275127
  time_since_restore: 20.765223741531372
  time_this_iter_s: 20.765223741531372
  time_total_s: 20.765223741531372
  timers:
    learn_throughput: 6704.389
    learn_time_ms: 12066.126
    sample_throughput: 9389.874
    sample_time_ms: 8615.238
    update_time_ms: 46.782
  timestamp: 1602432948
  timesteps_since_restore: 0
  timesteps_total: 80896
  training_iteration: 1
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 25.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      1 |          20.7652 | 80896 |  219.837 |              273.444 |              149.354 |            891.076 |
+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3612.772151898734
    time_step_min: 3251
  date: 2020-10-11_16-16-07
  done: false
  episode_len_mean: 890.5569620253165
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 218.63048203554516
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 158
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1560483149119787
        entropy_coeff: 0.00010000000000000002
        kl: 0.005446308026356357
        model: {}
        policy_loss: -0.013145096733101777
        total_loss: 172.32416643415178
        vf_explained_var: 0.7585111260414124
        vf_loss: 172.33633422851562
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.58636363636363
    gpu_util_percent0: 0.1886363636363636
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4681818181818187
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13861688092893748
    mean_env_wait_ms: 0.6527614905773435
    mean_inference_ms: 5.77088424227358
    mean_raw_obs_processing_ms: 0.3094348867722723
  time_since_restore: 39.82163381576538
  time_this_iter_s: 19.05641007423401
  time_total_s: 39.82163381576538
  timers:
    learn_throughput: 6717.507
    learn_time_ms: 12042.562
    sample_throughput: 10382.684
    sample_time_ms: 7791.435
    update_time_ms: 37.14
  timestamp: 1602432967
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 2
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      2 |          39.8216 | 161792 |   218.63 |              273.444 |              149.354 |            890.557 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3609.4388185654007
    time_step_min: 3251
  date: 2020-10-11_16-16-25
  done: false
  episode_len_mean: 887.1223628691984
  episode_reward_max: 273.4444444444444
  episode_reward_mean: 219.13553254059562
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 237
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1498419557298933
        entropy_coeff: 0.00010000000000000002
        kl: 0.006340766059500831
        model: {}
        policy_loss: -0.014920676459691353
        total_loss: 76.00567081996373
        vf_explained_var: 0.866301953792572
        vf_loss: 76.01943751743862
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.46190476190476
    gpu_util_percent0: 0.33380952380952383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13545802809359248
    mean_env_wait_ms: 0.6503085829247192
    mean_inference_ms: 5.572566056238619
    mean_raw_obs_processing_ms: 0.3015824022104329
  time_since_restore: 58.027791023254395
  time_this_iter_s: 18.206157207489014
  time_total_s: 58.027791023254395
  timers:
    learn_throughput: 6747.04
    learn_time_ms: 11989.851
    sample_throughput: 11112.788
    sample_time_ms: 7279.541
    update_time_ms: 35.88
  timestamp: 1602432985
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 3
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      3 |          58.0278 | 242688 |  219.136 |              273.444 |              149.354 |            887.122 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3612.3860759493673
    time_step_min: 3236
  date: 2020-10-11_16-16-43
  done: false
  episode_len_mean: 884.8006329113924
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 218.68897839150986
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 316
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1339221341269357
        entropy_coeff: 0.00010000000000000002
        kl: 0.006889853426920516
        model: {}
        policy_loss: -0.016060244691159044
        total_loss: 57.26039069039481
        vf_explained_var: 0.9008350372314453
        vf_loss: 57.275186266217915
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.157142857142865
    gpu_util_percent0: 0.3380952380952381
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1331958726813208
    mean_env_wait_ms: 0.6487802760465601
    mean_inference_ms: 5.425174772283316
    mean_raw_obs_processing_ms: 0.29582564215470597
  time_since_restore: 76.0679042339325
  time_this_iter_s: 18.0401132106781
  time_total_s: 76.0679042339325
  timers:
    learn_throughput: 6777.158
    learn_time_ms: 11936.566
    sample_throughput: 11536.285
    sample_time_ms: 7012.31
    update_time_ms: 31.516
  timestamp: 1602433003
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 4
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      4 |          76.0679 | 323584 |  218.689 |              275.717 |              149.354 |            884.801 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3607.460759493671
    time_step_min: 3236
  date: 2020-10-11_16-17-01
  done: false
  episode_len_mean: 882.3113924050633
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 219.43523846055473
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 395
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1165154491152083
        entropy_coeff: 0.00010000000000000002
        kl: 0.0067611168404775
        model: {}
        policy_loss: -0.016354712857199565
        total_loss: 47.563328879220144
        vf_explained_var: 0.917331337928772
        vf_loss: 47.57844488961356
    num_steps_sampled: 404480
    num_steps_trained: 404480
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.02380952380953
    gpu_util_percent0: 0.34476190476190477
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1314880972380966
    mean_env_wait_ms: 0.647942514465797
    mean_inference_ms: 5.310229644984075
    mean_raw_obs_processing_ms: 0.29130235731107407
  time_since_restore: 93.97231364250183
  time_this_iter_s: 17.904409408569336
  time_total_s: 93.97231364250183
  timers:
    learn_throughput: 6782.867
    learn_time_ms: 11926.519
    sample_throughput: 11904.351
    sample_time_ms: 6795.499
    update_time_ms: 34.942
  timestamp: 1602433021
  timesteps_since_restore: 0
  timesteps_total: 404480
  training_iteration: 5
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      5 |          93.9723 | 404480 |  219.435 |              275.717 |              149.354 |            882.311 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3606.8284600389866
    time_step_min: 3236
  date: 2020-10-11_16-17-19
  done: false
  episode_len_mean: 877.4658869395712
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 219.53104140823424
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 118
  episodes_total: 513
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.092801911490304
        entropy_coeff: 0.00010000000000000002
        kl: 0.0062296149720038685
        model: {}
        policy_loss: -0.016466571666699435
        total_loss: 56.3185304914202
        vf_explained_var: 0.9366416335105896
        vf_loss: 56.333861759730745
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.05500000000001
    gpu_util_percent0: 0.382
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.475
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12959529747481283
    mean_env_wait_ms: 0.6477971817067627
    mean_inference_ms: 5.182745401972663
    mean_raw_obs_processing_ms: 0.286488595152834
  time_since_restore: 111.8152723312378
  time_this_iter_s: 17.842958688735962
  time_total_s: 111.8152723312378
  timers:
    learn_throughput: 6796.691
    learn_time_ms: 11902.262
    sample_throughput: 12148.614
    sample_time_ms: 6658.867
    update_time_ms: 35.202
  timestamp: 1602433039
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 6
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      6 |          111.815 | 485376 |  219.531 |              275.717 |              149.354 |            877.466 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3600.9762658227846
    time_step_min: 3236
  date: 2020-10-11_16-17-37
  done: false
  episode_len_mean: 872.1598101265823
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 220.4177375015981
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 119
  episodes_total: 632
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.1184720993041992
        entropy_coeff: 0.00010000000000000002
        kl: 0.006490583797650678
        model: {}
        policy_loss: -0.01627908361011318
        total_loss: 31.425927298409597
        vf_explained_var: 0.9506322145462036
        vf_loss: 31.44101824079241
    num_steps_sampled: 566272
    num_steps_trained: 566272
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.423809523809524
    gpu_util_percent0: 0.24952380952380956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4809523809523806
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12828566444803613
    mean_env_wait_ms: 0.6478166533336334
    mean_inference_ms: 5.0918193072553635
    mean_raw_obs_processing_ms: 0.2829554308475049
  time_since_restore: 129.9019570350647
  time_this_iter_s: 18.086684703826904
  time_total_s: 129.9019570350647
  timers:
    learn_throughput: 6795.729
    learn_time_ms: 11903.948
    sample_throughput: 12297.469
    sample_time_ms: 6578.264
    update_time_ms: 35.836
  timestamp: 1602433057
  timesteps_since_restore: 0
  timesteps_total: 566272
  training_iteration: 7
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      7 |          129.902 | 566272 |  220.418 |              275.717 |              149.354 |             872.16 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3596.4275668073137
    time_step_min: 3236
  date: 2020-10-11_16-17-55
  done: false
  episode_len_mean: 868.098452883263
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 221.10693432212403
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 711
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.10015412739345
        entropy_coeff: 0.00010000000000000002
        kl: 0.006557688050504241
        model: {}
        policy_loss: -0.018214247721646513
        total_loss: 23.04970223563058
        vf_explained_var: 0.9621651768684387
        vf_loss: 23.066714423043386
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.91428571428571
    gpu_util_percent0: 0.27666666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1275760484783097
    mean_env_wait_ms: 0.6478968142099572
    mean_inference_ms: 5.042569339222437
    mean_raw_obs_processing_ms: 0.2810865791155001
  time_since_restore: 147.80396723747253
  time_this_iter_s: 17.902010202407837
  time_total_s: 147.80396723747253
  timers:
    learn_throughput: 6801.445
    learn_time_ms: 11893.944
    sample_throughput: 12433.85
    sample_time_ms: 6506.11
    update_time_ms: 36.165
  timestamp: 1602433075
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 8
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      8 |          147.804 | 647168 |  221.107 |              275.717 |              149.354 |            868.098 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3591.618987341772
    time_step_min: 3236
  date: 2020-10-11_16-18-13
  done: false
  episode_len_mean: 863.7075949367089
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 221.83550696841823
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 790
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0786409548350744
        entropy_coeff: 0.00010000000000000002
        kl: 0.006580007595143148
        model: {}
        policy_loss: -0.018403502513787577
        total_loss: 22.735295704432897
        vf_explained_var: 0.9610903859138489
        vf_loss: 22.752492087227957
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.928571428571427
    gpu_util_percent0: 0.26142857142857145
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12695482879374936
    mean_env_wait_ms: 0.6480843407701399
    mean_inference_ms: 4.999428668526167
    mean_raw_obs_processing_ms: 0.27942825537360366
  time_since_restore: 165.73263382911682
  time_this_iter_s: 17.928666591644287
  time_total_s: 165.73263382911682
  timers:
    learn_throughput: 6804.452
    learn_time_ms: 11888.687
    sample_throughput: 12556.493
    sample_time_ms: 6442.563
    update_time_ms: 36.573
  timestamp: 1602433093
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 9
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      9 |          165.733 | 728064 |  221.836 |              275.717 |              149.354 |            863.708 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3588.164212910532
    time_step_min: 3236
  date: 2020-10-11_16-18-32
  done: false
  episode_len_mean: 859.8516421291054
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 222.35895763981821
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 93
  episodes_total: 883
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0437617642538888
        entropy_coeff: 0.00010000000000000002
        kl: 0.007118354751063245
        model: {}
        policy_loss: -0.017273931497974054
        total_loss: 26.358385358537948
        vf_explained_var: 0.9660363793373108
        vf_loss: 26.374339512416295
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.442857142857147
    gpu_util_percent0: 0.35190476190476194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4809523809523806
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12631327428200384
    mean_env_wait_ms: 0.6485025433533471
    mean_inference_ms: 4.955339784300054
    mean_raw_obs_processing_ms: 0.2777230061320137
  time_since_restore: 183.98267531394958
  time_this_iter_s: 18.250041484832764
  time_total_s: 183.98267531394958
  timers:
    learn_throughput: 6798.509
    learn_time_ms: 11899.079
    sample_throughput: 12607.726
    sample_time_ms: 6416.383
    update_time_ms: 36.159
  timestamp: 1602433112
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 10
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     10 |          183.983 | 808960 |  222.359 |              275.717 |              149.354 |            859.852 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3579.2076023391814
    time_step_min: 3236
  date: 2020-10-11_16-18-50
  done: false
  episode_len_mean: 855.2738791423002
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.71601984759866
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 143
  episodes_total: 1026
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0532989501953125
        entropy_coeff: 0.00010000000000000002
        kl: 0.005947550958288568
        model: {}
        policy_loss: -0.017168237029441764
        total_loss: 19.90403720310756
        vf_explained_var: 0.9746130108833313
        vf_loss: 19.920121056692942
    num_steps_sampled: 889856
    num_steps_trained: 889856
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.025000000000006
    gpu_util_percent0: 0.3265
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.475
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12550035463846962
    mean_env_wait_ms: 0.6490592316159273
    mean_inference_ms: 4.899542005270903
    mean_raw_obs_processing_ms: 0.275590835737541
  time_since_restore: 201.92880582809448
  time_this_iter_s: 17.946130514144897
  time_total_s: 201.92880582809448
  timers:
    learn_throughput: 6809.929
    learn_time_ms: 11879.125
    sample_throughput: 13139.535
    sample_time_ms: 6156.687
    update_time_ms: 33.649
  timestamp: 1602433130
  timesteps_since_restore: 0
  timesteps_total: 889856
  training_iteration: 11
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     11 |          201.929 | 889856 |  223.716 |              275.717 |              149.354 |            855.274 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3575.6121157323687
    time_step_min: 3236
  date: 2020-10-11_16-19-08
  done: false
  episode_len_mean: 852.746835443038
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 224.26079054560057
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 80
  episodes_total: 1106
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.0376896517617362
        entropy_coeff: 0.00010000000000000002
        kl: 0.006494693790695497
        model: {}
        policy_loss: -0.017213530838489532
        total_loss: 15.385991505214147
        vf_explained_var: 0.9749676585197449
        vf_loss: 15.402009963989258
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.647619047619052
    gpu_util_percent0: 0.2523809523809524
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12511358324318259
    mean_env_wait_ms: 0.6493616281163671
    mean_inference_ms: 4.8731012510452
    mean_raw_obs_processing_ms: 0.27457766992040916
  time_since_restore: 219.99315357208252
  time_this_iter_s: 18.064347743988037
  time_total_s: 219.99315357208252
  timers:
    learn_throughput: 6821.55
    learn_time_ms: 11858.889
    sample_throughput: 13307.796
    sample_time_ms: 6078.843
    update_time_ms: 32.585
  timestamp: 1602433148
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 12
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     12 |          219.993 | 970752 |  224.261 |              275.717 |              149.354 |            852.747 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3571.8481012658226
    time_step_min: 3236
  date: 2020-10-11_16-19-26
  done: false
  episode_len_mean: 850.7628691983123
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 224.83109576780456
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 1185
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 1.019127641405378
        entropy_coeff: 0.00010000000000000002
        kl: 0.007594235574028322
        model: {}
        policy_loss: -0.01849585006545697
        total_loss: 14.956309591020856
        vf_explained_var: 0.9742900133132935
        vf_loss: 14.973388808114189
    num_steps_sampled: 1051648
    num_steps_trained: 1051648
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.109523809523814
    gpu_util_percent0: 0.21095238095238095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12476645523409689
    mean_env_wait_ms: 0.6496467586134247
    mean_inference_ms: 4.849312962133114
    mean_raw_obs_processing_ms: 0.2736662153836395
  time_since_restore: 237.87757992744446
  time_this_iter_s: 17.88442635536194
  time_total_s: 237.87757992744446
  timers:
    learn_throughput: 6820.96
    learn_time_ms: 11859.915
    sample_throughput: 13383.561
    sample_time_ms: 6044.43
    update_time_ms: 32.91
  timestamp: 1602433166
  timesteps_since_restore: 0
  timesteps_total: 1051648
  training_iteration: 13
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     13 |          237.878 | 1051648 |  224.831 |              275.717 |              149.354 |            850.763 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3567.480407523511
    time_step_min: 3236
  date: 2020-10-11_16-19-44
  done: false
  episode_len_mean: 848.564263322884
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 225.49286754694268
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 91
  episodes_total: 1276
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9859031098229545
        entropy_coeff: 0.00010000000000000002
        kl: 0.006209247945142644
        model: {}
        policy_loss: -0.015815080343080417
        total_loss: 22.0059392111642
        vf_explained_var: 0.9709354043006897
        vf_loss: 22.02061108180455
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.1
    gpu_util_percent0: 0.2561904761904762
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12440590023740428
    mean_env_wait_ms: 0.6500161752138565
    mean_inference_ms: 4.824470182458269
    mean_raw_obs_processing_ms: 0.27270381848447495
  time_since_restore: 256.0939621925354
  time_this_iter_s: 18.216382265090942
  time_total_s: 256.0939621925354
  timers:
    learn_throughput: 6819.798
    learn_time_ms: 11861.934
    sample_throughput: 13351.452
    sample_time_ms: 6058.967
    update_time_ms: 33.426
  timestamp: 1602433184
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 14
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     14 |          256.094 | 1132544 |  225.493 |              275.717 |              149.354 |            848.564 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3559.1558533145276
    time_step_min: 3231
  date: 2020-10-11_16-20-02
  done: false
  episode_len_mean: 845.444287729196
  episode_reward_max: 276.47474747474723
  episode_reward_mean: 226.7541636392129
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 142
  episodes_total: 1418
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9841553313391549
        entropy_coeff: 0.00010000000000000002
        kl: 0.006351638518806014
        model: {}
        policy_loss: -0.016068647761130705
        total_loss: 18.397855486188615
        vf_explained_var: 0.977173924446106
        vf_loss: 18.41275133405413
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.575000000000006
    gpu_util_percent0: 0.23499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.475
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12391098352348277
    mean_env_wait_ms: 0.650553499448869
    mean_inference_ms: 4.790647346666216
    mean_raw_obs_processing_ms: 0.2714149181579573
  time_since_restore: 273.77138781547546
  time_this_iter_s: 17.677425622940063
  time_total_s: 273.77138781547546
  timers:
    learn_throughput: 6829.723
    learn_time_ms: 11844.697
    sample_throughput: 13356.997
    sample_time_ms: 6056.451
    update_time_ms: 30.306
  timestamp: 1602433202
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 15
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     15 |          273.771 | 1213440 |  226.754 |              276.475 |              149.354 |            845.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3554.4263824117256
    time_step_min: 3231
  date: 2020-10-11_16-20-20
  done: false
  episode_len_mean: 843.487674883411
  episode_reward_max: 276.47474747474723
  episode_reward_mean: 227.47075013963746
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 83
  episodes_total: 1501
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9706924217087882
        entropy_coeff: 0.00010000000000000002
        kl: 0.006457218434661627
        model: {}
        policy_loss: -0.017864259225981578
        total_loss: 12.351537431989398
        vf_explained_var: 0.9794679284095764
        vf_loss: 12.368207114083427
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.05714285714286
    gpu_util_percent0: 0.2666666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12366096253505773
    mean_env_wait_ms: 0.6508345164140612
    mean_inference_ms: 4.773345365170736
    mean_raw_obs_processing_ms: 0.2707580912826306
  time_since_restore: 291.6409411430359
  time_this_iter_s: 17.869553327560425
  time_total_s: 291.6409411430359
  timers:
    learn_throughput: 6832.205
    learn_time_ms: 11840.395
    sample_throughput: 13338.974
    sample_time_ms: 6064.634
    update_time_ms: 30.189
  timestamp: 1602433220
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 16
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     16 |          291.641 | 1294336 |  227.471 |              276.475 |              149.354 |            843.488 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3549.3708860759493
    time_step_min: 3231
  date: 2020-10-11_16-20-38
  done: false
  episode_len_mean: 841.8506329113924
  episode_reward_max: 276.47474747474723
  episode_reward_mean: 228.23673443293686
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 1580
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9509219697543553
        entropy_coeff: 0.00010000000000000002
        kl: 0.0061031510787350795
        model: {}
        policy_loss: -0.01630664457167898
        total_loss: 13.894207954406738
        vf_explained_var: 0.975964367389679
        vf_loss: 13.909389223371234
    num_steps_sampled: 1375232
    num_steps_trained: 1375232
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.16190476190476
    gpu_util_percent0: 0.3095238095238096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12343837132751707
    mean_env_wait_ms: 0.6510906399362479
    mean_inference_ms: 4.758010510979952
    mean_raw_obs_processing_ms: 0.27016668535832183
  time_since_restore: 309.67595911026
  time_this_iter_s: 18.03501796722412
  time_total_s: 309.67595911026
  timers:
    learn_throughput: 6832.998
    learn_time_ms: 11839.02
    sample_throughput: 13356.996
    sample_time_ms: 6056.452
    update_time_ms: 28.12
  timestamp: 1602433238
  timesteps_since_restore: 0
  timesteps_total: 1375232
  training_iteration: 17
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     17 |          309.676 | 1375232 |  228.237 |              276.475 |              149.354 |            841.851 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3543.2877526753864
    time_step_min: 3220
  date: 2020-10-11_16-20-56
  done: false
  episode_len_mean: 840.3252080856124
  episode_reward_max: 278.1414141414138
  episode_reward_mean: 229.15842131181006
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 102
  episodes_total: 1682
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9166804041181292
        entropy_coeff: 0.00010000000000000002
        kl: 0.006260165612080267
        model: {}
        policy_loss: -0.014970483524458749
        total_loss: 15.519641603742327
        vf_explained_var: 0.9795632362365723
        vf_loss: 15.533452033996582
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.885
    gpu_util_percent0: 0.24550000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12317131619295082
    mean_env_wait_ms: 0.6513984586795933
    mean_inference_ms: 4.739667866243492
    mean_raw_obs_processing_ms: 0.26945875896825744
  time_since_restore: 327.5367546081543
  time_this_iter_s: 17.860795497894287
  time_total_s: 327.5367546081543
  timers:
    learn_throughput: 6834.494
    learn_time_ms: 11836.429
    sample_throughput: 13356.865
    sample_time_ms: 6056.511
    update_time_ms: 26.021
  timestamp: 1602433256
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 18
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     18 |          327.537 | 1456128 |  229.158 |              278.141 |              149.354 |            840.325 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3536.5250965250966
    time_step_min: 3181
  date: 2020-10-11_16-21-14
  done: false
  episode_len_mean: 839.1671263099835
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 230.1830661830661
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 131
  episodes_total: 1813
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.9101576294217791
        entropy_coeff: 0.00010000000000000002
        kl: 0.0055511897163731715
        model: {}
        policy_loss: -0.013219582049974374
        total_loss: 15.21727466583252
        vf_explained_var: 0.9794386625289917
        vf_loss: 15.22947461264474
    num_steps_sampled: 1537024
    num_steps_trained: 1537024
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.795238095238098
    gpu_util_percent0: 0.2866666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4809523809523806
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12286276401652159
    mean_env_wait_ms: 0.6517618829218221
    mean_inference_ms: 4.71866162159186
    mean_raw_obs_processing_ms: 0.2686600257587414
  time_since_restore: 345.5379207134247
  time_this_iter_s: 18.001166105270386
  time_total_s: 345.5379207134247
  timers:
    learn_throughput: 6833.207
    learn_time_ms: 11838.658
    sample_throughput: 13331.164
    sample_time_ms: 6068.187
    update_time_ms: 25.559
  timestamp: 1602433274
  timesteps_since_restore: 0
  timesteps_total: 1537024
  training_iteration: 19
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     19 |          345.538 | 1537024 |  230.183 |              284.051 |              149.354 |            839.167 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3532.4077004219407
    time_step_min: 3181
  date: 2020-10-11_16-21-32
  done: false
  episode_len_mean: 838.5385021097046
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 230.8069140774836
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 83
  episodes_total: 1896
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8989295278276715
        entropy_coeff: 0.00010000000000000002
        kl: 0.006024706177413464
        model: {}
        policy_loss: -0.016748275740870407
        total_loss: 8.856049401419503
        vf_explained_var: 0.985133707523346
        vf_loss: 8.87168298448835
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.2904761904762
    gpu_util_percent0: 0.27
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12269316854403324
    mean_env_wait_ms: 0.6519743856489882
    mean_inference_ms: 4.70681419425705
    mean_raw_obs_processing_ms: 0.26821655590462323
  time_since_restore: 363.4639821052551
  time_this_iter_s: 17.926061391830444
  time_total_s: 363.4639821052551
  timers:
    learn_throughput: 6843.975
    learn_time_ms: 11820.031
    sample_throughput: 13360.485
    sample_time_ms: 6054.87
    update_time_ms: 25.441
  timestamp: 1602433292
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 20
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     20 |          363.464 | 1617920 |  230.807 |              284.051 |              149.354 |            838.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3528.400506329114
    time_step_min: 3181
  date: 2020-10-11_16-21-50
  done: false
  episode_len_mean: 837.9822784810127
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 231.41406469760892
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 1975
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8814251933779035
        entropy_coeff: 0.00010000000000000002
        kl: 0.006353956514171192
        model: {}
        policy_loss: -0.016337690276226828
        total_loss: 8.809574127197266
        vf_explained_var: 0.9844195246696472
        vf_loss: 8.824729646955218
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.99000000000001
    gpu_util_percent0: 0.26549999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12253687669271257
    mean_env_wait_ms: 0.6521445343420229
    mean_inference_ms: 4.696037997486925
    mean_raw_obs_processing_ms: 0.26780478502415517
  time_since_restore: 381.23959612846375
  time_this_iter_s: 17.775614023208618
  time_total_s: 381.23959612846375
  timers:
    learn_throughput: 6850.451
    learn_time_ms: 11808.857
    sample_throughput: 13375.051
    sample_time_ms: 6048.276
    update_time_ms: 26.002
  timestamp: 1602433310
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 21
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     21 |           381.24 | 1698816 |  231.414 |              284.051 |              149.354 |            837.982 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3524.522409638554
    time_step_min: 3181
  date: 2020-10-11_16-22-08
  done: false
  episode_len_mean: 837.0515662650603
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 232.0016551052695
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 100
  episodes_total: 2075
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8468929103442601
        entropy_coeff: 0.00010000000000000002
        kl: 0.006101464320506368
        model: {}
        policy_loss: -0.014634852497173207
        total_loss: 13.325916017804827
        vf_explained_var: 0.9815999865531921
        vf_loss: 13.339415413992745
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.580952380952382
    gpu_util_percent0: 0.31190476190476196
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12235089383127508
    mean_env_wait_ms: 0.6523542058186689
    mean_inference_ms: 4.683351063520958
    mean_raw_obs_processing_ms: 0.2673125083760541
  time_since_restore: 399.2973039150238
  time_this_iter_s: 18.05770778656006
  time_total_s: 399.2973039150238
  timers:
    learn_throughput: 6845.537
    learn_time_ms: 11817.335
    sample_throughput: 13396.713
    sample_time_ms: 6038.496
    update_time_ms: 26.119
  timestamp: 1602433328
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 22
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     22 |          399.297 | 1779712 |  232.002 |              284.051 |              149.354 |            837.052 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3520.280598368087
    time_step_min: 3181
  date: 2020-10-11_16-22-26
  done: false
  episode_len_mean: 836.0838621940163
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 232.64435378261302
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 131
  episodes_total: 2206
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8442171726908002
        entropy_coeff: 0.00010000000000000002
        kl: 0.0062143402839345595
        model: {}
        policy_loss: -0.01575768951858793
        total_loss: 15.60951382773263
        vf_explained_var: 0.9803310036659241
        vf_loss: 15.624112946646553
    num_steps_sampled: 1860608
    num_steps_trained: 1860608
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.81904761904762
    gpu_util_percent0: 0.3495238095238095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4809523809523806
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12212652245379878
    mean_env_wait_ms: 0.6525856242265216
    mean_inference_ms: 4.667880347689874
    mean_raw_obs_processing_ms: 0.2667260125902466
  time_since_restore: 417.2645218372345
  time_this_iter_s: 17.967217922210693
  time_total_s: 417.2645218372345
  timers:
    learn_throughput: 6853.638
    learn_time_ms: 11803.367
    sample_throughput: 13345.687
    sample_time_ms: 6061.584
    update_time_ms: 25.135
  timestamp: 1602433346
  timesteps_since_restore: 0
  timesteps_total: 1860608
  training_iteration: 23
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     23 |          417.265 | 1860608 |  232.644 |              284.051 |              149.354 |            836.084 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3516.2487996508075
    time_step_min: 3181
  date: 2020-10-11_16-22-44
  done: false
  episode_len_mean: 835.2937581841991
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 233.25523237614019
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 85
  episodes_total: 2291
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8486343026161194
        entropy_coeff: 0.00010000000000000002
        kl: 0.005781072724078383
        model: {}
        policy_loss: -0.01596627783562456
        total_loss: 9.746046611240931
        vf_explained_var: 0.9830135703086853
        vf_loss: 9.760941914149694
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.376190476190487
    gpu_util_percent0: 0.3838095238095238
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1219983612056573
    mean_env_wait_ms: 0.6527434071832637
    mean_inference_ms: 4.658896681324457
    mean_raw_obs_processing_ms: 0.26638959910373616
  time_since_restore: 435.35903000831604
  time_this_iter_s: 18.094508171081543
  time_total_s: 435.35903000831604
  timers:
    learn_throughput: 6849.785
    learn_time_ms: 11810.006
    sample_throughput: 13389.983
    sample_time_ms: 6041.531
    update_time_ms: 25.961
  timestamp: 1602433364
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 24
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     24 |          435.359 | 1941504 |  233.255 |              284.051 |              149.354 |            835.294 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3512.595529312526
    time_step_min: 3181
  date: 2020-10-11_16-23-02
  done: false
  episode_len_mean: 834.419232391396
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 233.80875818497074
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 80
  episodes_total: 2371
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8333808183670044
        entropy_coeff: 0.00010000000000000002
        kl: 0.005867979555789914
        model: {}
        policy_loss: -0.01597744705421584
        total_loss: 9.252091816493444
        vf_explained_var: 0.9832115769386292
        vf_loss: 9.266979081290108
    num_steps_sampled: 2022400
    num_steps_trained: 2022400
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.7904761904762
    gpu_util_percent0: 0.24666666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12188093159795932
    mean_env_wait_ms: 0.6528875931644009
    mean_inference_ms: 4.65074909708012
    mean_raw_obs_processing_ms: 0.2660778839811452
  time_since_restore: 453.2706034183502
  time_this_iter_s: 17.91157341003418
  time_total_s: 453.2706034183502
  timers:
    learn_throughput: 6847.1
    learn_time_ms: 11814.637
    sample_throughput: 13351.853
    sample_time_ms: 6058.784
    update_time_ms: 27.431
  timestamp: 1602433382
  timesteps_since_restore: 0
  timesteps_total: 2022400
  training_iteration: 25
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     25 |          453.271 | 2022400 |  233.809 |              284.051 |              149.354 |            834.419 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3507.8851732473813
    time_step_min: 3181
  date: 2020-10-11_16-23-20
  done: false
  episode_len_mean: 832.9838839645447
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 234.52244849787147
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 111
  episodes_total: 2482
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8008829014641898
        entropy_coeff: 0.00010000000000000002
        kl: 0.005799769623471158
        model: {}
        policy_loss: -0.014681054593113783
        total_loss: 11.853715079171318
        vf_explained_var: 0.9833112359046936
        vf_loss: 11.867315701075963
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.104761904761908
    gpu_util_percent0: 0.27952380952380956
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12172447167281233
    mean_env_wait_ms: 0.6530839641954829
    mean_inference_ms: 4.64008255868639
    mean_raw_obs_processing_ms: 0.26565535913099086
  time_since_restore: 471.2589874267578
  time_this_iter_s: 17.988384008407593
  time_total_s: 471.2589874267578
  timers:
    learn_throughput: 6839.696
    learn_time_ms: 11827.426
    sample_throughput: 13352.685
    sample_time_ms: 6058.407
    update_time_ms: 25.87
  timestamp: 1602433400
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 26
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     26 |          471.259 | 2103296 |  234.522 |              284.051 |              149.354 |            832.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3502.5111281657714
    time_step_min: 3181
  date: 2020-10-11_16-23-38
  done: false
  episode_len_mean: 831.4370683039141
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 235.33669775266085
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 124
  episodes_total: 2606
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.8017460022653852
        entropy_coeff: 0.00010000000000000002
        kl: 0.005671164553080287
        model: {}
        policy_loss: -0.014465352753177285
        total_loss: 8.887888090951103
        vf_explained_var: 0.9866734743118286
        vf_loss: 8.901299612862724
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.825
    gpu_util_percent0: 0.3435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4850000000000003
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12156732403321287
    mean_env_wait_ms: 0.6532861211607012
    mean_inference_ms: 4.6290150078958066
    mean_raw_obs_processing_ms: 0.2652468964390611
  time_since_restore: 489.113144159317
  time_this_iter_s: 17.854156732559204
  time_total_s: 489.113144159317
  timers:
    learn_throughput: 6849.659
    learn_time_ms: 11810.223
    sample_throughput: 13342.226
    sample_time_ms: 6063.156
    update_time_ms: 26.04
  timestamp: 1602433418
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 27
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     27 |          489.113 | 2184192 |  235.337 |              284.051 |              149.354 |            831.437 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3499.0528667163067
    time_step_min: 3181
  date: 2020-10-11_16-23-56
  done: false
  episode_len_mean: 830.5487714072971
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 235.86067676015548
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 80
  episodes_total: 2686
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7950462784085955
        entropy_coeff: 0.00010000000000000002
        kl: 0.005771402269601822
        model: {}
        policy_loss: -0.01582781528122723
        total_loss: 8.700923919677734
        vf_explained_var: 0.9843843579292297
        vf_loss: 8.715677533830915
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.099999999999994
    gpu_util_percent0: 0.28095238095238095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12147265025706677
    mean_env_wait_ms: 0.6534144924872379
    mean_inference_ms: 4.6224064736646024
    mean_raw_obs_processing_ms: 0.26499446109715585
  time_since_restore: 507.1111900806427
  time_this_iter_s: 17.998045921325684
  time_total_s: 507.1111900806427
  timers:
    learn_throughput: 6850.595
    learn_time_ms: 11808.61
    sample_throughput: 13312.65
    sample_time_ms: 6076.626
    update_time_ms: 27.686
  timestamp: 1602433436
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 28
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     28 |          507.111 | 2265088 |  235.861 |              284.051 |              149.354 |            830.549 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3495.485755499459
    time_step_min: 3181
  date: 2020-10-11_16-24-14
  done: false
  episode_len_mean: 829.419401370357
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 236.40114815664757
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 87
  episodes_total: 2773
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7676581995827811
        entropy_coeff: 0.00010000000000000002
        kl: 0.0057737694254943305
        model: {}
        policy_loss: -0.016033925049539124
        total_loss: 8.688706806727819
        vf_explained_var: 0.9849727749824524
        vf_loss: 8.703662736075264
    num_steps_sampled: 2345984
    num_steps_trained: 2345984
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.225000000000005
    gpu_util_percent0: 0.2625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12136899684599552
    mean_env_wait_ms: 0.6535625623156652
    mean_inference_ms: 4.615496740040499
    mean_raw_obs_processing_ms: 0.26471858086588224
  time_since_restore: 524.9049787521362
  time_this_iter_s: 17.79378867149353
  time_total_s: 524.9049787521362
  timers:
    learn_throughput: 6857.319
    learn_time_ms: 11797.03
    sample_throughput: 13331.287
    sample_time_ms: 6068.131
    update_time_ms: 26.89
  timestamp: 1602433454
  timesteps_since_restore: 0
  timesteps_total: 2345984
  training_iteration: 29
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     29 |          524.905 | 2345984 |  236.401 |              284.051 |              149.354 |            829.419 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3490.869370917841
    time_step_min: 3181
  date: 2020-10-11_16-24-32
  done: false
  episode_len_mean: 827.9295290477827
  episode_reward_max: 284.05050505050457
  episode_reward_mean: 237.1006003659836
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 136
  episodes_total: 2909
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.754608290536063
        entropy_coeff: 0.00010000000000000002
        kl: 0.0056725469683962205
        model: {}
        policy_loss: -0.014731894646372114
        total_loss: 10.76213536943708
        vf_explained_var: 0.9853909611701965
        vf_loss: 10.775808334350586
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.371428571428574
    gpu_util_percent0: 0.2623809523809524
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12122488602374934
    mean_env_wait_ms: 0.6537992204560652
    mean_inference_ms: 4.605299970823488
    mean_raw_obs_processing_ms: 0.2643337813548178
  time_since_restore: 542.7597060203552
  time_this_iter_s: 17.854727268218994
  time_total_s: 542.7597060203552
  timers:
    learn_throughput: 6859.082
    learn_time_ms: 11793.998
    sample_throughput: 13340.167
    sample_time_ms: 6064.092
    update_time_ms: 25.739
  timestamp: 1602433472
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 30
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     30 |           542.76 | 2426880 |  237.101 |              284.051 |              149.354 |             827.93 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3488.1255829447036
    time_step_min: 3167
  date: 2020-10-11_16-24-51
  done: false
  episode_len_mean: 827.1465689540306
  episode_reward_max: 286.1717171717171
  episode_reward_mean: 237.51632581645902
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 93
  episodes_total: 3002
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7502403259277344
        entropy_coeff: 0.00010000000000000002
        kl: 0.005389300108488117
        model: {}
        policy_loss: -0.015990441931145533
        total_loss: 8.786728995186943
        vf_explained_var: 0.9851738214492798
        vf_loss: 8.801716668265206
    num_steps_sampled: 2507776
    num_steps_trained: 2507776
  iterations_since_restore: 31
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.41428571428571
    gpu_util_percent0: 0.3657142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12113321401035924
    mean_env_wait_ms: 0.6539503979829405
    mean_inference_ms: 4.598897069532904
    mean_raw_obs_processing_ms: 0.26409110198934116
  time_since_restore: 560.7473194599152
  time_this_iter_s: 17.987613439559937
  time_total_s: 560.7473194599152
  timers:
    learn_throughput: 6851.57
    learn_time_ms: 11806.929
    sample_throughput: 13324.93
    sample_time_ms: 6071.026
    update_time_ms: 26.328
  timestamp: 1602433491
  timesteps_since_restore: 0
  timesteps_total: 2507776
  training_iteration: 31
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     31 |          560.747 | 2507776 |  237.516 |              286.172 |              149.354 |            827.147 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3485.4686790003248
    time_step_min: 3167
  date: 2020-10-11_16-25-09
  done: false
  episode_len_mean: 826.4852320675105
  episode_reward_max: 286.1717171717171
  episode_reward_mean: 237.91888702015282
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 79
  episodes_total: 3081
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7436325294630868
        entropy_coeff: 0.00010000000000000002
        kl: 0.005975004219050918
        model: {}
        policy_loss: -0.016552875034644136
        total_loss: 7.9364085878644675
        vf_explained_var: 0.9853001236915588
        vf_loss: 7.951840877532959
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 32
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.41904761904762
    gpu_util_percent0: 0.28428571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12105725915307468
    mean_env_wait_ms: 0.6540754170232392
    mean_inference_ms: 4.593636902182076
    mean_raw_obs_processing_ms: 0.2638873249083529
  time_since_restore: 578.7367494106293
  time_this_iter_s: 17.98942995071411
  time_total_s: 578.7367494106293
  timers:
    learn_throughput: 6855.226
    learn_time_ms: 11800.632
    sample_throughput: 13331.603
    sample_time_ms: 6067.988
    update_time_ms: 28.595
  timestamp: 1602433509
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 32
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     32 |          578.737 | 2588672 |  237.919 |              286.172 |              149.354 |            826.485 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3482.42893081761
    time_step_min: 3167
  date: 2020-10-11_16-25-27
  done: false
  episode_len_mean: 825.9084905660377
  episode_reward_max: 286.1717171717171
  episode_reward_mean: 238.3794549266247
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 99
  episodes_total: 3180
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7142769013132367
        entropy_coeff: 0.00010000000000000002
        kl: 0.005908405807401452
        model: {}
        policy_loss: -0.01583481377123722
        total_loss: 8.07387890134539
        vf_explained_var: 0.9876317977905273
        vf_loss: 8.08860342843192
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 33
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.533333333333342
    gpu_util_percent0: 0.20523809523809522
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12096483136185682
    mean_env_wait_ms: 0.6542389904427562
    mean_inference_ms: 4.587449996773385
    mean_raw_obs_processing_ms: 0.2636353107501833
  time_since_restore: 596.7136299610138
  time_this_iter_s: 17.97688055038452
  time_total_s: 596.7136299610138
  timers:
    learn_throughput: 6851.096
    learn_time_ms: 11807.746
    sample_throughput: 13344.606
    sample_time_ms: 6062.075
    update_time_ms: 27.62
  timestamp: 1602433527
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 33
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     33 |          596.714 | 2669568 |  238.379 |              286.172 |              149.354 |            825.908 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5a8f_00000:
  custom_metrics:
    time_step_max: 4070
    time_step_mean: 3479.037730153939
    time_step_min: 3167
  date: 2020-10-11_16-25-45
  done: true
  episode_len_mean: 825.1364322366435
  episode_reward_max: 286.1717171717171
  episode_reward_mean: 238.8932732089991
  episode_reward_min: 149.35353535353508
  episodes_this_iter: 133
  episodes_total: 3313
  experiment_id: 9ca8105c499c47c8a96ac59004499d6d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.19999999999999998
        cur_lr: 5.000000000000001e-05
        entropy: 0.7120769960539681
        entropy_coeff: 0.00010000000000000002
        kl: 0.004977691253381116
        model: {}
        policy_loss: -0.013245187367179565
        total_loss: 9.229144777570452
        vf_explained_var: 0.9872849583625793
        vf_loss: 9.241465432303292
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 34
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.757142857142867
    gpu_util_percent0: 0.2871428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5
    vram_util_percent0: 0.09732699245654314
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 25709
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12084952624888429
    mean_env_wait_ms: 0.6544306434885966
    mean_inference_ms: 4.579308231399524
    mean_raw_obs_processing_ms: 0.2633344225374542
  time_since_restore: 614.8885405063629
  time_this_iter_s: 18.17491054534912
  time_total_s: 614.8885405063629
  timers:
    learn_throughput: 6849.811
    learn_time_ms: 11809.961
    sample_throughput: 13333.898
    sample_time_ms: 6066.943
    update_time_ms: 28.07
  timestamp: 1602433545
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 34
  trial_id: f5a8f_00000
  
== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | TERMINATED |       |     34 |          614.889 | 2750464 |  238.893 |              286.172 |              149.354 |            825.136 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 26.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5a8f_00000 | TERMINATED |       |     34 |          614.889 | 2750464 |  238.893 |              286.172 |              149.354 |            825.136 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "train.py", line 72, in <module>
    train_func()
  File "train.py", line 57, in train_func
    result = analysis.dataframe().to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 89, in dataframe
    metric = self._validate_metric(metric)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 64, in _validate_metric
    raise ValueError(
ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.
