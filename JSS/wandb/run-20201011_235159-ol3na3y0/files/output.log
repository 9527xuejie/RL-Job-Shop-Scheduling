2020-10-11 23:52:03,727	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c3e84_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=16025)[0m 2020-10-11 23:52:06,479	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=15994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=15920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=15920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16020)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_23-52-47
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.173644055922826
        entropy_coeff: 0.0005000000000000001
        kl: 0.015610505981991688
        model: {}
        policy_loss: -0.014618238201364875
        total_loss: 500.41066487630206
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.427272727272733
    gpu_util_percent0: 0.38613636363636367
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5863636363636355
    vram_util_percent0: 0.08919839589731358
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16814098199159505
    mean_env_wait_ms: 1.1689195341444119
    mean_inference_ms: 5.946547657518188
    mean_raw_obs_processing_ms: 0.447612328454277
  time_since_restore: 35.758862257003784
  time_this_iter_s: 35.758862257003784
  time_total_s: 35.758862257003784
  timers:
    learn_throughput: 6173.978
    learn_time_ms: 26205.472
    sample_throughput: 17076.436
    sample_time_ms: 9474.577
    update_time_ms: 44.899
  timestamp: 1602460367
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      1 |          35.7589 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3606.409722222222
    time_step_min: 3376
  date: 2020-10-11_23-53-21
  done: false
  episode_len_mean: 889.5854430379746
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 217.71659634317845
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1365770598252614
        entropy_coeff: 0.0005000000000000001
        kl: 0.017191649104158085
        model: {}
        policy_loss: -0.017796074505895376
        total_loss: 111.8468189239502
        vf_explained_var: 0.8318183422088623
        vf_loss: 111.86346244812012
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.124390243902436
    gpu_util_percent0: 0.3904878048780488
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765853658536586
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16429023900903234
    mean_env_wait_ms: 1.1670934225329412
    mean_inference_ms: 5.693764506433915
    mean_raw_obs_processing_ms: 0.4389341132209361
  time_since_restore: 69.6778724193573
  time_this_iter_s: 33.919010162353516
  time_total_s: 69.6778724193573
  timers:
    learn_throughput: 6196.134
    learn_time_ms: 26111.767
    sample_throughput: 18703.71
    sample_time_ms: 8650.262
    update_time_ms: 33.834
  timestamp: 1602460401
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      2 |          69.6779 | 323584 |  217.717 |              258.596 |              108.444 |            889.585 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3610.2264573991033
    time_step_min: 3376
  date: 2020-10-11_23-53-55
  done: false
  episode_len_mean: 886.7573839662447
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 218.04711673698995
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1178800563017528
        entropy_coeff: 0.0005000000000000001
        kl: 0.01895342906937003
        model: {}
        policy_loss: -0.020608155988156796
        total_loss: 47.97189585367838
        vf_explained_var: 0.9181000590324402
        vf_loss: 47.99116611480713
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.712195121951215
    gpu_util_percent0: 0.3675609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775609756097561
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1616709682303659
    mean_env_wait_ms: 1.166511249009767
    mean_inference_ms: 5.501047917707472
    mean_raw_obs_processing_ms: 0.4315839470969778
  time_since_restore: 103.09797406196594
  time_this_iter_s: 33.42010164260864
  time_total_s: 103.09797406196594
  timers:
    learn_throughput: 6196.165
    learn_time_ms: 26111.634
    sample_throughput: 19801.589
    sample_time_ms: 8170.657
    update_time_ms: 39.016
  timestamp: 1602460435
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      3 |          103.098 | 485376 |  218.047 |              258.596 |              108.444 |            886.757 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3601.8675496688743
    time_step_min: 3318
  date: 2020-10-11_23-54-28
  done: false
  episode_len_mean: 880.0727848101266
  episode_reward_max: 269.50505050505024
  episode_reward_mean: 220.01737309806916
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0780468980471294
        entropy_coeff: 0.0005000000000000001
        kl: 0.020812264488389094
        model: {}
        policy_loss: -0.02196501971532901
        total_loss: 30.698612372080486
        vf_explained_var: 0.9449300765991211
        vf_loss: 30.719035625457764
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.235
    gpu_util_percent0: 0.37
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15975550006447464
    mean_env_wait_ms: 1.1672415947821997
    mean_inference_ms: 5.353861215492101
    mean_raw_obs_processing_ms: 0.4255613418012045
  time_since_restore: 136.20136380195618
  time_this_iter_s: 33.103389739990234
  time_total_s: 136.20136380195618
  timers:
    learn_throughput: 6198.8
    learn_time_ms: 26100.535
    sample_throughput: 20575.724
    sample_time_ms: 7863.247
    update_time_ms: 38.967
  timestamp: 1602460468
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      4 |          136.201 | 647168 |  220.017 |              269.505 |              108.444 |            880.073 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3588.9133858267714
    time_step_min: 3274
  date: 2020-10-11_23-55-01
  done: false
  episode_len_mean: 873.5848101265823
  episode_reward_max: 269.9595959595956
  episode_reward_mean: 221.68801943485474
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0384299953778584
        entropy_coeff: 0.0005000000000000001
        kl: 0.01657536276616156
        model: {}
        policy_loss: -0.021145432954654098
        total_loss: 27.263306617736816
        vf_explained_var: 0.9579987525939941
        vf_loss: 27.282485008239746
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.630000000000003
    gpu_util_percent0: 0.3945
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15831189474773888
    mean_env_wait_ms: 1.169238918058159
    mean_inference_ms: 5.240085616301631
    mean_raw_obs_processing_ms: 0.42068439358753973
  time_since_restore: 169.28254675865173
  time_this_iter_s: 33.08118295669556
  time_total_s: 169.28254675865173
  timers:
    learn_throughput: 6200.547
    learn_time_ms: 26093.181
    sample_throughput: 21076.731
    sample_time_ms: 7676.333
    update_time_ms: 39.202
  timestamp: 1602460501
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      5 |          169.283 | 808960 |  221.688 |               269.96 |              108.444 |            873.585 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3565.3918291550603
    time_step_min: 3210
  date: 2020-10-11_23-55-34
  done: false
  episode_len_mean: 860.4
  episode_reward_max: 279.6565656565653
  episode_reward_mean: 225.89213400978093
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0250003933906555
        entropy_coeff: 0.0005000000000000001
        kl: 0.013526818404595057
        model: {}
        policy_loss: -0.01772505196277052
        total_loss: 26.441813786824543
        vf_explained_var: 0.9644567370414734
        vf_loss: 26.458022594451904
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.252499999999998
    gpu_util_percent0: 0.40225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15635664935862897
    mean_env_wait_ms: 1.1741424847111206
    mean_inference_ms: 5.085328596947019
    mean_raw_obs_processing_ms: 0.41426522337983296
  time_since_restore: 202.25503134727478
  time_this_iter_s: 32.97248458862305
  time_total_s: 202.25503134727478
  timers:
    learn_throughput: 6207.164
    learn_time_ms: 26065.364
    sample_throughput: 21407.646
    sample_time_ms: 7557.673
    update_time_ms: 37.069
  timestamp: 1602460534
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      6 |          202.255 | 970752 |  225.892 |              279.657 |              108.444 |              860.4 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3553.7184466019417
    time_step_min: 3210
  date: 2020-10-11_23-56-07
  done: false
  episode_len_mean: 855.4153481012659
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 227.94410880961502
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9949737389882406
        entropy_coeff: 0.0005000000000000001
        kl: 0.017064105874548357
        model: {}
        policy_loss: -0.019350508839124814
        total_loss: 14.205546617507935
        vf_explained_var: 0.9728456139564514
        vf_loss: 14.222834984461466
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.285000000000004
    gpu_util_percent0: 0.38925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1556358543388346
    mean_env_wait_ms: 1.1761209963502055
    mean_inference_ms: 5.028623306948034
    mean_raw_obs_processing_ms: 0.4118964415322733
  time_since_restore: 235.4874963760376
  time_this_iter_s: 33.23246502876282
  time_total_s: 235.4874963760376
  timers:
    learn_throughput: 6206.982
    learn_time_ms: 26066.131
    sample_throughput: 21601.25
    sample_time_ms: 7489.937
    update_time_ms: 35.734
  timestamp: 1602460567
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      7 |          235.487 | 1132544 |  227.944 |               279.96 |              108.444 |            855.415 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3542.3737446197993
    time_step_min: 3210
  date: 2020-10-11_23-56-40
  done: false
  episode_len_mean: 851.2060478199719
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 229.65006606145838
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9782926291227341
        entropy_coeff: 0.0005000000000000001
        kl: 0.014610825572162867
        model: {}
        policy_loss: -0.020831374839569133
        total_loss: 14.28525439898173
        vf_explained_var: 0.9710069298744202
        vf_loss: 14.304383834203085
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.6
    gpu_util_percent0: 0.40924999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15500856327569595
    mean_env_wait_ms: 1.1778585157643424
    mean_inference_ms: 4.979653597549868
    mean_raw_obs_processing_ms: 0.40977347231374067
  time_since_restore: 268.4302875995636
  time_this_iter_s: 32.942791223526
  time_total_s: 268.4302875995636
  timers:
    learn_throughput: 6209.244
    learn_time_ms: 26056.635
    sample_throughput: 21823.436
    sample_time_ms: 7413.681
    update_time_ms: 33.664
  timestamp: 1602460600
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      8 |           268.43 | 1294336 |   229.65 |               279.96 |              108.444 |            851.206 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3531.60127388535
    time_step_min: 3210
  date: 2020-10-11_23-57-13
  done: false
  episode_len_mean: 846.639549436796
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 231.03556212942934
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 176
  episodes_total: 1598
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9375824729601542
        entropy_coeff: 0.0005000000000000001
        kl: 0.014559448541452488
        model: {}
        policy_loss: -0.01767023448095036
        total_loss: 16.797565460205078
        vf_explained_var: 0.9735689163208008
        vf_loss: 16.813520590464275
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.4325
    gpu_util_percent0: 0.42625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15440927745699023
    mean_env_wait_ms: 1.1797947181398996
    mean_inference_ms: 4.932628522517437
    mean_raw_obs_processing_ms: 0.40763801100655095
  time_since_restore: 301.2573320865631
  time_this_iter_s: 32.82704448699951
  time_total_s: 301.2573320865631
  timers:
    learn_throughput: 6214.966
    learn_time_ms: 26032.643
    sample_throughput: 21989.392
    sample_time_ms: 7357.73
    update_time_ms: 32.544
  timestamp: 1602460633
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |      9 |          301.257 | 1456128 |  231.036 |               279.96 |              108.444 |             846.64 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3517.157020364416
    time_step_min: 3210
  date: 2020-10-11_23-57-47
  done: false
  episode_len_mean: 839.9730728616685
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 233.21581176069023
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 296
  episodes_total: 1894
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9380860378344854
        entropy_coeff: 0.0005000000000000001
        kl: 0.011898866932218274
        model: {}
        policy_loss: -0.017333574631872278
        total_loss: 17.59175729751587
        vf_explained_var: 0.975057065486908
        vf_loss: 17.60777521133423
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.2475
    gpu_util_percent0: 0.3925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15356503109273237
    mean_env_wait_ms: 1.1830350143819963
    mean_inference_ms: 4.868250610809849
    mean_raw_obs_processing_ms: 0.40483303792699565
  time_since_restore: 334.6806583404541
  time_this_iter_s: 33.42332625389099
  time_total_s: 334.6806583404541
  timers:
    learn_throughput: 6209.472
    learn_time_ms: 26055.676
    sample_throughput: 22077.94
    sample_time_ms: 7328.22
    update_time_ms: 33.72
  timestamp: 1602460667
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     10 |          334.681 | 1617920 |  233.216 |               279.96 |              108.444 |            839.973 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3509.8751233958537
    time_step_min: 3210
  date: 2020-10-11_23-58-20
  done: false
  episode_len_mean: 836.5438169425511
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 234.42221140322403
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9222126603126526
        entropy_coeff: 0.0005000000000000001
        kl: 0.012968079497416815
        model: {}
        policy_loss: -0.020986247768936057
        total_loss: 11.698777198791504
        vf_explained_var: 0.9765604138374329
        vf_loss: 11.718279043833414
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.0425
    gpu_util_percent0: 0.3825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531954421584515
    mean_env_wait_ms: 1.1845829691050018
    mean_inference_ms: 4.839528300336072
    mean_raw_obs_processing_ms: 0.4035696026912885
  time_since_restore: 367.70371651649475
  time_this_iter_s: 33.02305817604065
  time_total_s: 367.70371651649475
  timers:
    learn_throughput: 6213.049
    learn_time_ms: 26040.676
    sample_throughput: 22885.734
    sample_time_ms: 7069.557
    update_time_ms: 31.443
  timestamp: 1602460700
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     11 |          367.704 | 1779712 |  234.422 |               279.96 |              108.444 |            836.544 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3502.0650183150183
    time_step_min: 3195
  date: 2020-10-11_23-58-53
  done: false
  episode_len_mean: 833.3580470162749
  episode_reward_max: 281.9292929292934
  episode_reward_mean: 235.5961376879098
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8862308661142985
        entropy_coeff: 0.0005000000000000001
        kl: 0.012640196674813827
        model: {}
        policy_loss: -0.017751493442726012
        total_loss: 10.953618367513021
        vf_explained_var: 0.9770269393920898
        vf_loss: 10.969916979471842
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.452499999999997
    gpu_util_percent0: 0.396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15286083097210518
    mean_env_wait_ms: 1.186023040708463
    mean_inference_ms: 4.813683137039607
    mean_raw_obs_processing_ms: 0.4023821764623706
  time_since_restore: 400.96393036842346
  time_this_iter_s: 33.26021385192871
  time_total_s: 400.96393036842346
  timers:
    learn_throughput: 6210.13
    learn_time_ms: 26052.918
    sample_throughput: 23157.446
    sample_time_ms: 6986.608
    update_time_ms: 33.554
  timestamp: 1602460733
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     12 |          400.964 | 1941504 |  235.596 |              281.929 |              108.444 |            833.358 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3491.7221770917954
    time_step_min: 3188
  date: 2020-10-11_23-59-27
  done: false
  episode_len_mean: 829.4164658634538
  episode_reward_max: 284.95959595959624
  episode_reward_mean: 237.2811853474504
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 278
  episodes_total: 2490
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8560250153144201
        entropy_coeff: 0.0005000000000000001
        kl: 0.013018874218687415
        model: {}
        policy_loss: -0.018844387494027615
        total_loss: 17.598385175069172
        vf_explained_var: 0.9760429263114929
        vf_loss: 17.615704854329426
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.77560975609756
    gpu_util_percent0: 0.3619512195121951
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775609756097561
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15233753448854476
    mean_env_wait_ms: 1.1884150061298973
    mean_inference_ms: 4.774157064778861
    mean_raw_obs_processing_ms: 0.40055861342502397
  time_since_restore: 434.23156571388245
  time_this_iter_s: 33.267635345458984
  time_total_s: 434.23156571388245
  timers:
    learn_throughput: 6207.267
    learn_time_ms: 26064.932
    sample_throughput: 23252.248
    sample_time_ms: 6958.123
    update_time_ms: 33.794
  timestamp: 1602460767
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     13 |          434.232 | 2103296 |  237.281 |               284.96 |              108.444 |            829.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3484.0628291948833
    time_step_min: 3188
  date: 2020-10-12_00-00-00
  done: false
  episode_len_mean: 827.1075949367089
  episode_reward_max: 284.95959595959624
  episode_reward_mean: 238.53735042156484
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 196
  episodes_total: 2686
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8533629179000854
        entropy_coeff: 0.0005000000000000001
        kl: 0.012064915693675479
        model: {}
        policy_loss: -0.01757357595488429
        total_loss: 9.033319552739462
        vf_explained_var: 0.9827486872673035
        vf_loss: 9.04951016108195
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.509999999999998
    gpu_util_percent0: 0.34375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7925000000000004
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520337428122405
    mean_env_wait_ms: 1.1899202725870823
    mean_inference_ms: 4.750134574744061
    mean_raw_obs_processing_ms: 0.39950529020394043
  time_since_restore: 467.4650866985321
  time_this_iter_s: 33.23352098464966
  time_total_s: 467.4650866985321
  timers:
    learn_throughput: 6204.685
    learn_time_ms: 26075.781
    sample_throughput: 23250.622
    sample_time_ms: 6958.609
    update_time_ms: 34.053
  timestamp: 1602460800
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     14 |          467.465 | 2265088 |  238.537 |               284.96 |              108.444 |            827.108 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3477.158380681818
    time_step_min: 3159
  date: 2020-10-12_00-00-33
  done: false
  episode_len_mean: 825.2127285513361
  episode_reward_max: 287.838383838384
  episode_reward_mean: 239.4686101521544
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8365094314018885
        entropy_coeff: 0.0005000000000000001
        kl: 0.012247296903903285
        model: {}
        policy_loss: -0.018671032196531694
        total_loss: 10.58807865778605
        vf_explained_var: 0.9776117205619812
        vf_loss: 10.605330864588419
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.369999999999997
    gpu_util_percent0: 0.41050000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7775000000000007
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15180432352852463
    mean_env_wait_ms: 1.1910266136558252
    mean_inference_ms: 4.7324183355467975
    mean_raw_obs_processing_ms: 0.3987049980813999
  time_since_restore: 500.70297384262085
  time_this_iter_s: 33.237887144088745
  time_total_s: 500.70297384262085
  timers:
    learn_throughput: 6199.473
    learn_time_ms: 26097.703
    sample_throughput: 23273.756
    sample_time_ms: 6951.693
    update_time_ms: 33.977
  timestamp: 1602460833
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     15 |          500.703 | 2426880 |  239.469 |              287.838 |              108.444 |            825.213 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3470.8005962239154
    time_step_min: 3159
  date: 2020-10-12_00-01-07
  done: false
  episode_len_mean: 822.7938956350508
  episode_reward_max: 287.838383838384
  episode_reward_mean: 240.39231169588894
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 203
  episodes_total: 3047
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7875953118006388
        entropy_coeff: 0.0005000000000000001
        kl: 0.012844017163539926
        model: {}
        policy_loss: -0.018508915634204943
        total_loss: 12.148565451304117
        vf_explained_var: 0.9806814193725586
        vf_loss: 12.165541172027588
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.046341463414635
    gpu_util_percent0: 0.3619512195121951
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778048780487805
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151977175273845
    mean_env_wait_ms: 1.1923505976582136
    mean_inference_ms: 4.711361693479119
    mean_raw_obs_processing_ms: 0.39771416048751707
  time_since_restore: 534.2328395843506
  time_this_iter_s: 33.529865741729736
  time_total_s: 534.2328395843506
  timers:
    learn_throughput: 6191.039
    learn_time_ms: 26133.255
    sample_throughput: 23215.14
    sample_time_ms: 6969.245
    update_time_ms: 34.684
  timestamp: 1602460867
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     16 |          534.233 | 2588672 |  240.392 |              287.838 |              108.444 |            822.794 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3462.0833079963513
    time_step_min: 3159
  date: 2020-10-12_00-01-40
  done: false
  episode_len_mean: 820.0747663551402
  episode_reward_max: 287.838383838384
  episode_reward_mean: 241.72424272876486
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 270
  episodes_total: 3317
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7780205855766932
        entropy_coeff: 0.0005000000000000001
        kl: 0.011581299128010869
        model: {}
        policy_loss: -0.019016701029613614
        total_loss: 9.738775412241617
        vf_explained_var: 0.9845864176750183
        vf_loss: 9.756444136301676
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.953658536585365
    gpu_util_percent0: 0.41341463414634144
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7731707317073173
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151211362416949
    mean_env_wait_ms: 1.1940829256796068
    mean_inference_ms: 4.686795656323444
    mean_raw_obs_processing_ms: 0.39664132241013406
  time_since_restore: 567.6532590389252
  time_this_iter_s: 33.420419454574585
  time_total_s: 567.6532590389252
  timers:
    learn_throughput: 6185.413
    learn_time_ms: 26157.024
    sample_throughput: 23258.29
    sample_time_ms: 6956.315
    update_time_ms: 41.651
  timestamp: 1602460900
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | RUNNING  | 172.17.0.4:16025 |     17 |          567.653 | 2750464 |  241.724 |              287.838 |              108.444 |            820.075 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c3e84_00000:
  custom_metrics:
    time_step_max: 4216
    time_step_mean: 3457.655452436195
    time_step_min: 3143
  date: 2020-10-12_00-02-13
  done: true
  episode_len_mean: 818.5632911392405
  episode_reward_max: 289.8080808080809
  episode_reward_mean: 242.40589438690702
  episode_reward_min: 108.44444444444467
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: ec65b75b2e2a40338a0e6d44b9da0a1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7674157321453094
        entropy_coeff: 0.0005000000000000001
        kl: 0.011885686234260598
        model: {}
        policy_loss: -0.019695386639796197
        total_loss: 8.469818592071533
        vf_explained_var: 0.9826800227165222
        vf_loss: 8.488114754358927
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.479999999999997
    gpu_util_percent0: 0.3965
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16025
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15104105360385983
    mean_env_wait_ms: 1.1949953426227273
    mean_inference_ms: 4.67364928437513
    mean_raw_obs_processing_ms: 0.3960441883332488
  time_since_restore: 600.569762468338
  time_this_iter_s: 32.91650342941284
  time_total_s: 600.569762468338
  timers:
    learn_throughput: 6186.053
    learn_time_ms: 26154.318
    sample_throughput: 23263.044
    sample_time_ms: 6954.894
    update_time_ms: 42.657
  timestamp: 1602460933
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c3e84_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | TERMINATED |       |     18 |           600.57 | 2912256 |  242.406 |              289.808 |              108.444 |            818.563 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c3e84_00000 | TERMINATED |       |     18 |           600.57 | 2912256 |  242.406 |              289.808 |              108.444 |            818.563 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


