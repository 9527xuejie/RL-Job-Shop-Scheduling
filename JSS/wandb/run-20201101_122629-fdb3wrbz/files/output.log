2020-11-01 12:26:33,451	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 12.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7b004_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=34519)[0m 2020-11-01 12:26:36,168	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=34570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34518)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34518)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34510)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34510)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34523)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1454.2822384428223
    time_step_min: 1292
  date: 2020-11-01_12-27-04
  done: false
  episode_len_mean: 116.8627760252366
  episode_reward_max: 43.628865979381466
  episode_reward_mean: 35.1516797294221
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1268
  episodes_total: 1268
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1449244519074757
        entropy_coeff: 0.0005000000000000001
        kl: 0.007437704674278696
        model: {}
        policy_loss: -0.00946940048985804
        total_loss: 55.00797367095947
        vf_explained_var: 0.7487528324127197
        vf_loss: 55.01652844746908
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.32592592592592
    gpu_util_percent0: 0.37481481481481477
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4333333333333336
    vram_util_percent0: 0.08172381958869332
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17352791633057102
    mean_env_wait_ms: 0.6811877523118316
    mean_inference_ms: 5.513942130136428
    mean_raw_obs_processing_ms: 0.46789447756981023
  time_since_restore: 22.46462392807007
  time_this_iter_s: 22.46462392807007
  time_total_s: 22.46462392807007
  timers:
    learn_throughput: 11371.952
    learn_time_ms: 14227.284
    sample_throughput: 19879.837
    sample_time_ms: 8138.497
    update_time_ms: 45.686
  timestamp: 1604233624
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      1 |          22.4646 | 161792 |  35.1517 |              43.6289 |              15.1237 |            116.863 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1429.8942416258938
    time_step_min: 1292
  date: 2020-11-01_12-27-24
  done: false
  episode_len_mean: 115.70282317979198
  episode_reward_max: 43.62886597938149
  episode_reward_mean: 36.47211286591811
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1424
  episodes_total: 2692
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1268550356229146
        entropy_coeff: 0.0005000000000000001
        kl: 0.008950442192144692
        model: {}
        policy_loss: -0.011557365185581148
        total_loss: 11.271961530049643
        vf_explained_var: 0.8903374671936035
        vf_loss: 11.282292207082113
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.204166666666666
    gpu_util_percent0: 0.3720833333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5041666666666664
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16745964588212917
    mean_env_wait_ms: 0.6700706773938075
    mean_inference_ms: 5.2198211020760175
    mean_raw_obs_processing_ms: 0.44909095470061955
  time_since_restore: 43.08302044868469
  time_this_iter_s: 20.618396520614624
  time_total_s: 43.08302044868469
  timers:
    learn_throughput: 11459.566
    learn_time_ms: 14118.51
    sample_throughput: 22090.571
    sample_time_ms: 7324.03
    update_time_ms: 43.623
  timestamp: 1604233644
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      2 |           43.083 | 323584 |  36.4721 |              43.6289 |              15.1237 |            115.703 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1407.1911728846624
    time_step_min: 1292
  date: 2020-11-01_12-27-44
  done: false
  episode_len_mean: 114.6612669245648
  episode_reward_max: 43.62886597938149
  episode_reward_mean: 37.6345041775509
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1444
  episodes_total: 4136
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1022506852944691
        entropy_coeff: 0.0005000000000000001
        kl: 0.010415543181200823
        model: {}
        policy_loss: -0.012739738527064523
        total_loss: 7.215804258982341
        vf_explained_var: 0.9305369257926941
        vf_loss: 7.227012077967326
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.087500000000002
    gpu_util_percent0: 0.37166666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5083333333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16367371839915396
    mean_env_wait_ms: 0.6634994267663006
    mean_inference_ms: 5.010201052450705
    mean_raw_obs_processing_ms: 0.43679686634070053
  time_since_restore: 63.11474633216858
  time_this_iter_s: 20.031725883483887
  time_total_s: 63.11474633216858
  timers:
    learn_throughput: 11492.021
    learn_time_ms: 14078.638
    sample_throughput: 23568.631
    sample_time_ms: 6864.718
    update_time_ms: 36.686
  timestamp: 1604233664
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      3 |          63.1147 | 485376 |  37.6345 |              43.6289 |              15.1237 |            114.661 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1387.3099946552645
    time_step_min: 1292
  date: 2020-11-01_12-28-04
  done: false
  episode_len_mean: 113.46689093484419
  episode_reward_max: 43.62886597938149
  episode_reward_mean: 38.66655836570194
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1512
  episodes_total: 5648
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0769410530726116
        entropy_coeff: 0.0005000000000000001
        kl: 0.0091951551536719
        model: {}
        policy_loss: -0.014317200764101775
        total_loss: 4.537634372711182
        vf_explained_var: 0.9580438733100891
        vf_loss: 4.550650993982951
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.513043478260872
    gpu_util_percent0: 0.4282608695652175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5173913043478255
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16103675868646175
    mean_env_wait_ms: 0.6593645086787177
    mean_inference_ms: 4.8577089246646405
    mean_raw_obs_processing_ms: 0.42820753933909217
  time_since_restore: 82.97024512290955
  time_this_iter_s: 19.855498790740967
  time_total_s: 82.97024512290955
  timers:
    learn_throughput: 11507.373
    learn_time_ms: 14059.855
    sample_throughput: 24572.569
    sample_time_ms: 6584.253
    update_time_ms: 36.417
  timestamp: 1604233684
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      4 |          82.9702 | 647168 |  38.6666 |              43.6289 |              15.1237 |            113.467 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1372.565211247704
    time_step_min: 1292
  date: 2020-11-01_12-28-24
  done: false
  episode_len_mean: 112.40185601799774
  episode_reward_max: 43.62886597938149
  episode_reward_mean: 39.44358453260353
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1464
  episodes_total: 7112
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.044628421465556
        entropy_coeff: 0.0005000000000000001
        kl: 0.009637930120031038
        model: {}
        policy_loss: -0.015056621322097877
        total_loss: 3.0646530191103616
        vf_explained_var: 0.9720616936683655
        vf_loss: 3.0783043106396994
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.678260869565225
    gpu_util_percent0: 0.44782608695652176
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.508695652173913
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15917782673985395
    mean_env_wait_ms: 0.6566410931470792
    mean_inference_ms: 4.748845539400791
    mean_raw_obs_processing_ms: 0.4219900698653993
  time_since_restore: 102.53243446350098
  time_this_iter_s: 19.56218934059143
  time_total_s: 102.53243446350098
  timers:
    learn_throughput: 11519.656
    learn_time_ms: 14044.863
    sample_throughput: 25439.401
    sample_time_ms: 6359.898
    update_time_ms: 36.623
  timestamp: 1604233704
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      5 |          102.532 | 808960 |  39.4436 |              43.6289 |              15.1237 |            112.402 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1360.8171568057655
    time_step_min: 1292
  date: 2020-11-01_12-28-44
  done: false
  episode_len_mean: 111.4935170178282
  episode_reward_max: 43.628865979381494
  episode_reward_mean: 40.051285019680485
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1526
  episodes_total: 8638
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.008226936062177
        entropy_coeff: 0.0005000000000000001
        kl: 0.008314594083155194
        model: {}
        policy_loss: -0.011961210014609
        total_loss: 2.176027218500773
        vf_explained_var: 0.9811684489250183
        vf_loss: 2.1868296464284263
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.013043478260872
    gpu_util_percent0: 0.3617391304347826
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.526086956521739
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576901249282025
    mean_env_wait_ms: 0.6545619856913595
    mean_inference_ms: 4.661154625197678
    mean_raw_obs_processing_ms: 0.41690510698628513
  time_since_restore: 122.15152668952942
  time_this_iter_s: 19.619092226028442
  time_total_s: 122.15152668952942
  timers:
    learn_throughput: 11527.252
    learn_time_ms: 14035.609
    sample_throughput: 26007.896
    sample_time_ms: 6220.88
    update_time_ms: 34.802
  timestamp: 1604233724
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      6 |          122.152 | 970752 |  40.0513 |              43.6289 |              15.1237 |            111.494 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1351.9801127931137
    time_step_min: 1292
  date: 2020-11-01_12-29-04
  done: false
  episode_len_mean: 110.74748570301716
  episode_reward_max: 43.628865979381494
  episode_reward_mean: 40.50685320002359
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1504
  episodes_total: 10142
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9799897919098536
        entropy_coeff: 0.0005000000000000001
        kl: 0.007559017394669354
        model: {}
        policy_loss: -0.013409938372205943
        total_loss: 1.644661049048106
        vf_explained_var: 0.9860979914665222
        vf_loss: 1.657049189011256
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.617391304347827
    gpu_util_percent0: 0.4239130434782608
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5217391304347827
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15650830518376826
    mean_env_wait_ms: 0.6530945053208776
    mean_inference_ms: 4.592386951937845
    mean_raw_obs_processing_ms: 0.41293979722789786
  time_since_restore: 141.83420944213867
  time_this_iter_s: 19.682682752609253
  time_total_s: 141.83420944213867
  timers:
    learn_throughput: 11524.629
    learn_time_ms: 14038.804
    sample_throughput: 26444.386
    sample_time_ms: 6118.198
    update_time_ms: 34.8
  timestamp: 1604233744
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      7 |          141.834 | 1132544 |  40.5069 |              43.6289 |              15.1237 |            110.747 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1344.8585277968427
    time_step_min: 1292
  date: 2020-11-01_12-29-24
  done: false
  episode_len_mean: 110.01317252587461
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 40.877048782789124
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1549
  episodes_total: 11691
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9412155350049337
        entropy_coeff: 0.0005000000000000001
        kl: 0.007740705274045467
        model: {}
        policy_loss: -0.012592456245329231
        total_loss: 1.2588910659154255
        vf_explained_var: 0.9897112846374512
        vf_loss: 1.2704059382279713
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.641666666666662
    gpu_util_percent0: 0.36375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15552725421090569
    mean_env_wait_ms: 0.6520038178299323
    mean_inference_ms: 4.534700600650504
    mean_raw_obs_processing_ms: 0.4096249844377919
  time_since_restore: 161.7805416584015
  time_this_iter_s: 19.946332216262817
  time_total_s: 161.7805416584015
  timers:
    learn_throughput: 11521.5
    learn_time_ms: 14042.616
    sample_throughput: 26651.946
    sample_time_ms: 6070.551
    update_time_ms: 35.676
  timestamp: 1604233764
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      8 |          161.781 | 1294336 |   40.877 |              43.6289 |              15.1237 |            110.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1339.0663941252176
    time_step_min: 1292
  date: 2020-11-01_12-29-44
  done: false
  episode_len_mean: 109.368015705225
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 41.17822892762955
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1553
  episodes_total: 13244
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9079152892033259
        entropy_coeff: 0.0005000000000000001
        kl: 0.0072981525445356965
        model: {}
        policy_loss: -0.010131318272518305
        total_loss: 0.949362243215243
        vf_explained_var: 0.9923892021179199
        vf_loss: 0.9584879080454508
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.282608695652176
    gpu_util_percent0: 0.4395652173913045
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5739130434782598
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15471153080234437
    mean_env_wait_ms: 0.6512233236906179
    mean_inference_ms: 4.486726941601045
    mean_raw_obs_processing_ms: 0.40688607613554295
  time_since_restore: 181.48901557922363
  time_this_iter_s: 19.708473920822144
  time_total_s: 181.48901557922363
  timers:
    learn_throughput: 11526.677
    learn_time_ms: 14036.31
    sample_throughput: 26886.791
    sample_time_ms: 6017.527
    update_time_ms: 34.242
  timestamp: 1604233784
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |      9 |          181.489 | 1456128 |  41.1782 |              43.6289 |              15.1237 |            109.368 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1334.3752454465434
    time_step_min: 1292
  date: 2020-11-01_12-30-04
  done: false
  episode_len_mean: 108.81228046473926
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 41.422618434137334
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1560
  episodes_total: 14804
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.869762510061264
        entropy_coeff: 0.0005000000000000001
        kl: 0.0075428458318735165
        model: {}
        policy_loss: -0.009666072980811199
        total_loss: 0.7397742619117101
        vf_explained_var: 0.994184672832489
        vf_loss: 0.7483666588862737
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.833333333333332
    gpu_util_percent0: 0.31916666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15401087755433693
    mean_env_wait_ms: 0.6506167732676298
    mean_inference_ms: 4.4459608456017845
    mean_raw_obs_processing_ms: 0.4045366030538726
  time_since_restore: 201.30298805236816
  time_this_iter_s: 19.81397247314453
  time_total_s: 201.30298805236816
  timers:
    learn_throughput: 11523.296
    learn_time_ms: 14040.428
    sample_throughput: 27081.39
    sample_time_ms: 5974.287
    update_time_ms: 34.416
  timestamp: 1604233804
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     10 |          201.303 | 1617920 |  41.4226 |              43.6289 |              15.1237 |            108.812 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1330.5694061408346
    time_step_min: 1292
  date: 2020-11-01_12-30-25
  done: false
  episode_len_mean: 108.33194716242662
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 41.6210186464785
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1548
  episodes_total: 16352
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8340491751829783
        entropy_coeff: 0.0005000000000000001
        kl: 0.006366107768068711
        model: {}
        policy_loss: -0.009178327105473727
        total_loss: 0.6055479943752289
        vf_explained_var: 0.9953274130821228
        vf_loss: 0.6138701190551122
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.46666666666667
    gpu_util_percent0: 0.37000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15341006651547073
    mean_env_wait_ms: 0.650181832154063
    mean_inference_ms: 4.4112331201416435
    mean_raw_obs_processing_ms: 0.40254424691393875
  time_since_restore: 221.31696248054504
  time_this_iter_s: 20.01397442817688
  time_total_s: 221.31696248054504
  timers:
    learn_throughput: 11519.218
    learn_time_ms: 14045.398
    sample_throughput: 28288.316
    sample_time_ms: 5719.393
    update_time_ms: 33.239
  timestamp: 1604233825
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     11 |          221.317 | 1779712 |   41.621 |              43.6289 |              15.1237 |            108.332 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1327.2690156599554
    time_step_min: 1292
  date: 2020-11-01_12-30-44
  done: false
  episode_len_mean: 107.91024281328495
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 41.79185500832971
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1563
  episodes_total: 17915
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8071108410755793
        entropy_coeff: 0.0005000000000000001
        kl: 0.006752079119905829
        model: {}
        policy_loss: -0.009787990158656612
        total_loss: 0.4518005351225535
        vf_explained_var: 0.9965425133705139
        vf_loss: 0.46064166476329166
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.460869565217386
    gpu_util_percent0: 0.4491304347826087
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5739130434782598
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15287929224510746
    mean_env_wait_ms: 0.649859182584871
    mean_inference_ms: 4.38067919169665
    mean_raw_obs_processing_ms: 0.40078994113897726
  time_since_restore: 240.91183829307556
  time_this_iter_s: 19.594875812530518
  time_total_s: 240.91183829307556
  timers:
    learn_throughput: 11522.834
    learn_time_ms: 14040.99
    sample_throughput: 28801.969
    sample_time_ms: 5617.394
    update_time_ms: 31.109
  timestamp: 1604233844
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     12 |          240.912 | 1941504 |  41.7919 |              43.6289 |              15.1237 |             107.91 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1324.5485464368408
    time_step_min: 1292
  date: 2020-11-01_12-31-05
  done: false
  episode_len_mean: 107.57801746276323
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 41.93343711446106
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1555
  episodes_total: 19470
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7690616647402445
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065094192589943605
        model: {}
        policy_loss: -0.010228886812304458
        total_loss: 0.3978396902481715
        vf_explained_var: 0.9969910979270935
        vf_loss: 0.4071512247125308
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.712500000000002
    gpu_util_percent0: 0.40458333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15241252197920177
    mean_env_wait_ms: 0.6496173991986937
    mean_inference_ms: 4.353964505075953
    mean_raw_obs_processing_ms: 0.3992612917500714
  time_since_restore: 260.9479441642761
  time_this_iter_s: 20.03610587120056
  time_total_s: 260.9479441642761
  timers:
    learn_throughput: 11495.402
    learn_time_ms: 14074.497
    sample_throughput: 29007.895
    sample_time_ms: 5577.516
    update_time_ms: 31.578
  timestamp: 1604233865
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     13 |          260.948 | 2103296 |  41.9334 |              43.6289 |              15.1237 |            107.578 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1322.226
    time_step_min: 1292
  date: 2020-11-01_12-31-25
  done: false
  episode_len_mean: 107.29351081530783
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.054489449346825
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1565
  episodes_total: 21035
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7336616019407908
        entropy_coeff: 0.0005000000000000001
        kl: 0.0064004862603421015
        model: {}
        policy_loss: -0.008804643754653322
        total_loss: 0.3278699740767479
        vf_explained_var: 0.9975385069847107
        vf_loss: 0.33576134343942005
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.491666666666664
    gpu_util_percent0: 0.32416666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15199672808495696
    mean_env_wait_ms: 0.6494243284753675
    mean_inference_ms: 4.330132256006824
    mean_raw_obs_processing_ms: 0.39788879446265113
  time_since_restore: 280.836660861969
  time_this_iter_s: 19.88871669769287
  time_total_s: 280.836660861969
  timers:
    learn_throughput: 11490.563
    learn_time_ms: 14080.424
    sample_throughput: 29086.085
    sample_time_ms: 5562.523
    update_time_ms: 31.329
  timestamp: 1604233885
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     14 |          280.837 | 2265088 |  42.0545 |              43.6289 |              15.1237 |            107.294 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1320.1891843971632
    time_step_min: 1292
  date: 2020-11-01_12-31-45
  done: false
  episode_len_mean: 107.05496791325514
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.16018734187611
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1560
  episodes_total: 22595
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7067601482073466
        entropy_coeff: 0.0005000000000000001
        kl: 0.006438710144720972
        model: {}
        policy_loss: -0.010162829411759352
        total_loss: 0.2576701765259107
        vf_explained_var: 0.9980695843696594
        vf_loss: 0.26689864446719486
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.404347826086955
    gpu_util_percent0: 0.3060869565217391
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5739130434782598
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15162840674833306
    mean_env_wait_ms: 0.6492838913939692
    mean_inference_ms: 4.308869472451551
    mean_raw_obs_processing_ms: 0.3966675681414554
  time_since_restore: 300.50964164733887
  time_this_iter_s: 19.672980785369873
  time_total_s: 300.50964164733887
  timers:
    learn_throughput: 11490.394
    learn_time_ms: 14080.631
    sample_throughput: 29052.047
    sample_time_ms: 5569.04
    update_time_ms: 29.544
  timestamp: 1604233905
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     15 |           300.51 | 2426880 |  42.1602 |              43.6289 |              15.1237 |            107.055 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1318.4346780546457
    time_step_min: 1292
  date: 2020-11-01_12-32-06
  done: false
  episode_len_mean: 106.84805829262234
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.2515568060273
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1559
  episodes_total: 24154
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6743296881516775
        entropy_coeff: 0.0005000000000000001
        kl: 0.006636352161876857
        model: {}
        policy_loss: -0.00975274900944593
        total_loss: 0.23658680294950804
        vf_explained_var: 0.9982344508171082
        vf_loss: 0.2453494481742382
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.991666666666664
    gpu_util_percent0: 0.33416666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15129670825904046
    mean_env_wait_ms: 0.6491675546769002
    mean_inference_ms: 4.289756257599939
    mean_raw_obs_processing_ms: 0.39556396298388297
  time_since_restore: 320.2244436740875
  time_this_iter_s: 19.714802026748657
  time_total_s: 320.2244436740875
  timers:
    learn_throughput: 11483.06
    learn_time_ms: 14089.624
    sample_throughput: 29083.807
    sample_time_ms: 5562.958
    update_time_ms: 30.273
  timestamp: 1604233926
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     16 |          320.224 | 2588672 |  42.2516 |              43.6289 |              15.1237 |            106.848 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1316.8612322791712
    time_step_min: 1292
  date: 2020-11-01_12-32-26
  done: false
  episode_len_mean: 106.6750029170394
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.333070966857214
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1557
  episodes_total: 25711
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6487419108549753
        entropy_coeff: 0.0005000000000000001
        kl: 0.006434203319561978
        model: {}
        policy_loss: -0.010461925092386082
        total_loss: 0.18015940859913826
        vf_explained_var: 0.9986326694488525
        vf_loss: 0.1896588665743669
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.604347826086954
    gpu_util_percent0: 0.4843478260869565
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5739130434782598
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15099532910883745
    mean_env_wait_ms: 0.6490596721671469
    mean_inference_ms: 4.272450859355698
    mean_raw_obs_processing_ms: 0.3945623850682107
  time_since_restore: 339.8860158920288
  time_this_iter_s: 19.661572217941284
  time_total_s: 339.8860158920288
  timers:
    learn_throughput: 11488.521
    learn_time_ms: 14082.927
    sample_throughput: 29093.385
    sample_time_ms: 5561.127
    update_time_ms: 30.118
  timestamp: 1604233946
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     17 |          339.886 | 2750464 |  42.3331 |              43.6289 |              15.1237 |            106.675 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1315.4772084481176
    time_step_min: 1292
  date: 2020-11-01_12-32-46
  done: false
  episode_len_mean: 106.53646368305209
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.40514405004122
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1549
  episodes_total: 27260
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6147788117329279
        entropy_coeff: 0.0005000000000000001
        kl: 0.006190092225248615
        model: {}
        policy_loss: -0.00844319449000371
        total_loss: 0.15160012369354567
        vf_explained_var: 0.9988699555397034
        vf_loss: 0.15911269187927246
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.108333333333334
    gpu_util_percent0: 0.40958333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15072186700405005
    mean_env_wait_ms: 0.6489589654205459
    mean_inference_ms: 4.256776083733925
    mean_raw_obs_processing_ms: 0.3936520268695803
  time_since_restore: 359.4751284122467
  time_this_iter_s: 19.589112520217896
  time_total_s: 359.4751284122467
  timers:
    learn_throughput: 11502.311
    learn_time_ms: 14066.043
    sample_throughput: 29213.386
    sample_time_ms: 5538.283
    update_time_ms: 28.725
  timestamp: 1604233966
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     18 |          359.475 | 2912256 |  42.4051 |              43.6289 |              15.1237 |            106.536 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1314.2216509171762
    time_step_min: 1292
  date: 2020-11-01_12-33-07
  done: false
  episode_len_mean: 106.39508657482911
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.47027859269532
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1559
  episodes_total: 28819
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5793089667956034
        entropy_coeff: 0.0005000000000000001
        kl: 0.005601404506402711
        model: {}
        policy_loss: -0.009277280846921107
        total_loss: 0.12121031371255715
        vf_explained_var: 0.9990783333778381
        vf_loss: 0.1296569655338923
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.066666666666663
    gpu_util_percent0: 0.3979166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1504690836889304
    mean_env_wait_ms: 0.6488696992500765
    mean_inference_ms: 4.242361495701079
    mean_raw_obs_processing_ms: 0.39280933914753613
  time_since_restore: 379.6264307498932
  time_this_iter_s: 20.151302337646484
  time_total_s: 379.6264307498932
  timers:
    learn_throughput: 11477.051
    learn_time_ms: 14097.001
    sample_throughput: 29213.738
    sample_time_ms: 5538.216
    update_time_ms: 30.107
  timestamp: 1604233987
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     19 |          379.626 | 3074048 |  42.4703 |              43.6289 |              15.1237 |            106.395 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1313.0996867271228
    time_step_min: 1292
  date: 2020-11-01_12-33-27
  done: false
  episode_len_mean: 106.30233860342555
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.528634054575335
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1541
  episodes_total: 30360
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5525011867284775
        entropy_coeff: 0.0005000000000000001
        kl: 0.005483048929211994
        model: {}
        policy_loss: -0.009698755030209819
        total_loss: 0.09727698999146621
        vf_explained_var: 0.9992494583129883
        vf_loss: 0.10615538681546847
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.075
    gpu_util_percent0: 0.43416666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15023976063883285
    mean_env_wait_ms: 0.6487841053204015
    mean_inference_ms: 4.22926206402729
    mean_raw_obs_processing_ms: 0.3920470315060969
  time_since_restore: 399.4815435409546
  time_this_iter_s: 19.8551127910614
  time_total_s: 399.4815435409546
  timers:
    learn_throughput: 11477.093
    learn_time_ms: 14096.949
    sample_throughput: 29223.589
    sample_time_ms: 5536.349
    update_time_ms: 30.052
  timestamp: 1604234007
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     20 |          399.482 | 3235840 |  42.5286 |              43.6289 |              15.1237 |            106.302 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1312.0721969578171
    time_step_min: 1292
  date: 2020-11-01_12-33-47
  done: false
  episode_len_mean: 106.19890350877193
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.58196716016847
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1560
  episodes_total: 31920
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.5238876193761826
        entropy_coeff: 0.0005000000000000001
        kl: 0.005134576039078335
        model: {}
        policy_loss: -0.009323944701463915
        total_loss: 0.0834660033384959
        vf_explained_var: 0.9993599057197571
        vf_loss: 0.09202497576673825
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.617391304347823
    gpu_util_percent0: 0.4456521739130434
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5739130434782598
    vram_util_percent0: 0.10109872089209576
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15002456451472287
    mean_env_wait_ms: 0.6487047149986278
    mean_inference_ms: 4.2170315233202755
    mean_raw_obs_processing_ms: 0.3913318433017469
  time_since_restore: 419.1035006046295
  time_this_iter_s: 19.621957063674927
  time_total_s: 419.1035006046295
  timers:
    learn_throughput: 11505.071
    learn_time_ms: 14062.668
    sample_throughput: 29282.333
    sample_time_ms: 5525.243
    update_time_ms: 30.159
  timestamp: 1604234027
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     21 |          419.104 | 3397632 |   42.582 |              43.6289 |              15.1237 |            106.199 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1311.1479420914095
    time_step_min: 1292
  date: 2020-11-01_12-34-08
  done: false
  episode_len_mean: 106.12468999312756
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.630005430799805
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1547
  episodes_total: 33467
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.49701932817697525
        entropy_coeff: 0.0005000000000000001
        kl: 0.005340795614756644
        model: {}
        policy_loss: -0.010354490535974037
        total_loss: 0.07194800892223914
        vf_explained_var: 0.9994434714317322
        vf_loss: 0.0814828487734
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.325
    gpu_util_percent0: 0.37458333333333327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14982882739957487
    mean_env_wait_ms: 0.6486235678612109
    mean_inference_ms: 4.205782708358309
    mean_raw_obs_processing_ms: 0.39066600076646296
  time_since_restore: 438.92495369911194
  time_this_iter_s: 19.821453094482422
  time_total_s: 438.92495369911194
  timers:
    learn_throughput: 11494.245
    learn_time_ms: 14075.914
    sample_throughput: 29271.325
    sample_time_ms: 5527.321
    update_time_ms: 31.246
  timestamp: 1604234048
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     22 |          438.925 | 3559424 |    42.63 |              43.6289 |              15.1237 |            106.125 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1310.3136940853449
    time_step_min: 1292
  date: 2020-11-01_12-34-28
  done: false
  episode_len_mean: 106.08285951027172
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.67351320494282
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1532
  episodes_total: 34999
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.4672253554066022
        entropy_coeff: 0.0005000000000000001
        kl: 0.005037993270282944
        model: {}
        policy_loss: -0.00685786875934961
        total_loss: 0.06014314107596874
        vf_explained_var: 0.9995446801185608
        vf_loss: 0.06622702504197757
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.15416666666667
    gpu_util_percent0: 0.3633333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496488629333257
    mean_env_wait_ms: 0.6485461766268289
    mean_inference_ms: 4.195418444138528
    mean_raw_obs_processing_ms: 0.3900530056382457
  time_since_restore: 458.79926347732544
  time_this_iter_s: 19.8743097782135
  time_total_s: 458.79926347732544
  timers:
    learn_throughput: 11517.323
    learn_time_ms: 14047.709
    sample_throughput: 29258.763
    sample_time_ms: 5529.694
    update_time_ms: 32.041
  timestamp: 1604234068
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     23 |          458.799 | 3721216 |  42.6735 |              43.6289 |              15.1237 |            106.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1309.5558966207143
    time_step_min: 1292
  date: 2020-11-01_12-34-49
  done: false
  episode_len_mean: 106.0737637588303
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.71301353738489
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1523
  episodes_total: 36522
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.4321850041548411
        entropy_coeff: 0.0005000000000000001
        kl: 0.0057120353837187094
        model: {}
        policy_loss: -0.009051567967010973
        total_loss: 0.05148738451922933
        vf_explained_var: 0.9995923042297363
        vf_loss: 0.059612637696166836
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.6125
    gpu_util_percent0: 0.35374999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14948084784143242
    mean_env_wait_ms: 0.6484509328204054
    mean_inference_ms: 4.185812792415693
    mean_raw_obs_processing_ms: 0.38947414275749065
  time_since_restore: 478.84203243255615
  time_this_iter_s: 20.042768955230713
  time_total_s: 478.84203243255615
  timers:
    learn_throughput: 11501.58
    learn_time_ms: 14066.937
    sample_throughput: 29276.676
    sample_time_ms: 5526.31
    update_time_ms: 31.839
  timestamp: 1604234089
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 7b004_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     24 |          478.842 | 3883008 |   42.713 |              43.6289 |              15.1237 |            106.074 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1308.854354630823
    time_step_min: 1292
  date: 2020-11-01_12-35-09
  done: false
  episode_len_mean: 106.09423946178913
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.74960796999439
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1530
  episodes_total: 38052
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.40411561727523804
        entropy_coeff: 0.0005000000000000001
        kl: 0.004467884932334225
        model: {}
        policy_loss: -0.007561299067068224
        total_loss: 0.0415184999195238
        vf_explained_var: 0.9996755123138428
        vf_loss: 0.0483882799744606
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.00833333333333
    gpu_util_percent0: 0.3670833333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14932390485994398
    mean_env_wait_ms: 0.6483514849496743
    mean_inference_ms: 4.176778186793073
    mean_raw_obs_processing_ms: 0.38892542131807273
  time_since_restore: 498.6148178577423
  time_this_iter_s: 19.772785425186157
  time_total_s: 498.6148178577423
  timers:
    learn_throughput: 11493.615
    learn_time_ms: 14076.686
    sample_throughput: 29308.484
    sample_time_ms: 5520.313
    update_time_ms: 31.941
  timestamp: 1604234109
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 7b004_00000
  
2020-11-01 12:35:10,587	WARNING util.py:136 -- The `process_trial` operation took 0.5158097743988037 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     25 |          498.615 | 4044800 |  42.7496 |              43.6289 |              15.1237 |            106.094 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1308.2223065826438
    time_step_min: 1292
  date: 2020-11-01_12-35-30
  done: false
  episode_len_mean: 106.13998179427531
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.78251353698859
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1496
  episodes_total: 39548
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3710899030168851
        entropy_coeff: 0.0005000000000000001
        kl: 0.005478878777163724
        model: {}
        policy_loss: -0.008370831223146524
        total_loss: 0.03866795807455977
        vf_explained_var: 0.9996917843818665
        vf_loss: 0.04667644730458657
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.104166666666668
    gpu_util_percent0: 0.3454166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14918014489593562
    mean_env_wait_ms: 0.6482521101593612
    mean_inference_ms: 4.168509263007074
    mean_raw_obs_processing_ms: 0.38842351941405706
  time_since_restore: 518.4228372573853
  time_this_iter_s: 19.808019399642944
  time_total_s: 518.4228372573853
  timers:
    learn_throughput: 11494.237
    learn_time_ms: 14075.924
    sample_throughput: 29292.382
    sample_time_ms: 5523.347
    update_time_ms: 32.345
  timestamp: 1604234130
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 7b004_00000
  
2020-11-01 12:35:31,149	WARNING util.py:136 -- The `process_trial` operation took 0.5663919448852539 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     26 |          518.423 | 4206592 |  42.7825 |              43.6289 |              15.1237 |             106.14 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1307.6298878595808
    time_step_min: 1292
  date: 2020-11-01_12-35-51
  done: false
  episode_len_mean: 106.21381074168798
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.81325152203418
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1507
  episodes_total: 41055
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.3422661249836286
        entropy_coeff: 0.0005000000000000001
        kl: 0.004864616707588236
        model: {}
        policy_loss: -0.008692707876131559
        total_loss: 0.03158797137439251
        vf_explained_var: 0.9997386336326599
        vf_loss: 0.03996535111218691
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.462500000000002
    gpu_util_percent0: 0.33499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14904403737255034
    mean_env_wait_ms: 0.6481460554960611
    mean_inference_ms: 4.160632746558721
    mean_raw_obs_processing_ms: 0.38794815762152746
  time_since_restore: 538.5130481719971
  time_this_iter_s: 20.090210914611816
  time_total_s: 538.5130481719971
  timers:
    learn_throughput: 11475.693
    learn_time_ms: 14098.67
    sample_throughput: 29224.222
    sample_time_ms: 5536.23
    update_time_ms: 32.82
  timestamp: 1604234151
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: 7b004_00000
  
2020-11-01 12:35:52,001	WARNING util.py:136 -- The `process_trial` operation took 0.5398478507995605 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     27 |          538.513 | 4368384 |  42.8133 |              43.6289 |              15.1237 |            106.214 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1307.0917562892712
    time_step_min: 1292
  date: 2020-11-01_12-36-11
  done: false
  episode_len_mean: 106.31207674943566
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.841272069147415
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1473
  episodes_total: 42528
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.31406934062639874
        entropy_coeff: 0.0005000000000000001
        kl: 0.00531899471146365
        model: {}
        policy_loss: -0.006233617905915405
        total_loss: 0.027707914200921852
        vf_explained_var: 0.9997760653495789
        vf_loss: 0.0338326171040535
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.541666666666668
    gpu_util_percent0: 0.38791666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14891911374014252
    mean_env_wait_ms: 0.6480333835817965
    mean_inference_ms: 4.153395707395419
    mean_raw_obs_processing_ms: 0.38750819763907707
  time_since_restore: 558.2239861488342
  time_this_iter_s: 19.710937976837158
  time_total_s: 558.2239861488342
  timers:
    learn_throughput: 11465.354
    learn_time_ms: 14111.382
    sample_throughput: 29254.98
    sample_time_ms: 5530.409
    update_time_ms: 31.925
  timestamp: 1604234171
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: 7b004_00000
  
2020-11-01 12:36:12,490	WARNING util.py:136 -- The `process_trial` operation took 0.5777196884155273 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     28 |          558.224 | 4530176 |  42.8413 |              43.6289 |              15.1237 |            106.312 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1306.5912378872663
    time_step_min: 1292
  date: 2020-11-01_12-36-32
  done: false
  episode_len_mean: 106.44389390185694
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.86740122159219
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1469
  episodes_total: 43997
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.2867726534605026
        entropy_coeff: 0.0005000000000000001
        kl: 0.005043890094384551
        model: {}
        policy_loss: -0.007655571622308344
        total_loss: 0.01982968676990519
        vf_explained_var: 0.999823808670044
        vf_loss: 0.027376449356476467
    num_steps_sampled: 4691968
    num_steps_trained: 4691968
  iterations_since_restore: 29
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.208333333333332
    gpu_util_percent0: 0.3120833333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.148801680479015
    mean_env_wait_ms: 0.6479110446105578
    mean_inference_ms: 4.146556745190422
    mean_raw_obs_processing_ms: 0.3870915915108458
  time_since_restore: 578.142192363739
  time_this_iter_s: 19.918206214904785
  time_total_s: 578.142192363739
  timers:
    learn_throughput: 11477.643
    learn_time_ms: 14096.274
    sample_throughput: 29295.707
    sample_time_ms: 5522.72
    update_time_ms: 31.506
  timestamp: 1604234192
  timesteps_since_restore: 0
  timesteps_total: 4691968
  training_iteration: 29
  trial_id: 7b004_00000
  
2020-11-01 12:36:33,192	WARNING util.py:136 -- The `process_trial` operation took 0.567206621170044 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     29 |          578.142 | 4691968 |  42.8674 |              43.6289 |              15.1237 |            106.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1306.1297474625158
    time_step_min: 1292
  date: 2020-11-01_12-36-52
  done: false
  episode_len_mean: 106.60159721916663
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.89145908926165
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1457
  episodes_total: 45454
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.25657347589731216
        entropy_coeff: 0.0005000000000000001
        kl: 0.004977851562822859
        model: {}
        policy_loss: -0.0074265640663118875
        total_loss: 0.020246487848150235
        vf_explained_var: 0.999823272228241
        vf_loss: 0.02755244541913271
    num_steps_sampled: 4853760
    num_steps_trained: 4853760
  iterations_since_restore: 30
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.96666666666667
    gpu_util_percent0: 0.34375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1486911615858267
    mean_env_wait_ms: 0.647780786364401
    mean_inference_ms: 4.140117442125262
    mean_raw_obs_processing_ms: 0.3867002477159633
  time_since_restore: 597.9215953350067
  time_this_iter_s: 19.7794029712677
  time_total_s: 597.9215953350067
  timers:
    learn_throughput: 11482.292
    learn_time_ms: 14090.567
    sample_throughput: 29325.187
    sample_time_ms: 5517.169
    update_time_ms: 29.907
  timestamp: 1604234212
  timesteps_since_restore: 0
  timesteps_total: 4853760
  training_iteration: 30
  trial_id: 7b004_00000
  
2020-11-01 12:36:53,780	WARNING util.py:136 -- The `process_trial` operation took 0.5981490612030029 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | RUNNING  | 172.17.0.4:34519 |     30 |          597.922 | 4853760 |  42.8915 |              43.6289 |              15.1237 |            106.602 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7b004_00000:
  custom_metrics:
    time_step_max: 1845
    time_step_mean: 1305.6988838856996
    time_step_min: 1292
  date: 2020-11-01_12-37-13
  done: true
  episode_len_mean: 106.77159124834733
  episode_reward_max: 43.6288659793815
  episode_reward_mean: 42.91394806184951
  episode_reward_min: 15.123711340206203
  episodes_this_iter: 1440
  episodes_total: 46894
  experiment_id: 1ac0a7e0bdbf42669f7b08f6bcd05da9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.0e-05
        entropy: 0.22576802472273508
        entropy_coeff: 0.0005000000000000001
        kl: 0.0045362276723608375
        model: {}
        policy_loss: -0.005217552456694345
        total_loss: 0.01427166493764768
        vf_explained_var: 0.9998777508735657
        vf_loss: 0.01948869600892067
    num_steps_sampled: 5015552
    num_steps_trained: 5015552
  iterations_since_restore: 31
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.72083333333333
    gpu_util_percent0: 0.36166666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.570833333333333
    vram_util_percent0: 0.10109872089209578
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34519
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14858768250616303
    mean_env_wait_ms: 0.6476419244786176
    mean_inference_ms: 4.134089086382151
    mean_raw_obs_processing_ms: 0.3863330350642181
  time_since_restore: 617.738039970398
  time_this_iter_s: 19.816444635391235
  time_total_s: 617.738039970398
  timers:
    learn_throughput: 11472.012
    learn_time_ms: 14103.193
    sample_throughput: 29323.896
    sample_time_ms: 5517.411
    update_time_ms: 29.881
  timestamp: 1604234233
  timesteps_since_restore: 0
  timesteps_total: 5015552
  training_iteration: 31
  trial_id: 7b004_00000
  
2020-11-01 12:37:14,609	WARNING util.py:136 -- The `process_trial` operation took 0.7420144081115723 seconds to complete, which may be a performance bottleneck.
== Status ==
Memory usage on this node: 24.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1101 12:37:14.976943 34403 34403 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed
== Status ==
Memory usage on this node: 24.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/554.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7b004_00000 | TERMINATED |       |     31 |          617.738 | 5015552 |  42.9139 |              43.6289 |              15.1237 |            106.772 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


