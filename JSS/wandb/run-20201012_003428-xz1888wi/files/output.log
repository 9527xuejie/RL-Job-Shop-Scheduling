2020-10-12 00:34:32,561	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b3241_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=21707)[0m 2020-10-12 00:34:35,352	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=21705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21646)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21646)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21681)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21681)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21678)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21678)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21612)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21612)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21683)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21683)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21656)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21656)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21692)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_00-35-09
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.1844606796900432
        entropy_coeff: 0.0005000000000000001
        kl: 0.004736573396561046
        model: {}
        policy_loss: -0.008793988274798418
        total_loss: 507.07532501220703
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.76060606060606
    gpu_util_percent0: 0.2854545454545455
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5545454545454547
    vram_util_percent0: 0.08582297226114873
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17635777689270415
    mean_env_wait_ms: 1.1915689311155606
    mean_inference_ms: 6.2233611351547875
    mean_raw_obs_processing_ms: 0.4814483752107871
  time_since_restore: 28.723170280456543
  time_this_iter_s: 28.723170280456543
  time_total_s: 28.723170280456543
  timers:
    learn_throughput: 8510.134
    learn_time_ms: 19011.687
    sample_throughput: 16788.646
    sample_time_ms: 9636.989
    update_time_ms: 33.816
  timestamp: 1602462909
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      1 |          28.7232 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3633.409722222222
    time_step_min: 3355
  date: 2020-10-12_00-35-36
  done: false
  episode_len_mean: 891.4462025316456
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 215.12597493926586
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1499081552028656
        entropy_coeff: 0.0005000000000000001
        kl: 0.011943186012407144
        model: {}
        policy_loss: -0.01399896697451671
        total_loss: 141.3709233601888
        vf_explained_var: 0.7990478873252869
        vf_loss: 141.38370768229166
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.15
    gpu_util_percent0: 0.421875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17093090023281837
    mean_env_wait_ms: 1.1820411721422805
    mean_inference_ms: 5.900383954597142
    mean_raw_obs_processing_ms: 0.4662031146118563
  time_since_restore: 55.40846347808838
  time_this_iter_s: 26.685293197631836
  time_total_s: 55.40846347808838
  timers:
    learn_throughput: 8558.232
    learn_time_ms: 18904.839
    sample_throughput: 18561.895
    sample_time_ms: 8716.352
    update_time_ms: 36.47
  timestamp: 1602462936
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      2 |          55.4085 | 323584 |  215.126 |              258.596 |              126.929 |            891.446 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3628.8699551569507
    time_step_min: 3313
  date: 2020-10-12_00-36-02
  done: false
  episode_len_mean: 887.8396624472574
  episode_reward_max: 264.0505050505047
  episode_reward_mean: 216.81134126070813
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.138692557811737
        entropy_coeff: 0.0005000000000000001
        kl: 0.013796123831222454
        model: {}
        policy_loss: -0.014297678115932891
        total_loss: 56.56118933359782
        vf_explained_var: 0.9000906348228455
        vf_loss: 56.57398796081543
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.643333333333334
    gpu_util_percent0: 0.31999999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1675041757512338
    mean_env_wait_ms: 1.1780216409992887
    mean_inference_ms: 5.672173010046443
    mean_raw_obs_processing_ms: 0.45558805759849014
  time_since_restore: 81.51373887062073
  time_this_iter_s: 26.10527539253235
  time_total_s: 81.51373887062073
  timers:
    learn_throughput: 8578.82
    learn_time_ms: 18859.47
    sample_throughput: 19659.678
    sample_time_ms: 8229.636
    update_time_ms: 36.066
  timestamp: 1602462962
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      3 |          81.5137 | 485376 |  216.811 |              264.051 |              126.929 |             887.84 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3612.1688741721855
    time_step_min: 3313
  date: 2020-10-12_00-36-28
  done: false
  episode_len_mean: 883.1376582278481
  episode_reward_max: 266.47474747474683
  episode_reward_mean: 218.63335890551056
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1143733362356822
        entropy_coeff: 0.0005000000000000001
        kl: 0.014886149050047
        model: {}
        policy_loss: -0.012436738121323287
        total_loss: 44.42721939086914
        vf_explained_var: 0.9232220649719238
        vf_loss: 44.43798033396403
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.47666666666667
    gpu_util_percent0: 0.38666666666666677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16501357589023596
    mean_env_wait_ms: 1.1757145917608327
    mean_inference_ms: 5.506883464065369
    mean_raw_obs_processing_ms: 0.44734170318403266
  time_since_restore: 107.43345904350281
  time_this_iter_s: 25.91972017288208
  time_total_s: 107.43345904350281
  timers:
    learn_throughput: 8594.172
    learn_time_ms: 18825.782
    sample_throughput: 20344.959
    sample_time_ms: 7952.437
    update_time_ms: 32.793
  timestamp: 1602462988
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      4 |          107.433 | 647168 |  218.633 |              266.475 |              126.929 |            883.138 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3599.799212598425
    time_step_min: 3284
  date: 2020-10-12_00-36-54
  done: false
  episode_len_mean: 878.367088607595
  episode_reward_max: 275.7171717171712
  episode_reward_mean: 220.47704897071964
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0744238495826721
        entropy_coeff: 0.0005000000000000001
        kl: 0.013548169750720263
        model: {}
        policy_loss: -0.013068524984798083
        total_loss: 35.48363653818766
        vf_explained_var: 0.9421424269676208
        vf_loss: 35.49520937601725
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.232258064516127
    gpu_util_percent0: 0.33709677419354844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1631359538150579
    mean_env_wait_ms: 1.1750377101166456
    mean_inference_ms: 5.381197662374207
    mean_raw_obs_processing_ms: 0.4407494451328492
  time_since_restore: 133.5845820903778
  time_this_iter_s: 26.151123046875
  time_total_s: 133.5845820903778
  timers:
    learn_throughput: 8589.618
    learn_time_ms: 18835.762
    sample_throughput: 20753.178
    sample_time_ms: 7796.011
    update_time_ms: 34.634
  timestamp: 1602463014
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      5 |          133.585 | 808960 |  220.477 |              275.717 |              126.929 |            878.367 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3571.7137546468402
    time_step_min: 3181
  date: 2020-10-12_00-37-20
  done: false
  episode_len_mean: 865.3885869565217
  episode_reward_max: 284.0505050505052
  episode_reward_mean: 224.59823781291152
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0565401017665863
        entropy_coeff: 0.0005000000000000001
        kl: 0.012333752975488702
        model: {}
        policy_loss: -0.011721641213322679
        total_loss: 35.30999501546224
        vf_explained_var: 0.9584090113639832
        vf_loss: 35.32039451599121
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.490000000000002
    gpu_util_percent0: 0.38866666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16055540896063045
    mean_env_wait_ms: 1.1766305166612212
    mean_inference_ms: 5.209999345757406
    mean_raw_obs_processing_ms: 0.4317826015546678
  time_since_restore: 159.3669502735138
  time_this_iter_s: 25.782368183135986
  time_total_s: 159.3669502735138
  timers:
    learn_throughput: 8605.528
    learn_time_ms: 18800.937
    sample_throughput: 21074.36
    sample_time_ms: 7677.196
    update_time_ms: 32.676
  timestamp: 1602463040
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      6 |          159.367 | 970752 |  224.598 |              284.051 |              126.929 |            865.389 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3560.3729773462783
    time_step_min: 3181
  date: 2020-10-12_00-37-46
  done: false
  episode_len_mean: 860.2539556962025
  episode_reward_max: 284.0505050505052
  episode_reward_mean: 226.65335315177066
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0342101355393727
        entropy_coeff: 0.0005000000000000001
        kl: 0.013541543235381445
        model: {}
        policy_loss: -0.015202047865993032
        total_loss: 20.40529505411784
        vf_explained_var: 0.9631624221801758
        vf_loss: 20.418982982635498
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.506666666666668
    gpu_util_percent0: 0.26166666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15958491496948707
    mean_env_wait_ms: 1.1775491725993916
    mean_inference_ms: 5.146153771247696
    mean_raw_obs_processing_ms: 0.4283815427340617
  time_since_restore: 185.07372856140137
  time_this_iter_s: 25.706778287887573
  time_total_s: 185.07372856140137
  timers:
    learn_throughput: 8611.942
    learn_time_ms: 18786.935
    sample_throughput: 21370.663
    sample_time_ms: 7570.752
    update_time_ms: 30.684
  timestamp: 1602463066
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      7 |          185.074 | 1132544 |  226.653 |              284.051 |              126.929 |            860.254 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3548.2259684361547
    time_step_min: 3181
  date: 2020-10-12_00-38-11
  done: false
  episode_len_mean: 854.9521800281294
  episode_reward_max: 284.0505050505052
  episode_reward_mean: 228.62994928184781
  episode_reward_min: 126.92929292929256
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0114166637261708
        entropy_coeff: 0.0005000000000000001
        kl: 0.011823524876187244
        model: {}
        policy_loss: -0.012997749256707417
        total_loss: 15.665362119674683
        vf_explained_var: 0.96977299451828
        vf_loss: 15.67709215482076
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.386666666666667
    gpu_util_percent0: 0.31366666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15874850398514187
    mean_env_wait_ms: 1.1785136037321717
    mean_inference_ms: 5.091539298185805
    mean_raw_obs_processing_ms: 0.4253631915291848
  time_since_restore: 210.7569944858551
  time_this_iter_s: 25.683265924453735
  time_total_s: 210.7569944858551
  timers:
    learn_throughput: 8628.098
    learn_time_ms: 18751.758
    sample_throughput: 21534.672
    sample_time_ms: 7513.093
    update_time_ms: 29.432
  timestamp: 1602463091
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      8 |          210.757 | 1294336 |   228.63 |              284.051 |              126.929 |            854.952 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3535.8471419396274
    time_step_min: 3144
  date: 2020-10-12_00-38-37
  done: false
  episode_len_mean: 850.1141955835963
  episode_reward_max: 289.656565656566
  episode_reward_mean: 230.3621387375329
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 163
  episodes_total: 1585
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9612872848908106
        entropy_coeff: 0.0005000000000000001
        kl: 0.0109681764151901
        model: {}
        policy_loss: -0.013034443341894075
        total_loss: 21.673526763916016
        vf_explained_var: 0.963329553604126
        vf_loss: 21.685396989186604
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.836666666666666
    gpu_util_percent0: 0.3463333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15798299962041273
    mean_env_wait_ms: 1.1797114473470687
    mean_inference_ms: 5.042105749053138
    mean_raw_obs_processing_ms: 0.4225436916168429
  time_since_restore: 236.41399264335632
  time_this_iter_s: 25.65699815750122
  time_total_s: 236.41399264335632
  timers:
    learn_throughput: 8632.431
    learn_time_ms: 18742.345
    sample_throughput: 21726.819
    sample_time_ms: 7446.649
    update_time_ms: 28.769
  timestamp: 1602463117
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |      9 |          236.414 | 1456128 |  230.362 |              289.657 |               119.96 |            850.114 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3513.7462526766594
    time_step_min: 3144
  date: 2020-10-12_00-39-03
  done: false
  episode_len_mean: 840.8918776371308
  episode_reward_max: 289.656565656566
  episode_reward_mean: 233.6020329881088
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 311
  episodes_total: 1896
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9394480933745702
        entropy_coeff: 0.0005000000000000001
        kl: 0.0088177805300802
        model: {}
        policy_loss: -0.012658713152632117
        total_loss: 25.97125768661499
        vf_explained_var: 0.9646245837211609
        vf_loss: 25.983063220977783
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.303333333333338
    gpu_util_percent0: 0.30499999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15678653788740787
    mean_env_wait_ms: 1.1824156771676657
    mean_inference_ms: 4.964808155787247
    mean_raw_obs_processing_ms: 0.4181682060723411
  time_since_restore: 262.16829204559326
  time_this_iter_s: 25.75429940223694
  time_total_s: 262.16829204559326
  timers:
    learn_throughput: 8633.08
    learn_time_ms: 18740.936
    sample_throughput: 21874.811
    sample_time_ms: 7396.27
    update_time_ms: 29.206
  timestamp: 1602463143
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     10 |          262.168 | 1617920 |  233.602 |              289.657 |               119.96 |            840.892 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3504.369693978282
    time_step_min: 3144
  date: 2020-10-12_00-39-29
  done: false
  episode_len_mean: 836.410905550146
  episode_reward_max: 289.656565656566
  episode_reward_mean: 235.05091813952558
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9202825079361597
        entropy_coeff: 0.0005000000000000001
        kl: 0.009932459720099965
        model: {}
        policy_loss: -0.013969551034582159
        total_loss: 13.155819574991861
        vf_explained_var: 0.9736799597740173
        vf_loss: 13.16875950495402
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.013333333333332
    gpu_util_percent0: 0.3813333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15628312659470767
    mean_env_wait_ms: 1.1837066333493702
    mean_inference_ms: 4.932328710138464
    mean_raw_obs_processing_ms: 0.41631670575253915
  time_since_restore: 288.08132553100586
  time_this_iter_s: 25.913033485412598
  time_total_s: 288.08132553100586
  timers:
    learn_throughput: 8640.385
    learn_time_ms: 18725.092
    sample_throughput: 22694.316
    sample_time_ms: 7129.186
    update_time_ms: 29.289
  timestamp: 1602463169
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     11 |          288.081 | 1779712 |  235.051 |              289.657 |               119.96 |            836.411 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3495.66804029304
    time_step_min: 3144
  date: 2020-10-12_00-39-55
  done: false
  episode_len_mean: 832.2314647377939
  episode_reward_max: 289.656565656566
  episode_reward_mean: 236.35261749502246
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8970757275819778
        entropy_coeff: 0.0005000000000000001
        kl: 0.009826100819433728
        model: {}
        policy_loss: -0.012527460237227691
        total_loss: 14.410746812820435
        vf_explained_var: 0.9711305499076843
        vf_loss: 14.422248760859171
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.329032258064515
    gpu_util_percent0: 0.34935483870967743
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15582450612140622
    mean_env_wait_ms: 1.1850184955133167
    mean_inference_ms: 4.90271640929671
    mean_raw_obs_processing_ms: 0.414575244620262
  time_since_restore: 314.0320568084717
  time_this_iter_s: 25.95073127746582
  time_total_s: 314.0320568084717
  timers:
    learn_throughput: 8640.21
    learn_time_ms: 18725.471
    sample_throughput: 22927.446
    sample_time_ms: 7056.695
    update_time_ms: 27.636
  timestamp: 1602463195
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     12 |          314.032 | 1941504 |  236.353 |              289.657 |               119.96 |            832.231 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3480.5958299919807
    time_step_min: 3144
  date: 2020-10-12_00-40-21
  done: false
  episode_len_mean: 825.7533703409993
  episode_reward_max: 289.656565656566
  episode_reward_mean: 238.7562460449057
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 310
  episodes_total: 2522
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8624657144149145
        entropy_coeff: 0.0005000000000000001
        kl: 0.010747052185858289
        model: {}
        policy_loss: -0.010738464169359455
        total_loss: 17.4642817179362
        vf_explained_var: 0.9763777852058411
        vf_loss: 17.47383960088094
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.463333333333335
    gpu_util_percent0: 0.27599999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15504538541753937
    mean_env_wait_ms: 1.1877438346019034
    mean_inference_ms: 4.8529021413923745
    mean_raw_obs_processing_ms: 0.41166473314732654
  time_since_restore: 340.0067524909973
  time_this_iter_s: 25.974695682525635
  time_total_s: 340.0067524909973
  timers:
    learn_throughput: 8637.678
    learn_time_ms: 18730.96
    sample_throughput: 22986.742
    sample_time_ms: 7038.492
    update_time_ms: 26.316
  timestamp: 1602463221
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     13 |          340.007 | 2103296 |  238.756 |              289.657 |               119.96 |            825.753 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3472.3747178329572
    time_step_min: 3144
  date: 2020-10-12_00-40-47
  done: false
  episode_len_mean: 822.81347728965
  episode_reward_max: 289.656565656566
  episode_reward_mean: 239.92902216506076
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 164
  episodes_total: 2686
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8493493646383286
        entropy_coeff: 0.0005000000000000001
        kl: 0.0095726503059268
        model: {}
        policy_loss: -0.014107674040133134
        total_loss: 9.838747898737589
        vf_explained_var: 0.979136049747467
        vf_loss: 9.851844310760498
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.680000000000003
    gpu_util_percent0: 0.4153333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15469024370232862
    mean_env_wait_ms: 1.1890525567614338
    mean_inference_ms: 4.829940487085058
    mean_raw_obs_processing_ms: 0.4103309506701852
  time_since_restore: 366.0783040523529
  time_this_iter_s: 26.07155156135559
  time_total_s: 366.0783040523529
  timers:
    learn_throughput: 8628.527
    learn_time_ms: 18750.825
    sample_throughput: 23008.696
    sample_time_ms: 7031.776
    update_time_ms: 27.952
  timestamp: 1602463247
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     14 |          366.078 | 2265088 |  239.929 |              289.657 |               119.96 |            822.813 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3466.1537642045455
    time_step_min: 3128
  date: 2020-10-12_00-41-13
  done: false
  episode_len_mean: 820.4451476793249
  episode_reward_max: 292.0808080808081
  episode_reward_mean: 240.9485466479136
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8338879346847534
        entropy_coeff: 0.0005000000000000001
        kl: 0.01033367410612603
        model: {}
        policy_loss: -0.01483139362729465
        total_loss: 10.133917252222696
        vf_explained_var: 0.9774671196937561
        vf_loss: 10.147615512212118
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.076666666666668
    gpu_util_percent0: 0.34933333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15437150720985732
    mean_env_wait_ms: 1.1902354217555309
    mean_inference_ms: 4.8095036893850915
    mean_raw_obs_processing_ms: 0.40911099016087743
  time_since_restore: 391.7252502441406
  time_this_iter_s: 25.64694619178772
  time_total_s: 391.7252502441406
  timers:
    learn_throughput: 8636.589
    learn_time_ms: 18733.321
    sample_throughput: 23112.005
    sample_time_ms: 7000.345
    update_time_ms: 27.233
  timestamp: 1602463273
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     15 |          391.725 | 2426880 |  240.949 |              292.081 |               119.96 |            820.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3455.0154689010633
    time_step_min: 3128
  date: 2020-10-12_00-41-39
  done: false
  episode_len_mean: 816.557329926541
  episode_reward_max: 295.71717171717194
  episode_reward_mean: 242.71682329523267
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 287
  episodes_total: 3131
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7884974231322607
        entropy_coeff: 0.0005000000000000001
        kl: 0.009750418597832322
        model: {}
        policy_loss: -0.011323079930055732
        total_loss: 14.285295089085897
        vf_explained_var: 0.978984534740448
        vf_loss: 14.295549710591635
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.473333333333336
    gpu_util_percent0: 0.34933333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538515577517629
    mean_env_wait_ms: 1.1924357200366262
    mean_inference_ms: 4.776401898610369
    mean_raw_obs_processing_ms: 0.40715974757351686
  time_since_restore: 417.44402265548706
  time_this_iter_s: 25.718772411346436
  time_total_s: 417.44402265548706
  timers:
    learn_throughput: 8630.601
    learn_time_ms: 18746.318
    sample_throughput: 23180.919
    sample_time_ms: 6979.533
    update_time_ms: 27.937
  timestamp: 1602463299
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     16 |          417.444 | 2588672 |  242.717 |              295.717 |               119.96 |            816.557 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3448.23556231003
    time_step_min: 3128
  date: 2020-10-12_00-42-05
  done: false
  episode_len_mean: 814.3541289933695
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 243.74135569072268
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 187
  episodes_total: 3318
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7774684528509775
        entropy_coeff: 0.0005000000000000001
        kl: 0.011015526096646985
        model: {}
        policy_loss: -0.013528073145910943
        total_loss: 8.51339062054952
        vf_explained_var: 0.9826042652130127
        vf_loss: 8.525655190149942
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.603333333333335
    gpu_util_percent0: 0.2846666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15355256501399833
    mean_env_wait_ms: 1.1936851596587932
    mean_inference_ms: 4.756991349294193
    mean_raw_obs_processing_ms: 0.40600568024797123
  time_since_restore: 443.15251064300537
  time_this_iter_s: 25.70848798751831
  time_total_s: 443.15251064300537
  timers:
    learn_throughput: 8625.147
    learn_time_ms: 18758.174
    sample_throughput: 23229.94
    sample_time_ms: 6964.805
    update_time_ms: 30.523
  timestamp: 1602463325
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     17 |          443.153 | 2750464 |  243.741 |              296.778 |               119.96 |            814.354 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3443.2491299303942
    time_step_min: 3128
  date: 2020-10-12_00-42-31
  done: false
  episode_len_mean: 812.615074798619
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 244.57649277585983
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7627457231283188
        entropy_coeff: 0.0005000000000000001
        kl: 0.009601698955520988
        model: {}
        policy_loss: -0.012899532720136145
        total_loss: 9.354751189549765
        vf_explained_var: 0.9782766699790955
        vf_loss: 9.366591850916544
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.613333333333333
    gpu_util_percent0: 0.29600000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.153315532135448
    mean_env_wait_ms: 1.1946987535804758
    mean_inference_ms: 4.741822966986342
    mean_raw_obs_processing_ms: 0.40509418637465494
  time_since_restore: 468.7913398742676
  time_this_iter_s: 25.638829231262207
  time_total_s: 468.7913398742676
  timers:
    learn_throughput: 8615.799
    learn_time_ms: 18778.525
    sample_throughput: 23317.475
    sample_time_ms: 6938.659
    update_time_ms: 30.808
  timestamp: 1602463351
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     18 |          468.791 | 2912256 |  244.576 |              296.778 |               119.96 |            812.615 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3435.287984913793
    time_step_min: 3128
  date: 2020-10-12_00-42-56
  done: false
  episode_len_mean: 809.8588235294118
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 245.76408469723972
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 264
  episodes_total: 3740
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7158689250548681
        entropy_coeff: 0.0005000000000000001
        kl: 0.008825597275669375
        model: {}
        policy_loss: -0.01228552074947705
        total_loss: 11.700799783070883
        vf_explained_var: 0.982060432434082
        vf_loss: 11.712119499842325
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.523333333333333
    gpu_util_percent0: 0.3936666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15295545824116785
    mean_env_wait_ms: 1.1964427565976898
    mean_inference_ms: 4.718885372054643
    mean_raw_obs_processing_ms: 0.40372553776087644
  time_since_restore: 494.42601442337036
  time_this_iter_s: 25.634674549102783
  time_total_s: 494.42601442337036
  timers:
    learn_throughput: 8612.179
    learn_time_ms: 18786.42
    sample_throughput: 23357.375
    sample_time_ms: 6926.806
    update_time_ms: 31.976
  timestamp: 1602463376
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     19 |          494.426 | 3074048 |  245.764 |              296.778 |               119.96 |            809.859 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3429.9956654767975
    time_step_min: 3128
  date: 2020-10-12_00-43-22
  done: false
  episode_len_mean: 808.0273417721519
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 246.56151387290626
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 210
  episodes_total: 3950
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7133776545524597
        entropy_coeff: 0.0005000000000000001
        kl: 0.008661127726857861
        model: {}
        policy_loss: -0.011410674856354793
        total_loss: 9.529250224431356
        vf_explained_var: 0.9818534255027771
        vf_loss: 9.53971815109253
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.026666666666667
    gpu_util_percent0: 0.331
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15269072831811234
    mean_env_wait_ms: 1.1976233330049453
    mean_inference_ms: 4.701998705625743
    mean_raw_obs_processing_ms: 0.40271435186642335
  time_since_restore: 520.2010986804962
  time_this_iter_s: 25.775084257125854
  time_total_s: 520.2010986804962
  timers:
    learn_throughput: 8609.524
    learn_time_ms: 18792.211
    sample_throughput: 23396.05
    sample_time_ms: 6915.355
    update_time_ms: 38.052
  timestamp: 1602463402
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     20 |          520.201 | 3235840 |  246.562 |              296.778 |               119.96 |            808.027 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3426.9416666666666
    time_step_min: 3128
  date: 2020-10-12_00-43-48
  done: false
  episode_len_mean: 806.6051606621227
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 247.07579199984258
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.7092459797859192
        entropy_coeff: 0.0005000000000000001
        kl: 0.009558615429947773
        model: {}
        policy_loss: -0.01332222429725031
        total_loss: 9.141198794047037
        vf_explained_var: 0.9796674847602844
        vf_loss: 9.153441508611044
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.55
    gpu_util_percent0: 0.3556666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15250572109161986
    mean_env_wait_ms: 1.1984995404570395
    mean_inference_ms: 4.690277082000574
    mean_raw_obs_processing_ms: 0.40200715375383594
  time_since_restore: 545.9580459594727
  time_this_iter_s: 25.75694727897644
  time_total_s: 545.9580459594727
  timers:
    learn_throughput: 8613.747
    learn_time_ms: 18782.998
    sample_throughput: 23446.556
    sample_time_ms: 6900.459
    update_time_ms: 38.692
  timestamp: 1602463428
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     21 |          545.958 | 3397632 |  247.076 |              296.778 |               119.96 |            806.605 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3420.3870297715207
    time_step_min: 3128
  date: 2020-10-12_00-44-14
  done: false
  episode_len_mean: 804.3934877321715
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 248.00775700133644
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 253
  episodes_total: 4361
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.6544481615225474
        entropy_coeff: 0.0005000000000000001
        kl: 0.008479299256578088
        model: {}
        policy_loss: -0.010675058952377489
        total_loss: 12.866840124130249
        vf_explained_var: 0.9794535636901855
        vf_loss: 12.876570304234823
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.583333333333332
    gpu_util_percent0: 0.4016666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522306337958885
    mean_env_wait_ms: 1.1999302598561359
    mean_inference_ms: 4.672917815694801
    mean_raw_obs_processing_ms: 0.4009728167897615
  time_since_restore: 571.7668812274933
  time_this_iter_s: 25.80883526802063
  time_total_s: 571.7668812274933
  timers:
    learn_throughput: 8611.122
    learn_time_ms: 18788.725
    sample_throughput: 23541.144
    sample_time_ms: 6872.733
    update_time_ms: 45.363
  timestamp: 1602463454
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     22 |          571.767 | 3559424 |  248.008 |              296.778 |               119.96 |            804.393 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3415.5333772507684
    time_step_min: 3125
  date: 2020-10-12_00-44-40
  done: false
  episode_len_mean: 802.9893059799215
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 248.7543527814152
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 221
  episodes_total: 4582
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.6692428688208262
        entropy_coeff: 0.0005000000000000001
        kl: 0.007938920675466457
        model: {}
        policy_loss: -0.010552310035564005
        total_loss: 9.636853218078613
        vf_explained_var: 0.9819562435150146
        vf_loss: 9.646549145380655
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.766666666666666
    gpu_util_percent0: 0.3559999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15201154859165272
    mean_env_wait_ms: 1.2010574237682454
    mean_inference_ms: 4.6588317447503345
    mean_raw_obs_processing_ms: 0.40011754321514154
  time_since_restore: 597.3807194232941
  time_this_iter_s: 25.61383819580078
  time_total_s: 597.3807194232941
  timers:
    learn_throughput: 8616.903
    learn_time_ms: 18776.118
    sample_throughput: 23625.313
    sample_time_ms: 6848.248
    update_time_ms: 45.242
  timestamp: 1602463480
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | RUNNING  | 172.17.0.4:21707 |     23 |          597.381 | 3721216 |  248.754 |              296.778 |               119.96 |            802.989 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b3241_00000:
  custom_metrics:
    time_step_max: 4218
    time_step_mean: 3411.9061969439726
    time_step_min: 3125
  date: 2020-10-12_00-45-06
  done: true
  episode_len_mean: 802.282911392405
  episode_reward_max: 296.7777777777779
  episode_reward_mean: 249.25700038358266
  episode_reward_min: 119.95959595959627
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: 4421f799f8c24e5999ff09a313432f36
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.6708525369564692
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086898449032257
        model: {}
        policy_loss: -0.011157065736673152
        total_loss: 8.120760242144266
        vf_explained_var: 0.9814209938049316
        vf_loss: 8.1309494972229
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.965517241379313
    gpu_util_percent0: 0.38999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775862068965517
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 21707
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15186447463099992
    mean_env_wait_ms: 1.201805766161612
    mean_inference_ms: 4.649418666624161
    mean_raw_obs_processing_ms: 0.3995488521334772
  time_since_restore: 623.0496788024902
  time_this_iter_s: 25.668959379196167
  time_total_s: 623.0496788024902
  timers:
    learn_throughput: 8620.777
    learn_time_ms: 18767.682
    sample_throughput: 23735.513
    sample_time_ms: 6816.453
    update_time_ms: 43.973
  timestamp: 1602463506
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: b3241_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | TERMINATED |       |     24 |           623.05 | 3883008 |  249.257 |              296.778 |               119.96 |            802.283 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b3241_00000 | TERMINATED |       |     24 |           623.05 | 3883008 |  249.257 |              296.778 |               119.96 |            802.283 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


