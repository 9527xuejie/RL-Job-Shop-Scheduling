2020-10-11 03:04:53,068	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_8965d_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=79485)[0m 2020-10-11 03:04:55,981	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=79501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79469)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79469)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79440)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79440)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79444)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79444)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79448)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79448)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79437)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79437)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79400)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=79436)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=79436)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_03-05-33
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1842363306454249
        entropy_coeff: 0.0
        kl: 0.005170767627922552
        model: {}
        policy_loss: -0.0036312390418191043
        total_loss: 701.1910749162946
        vf_explained_var: 0.005364171229302883
        vf_loss: 701.1936819893973
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.157894736842106
    gpu_util_percent0: 0.33263157894736844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002631578947368421
    ram_util_percent: 6.284210526315791
    vram_util_percent0: 0.19082183977490466
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16650889456437745
    mean_env_wait_ms: 1.1808384815532875
    mean_inference_ms: 5.455595524673956
    mean_raw_obs_processing_ms: 0.44388471028067955
  time_since_restore: 31.627118587493896
  time_this_iter_s: 31.627118587493896
  time_total_s: 31.627118587493896
  timers:
    learn_throughput: 7157.44
    learn_time_ms: 22604.731
    sample_throughput: 18074.421
    sample_time_ms: 8951.435
    update_time_ms: 41.865
  timestamp: 1602385533
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      1 |          31.6271 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3608.4930555555557
    time_step_min: 3338
  date: 2020-10-11_03-06-03
  done: false
  episode_len_mean: 889.7278481012659
  episode_reward_max: 261.17171717171686
  episode_reward_mean: 218.91912798874804
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1576404656682695
        entropy_coeff: 0.0
        kl: 0.00541946424969605
        model: {}
        policy_loss: -0.0027532078134494702
        total_loss: 348.5731724330357
        vf_explained_var: 0.42672181129455566
        vf_loss: 348.5748378208705
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.86756756756757
    gpu_util_percent0: 0.31405405405405407
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4594594594594605
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1630762801351323
    mean_env_wait_ms: 1.1797619568464663
    mean_inference_ms: 5.273255864029901
    mean_raw_obs_processing_ms: 0.43521527706099533
  time_since_restore: 61.79162955284119
  time_this_iter_s: 30.16451096534729
  time_total_s: 61.79162955284119
  timers:
    learn_throughput: 7219.222
    learn_time_ms: 22411.278
    sample_throughput: 19309.603
    sample_time_ms: 8378.836
    update_time_ms: 41.866
  timestamp: 1602385563
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      2 |          61.7916 | 323584 |  218.919 |              261.172 |              145.717 |            889.728 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3614.080717488789
    time_step_min: 3283
  date: 2020-10-11_03-06-33
  done: false
  episode_len_mean: 886.5337552742616
  episode_reward_max: 268.5959595959595
  episode_reward_mean: 218.42142948472042
  episode_reward_min: 137.98989898989885
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1559413501194544
        entropy_coeff: 0.0
        kl: 0.004122215190104076
        model: {}
        policy_loss: -0.0029955087562224697
        total_loss: 174.77842930385046
        vf_explained_var: 0.704023003578186
        vf_loss: 174.78059932163782
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.425714285714285
    gpu_util_percent0: 0.39542857142857135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1607148633878789
    mean_env_wait_ms: 1.1799783300715945
    mean_inference_ms: 5.129048250541213
    mean_raw_obs_processing_ms: 0.42859065650950706
  time_since_restore: 91.5093104839325
  time_this_iter_s: 29.71768093109131
  time_total_s: 91.5093104839325
  timers:
    learn_throughput: 7217.728
    learn_time_ms: 22415.919
    sample_throughput: 20244.476
    sample_time_ms: 7991.909
    update_time_ms: 36.808
  timestamp: 1602385593
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      3 |          91.5093 | 485376 |  218.421 |              268.596 |               137.99 |            886.534 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3620.9403973509934
    time_step_min: 3283
  date: 2020-10-11_03-07-02
  done: false
  episode_len_mean: 884.3465189873418
  episode_reward_max: 268.5959595959595
  episode_reward_mean: 217.0501214678428
  episode_reward_min: 127.83838383838376
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1433956452778407
        entropy_coeff: 0.0
        kl: 0.011157147852437837
        model: {}
        policy_loss: -0.006524423045837986
        total_loss: 118.12804303850446
        vf_explained_var: 0.8102689981460571
        vf_loss: 118.13345500401088
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.922222222222228
    gpu_util_percent0: 0.32916666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15906279307193447
    mean_env_wait_ms: 1.1803416037117012
    mean_inference_ms: 5.025722546119166
    mean_raw_obs_processing_ms: 0.42343061902757856
  time_since_restore: 120.92118549346924
  time_this_iter_s: 29.411875009536743
  time_total_s: 120.92118549346924
  timers:
    learn_throughput: 7227.304
    learn_time_ms: 22386.218
    sample_throughput: 20902.89
    sample_time_ms: 7740.174
    update_time_ms: 32.193
  timestamp: 1602385622
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      4 |          120.921 | 647168 |   217.05 |              268.596 |              127.838 |            884.347 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3620.503937007874
    time_step_min: 3283
  date: 2020-10-11_03-07-32
  done: false
  episode_len_mean: 882.3784810126582
  episode_reward_max: 268.5959595959595
  episode_reward_mean: 217.7689553765501
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.122412042958396
        entropy_coeff: 0.0
        kl: 0.011655572070074933
        model: {}
        policy_loss: -0.0051338946317888
        total_loss: 82.77458899361747
        vf_explained_var: 0.8529062271118164
        vf_loss: 82.77855736868722
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.619999999999997
    gpu_util_percent0: 0.3831428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488571428571428
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15784420053771214
    mean_env_wait_ms: 1.1811709805615105
    mean_inference_ms: 4.948116051881362
    mean_raw_obs_processing_ms: 0.4193234018121655
  time_since_restore: 150.60053706169128
  time_this_iter_s: 29.679351568222046
  time_total_s: 150.60053706169128
  timers:
    learn_throughput: 7219.864
    learn_time_ms: 22409.287
    sample_throughput: 21261.763
    sample_time_ms: 7609.529
    update_time_ms: 33.41
  timestamp: 1602385652
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      5 |          150.601 | 808960 |  217.769 |              268.596 |              100.717 |            882.378 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3612.6114832535886
    time_step_min: 3270
  date: 2020-10-11_03-08-02
  done: false
  episode_len_mean: 875.2786579683132
  episode_reward_max: 270.5656565656563
  episode_reward_mean: 219.21656452690914
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 283
  episodes_total: 1073
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.093424984386989
        entropy_coeff: 0.0
        kl: 0.011833667954696077
        model: {}
        policy_loss: -0.0047162945328247064
        total_loss: 84.12505449567523
        vf_explained_var: 0.9030861258506775
        vf_loss: 84.12858745029995
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.441666666666663
    gpu_util_percent0: 0.35666666666666663
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15635022109412414
    mean_env_wait_ms: 1.1849270665708103
    mean_inference_ms: 4.851661557459233
    mean_raw_obs_processing_ms: 0.41435005926343393
  time_since_restore: 180.30717658996582
  time_this_iter_s: 29.706639528274536
  time_total_s: 180.30717658996582
  timers:
    learn_throughput: 7213.127
    learn_time_ms: 22430.216
    sample_throughput: 21510.655
    sample_time_ms: 7521.482
    update_time_ms: 34.755
  timestamp: 1602385682
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      6 |          180.307 | 970752 |  219.217 |              270.566 |              100.717 |            875.279 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3598.6925566343043
    time_step_min: 3251
  date: 2020-10-11_03-08-32
  done: false
  episode_len_mean: 869.2507911392405
  episode_reward_max: 273.4444444444445
  episode_reward_mean: 221.35775476281785
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 191
  episodes_total: 1264
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1025844471795219
        entropy_coeff: 0.0
        kl: 0.01058941793494991
        model: {}
        policy_loss: -0.006015941284463874
        total_loss: 54.948163168770925
        vf_explained_var: 0.8946520686149597
        vf_loss: 54.9531192779541
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.722857142857144
    gpu_util_percent0: 0.34771428571428564
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285714
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15564551011761274
    mean_env_wait_ms: 1.1871211004853426
    mean_inference_ms: 4.80531468192551
    mean_raw_obs_processing_ms: 0.41195157872736426
  time_since_restore: 209.99847984313965
  time_this_iter_s: 29.691303253173828
  time_total_s: 209.99847984313965
  timers:
    learn_throughput: 7211.105
    learn_time_ms: 22436.505
    sample_throughput: 21675.57
    sample_time_ms: 7464.256
    update_time_ms: 35.702
  timestamp: 1602385712
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      7 |          209.998 | 1132544 |  221.358 |              273.444 |              100.717 |            869.251 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3589.5731707317073
    time_step_min: 3251
  date: 2020-10-11_03-09-01
  done: false
  episode_len_mean: 864.0661040787624
  episode_reward_max: 273.4444444444445
  episode_reward_mean: 222.82485189447195
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0813640441213335
        entropy_coeff: 0.0
        kl: 0.009267381858080626
        model: {}
        policy_loss: -0.006577716495875003
        total_loss: 50.115325110299246
        vf_explained_var: 0.9058211445808411
        vf_loss: 50.12097494942801
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.70277777777778
    gpu_util_percent0: 0.3583333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516002319435832
    mean_env_wait_ms: 1.1890065704944877
    mean_inference_ms: 4.773148159515001
    mean_raw_obs_processing_ms: 0.4102910945924647
  time_since_restore: 239.6490421295166
  time_this_iter_s: 29.650562286376953
  time_total_s: 239.6490421295166
  timers:
    learn_throughput: 7212.109
    learn_time_ms: 22433.384
    sample_throughput: 21785.714
    sample_time_ms: 7426.518
    update_time_ms: 34.704
  timestamp: 1602385741
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      8 |          239.649 | 1294336 |  222.825 |              273.444 |              100.717 |            864.066 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3581.103737113402
    time_step_min: 3188
  date: 2020-10-11_03-09-31
  done: false
  episode_len_mean: 858.623417721519
  episode_reward_max: 282.98989898989885
  episode_reward_mean: 224.14026339342774
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0490512677601405
        entropy_coeff: 0.0
        kl: 0.00982223471094455
        model: {}
        policy_loss: -0.004523107299714216
        total_loss: 48.01645524161203
        vf_explained_var: 0.9067880511283875
        vf_loss: 48.01999609810965
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.91111111111111
    gpu_util_percent0: 0.33277777777777784
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15472678549290808
    mean_env_wait_ms: 1.191055155586821
    mean_inference_ms: 4.74497614898343
    mean_raw_obs_processing_ms: 0.4088028638101343
  time_since_restore: 269.6258068084717
  time_this_iter_s: 29.976764678955078
  time_total_s: 269.6258068084717
  timers:
    learn_throughput: 7206.5
    learn_time_ms: 22450.842
    sample_throughput: 21827.853
    sample_time_ms: 7412.181
    update_time_ms: 34.941
  timestamp: 1602385771
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |      9 |          269.626 | 1456128 |   224.14 |               282.99 |              100.717 |            858.623 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3566.665772532189
    time_step_min: 3188
  date: 2020-10-11_03-10-01
  done: false
  episode_len_mean: 848.0829809725159
  episode_reward_max: 282.98989898989885
  episode_reward_mean: 226.20342964528993
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 312
  episodes_total: 1892
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0074022540024348
        entropy_coeff: 0.0
        kl: 0.009299089200794697
        model: {}
        policy_loss: -0.005653503442382706
        total_loss: 53.85635430472238
        vf_explained_var: 0.9354594945907593
        vf_loss: 53.8610771724156
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.468571428571426
    gpu_util_percent0: 0.36142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404379297510393
    mean_env_wait_ms: 1.195583900586921
    mean_inference_ms: 4.69977048394818
    mean_raw_obs_processing_ms: 0.40640972143419785
  time_since_restore: 299.2758638858795
  time_this_iter_s: 29.650057077407837
  time_total_s: 299.2758638858795
  timers:
    learn_throughput: 7207.072
    learn_time_ms: 22449.061
    sample_throughput: 21907.131
    sample_time_ms: 7385.358
    update_time_ms: 33.276
  timestamp: 1602385801
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     10 |          299.276 | 1617920 |  226.203 |               282.99 |              100.717 |            848.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3556.982724580454
    time_step_min: 3155
  date: 2020-10-11_03-10-31
  done: false
  episode_len_mean: 843.1523855890945
  episode_reward_max: 287.9898989898987
  episode_reward_mean: 227.84310485576287
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 162
  episodes_total: 2054
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0086917621748788
        entropy_coeff: 0.0
        kl: 0.008337604214570351
        model: {}
        policy_loss: -0.00322213487067659
        total_loss: 32.050484384809224
        vf_explained_var: 0.9346650242805481
        vf_loss: 32.05287388392857
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.69722222222222
    gpu_util_percent0: 0.3436111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15376561196217597
    mean_env_wait_ms: 1.1977765349046432
    mean_inference_ms: 4.680667876901594
    mean_raw_obs_processing_ms: 0.40540506001201687
  time_since_restore: 328.9854037761688
  time_this_iter_s: 29.709539890289307
  time_total_s: 328.9854037761688
  timers:
    learn_throughput: 7214.72
    learn_time_ms: 22425.264
    sample_throughput: 22430.932
    sample_time_ms: 7212.897
    update_time_ms: 32.944
  timestamp: 1602385831
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     11 |          328.985 | 1779712 |  227.843 |               287.99 |              100.717 |            843.152 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3547.264194139194
    time_step_min: 3155
  date: 2020-10-11_03-11-01
  done: false
  episode_len_mean: 838.9290235081374
  episode_reward_max: 287.9898989898987
  episode_reward_mean: 229.36360439841434
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9790345174925668
        entropy_coeff: 0.0
        kl: 0.00762276743937816
        model: {}
        policy_loss: -0.005804026665698204
        total_loss: 27.661265645708358
        vf_explained_var: 0.9387838244438171
        vf_loss: 27.66630813053676
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.045714285714286
    gpu_util_percent0: 0.3528571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15351694864072782
    mean_env_wait_ms: 1.1997985506615214
    mean_inference_ms: 4.663717098017251
    mean_raw_obs_processing_ms: 0.40449483032493483
  time_since_restore: 358.596795797348
  time_this_iter_s: 29.6113920211792
  time_total_s: 358.596795797348
  timers:
    learn_throughput: 7210.675
    learn_time_ms: 22437.844
    sample_throughput: 22634.27
    sample_time_ms: 7148.099
    update_time_ms: 32.668
  timestamp: 1602385861
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     12 |          358.597 | 1941504 |  229.364 |               287.99 |              100.717 |            838.929 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3533.24681724846
    time_step_min: 3155
  date: 2020-10-11_03-11-31
  done: false
  episode_len_mean: 832.8250101502233
  episode_reward_max: 287.9898989898987
  episode_reward_mean: 231.32864577566144
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 251
  episodes_total: 2463
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9274024069309235
        entropy_coeff: 0.0
        kl: 0.0069575371287230936
        model: {}
        policy_loss: -0.0034727306748599013
        total_loss: 35.26510647365025
        vf_explained_var: 0.9494942426681519
        vf_loss: 35.267883845738005
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.17222222222222
    gpu_util_percent0: 0.35888888888888887
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15317089334348064
    mean_env_wait_ms: 1.2030925386236255
    mean_inference_ms: 4.6398876601895065
    mean_raw_obs_processing_ms: 0.40320709285076145
  time_since_restore: 388.41063928604126
  time_this_iter_s: 29.813843488693237
  time_total_s: 388.41063928604126
  timers:
    learn_throughput: 7212.205
    learn_time_ms: 22433.082
    sample_throughput: 22594.016
    sample_time_ms: 7160.834
    update_time_ms: 32.836
  timestamp: 1602385891
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     13 |          388.411 | 2103296 |  231.329 |               287.99 |              100.717 |            832.825 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3523.5876598946575
    time_step_min: 3155
  date: 2020-10-11_03-12-00
  done: false
  episode_len_mean: 828.144825018615
  episode_reward_max: 287.9898989898987
  episode_reward_mean: 232.8312198680775
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 223
  episodes_total: 2686
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9347574625696454
        entropy_coeff: 0.0
        kl: 0.008625899641109365
        model: {}
        policy_loss: -0.003543961394046034
        total_loss: 22.11450563158308
        vf_explained_var: 0.9591014981269836
        vf_loss: 22.11718681880406
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.600000000000005
    gpu_util_percent0: 0.3605555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15289879738822792
    mean_env_wait_ms: 1.2057340671336731
    mean_inference_ms: 4.621688104783873
    mean_raw_obs_processing_ms: 0.4022459324630692
  time_since_restore: 417.94883370399475
  time_this_iter_s: 29.53819441795349
  time_total_s: 417.94883370399475
  timers:
    learn_throughput: 7210.33
    learn_time_ms: 22438.917
    sample_throughput: 22563.314
    sample_time_ms: 7170.578
    update_time_ms: 35.337
  timestamp: 1602385920
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     14 |          417.949 | 2265088 |  232.831 |               287.99 |              100.717 |            828.145 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3515.935369318182
    time_step_min: 3133
  date: 2020-10-11_03-12-30
  done: false
  episode_len_mean: 825.4036568213784
  episode_reward_max: 291.3232323232323
  episode_reward_mean: 233.95349060222458
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.913400833095823
        entropy_coeff: 0.0
        kl: 0.007934670263369168
        model: {}
        policy_loss: -0.0044900195373754415
        total_loss: 19.28667790549142
        vf_explained_var: 0.9572562575340271
        vf_loss: 19.29037434714181
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.594285714285714
    gpu_util_percent0: 0.44171428571428567
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494285714285715
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15272601051791285
    mean_env_wait_ms: 1.2074718078135336
    mean_inference_ms: 4.610054891058897
    mean_raw_obs_processing_ms: 0.4016185314758806
  time_since_restore: 447.696759223938
  time_this_iter_s: 29.747925519943237
  time_total_s: 447.696759223938
  timers:
    learn_throughput: 7214.94
    learn_time_ms: 22424.581
    sample_throughput: 22501.353
    sample_time_ms: 7190.323
    update_time_ms: 35.459
  timestamp: 1602385950
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     15 |          447.697 | 2426880 |  233.953 |              291.323 |              100.717 |            825.404 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3506.902285525008
    time_step_min: 3133
  date: 2020-10-11_03-13-00
  done: false
  episode_len_mean: 822.0541516245487
  episode_reward_max: 291.3232323232323
  episode_reward_mean: 235.2833620086654
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 203
  episodes_total: 3047
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.861420465367181
        entropy_coeff: 0.0
        kl: 0.0074423339350947314
        model: {}
        policy_loss: -0.003549012027048905
        total_loss: 19.62413351876395
        vf_explained_var: 0.9669039845466614
        vf_loss: 19.626938138689315
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.95555555555556
    gpu_util_percent0: 0.3155555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15251913789444374
    mean_env_wait_ms: 1.2097270351722968
    mean_inference_ms: 4.59621764730994
    mean_raw_obs_processing_ms: 0.4008701329894248
  time_since_restore: 477.4012749195099
  time_this_iter_s: 29.7045156955719
  time_total_s: 477.4012749195099
  timers:
    learn_throughput: 7219.41
    learn_time_ms: 22410.694
    sample_throughput: 22461.565
    sample_time_ms: 7203.06
    update_time_ms: 35.048
  timestamp: 1602385980
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     16 |          477.401 | 2588672 |  235.283 |              291.323 |              100.717 |            822.054 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3496.152887537994
    time_step_min: 3133
  date: 2020-10-11_03-13-30
  done: false
  episode_len_mean: 818.210970464135
  episode_reward_max: 291.3232323232323
  episode_reward_mean: 236.9636783750706
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 271
  episodes_total: 3318
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8642081362860543
        entropy_coeff: 0.0
        kl: 0.007410059117579034
        model: {}
        policy_loss: -0.003910722822183743
        total_loss: 16.35386712210519
        vf_explained_var: 0.9708972573280334
        vf_loss: 16.35703706741333
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.130555555555556
    gpu_util_percent0: 0.3291666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15227832601662392
    mean_env_wait_ms: 1.2124103058764975
    mean_inference_ms: 4.580212852284663
    mean_raw_obs_processing_ms: 0.4000003696451067
  time_since_restore: 507.176167011261
  time_this_iter_s: 29.7748920917511
  time_total_s: 507.176167011261
  timers:
    learn_throughput: 7218.142
    learn_time_ms: 22414.632
    sample_throughput: 22451.457
    sample_time_ms: 7206.303
    update_time_ms: 35.185
  timestamp: 1602386010
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     17 |          507.176 | 2750464 |  236.964 |              291.323 |              100.717 |            818.211 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3489.9141531322507
    time_step_min: 3133
  date: 2020-10-11_03-14-00
  done: false
  episode_len_mean: 816.108170310702
  episode_reward_max: 291.3232323232323
  episode_reward_mean: 237.87922667410567
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.8401348207678113
        entropy_coeff: 0.0
        kl: 0.008324021939188242
        model: {}
        policy_loss: -0.0036155749985482544
        total_loss: 13.276440279824394
        vf_explained_var: 0.9704254865646362
        vf_loss: 13.279223305838448
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.3
    gpu_util_percent0: 0.336111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15215061024371157
    mean_env_wait_ms: 1.2138476495895938
    mean_inference_ms: 4.571702343476147
    mean_raw_obs_processing_ms: 0.39953994016084593
  time_since_restore: 536.9390978813171
  time_this_iter_s: 29.762930870056152
  time_total_s: 536.9390978813171
  timers:
    learn_throughput: 7218.265
    learn_time_ms: 22414.249
    sample_throughput: 22420.274
    sample_time_ms: 7216.326
    update_time_ms: 36.028
  timestamp: 1602386040
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     18 |          536.939 | 2912256 |  237.879 |              291.323 |              100.717 |            816.108 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3483.718012081274
    time_step_min: 3133
  date: 2020-10-11_03-14-30
  done: false
  episode_len_mean: 813.6708446866485
  episode_reward_max: 291.3232323232323
  episode_reward_mean: 238.719235956293
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 194
  episodes_total: 3670
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.79311802983284
        entropy_coeff: 0.0
        kl: 0.007133410378758397
        model: {}
        policy_loss: -0.004275062437435346
        total_loss: 17.09698486328125
        vf_explained_var: 0.9713118672370911
        vf_loss: 17.10054656437465
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.708333333333332
    gpu_util_percent0: 0.4316666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15199932330368832
    mean_env_wait_ms: 1.2156181193929247
    mean_inference_ms: 4.561907046012792
    mean_raw_obs_processing_ms: 0.3990000696152467
  time_since_restore: 566.9827466011047
  time_this_iter_s: 30.043648719787598
  time_total_s: 566.9827466011047
  timers:
    learn_throughput: 7212.902
    learn_time_ms: 22430.917
    sample_throughput: 22462.786
    sample_time_ms: 7202.668
    update_time_ms: 36.567
  timestamp: 1602386070
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     19 |          566.983 | 3074048 |  238.719 |              291.323 |              100.717 |            813.671 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3475.493880673126
    time_step_min: 3126
  date: 2020-10-11_03-15-00
  done: false
  episode_len_mean: 810.4503797468354
  episode_reward_max: 292.38383838383777
  episode_reward_mean: 239.92603247666526
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 280
  episodes_total: 3950
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7975629184927259
        entropy_coeff: 0.0
        kl: 0.006736140897763627
        model: {}
        policy_loss: -0.003342746798547783
        total_loss: 14.42973245893206
        vf_explained_var: 0.97663813829422
        vf_loss: 14.43240145274571
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.87222222222222
    gpu_util_percent0: 0.30361111111111105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15181345621296172
    mean_env_wait_ms: 1.2179861920755621
    mean_inference_ms: 4.549359667574538
    mean_raw_obs_processing_ms: 0.39831587407563307
  time_since_restore: 597.142436504364
  time_this_iter_s: 30.159689903259277
  time_total_s: 597.142436504364
  timers:
    learn_throughput: 7206.328
    learn_time_ms: 22451.379
    sample_throughput: 22377.095
    sample_time_ms: 7230.25
    update_time_ms: 38.683
  timestamp: 1602386100
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | RUNNING  | 172.17.0.4:79485 |     20 |          597.142 | 3235840 |  239.926 |              292.384 |              100.717 |             810.45 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8965d_00000:
  custom_metrics:
    time_step_max: 4391
    time_step_mean: 3470.718137254902
    time_step_min: 3126
  date: 2020-10-11_03-15-30
  done: true
  episode_len_mean: 808.9060370009737
  episode_reward_max: 292.38383838383777
  episode_reward_mean: 240.6037197682766
  episode_reward_min: 100.71717171717155
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 2f85550d0e5045d5a517aec278252a2e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7796908744743892
        entropy_coeff: 0.0
        kl: 0.007354228391445109
        model: {}
        policy_loss: -0.003630690476191895
        total_loss: 12.837982245853969
        vf_explained_var: 0.9722042679786682
        vf_loss: 12.840877192361015
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.10857142857143
    gpu_util_percent0: 0.33028571428571424
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 79485
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517138077035637
    mean_env_wait_ms: 1.2192098776512956
    mean_inference_ms: 4.542848920490744
    mean_raw_obs_processing_ms: 0.3979637529365497
  time_since_restore: 626.8676991462708
  time_this_iter_s: 29.72526264190674
  time_total_s: 626.8676991462708
  timers:
    learn_throughput: 7208.748
    learn_time_ms: 22443.841
    sample_throughput: 22344.712
    sample_time_ms: 7240.729
    update_time_ms: 38.722
  timestamp: 1602386130
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 8965d_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | TERMINATED |       |     21 |          626.868 | 3397632 |  240.604 |              292.384 |              100.717 |            808.906 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8965d_00000 | TERMINATED |       |     21 |          626.868 | 3397632 |  240.604 |              292.384 |              100.717 |            808.906 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


