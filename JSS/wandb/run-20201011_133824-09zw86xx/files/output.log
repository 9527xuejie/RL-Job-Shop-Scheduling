2020-10-11 13:38:28,887	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_0c910_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=57147)[0m 2020-10-11 13:38:31,721	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=57110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57140)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57140)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=57129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=57129)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3584.5733333333333
    time_step_min: 3342
  date: 2020-10-11_13-39-19
  done: false
  episode_len_mean: 890.4599156118144
  episode_reward_max: 265.262626262626
  episode_reward_mean: 220.14243702851277
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 237
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.183405621846517
        entropy_coeff: 0.00010000000000000002
        kl: 0.005417312557498614
        model: {}
        policy_loss: -0.01164420226899286
        total_loss: 500.0900614420573
        vf_explained_var: 0.5788030028343201
        vf_loss: 500.1007486979167
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.291999999999998
    gpu_util_percent0: 0.3655999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.706000000000001
    vram_util_percent0: 0.095729747458183
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18649280568117266
    mean_env_wait_ms: 1.6224726764976924
    mean_inference_ms: 5.210576986375875
    mean_raw_obs_processing_ms: 0.5402099942675194
  time_since_restore: 42.41452646255493
  time_this_iter_s: 42.41452646255493
  time_total_s: 42.41452646255493
  timers:
    learn_throughput: 7339.398
    learn_time_ms: 33066.473
    sample_throughput: 26197.848
    sample_time_ms: 9263.662
    update_time_ms: 48.116
  timestamp: 1602423559
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 1
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 28.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      1 |          42.4145 | 242688 |  220.142 |              265.263 |              128.444 |             890.46 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3596.0801033591733
    time_step_min: 3342
  date: 2020-10-11_13-40-01
  done: false
  episode_len_mean: 889.9767932489451
  episode_reward_max: 265.262626262626
  episode_reward_mean: 219.4833141542
  episode_reward_min: 128.4444444444439
  episodes_this_iter: 237
  episodes_total: 474
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.1537396430969238
        entropy_coeff: 0.00010000000000000002
        kl: 0.0063223874506851034
        model: {}
        policy_loss: -0.01292644344891111
        total_loss: 118.77798614501953
        vf_explained_var: 0.8242553472518921
        vf_loss: 118.78976287841797
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.157142857142855
    gpu_util_percent0: 0.39591836734693875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.975510204081633
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18392495269714415
    mean_env_wait_ms: 1.6249289157083062
    mean_inference_ms: 5.1087783801612385
    mean_raw_obs_processing_ms: 0.5377210914107752
  time_since_restore: 84.24965119361877
  time_this_iter_s: 41.83512473106384
  time_total_s: 84.24965119361877
  timers:
    learn_throughput: 7308.507
    learn_time_ms: 33206.237
    sample_throughput: 27466.347
    sample_time_ms: 8835.831
    update_time_ms: 33.871
  timestamp: 1602423601
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 2
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      2 |          84.2497 | 485376 |  219.483 |              265.263 |              128.444 |            889.977 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3604.996794871795
    time_step_min: 3342
  date: 2020-10-11_13-40-42
  done: false
  episode_len_mean: 890.9620253164557
  episode_reward_max: 272.5353535353529
  episode_reward_mean: 219.47287218173275
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 237
  episodes_total: 711
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.1413612922032674
        entropy_coeff: 0.00010000000000000002
        kl: 0.007382060183833043
        model: {}
        policy_loss: -0.013708739137897889
        total_loss: 46.49901860555013
        vf_explained_var: 0.920490562915802
        vf_loss: 46.5113644917806
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.477083333333333
    gpu_util_percent0: 0.43624999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.0
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1821279907045208
    mean_env_wait_ms: 1.6259683279915018
    mean_inference_ms: 5.002364641593234
    mean_raw_obs_processing_ms: 0.5332183491679666
  time_since_restore: 125.52451086044312
  time_this_iter_s: 41.27485966682434
  time_total_s: 125.52451086044312
  timers:
    learn_throughput: 7299.04
    learn_time_ms: 33249.302
    sample_throughput: 28542.542
    sample_time_ms: 8502.677
    update_time_ms: 35.706
  timestamp: 1602423642
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 3
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      3 |          125.525 | 728064 |  219.473 |              272.535 |              125.566 |            890.962 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3603.090592334495
    time_step_min: 3279
  date: 2020-10-11_13-41-23
  done: false
  episode_len_mean: 889.2753164556962
  episode_reward_max: 272.5353535353529
  episode_reward_mean: 220.44786472318097
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 237
  episodes_total: 948
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.1303584734598795
        entropy_coeff: 0.00010000000000000002
        kl: 0.007656073321898779
        model: {}
        policy_loss: -0.014872616700207194
        total_loss: 28.509580612182617
        vf_explained_var: 0.9502187967300415
        vf_loss: 28.523034540812173
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.166666666666668
    gpu_util_percent0: 0.4593749999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9875000000000003
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18080746237806275
    mean_env_wait_ms: 1.6274385393279494
    mean_inference_ms: 4.918048305389624
    mean_raw_obs_processing_ms: 0.5288776263149525
  time_since_restore: 166.3393199443817
  time_this_iter_s: 40.8148090839386
  time_total_s: 166.3393199443817
  timers:
    learn_throughput: 7320.037
    learn_time_ms: 33153.931
    sample_throughput: 29103.042
    sample_time_ms: 8338.922
    update_time_ms: 35.795
  timestamp: 1602423683
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 4
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      4 |          166.339 | 970752 |  220.448 |              272.535 |              125.566 |            889.275 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3591.087431693989
    time_step_min: 3272
  date: 2020-10-11_13-42-04
  done: false
  episode_len_mean: 886.1063291139241
  episode_reward_max: 287.0808080808079
  episode_reward_mean: 222.14000767165302
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 237
  episodes_total: 1185
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.1050755818684896
        entropy_coeff: 0.00010000000000000002
        kl: 0.007907051127403975
        model: {}
        policy_loss: -0.01476247279594342
        total_loss: 25.631104787190754
        vf_explained_var: 0.95306795835495
        vf_loss: 25.644395701090495
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.208333333333332
    gpu_util_percent0: 0.39937500000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.983333333333333
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17980136330957153
    mean_env_wait_ms: 1.629206943339713
    mean_inference_ms: 4.851724455781136
    mean_raw_obs_processing_ms: 0.5252574580740458
  time_since_restore: 207.09785199165344
  time_this_iter_s: 40.75853204727173
  time_total_s: 207.09785199165344
  timers:
    learn_throughput: 7328.948
    learn_time_ms: 33113.622
    sample_throughput: 29555.486
    sample_time_ms: 8211.267
    update_time_ms: 36.929
  timestamp: 1602423724
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 5
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      5 |          207.098 | 1213440 |   222.14 |              287.081 |              125.566 |            886.106 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3576.539270687237
    time_step_min: 3199
  date: 2020-10-11_13-42-45
  done: false
  episode_len_mean: 881.1308658294779
  episode_reward_max: 287.0808080808079
  episode_reward_mean: 224.3184855828608
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 328
  episodes_total: 1513
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.0722557465235392
        entropy_coeff: 0.00010000000000000002
        kl: 0.0074570424854755405
        model: {}
        policy_loss: -0.013565628323704004
        total_loss: 27.71065483093262
        vf_explained_var: 0.9649067521095276
        vf_loss: 27.72283681233724
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.327083333333334
    gpu_util_percent0: 0.3843750000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9895833333333335
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17875955348171446
    mean_env_wait_ms: 1.6330988662679835
    mean_inference_ms: 4.783658076725951
    mean_raw_obs_processing_ms: 0.5213413330511294
  time_since_restore: 248.06917572021484
  time_this_iter_s: 40.9713237285614
  time_total_s: 248.06917572021484
  timers:
    learn_throughput: 7335.997
    learn_time_ms: 33081.803
    sample_throughput: 29736.454
    sample_time_ms: 8161.296
    update_time_ms: 37.991
  timestamp: 1602423765
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 6
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      6 |          248.069 | 1456128 |  224.318 |              287.081 |              125.566 |            881.131 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3560.7394911504425
    time_step_min: 3199
  date: 2020-10-11_13-43-26
  done: false
  episode_len_mean: 876.0395778364116
  episode_reward_max: 287.0808080808079
  episode_reward_mean: 226.7902507928891
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 382
  episodes_total: 1895
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.0884341796239216
        entropy_coeff: 0.00010000000000000002
        kl: 0.007538844800243775
        model: {}
        policy_loss: -0.014307811111211776
        total_loss: 18.356261444091796
        vf_explained_var: 0.9704130291938782
        vf_loss: 18.369169998168946
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.3625
    gpu_util_percent0: 0.40854166666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9874999999999994
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17788524788087012
    mean_env_wait_ms: 1.6363888350386924
    mean_inference_ms: 4.724955147094913
    mean_raw_obs_processing_ms: 0.5180021574950707
  time_since_restore: 289.33537769317627
  time_this_iter_s: 41.266201972961426
  time_total_s: 289.33537769317627
  timers:
    learn_throughput: 7331.136
    learn_time_ms: 33103.739
    sample_throughput: 29866.416
    sample_time_ms: 8125.782
    update_time_ms: 39.055
  timestamp: 1602423806
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 7
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      7 |          289.335 | 1698816 |   226.79 |              287.081 |              125.566 |             876.04 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3548.715542521994
    time_step_min: 3199
  date: 2020-10-11_13-44-07
  done: false
  episode_len_mean: 872.3459915611814
  episode_reward_max: 287.0808080808079
  episode_reward_mean: 228.69469661452766
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 238
  episodes_total: 2133
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.0660496314366659
        entropy_coeff: 0.00010000000000000002
        kl: 0.007379205866406361
        model: {}
        policy_loss: -0.015470299781494152
        total_loss: 13.194388008117675
        vf_explained_var: 0.9752231240272522
        vf_loss: 13.208488909403483
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.28125
    gpu_util_percent0: 0.4008333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.997916666666667
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17745909062111218
    mean_env_wait_ms: 1.638383793106903
    mean_inference_ms: 4.696075637795095
    mean_raw_obs_processing_ms: 0.5163099758844547
  time_since_restore: 330.2167761325836
  time_this_iter_s: 40.88139843940735
  time_total_s: 330.2167761325836
  timers:
    learn_throughput: 7337.129
    learn_time_ms: 33076.698
    sample_throughput: 29976.617
    sample_time_ms: 8095.91
    update_time_ms: 39.158
  timestamp: 1602423847
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 8
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      8 |          330.217 | 1941504 |  228.695 |              287.081 |              125.566 |            872.346 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3536.658344283837
    time_step_min: 3199
  date: 2020-10-11_13-44-48
  done: false
  episode_len_mean: 868.3392405063291
  episode_reward_max: 287.0808080808079
  episode_reward_mean: 230.37149980820848
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 237
  episodes_total: 2370
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 1.0399322668711344
        entropy_coeff: 0.00010000000000000002
        kl: 0.007398941119511922
        model: {}
        policy_loss: -0.014947781114218135
        total_loss: 14.543746058146159
        vf_explained_var: 0.9716641902923584
        vf_loss: 14.55731824239095
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.535416666666666
    gpu_util_percent0: 0.4145833333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.997916666666667
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17709417501453031
    mean_env_wait_ms: 1.6403352782943503
    mean_inference_ms: 4.67101488491544
    mean_raw_obs_processing_ms: 0.5147980710277961
  time_since_restore: 371.059494972229
  time_this_iter_s: 40.842718839645386
  time_total_s: 371.059494972229
  timers:
    learn_throughput: 7339.679
    learn_time_ms: 33065.208
    sample_throughput: 30110.616
    sample_time_ms: 8059.882
    update_time_ms: 38.172
  timestamp: 1602423888
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 9
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |      9 |          371.059 | 2184192 |  230.371 |              287.081 |              125.566 |            868.339 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3523.1224812327146
    time_step_min: 3199
  date: 2020-10-11_13-45-29
  done: false
  episode_len_mean: 864.312834224599
  episode_reward_max: 289.0505050505051
  episode_reward_mean: 232.51486600149687
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 248
  episodes_total: 2618
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.996833590666453
        entropy_coeff: 0.00010000000000000002
        kl: 0.006997622735798359
        model: {}
        policy_loss: -0.01445136262724797
        total_loss: 12.878556378682454
        vf_explained_var: 0.9770095348358154
        vf_loss: 12.89170799255371
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.133333333333333
    gpu_util_percent0: 0.4110416666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9874999999999994
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17676291029096722
    mean_env_wait_ms: 1.6425128910185887
    mean_inference_ms: 4.648257931075832
    mean_raw_obs_processing_ms: 0.5133801771135539
  time_since_restore: 411.94100284576416
  time_this_iter_s: 40.881507873535156
  time_total_s: 411.94100284576416
  timers:
    learn_throughput: 7345.933
    learn_time_ms: 33037.056
    sample_throughput: 30138.198
    sample_time_ms: 8052.505
    update_time_ms: 38.431
  timestamp: 1602423929
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 10
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |     10 |          411.941 | 2426880 |  232.515 |              289.051 |              125.566 |            864.313 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3503.765060240964
    time_step_min: 3187
  date: 2020-10-11_13-46-10
  done: false
  episode_len_mean: 857.9564227642277
  episode_reward_max: 289.353535353535
  episode_reward_mean: 235.23114067504295
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 457
  episodes_total: 3075
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.9877258141835531
        entropy_coeff: 0.00010000000000000002
        kl: 0.006413008334736029
        model: {}
        policy_loss: -0.012761204627652963
        total_loss: 16.585020701090496
        vf_explained_var: 0.9772671461105347
        vf_loss: 16.596597798665364
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.641666666666666
    gpu_util_percent0: 0.39375000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9874999999999994
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17625019669478184
    mean_env_wait_ms: 1.646253128980377
    mean_inference_ms: 4.613876675358799
    mean_raw_obs_processing_ms: 0.5112369307394627
  time_since_restore: 452.9522387981415
  time_this_iter_s: 41.01123595237732
  time_total_s: 452.9522387981415
  timers:
    learn_throughput: 7351.268
    learn_time_ms: 33013.082
    sample_throughput: 30594.255
    sample_time_ms: 7932.47
    update_time_ms: 38.269
  timestamp: 1602423970
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 11
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |     11 |          452.952 | 2669568 |  235.231 |              289.354 |              125.566 |            857.956 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3494.6830702568864
    time_step_min: 3155
  date: 2020-10-11_13-46-52
  done: false
  episode_len_mean: 854.4535864978903
  episode_reward_max: 289.9595959595964
  episode_reward_mean: 236.71028549509546
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 243
  episodes_total: 3318
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.9707570513089497
        entropy_coeff: 0.00010000000000000002
        kl: 0.006264591217041015
        model: {}
        policy_loss: -0.013565192092210054
        total_loss: 10.680348141988118
        vf_explained_var: 0.979314386844635
        vf_loss: 10.69275754292806
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.110204081632652
    gpu_util_percent0: 0.4538775510204081
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.0
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17601951918431213
    mean_env_wait_ms: 1.648108294857795
    mean_inference_ms: 4.598556606097392
    mean_raw_obs_processing_ms: 0.5102800265147465
  time_since_restore: 494.40811800956726
  time_this_iter_s: 41.45587921142578
  time_total_s: 494.40811800956726
  timers:
    learn_throughput: 7352.655
    learn_time_ms: 33006.854
    sample_throughput: 30733.953
    sample_time_ms: 7896.413
    update_time_ms: 41.519
  timestamp: 1602424012
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 12
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |     12 |          494.408 | 2912256 |   236.71 |               289.96 |              125.566 |            854.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3485.837946943483
    time_step_min: 3107
  date: 2020-10-11_13-47-33
  done: false
  episode_len_mean: 851.5558368495077
  episode_reward_max: 295.26262626262604
  episode_reward_mean: 237.96735285342862
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 237
  episodes_total: 3555
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.9530063947041829
        entropy_coeff: 0.00010000000000000002
        kl: 0.006591062434017659
        model: {}
        policy_loss: -0.014561809320002794
        total_loss: 11.435013961791991
        vf_explained_var: 0.9762901663780212
        vf_loss: 11.448352940877278
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.547916666666666
    gpu_util_percent0: 0.3935416666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.9895833333333335
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17581751280112987
    mean_env_wait_ms: 1.64984524866088
    mean_inference_ms: 4.584995171405163
    mean_raw_obs_processing_ms: 0.5094102476666298
  time_since_restore: 535.188779592514
  time_this_iter_s: 40.78066158294678
  time_total_s: 535.188779592514
  timers:
    learn_throughput: 7363.787
    learn_time_ms: 32956.954
    sample_throughput: 30761.523
    sample_time_ms: 7889.336
    update_time_ms: 39.844
  timestamp: 1602424053
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 13
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |     13 |          535.189 | 3154944 |  237.967 |              295.263 |              125.566 |            851.556 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3476.0406698564593
    time_step_min: 3107
  date: 2020-10-11_13-48-14
  done: false
  episode_len_mean: 848.1434138737335
  episode_reward_max: 295.26262626262604
  episode_reward_mean: 239.46914979884565
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 294
  episodes_total: 3849
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.9091014703114827
        entropy_coeff: 0.00010000000000000002
        kl: 0.007035565158973137
        model: {}
        policy_loss: -0.013190323300659657
        total_loss: 12.63042418162028
        vf_explained_var: 0.9792793393135071
        vf_loss: 12.642298189798991
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.389583333333334
    gpu_util_percent0: 0.4254166666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.99375
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1755940792526866
    mean_env_wait_ms: 1.652106620145796
    mean_inference_ms: 4.569805085977466
    mean_raw_obs_processing_ms: 0.5084309291989355
  time_since_restore: 576.2250940799713
  time_this_iter_s: 41.036314487457275
  time_total_s: 576.2250940799713
  timers:
    learn_throughput: 7360.108
    learn_time_ms: 32973.43
    sample_throughput: 30742.432
    sample_time_ms: 7894.236
    update_time_ms: 40.066
  timestamp: 1602424094
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 14
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | RUNNING  | 172.17.0.4:57147 |     14 |          576.225 | 3397632 |  239.469 |              295.263 |              125.566 |            848.143 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0c910_00000:
  custom_metrics:
    time_step_max: 4184
    time_step_mean: 3463.034705600766
    time_step_min: 3101
  date: 2020-10-11_13-48-55
  done: true
  episode_len_mean: 843.8332942555686
  episode_reward_max: 296.1717171717173
  episode_reward_mean: 241.25612514358104
  episode_reward_min: 125.56565656565631
  episodes_this_iter: 416
  episodes_total: 4265
  experiment_id: 3148de99f3e443238d833a44f7f7054c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000007
        cur_lr: 5.000000000000001e-05
        entropy: 0.9020651976267496
        entropy_coeff: 0.00010000000000000002
        kl: 0.005934530682861805
        model: {}
        policy_loss: -0.013015355682000518
        total_loss: 14.882675615946452
        vf_explained_var: 0.9776507019996643
        vf_loss: 14.894594383239745
    num_steps_sampled: 3640320
    num_steps_trained: 3640320
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.318749999999998
    gpu_util_percent0: 0.371875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.985416666666667
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 57147
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1753096715519796
    mean_env_wait_ms: 1.6549565575774388
    mean_inference_ms: 4.5509680688277365
    mean_raw_obs_processing_ms: 0.5072442332300805
  time_since_restore: 617.3845472335815
  time_this_iter_s: 41.15945315361023
  time_total_s: 617.3845472335815
  timers:
    learn_throughput: 7352.062
    learn_time_ms: 33009.515
    sample_throughput: 30728.129
    sample_time_ms: 7897.91
    update_time_ms: 38.497
  timestamp: 1602424135
  timesteps_since_restore: 0
  timesteps_total: 3640320
  training_iteration: 15
  trial_id: 0c910_00000
  
== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | TERMINATED |       |     15 |          617.385 | 3640320 |  241.256 |              296.172 |              125.566 |            843.833 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 29.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0c910_00000 | TERMINATED |       |     15 |          617.385 | 3640320 |  241.256 |              296.172 |              125.566 |            843.833 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


