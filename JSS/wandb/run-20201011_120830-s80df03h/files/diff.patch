diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index a6d8e00..d1a379e 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -29,13 +29,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -48,61 +64,30 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
     "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
-    "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
+    "                'values': [1e-4, 5e-5]\n",
     "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'num_envs_per_worker': {\n",
+    "                'values': [2, 3, 4]\n",
     "            },\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [1024, 1536]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-4-e4d446407002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: e8gk51z8\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\n"
      ]
     }
    ],
@@ -120,1221 +105,1194 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "2020-10-11 11:33:32,913 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 11:33:33,261 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:33:33,261 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "2020-10-11 11:33:33,263 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --sgd_minibatch_size=12112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
+      "2020-10-11 11:33:38,281 - wandb.wandb_agent - INFO - Running runs: ['gyz1jmjx']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gyz1jmjx\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_113335-gyz1jmjx\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:33:38,953\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "\u001b[2m\u001b[36m(pid=478)\u001b[0m 2020-10-11 11:33:41,717\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=380)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=380)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=440)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=440)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=471)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=471)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=387)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=387)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=438)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=438)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=414)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=414)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=434)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=434)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=502)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=502)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=433)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=433)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=443)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=443)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=441)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=441)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=374)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=374)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.267942583732\n",
+      "    time_step_min: 3363\n",
+      "  date: 2020-10-11_11-34-25\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 889.379746835443\n",
+      "  episode_reward_max: 261.32323232323233\n",
+      "  episode_reward_mean: 217.15624600434705\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
+      "        entropy: 1.1508206791347928\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011506594562282165\n",
       "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        policy_loss: -0.024802520728877023\n",
+      "        total_loss: -0.02261628385167569\n",
+      "        vf_explained_var: 0.004114177543669939\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 210783\n",
+      "    num_steps_trained: 210783\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 33.611111111111114\n",
+      "    gpu_util_percent0: 0.22022222222222218\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.57111111111111\n",
+      "    vram_util_percent0: 0.0693761160307569\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "    mean_action_processing_ms: 0.1636744937338249\n",
+      "    mean_env_wait_ms: 1.174430520550134\n",
+      "    mean_inference_ms: 5.3161623781693\n",
+      "    mean_raw_obs_processing_ms: 0.4152495414106662\n",
+      "  time_since_restore: 37.93847155570984\n",
+      "  time_this_iter_s: 37.93847155570984\n",
+      "  time_total_s: 37.93847155570984\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 8808.281\n",
+      "    learn_time_ms: 23930.096\n",
+      "    sample_throughput: 15134.176\n",
+      "    sample_time_ms: 13927.616\n",
+      "    update_time_ms: 46.272\n",
+      "  timestamp: 1602416065\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 210783\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 27.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      1 |          37.9385 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3620.4843049327355\n",
+      "    time_step_min: 3285\n",
+      "  date: 2020-10-11_11-34-56\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 894.6962025316456\n",
+      "  episode_reward_max: 268.29292929292905\n",
+      "  episode_reward_mean: 215.82137834036547\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
+      "        entropy: 1.1413822571436565\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012332628015428782\n",
       "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02454338926408026\n",
+      "        total_loss: -0.0221910018266903\n",
+      "        vf_explained_var: 0.004096451681107283\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 424086\n",
+      "    num_steps_trained: 424086\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 19.864864864864867\n",
+      "    gpu_util_percent0: 0.2378378378378378\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.851351351351352\n",
+      "    vram_util_percent0: 0.08374256512990523\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.16101945000676418\n",
+      "    mean_env_wait_ms: 1.169159001890284\n",
+      "    mean_inference_ms: 5.163287186706875\n",
+      "    mean_raw_obs_processing_ms: 0.41340410230382457\n",
+      "  time_since_restore: 69.00788903236389\n",
+      "  time_this_iter_s: 31.069417476654053\n",
+      "  time_total_s: 69.00788903236389\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 8801.604\n",
+      "    learn_time_ms: 24091.404\n",
+      "    sample_throughput: 20553.76\n",
+      "    sample_time_ms: 10316.507\n",
+      "    update_time_ms: 44.454\n",
+      "  timestamp: 1602416096\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 424086\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      2 |          69.0079 | 424086 |  215.821 |              268.293 |              133.141 |            894.696 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3628.0805270863834\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-35-32\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 897.2475386779184\n",
+      "  episode_reward_max: 268.89898989898984\n",
+      "  episode_reward_mean: 215.26092145079465\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
+      "        entropy: 1.1282787322998047\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011565119959414005\n",
       "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.02850140682939026\n",
+      "        total_loss: -0.026301210487468377\n",
+      "        vf_explained_var: 0.004243327304720879\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 637943\n",
+      "    num_steps_trained: 637943\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 29.75\n",
+      "    gpu_util_percent0: 0.35547619047619045\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.869047619047619\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.15856108821083387\n",
+      "    mean_env_wait_ms: 1.163652462203573\n",
+      "    mean_inference_ms: 5.0243813341893615\n",
+      "    mean_raw_obs_processing_ms: 0.4064302444759944\n",
+      "  time_since_restore: 105.58087587356567\n",
+      "  time_this_iter_s: 36.57298684120178\n",
+      "  time_total_s: 105.58087587356567\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 8776.554\n",
+      "    learn_time_ms: 24229.062\n",
+      "    sample_throughput: 19555.7\n",
+      "    sample_time_ms: 10873.948\n",
+      "    update_time_ms: 36.401\n",
+      "  timestamp: 1602416132\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 637943\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      3 |          105.581 | 637943 |  215.261 |              268.899 |              133.141 |            897.248 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3626.8021739130436\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-36-04\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 898.785864978903\n",
+      "  episode_reward_max: 268.89898989898984\n",
+      "  episode_reward_mean: 215.9509973149211\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
+      "        entropy: 1.1202221711476643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012885241769254208\n",
       "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.028739885789238744\n",
+      "        total_loss: -0.026274858611739345\n",
+      "        vf_explained_var: 0.004139645025134087\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 852049\n",
+      "    num_steps_trained: 852049\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 19.299999999999997\n",
+      "    gpu_util_percent0: 0.4605263157894737\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8789473684210534\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.15698071319986298\n",
+      "    mean_env_wait_ms: 1.1601976301052868\n",
+      "    mean_inference_ms: 4.9340688951794105\n",
+      "    mean_raw_obs_processing_ms: 0.40318035135376784\n",
+      "  time_since_restore: 137.01121926307678\n",
+      "  time_this_iter_s: 31.43034338951111\n",
+      "  time_total_s: 137.01121926307678\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 8757.236\n",
+      "    learn_time_ms: 24324.143\n",
+      "    sample_throughput: 21655.065\n",
+      "    sample_time_ms: 9836.602\n",
+      "    update_time_ms: 36.012\n",
+      "  timestamp: 1602416164\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 852049\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      4 |          137.011 | 852049 |  215.951 |              268.899 |              133.141 |            898.786 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3627.2143474503023\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-36-40\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 897.9054852320675\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 216.19639432297637\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
+      "        entropy: 1.1091025140550401\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011930530218200551\n",
       "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.03239480613006486\n",
+      "        total_loss: -0.030119610174248617\n",
+      "        vf_explained_var: 0.004592326004058123\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1064018\n",
+      "    num_steps_trained: 1064018\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 29.214285714285708\n",
+      "    gpu_util_percent0: 0.20214285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.885714285714286\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.1557465530250387\n",
+      "    mean_env_wait_ms: 1.1574808450465757\n",
+      "    mean_inference_ms: 4.862228219797691\n",
+      "    mean_raw_obs_processing_ms: 0.39960825263491473\n",
+      "  time_since_restore: 173.09106850624084\n",
+      "  time_this_iter_s: 36.07984924316406\n",
+      "  time_total_s: 173.09106850624084\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 8741.753\n",
+      "    learn_time_ms: 24343.355\n",
+      "    sample_throughput: 20897.294\n",
+      "    sample_time_ms: 10183.309\n",
+      "    update_time_ms: 33.526\n",
+      "  timestamp: 1602416200\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 1064018\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      5 |          173.091 | 1064018 |  216.196 |              269.051 |              133.141 |            897.905 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3625.2769010043044\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-37-11\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 896.626582278481\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 216.61624685675295\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
+      "        entropy: 1.1058683726522658\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013779823668301105\n",
       "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.03383349896305137\n",
+      "        total_loss: -0.031188121686379116\n",
+      "        vf_explained_var: 0.004375427961349487\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1275003\n",
+      "    num_steps_trained: 1275003\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 19.83888888888889\n",
+      "    gpu_util_percent0: 0.32833333333333337\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8916666666666675\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.15480226438213127\n",
+      "    mean_env_wait_ms: 1.1556744661925493\n",
+      "    mean_inference_ms: 4.808124976113362\n",
+      "    mean_raw_obs_processing_ms: 0.3973575039580816\n",
+      "  time_since_restore: 203.9486174583435\n",
+      "  time_this_iter_s: 30.85754895210266\n",
+      "  time_total_s: 203.9486174583435\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 8743.977\n",
+      "    learn_time_ms: 24302.5\n",
+      "    sample_throughput: 22152.544\n",
+      "    sample_time_ms: 9592.6\n",
+      "    update_time_ms: 34.755\n",
+      "  timestamp: 1602416231\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 1275003\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      6 |          203.949 | 1275003 |  216.616 |              269.051 |              117.838 |            896.627 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3622.4530962599633\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-37-47\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 894.9029535864979\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 217.01651232030957\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
+      "        entropy: 1.0927574502097235\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012546442604313294\n",
       "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.035685616752339736\n",
+      "        total_loss: -0.033285604065491095\n",
+      "        vf_explained_var: 0.0044588083401322365\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1484644\n",
+      "    num_steps_trained: 1484644\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 28.633333333333333\n",
+      "    gpu_util_percent0: 0.28500000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.876190476190477\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.1540133323616834\n",
+      "    mean_env_wait_ms: 1.1544321575145495\n",
+      "    mean_inference_ms: 4.763016603687438\n",
+      "    mean_raw_obs_processing_ms: 0.39503044627312545\n",
+      "  time_since_restore: 239.55271339416504\n",
+      "  time_this_iter_s: 35.60409593582153\n",
+      "  time_total_s: 239.55271339416504\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 8740.909\n",
+      "    learn_time_ms: 24264.294\n",
+      "    sample_throughput: 21534.624\n",
+      "    sample_time_ms: 9848.884\n",
+      "    update_time_ms: 35.412\n",
+      "  timestamp: 1602416267\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 1484644\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      7 |          239.553 | 1484644 |  217.017 |              269.051 |              117.838 |            894.903 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3621.7789079229124\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-38-17\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 892.9240506329114\n",
+      "  episode_reward_max: 274.3535353535355\n",
+      "  episode_reward_mean: 217.11181434599132\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
+      "        entropy: 1.0877870519955952\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014053100616567664\n",
       "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.036782152795543276\n",
+      "        total_loss: -0.03408031062119537\n",
+      "        vf_explained_var: 0.004147387109696865\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1692984\n",
+      "    num_steps_trained: 1692984\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 19.683333333333334\n",
+      "    gpu_util_percent0: 0.30944444444444447\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8916666666666675\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.15337511452129216\n",
+      "    mean_env_wait_ms: 1.1536417821691023\n",
+      "    mean_inference_ms: 4.726508534969858\n",
+      "    mean_raw_obs_processing_ms: 0.39338917198844775\n",
+      "  time_since_restore: 270.2423267364502\n",
+      "  time_this_iter_s: 30.689613342285156\n",
+      "  time_total_s: 270.2423267364502\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 8734.946\n",
+      "    learn_time_ms: 24227.168\n",
+      "    sample_throughput: 22406.357\n",
+      "    sample_time_ms: 9444.775\n",
+      "    update_time_ms: 36.407\n",
+      "  timestamp: 1602416297\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 1692984\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      8 |          270.242 | 1692984 |  217.112 |              274.354 |              117.838 |            892.924 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3619.964370546318\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-38-53\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 892.0590717299579\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.23367287502285\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
+      "        entropy: 1.0724814070595636\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012386405995736519\n",
       "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03819261729303333\n",
+      "        total_loss: -0.03582258429378271\n",
+      "        vf_explained_var: 0.0043792459182441235\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1902762\n",
+      "    num_steps_trained: 1902762\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 29.034146341463412\n",
+      "    gpu_util_percent0: 0.23902439024390246\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.880487804878049\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.1528267206439357\n",
+      "    mean_env_wait_ms: 1.153000049259824\n",
+      "    mean_inference_ms: 4.695004094684524\n",
+      "    mean_raw_obs_processing_ms: 0.39174524064795563\n",
+      "  time_since_restore: 305.92427682876587\n",
+      "  time_this_iter_s: 35.681950092315674\n",
+      "  time_total_s: 305.92427682876587\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 8726.411\n",
+      "    learn_time_ms: 24227.372\n",
+      "    sample_throughput: 21896.229\n",
+      "    sample_time_ms: 9655.452\n",
+      "    update_time_ms: 37.204\n",
+      "  timestamp: 1602416333\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 1902762\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.9/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      9 |          305.924 | 1902762 |  217.234 |               276.02 |              117.838 |            892.059 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3621.0990606319383\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-39-24\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 891.0700421940928\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.2751566295868\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
+      "        entropy: 1.0645562211672466\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013964535668492317\n",
       "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03785448128150569\n",
+      "        total_loss: -0.03516803009228574\n",
+      "        vf_explained_var: 0.004580974578857422\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2111836\n",
+      "    num_steps_trained: 2111836\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 19.80833333333333\n",
+      "    gpu_util_percent0: 0.3402777777777778\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8888888888888897\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.15236541509539533\n",
+      "    mean_env_wait_ms: 1.1525677384010393\n",
+      "    mean_inference_ms: 4.668415033559\n",
+      "    mean_raw_obs_processing_ms: 0.39051778190252684\n",
+      "  time_since_restore: 336.3577198982239\n",
+      "  time_this_iter_s: 30.433443069458008\n",
+      "  time_total_s: 336.3577198982239\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 8737.509\n",
+      "    learn_time_ms: 24169.773\n",
+      "    sample_throughput: 22569.624\n",
+      "    sample_time_ms: 9356.984\n",
+      "    update_time_ms: 37.424\n",
+      "  timestamp: 1602416364\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 2111836\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     10 |          336.358 | 2111836 |  217.275 |               276.02 |              117.838 |             891.07 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3620.0957735556417\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-39-59\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 889.4353663214423\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.5044344480476\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2607\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
+      "        entropy: 1.0534564057985942\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012721320200297568\n",
       "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.041706488778193794\n",
+      "        total_loss: -0.03926757205691603\n",
+      "        vf_explained_var: 0.0045647090300917625\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2318758\n",
+      "    num_steps_trained: 2318758\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 28.419512195121946\n",
+      "    gpu_util_percent0: 0.2424390243902439\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8756097560975613\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.1519518673022639\n",
+      "    mean_env_wait_ms: 1.152256679175318\n",
+      "    mean_inference_ms: 4.645006252307939\n",
+      "    mean_raw_obs_processing_ms: 0.38928804389411903\n",
+      "  time_since_restore: 371.5491871833801\n",
+      "  time_this_iter_s: 35.19146728515625\n",
+      "  time_total_s: 371.5491871833801\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 8728.437\n",
+      "    learn_time_ms: 24150.659\n",
+      "    sample_throughput: 23167.734\n",
+      "    sample_time_ms: 9098.753\n",
+      "    update_time_ms: 37.269\n",
+      "  timestamp: 1602416399\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 2318758\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     11 |          371.549 | 2318758 |  217.504 |               276.02 |              117.838 |            889.435 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3619.186434659091\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-40-30\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 887.9982419127989\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.57792055576846\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
+      "        entropy: 1.0404738320244684\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014134101724872986\n",
       "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.03792600789003902\n",
+      "        total_loss: -0.03520323522388935\n",
+      "        vf_explained_var: 0.0047518182545900345\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2525467\n",
+      "    num_steps_trained: 2525467\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 19.44054054054054\n",
+      "    gpu_util_percent0: 0.31675675675675674\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.88918918918919\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.1515918898863825\n",
+      "    mean_env_wait_ms: 1.152054790422858\n",
+      "    mean_inference_ms: 4.624642872725377\n",
+      "    mean_raw_obs_processing_ms: 0.38831806674843455\n",
+      "  time_since_restore: 402.2105643749237\n",
+      "  time_this_iter_s: 30.66137719154358\n",
+      "  time_total_s: 402.2105643749237\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 8716.718\n",
+      "    learn_time_ms: 24107.479\n",
+      "    sample_throughput: 23087.081\n",
+      "    sample_time_ms: 9101.978\n",
+      "    update_time_ms: 36.772\n",
+      "  timestamp: 1602416430\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 2525467\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     12 |          402.211 | 2525467 |  217.578 |               276.02 |              117.838 |            887.998 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3617.957746478873\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-41-04\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 886.2528399870172\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.87575855930265\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1343,82 +1301,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
+      "        entropy: 1.0285753292195938\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011995552655528574\n",
       "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.03939158841967583\n",
+      "        total_loss: -0.03709533503826927\n",
+      "        vf_explained_var: 0.004629951901733875\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2730545\n",
+      "    num_steps_trained: 2730545\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 28.517499999999995\n",
+      "    gpu_util_percent0: 0.15775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8875\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.15126712051208008\n",
+      "    mean_env_wait_ms: 1.1519746175500274\n",
+      "    mean_inference_ms: 4.606332420711713\n",
+      "    mean_raw_obs_processing_ms: 0.3873457283671401\n",
+      "  time_since_restore: 436.7092037200928\n",
+      "  time_this_iter_s: 34.49863934516907\n",
+      "  time_total_s: 436.7092037200928\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 8713.26\n",
+      "    learn_time_ms: 24016.292\n",
+      "    sample_throughput: 23298.0\n",
+      "    sample_time_ms: 8981.896\n",
+      "    update_time_ms: 39.203\n",
+      "  timestamp: 1602416464\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 2730545\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     13 |          436.709 | 2730545 |  217.876 |               276.02 |              117.838 |            886.253 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3615.473556231003\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-41-34\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 884.6006630500301\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.18630244579595\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1427,166 +1383,162 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
+      "        entropy: 1.0195737656425028\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014620853204499273\n",
       "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.040181194815565556\n",
+      "        total_loss: -0.03735898172154146\n",
+      "        vf_explained_var: 0.0048517691902816296\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2935105\n",
+      "    num_steps_trained: 2935105\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 20.248571428571434\n",
+      "    gpu_util_percent0: 0.2117142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.15097851241621377\n",
+      "    mean_env_wait_ms: 1.151986226839648\n",
+      "    mean_inference_ms: 4.59004149259784\n",
+      "    mean_raw_obs_processing_ms: 0.38655923185663227\n",
+      "  time_since_restore: 466.56523871421814\n",
+      "  time_this_iter_s: 29.856034994125366\n",
+      "  time_total_s: 466.56523871421814\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 8727.576\n",
+      "    learn_time_ms: 23867.521\n",
+      "    sample_throughput: 23216.942\n",
+      "    sample_time_ms: 8972.138\n",
+      "    update_time_ms: 39.799\n",
+      "  timestamp: 1602416494\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 2935105\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     14 |          466.565 | 2935105 |  218.186 |               276.02 |              117.838 |            884.601 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3615.3926850014177\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-42-09\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 883.6264416315049\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.1418403443718\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
+      "        entropy: 1.0012975103325314\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014535996855960952\n",
       "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03526349003530211\n",
+      "        total_loss: -0.032456420879397124\n",
+      "        vf_explained_var: 0.00504864938557148\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3141292\n",
+      "    num_steps_trained: 3141292\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 28.37317073170731\n",
+      "    gpu_util_percent0: 0.16682926829268294\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.890243902439025\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.1507143981115296\n",
+      "    mean_env_wait_ms: 1.1520130121453596\n",
+      "    mean_inference_ms: 4.575249397096355\n",
+      "    mean_raw_obs_processing_ms: 0.385776842638709\n",
+      "  time_since_restore: 501.3796808719635\n",
+      "  time_this_iter_s: 34.81444215774536\n",
+      "  time_total_s: 501.3796808719635\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 8733.554\n",
+      "    learn_time_ms: 23784.979\n",
+      "    sample_throughput: 23270.813\n",
+      "    sample_time_ms: 8926.521\n",
+      "    update_time_ms: 40.872\n",
+      "  timestamp: 1602416529\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 3141292\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     15 |           501.38 | 3141292 |  218.142 |               276.02 |              115.414 |            883.626 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3615.337407013815\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-42-40\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 882.57805907173\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.2741097685716\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1595,82 +1547,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
+      "        entropy: 0.9924393120933982\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013116635984795936\n",
       "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.036610624479020346\n",
+      "        total_loss: -0.03408654198488768\n",
+      "        vf_explained_var: 0.005047868471592665\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3346736\n",
+      "    num_steps_trained: 3346736\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 19.352777777777778\n",
+      "    gpu_util_percent0: 0.2844444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8972222222222226\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.15047497998216566\n",
+      "    mean_env_wait_ms: 1.1520761809338669\n",
+      "    mean_inference_ms: 4.561845659716743\n",
+      "    mean_raw_obs_processing_ms: 0.3851282199475179\n",
+      "  time_since_restore: 531.4751350879669\n",
+      "  time_this_iter_s: 30.095454216003418\n",
+      "  time_total_s: 531.4751350879669\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 8734.893\n",
+      "    learn_time_ms: 23717.899\n",
+      "    sample_throughput: 23225.831\n",
+      "    sample_time_ms: 8919.952\n",
+      "    update_time_ms: 38.881\n",
+      "  timestamp: 1602416560\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 3346736\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.9/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     16 |          531.475 | 3346736 |  218.274 |               276.02 |              115.414 |            882.578 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3613.5941014746313\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-43-14\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 881.4896996773393\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.48013267447354\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4029\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1679,82 +1629,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
+      "        entropy: 0.9786315595402437\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012351499815635821\n",
       "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.04146460597129429\n",
+      "        total_loss: -0.03909216941717793\n",
+      "        vf_explained_var: 0.005017775110900402\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3551522\n",
+      "    num_steps_trained: 3551522\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 28.402499999999996\n",
+      "    gpu_util_percent0: 0.28675\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.88\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.15025081057749468\n",
+      "    mean_env_wait_ms: 1.1521409602354007\n",
+      "    mean_inference_ms: 4.549440483702669\n",
+      "    mean_raw_obs_processing_ms: 0.38447308950954834\n",
+      "  time_since_restore: 565.6918759346008\n",
+      "  time_this_iter_s: 34.21674084663391\n",
+      "  time_total_s: 565.6918759346008\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 8753.328\n",
+      "    learn_time_ms: 23612.482\n",
+      "    sample_throughput: 23253.61\n",
+      "    sample_time_ms: 8888.418\n",
+      "    update_time_ms: 36.842\n",
+      "  timestamp: 1602416594\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 3551522\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     17 |          565.692 | 3551522 |   218.48 |               276.02 |              115.414 |             881.49 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3612.9728645587543\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-43-44\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 880.2920768870136\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.76413217974383\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1763,82 +1711,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
+      "        entropy: 0.9642671241479761\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014467166462803589\n",
       "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.041976395227453285\n",
+      "        total_loss: -0.03917938941980109\n",
+      "        vf_explained_var: 0.005014840513467789\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3755326\n",
+      "    num_steps_trained: 3755326\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 19.957142857142856\n",
+      "    gpu_util_percent0: 0.36085714285714293\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.15004368629945075\n",
+      "    mean_env_wait_ms: 1.152218182465942\n",
+      "    mean_inference_ms: 4.53807491236111\n",
+      "    mean_raw_obs_processing_ms: 0.3839184638798795\n",
+      "  time_since_restore: 595.9380519390106\n",
+      "  time_this_iter_s: 30.24617600440979\n",
+      "  time_total_s: 595.9380519390106\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 8751.49\n",
+      "    learn_time_ms: 23565.61\n",
+      "    sample_throughput: 23196.739\n",
+      "    sample_time_ms: 8890.655\n",
+      "    update_time_ms: 36.326\n",
+      "  timestamp: 1602416624\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 3755326\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     18 |          595.938 | 3755326 |  218.764 |               276.02 |              115.414 |            880.292 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3611.5343016759775\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-44-18\n",
+      "  done: true\n",
+      "  episode_len_mean: 879.0453031312459\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.88085384154653\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4503\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1847,270 +1793,104 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
+      "        entropy: 0.9430958418285146\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013297418954179567\n",
       "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.04472087937242845\n",
+      "        total_loss: -0.04215570407755235\n",
+      "        vf_explained_var: 0.004909925628453493\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3958341\n",
+      "    num_steps_trained: 3958341\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 27.860000000000003\n",
+      "    gpu_util_percent0: 0.26749999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8775000000000004\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.1498507029804729\n",
+      "    mean_env_wait_ms: 1.1523313063198106\n",
+      "    mean_inference_ms: 4.527459740401997\n",
+      "    mean_raw_obs_processing_ms: 0.38335573474692985\n",
+      "  time_since_restore: 629.5950663089752\n",
+      "  time_this_iter_s: 33.6570143699646\n",
+      "  time_total_s: 629.5950663089752\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 8771.996\n",
+      "    learn_time_ms: 23433.423\n",
+      "    sample_throughput: 23320.558\n",
+      "    sample_time_ms: 8814.45\n",
+      "    update_time_ms: 41.147\n",
+      "  timestamp: 1602416658\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 3958341\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
-      "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
-      "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
+      "| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 266\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_113335-gyz1jmjx/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_113335-gyz1jmjx/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3245\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 643\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602416658\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4278\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3619.96437\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 276.0202\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 117.83838\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 217.23367\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 2133\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
@@ -2119,2334 +1899,1875 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mspring-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gyz1jmjx\u001b[0m\n",
+      "2020-10-11 11:44:27,155 - wandb.wandb_agent - INFO - Cleaning up finished run: gyz1jmjx\n",
+      "2020-10-11 11:44:28,704 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:44:28,704 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "2020-10-11 11:44:28,708 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --sgd_minibatch_size=14112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 11:44:33,727 - wandb.wandb_agent - INFO - Running runs: ['8599p7pd']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevoted-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/8599p7pd\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_114430-8599p7pd\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
+      "2020-10-11 11:44:34,497\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "\u001b[2m\u001b[36m(pid=21893)\u001b[0m 2020-10-11 11:44:37,217\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=21919)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21919)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21915)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21915)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21906)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21906)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21925)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21925)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21937)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21937)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21940)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21940)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21932)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21932)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21899)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21899)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21933)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21933)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21926)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21926)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.267942583732\n",
+      "    time_step_min: 3363\n",
+      "  date: 2020-10-11_11-45-19\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 889.379746835443\n",
+      "  episode_reward_max: 261.32323232323233\n",
+      "  episode_reward_mean: 217.15624600434705\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1515328645706178\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010727026065190633\n",
       "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        policy_loss: -0.02324618815133969\n",
+      "        total_loss: -0.02121593654155731\n",
+      "        vf_explained_var: 0.0041161575354635715\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 210783\n",
+      "    num_steps_trained: 210783\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
+      "    cpu_util_percent: 35.288636363636364\n",
+      "    gpu_util_percent0: 0.2252272727272727\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5636363636363626\n",
+      "    vram_util_percent0: 0.07299710784459884\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
+      "    mean_action_processing_ms: 0.16648777601686732\n",
+      "    mean_env_wait_ms: 1.172007982092815\n",
+      "    mean_inference_ms: 5.605068870778583\n",
+      "    mean_raw_obs_processing_ms: 0.42467628377691685\n",
+      "  time_since_restore: 37.207940340042114\n",
+      "  time_this_iter_s: 37.207940340042114\n",
+      "  time_total_s: 37.207940340042114\n",
       "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
+      "    learn_throughput: 9291.256\n",
+      "    learn_time_ms: 22686.169\n",
+      "    sample_throughput: 14599.192\n",
+      "    sample_time_ms: 14437.991\n",
+      "    update_time_ms: 40.941\n",
+      "  timestamp: 1602416719\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 210783\n",
       "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 27.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      1 |          37.2079 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3621.2399103139014\n",
+      "    time_step_min: 3316\n",
+      "  date: 2020-10-11_11-45-49\n",
       "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 890.4978902953586\n",
+      "  episode_reward_max: 265.2626262626267\n",
+      "  episode_reward_mean: 217.21218514256464\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1433068990707398\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01189851804325978\n",
       "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02315738166992863\n",
+      "        total_loss: -0.02089200944950183\n",
+      "        vf_explained_var: 0.004307313822209835\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 422096\n",
+      "    num_steps_trained: 422096\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
+      "    cpu_util_percent: 21.04571428571429\n",
+      "    gpu_util_percent0: 0.27942857142857147\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.851428571428572\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
+      "    mean_action_processing_ms: 0.16371548482521198\n",
+      "    mean_env_wait_ms: 1.1686532604347295\n",
+      "    mean_inference_ms: 5.420568834611119\n",
+      "    mean_raw_obs_processing_ms: 0.4220212101908426\n",
+      "  time_since_restore: 66.73374390602112\n",
+      "  time_this_iter_s: 29.525803565979004\n",
+      "  time_total_s: 66.73374390602112\n",
       "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
+      "    learn_throughput: 9293.709\n",
+      "    learn_time_ms: 22708.694\n",
+      "    sample_throughput: 20029.689\n",
+      "    sample_time_ms: 10536.759\n",
+      "    update_time_ms: 64.624\n",
+      "  timestamp: 1602416749\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 422096\n",
       "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      2 |          66.7337 | 422096 |  217.212 |              265.263 |               131.02 |            890.498 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3612.7730600292825\n",
+      "    time_step_min: 3316\n",
+      "  date: 2020-10-11_11-46-23\n",
       "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 888.9957805907173\n",
+      "  episode_reward_max: 265.2626262626267\n",
+      "  episode_reward_mean: 219.07969995311745\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1310136556625365\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010968415128688017\n",
       "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.026474943245799902\n",
+      "        total_loss: -0.024394361876572172\n",
+      "        vf_explained_var: 0.0043815732933580875\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 632076\n",
+      "    num_steps_trained: 632076\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
+      "    cpu_util_percent: 31.284615384615392\n",
+      "    gpu_util_percent0: 0.2474358974358974\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8717948717948727\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
+      "    mean_action_processing_ms: 0.16112216399976034\n",
+      "    mean_env_wait_ms: 1.165414661820334\n",
+      "    mean_inference_ms: 5.249603295063079\n",
+      "    mean_raw_obs_processing_ms: 0.41388107167270655\n",
+      "  time_since_restore: 101.0947494506836\n",
+      "  time_this_iter_s: 34.361005544662476\n",
+      "  time_total_s: 101.0947494506836\n",
       "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
+      "    learn_throughput: 9336.421\n",
+      "    learn_time_ms: 22566.678\n",
+      "    sample_throughput: 19127.495\n",
+      "    sample_time_ms: 11015.138\n",
+      "    update_time_ms: 54.743\n",
+      "  timestamp: 1602416783\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 632076\n",
       "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      3 |          101.095 | 632076 |   219.08 |              265.263 |               131.02 |            888.996 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3606.198913043478\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-46-53\n",
       "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 889.0622362869199\n",
+      "  episode_reward_max: 272.38383838383766\n",
+      "  episode_reward_mean: 220.0991241529214\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1246707757314047\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012073339087267716\n",
       "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.027101184924443564\n",
+      "        total_loss: -0.024798984949787457\n",
+      "        vf_explained_var: 0.0042299311608076096\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 842831\n",
+      "    num_steps_trained: 842831\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
+      "    cpu_util_percent: 20.19428571428571\n",
+      "    gpu_util_percent0: 0.28\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.882857142857143\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
+      "    mean_action_processing_ms: 0.1594245792140959\n",
+      "    mean_env_wait_ms: 1.1635538804000238\n",
+      "    mean_inference_ms: 5.137971799065908\n",
+      "    mean_raw_obs_processing_ms: 0.40978856844149203\n",
+      "  time_since_restore: 130.50831294059753\n",
+      "  time_this_iter_s: 29.41356348991394\n",
+      "  time_total_s: 130.50831294059753\n",
       "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
+      "    learn_throughput: 9324.53\n",
+      "    learn_time_ms: 22597.143\n",
+      "    sample_throughput: 21248.889\n",
+      "    sample_time_ms: 9916.177\n",
+      "    update_time_ms: 52.503\n",
+      "  timestamp: 1602416813\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 842831\n",
       "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      4 |          130.508 | 842831 |  220.099 |              272.384 |               131.02 |            889.062 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3600.3318928262747\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-47-27\n",
       "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 887.8329113924051\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 220.93338447768807\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1125795602798463\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011277629248797893\n",
       "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.02982374553879102\n",
+      "        total_loss: -0.027679476700723172\n",
+      "        vf_explained_var: 0.004315233323723078\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1052082\n",
+      "    num_steps_trained: 1052082\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
+      "    cpu_util_percent: 30.494871794871795\n",
+      "    gpu_util_percent0: 0.26461538461538464\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.86923076923077\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
+      "    mean_action_processing_ms: 0.15798279899678966\n",
+      "    mean_env_wait_ms: 1.161820158517753\n",
+      "    mean_inference_ms: 5.045335862584878\n",
+      "    mean_raw_obs_processing_ms: 0.4053292285015951\n",
+      "  time_since_restore: 164.11815762519836\n",
+      "  time_this_iter_s: 33.60984468460083\n",
+      "  time_total_s: 164.11815762519836\n",
       "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
+      "    learn_throughput: 9337.496\n",
+      "    learn_time_ms: 22534.565\n",
+      "    sample_throughput: 20668.109\n",
+      "    sample_time_ms: 10180.728\n",
+      "    update_time_ms: 47.822\n",
+      "  timestamp: 1602416847\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 1052082\n",
       "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      5 |          164.118 | 1052082 |  220.933 |              274.657 |              129.505 |            887.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3593.0911047345767\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-47-56\n",
       "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 886.5386779184248\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 221.70511017346442\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1075134913126627\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012626525262991588\n",
       "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.029389831672112145\n",
+      "        total_loss: -0.02697527843217055\n",
+      "        vf_explained_var: 0.0045168716460466385\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1260658\n",
+      "    num_steps_trained: 1260658\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
+      "    cpu_util_percent: 19.840000000000003\n",
+      "    gpu_util_percent0: 0.29114285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
+      "    mean_action_processing_ms: 0.15687991735644435\n",
+      "    mean_env_wait_ms: 1.1606285217815193\n",
+      "    mean_inference_ms: 4.975068831532567\n",
+      "    mean_raw_obs_processing_ms: 0.40238811926569734\n",
+      "  time_since_restore: 193.20886325836182\n",
+      "  time_this_iter_s: 29.090705633163452\n",
+      "  time_total_s: 193.20886325836182\n",
       "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
+      "    learn_throughput: 9324.379\n",
+      "    learn_time_ms: 22533.369\n",
+      "    sample_throughput: 21975.909\n",
+      "    sample_time_ms: 9560.909\n",
+      "    update_time_ms: 46.818\n",
+      "  timestamp: 1602416876\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 1260658\n",
       "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      6 |          193.209 | 1260658 |  221.705 |              274.657 |              129.505 |            886.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3591.814837522992\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-48-30\n",
       "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 885.746835443038\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.2184411931245\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0938406944274903\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011840906552970409\n",
       "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.032349477522075176\n",
+      "        total_loss: -0.030090681153039138\n",
+      "        vf_explained_var: 0.004780403804033995\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1469454\n",
+      "    num_steps_trained: 1469454\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
+      "    cpu_util_percent: 29.6325\n",
+      "    gpu_util_percent0: 0.24625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.88\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
+      "    mean_action_processing_ms: 0.15593363019005474\n",
+      "    mean_env_wait_ms: 1.159485525524178\n",
+      "    mean_inference_ms: 4.915902748379981\n",
+      "    mean_raw_obs_processing_ms: 0.3994958671193922\n",
+      "  time_since_restore: 227.4704246520996\n",
+      "  time_this_iter_s: 34.26156139373779\n",
+      "  time_total_s: 227.4704246520996\n",
       "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
+      "    learn_throughput: 9297.743\n",
+      "    learn_time_ms: 22577.737\n",
+      "    sample_throughput: 21395.999\n",
+      "    sample_time_ms: 9811.274\n",
+      "    update_time_ms: 46.483\n",
+      "  timestamp: 1602416910\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 1469454\n",
       "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      7 |           227.47 | 1469454 |  222.218 |              274.657 |              129.505 |            885.747 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3588.4202355460384\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-48-59\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.915611814346\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.8558048842857\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0879791339238485\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013443161174654961\n",
       "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.032103987659017244\n",
+      "        total_loss: -0.029524152725934984\n",
+      "        vf_explained_var: 0.004608952905982733\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1677800\n",
+      "    num_steps_trained: 1677800\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
+      "    cpu_util_percent: 21.242424242424242\n",
+      "    gpu_util_percent0: 0.2706060606060606\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.884848484848485\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
+      "    mean_action_processing_ms: 0.15516089886252904\n",
+      "    mean_env_wait_ms: 1.1585878747820224\n",
+      "    mean_inference_ms: 4.867907119534596\n",
+      "    mean_raw_obs_processing_ms: 0.39737886686803015\n",
+      "  time_since_restore: 255.9719376564026\n",
+      "  time_this_iter_s: 28.50151300430298\n",
+      "  time_total_s: 255.9719376564026\n",
       "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
+      "    learn_throughput: 9322.664\n",
+      "    learn_time_ms: 22496.253\n",
+      "    sample_throughput: 22327.089\n",
+      "    sample_time_ms: 9393.298\n",
+      "    update_time_ms: 45.451\n",
+      "  timestamp: 1602416939\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 1677800\n",
       "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      8 |          255.972 | 1677800 |  222.856 |              274.657 |              129.505 |            884.916 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3586.915914489311\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-49-32\n",
       "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.29676511955\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.9680205713959\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0769737402598063\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01233778204768896\n",
       "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03488614509503047\n",
+      "        total_loss: -0.0325262863188982\n",
+      "        vf_explained_var: 0.00442349910736084\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1886205\n",
+      "    num_steps_trained: 1886205\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
+      "    cpu_util_percent: 29.876923076923084\n",
+      "    gpu_util_percent0: 0.22282051282051277\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.882051282051283\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
+      "    mean_action_processing_ms: 0.1544875213558879\n",
+      "    mean_env_wait_ms: 1.1577098829011632\n",
+      "    mean_inference_ms: 4.8263615190470395\n",
+      "    mean_raw_obs_processing_ms: 0.3953101185725302\n",
+      "  time_since_restore: 289.6378767490387\n",
+      "  time_this_iter_s: 33.66593909263611\n",
+      "  time_total_s: 289.6378767490387\n",
       "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
+      "    learn_throughput: 9319.587\n",
+      "    learn_time_ms: 22487.942\n",
+      "    sample_throughput: 21862.84\n",
+      "    sample_time_ms: 9586.053\n",
+      "    update_time_ms: 44.77\n",
+      "  timestamp: 1602416972\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 1886205\n",
       "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      9 |          289.638 | 1886205 |  222.968 |              274.657 |              129.505 |            884.297 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3585.0764304013665\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-50-02\n",
       "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.3721518987342\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.96387929932214\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0696190357208253\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013751295581459998\n",
       "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03426021374762058\n",
+      "        total_loss: -0.031616917625069615\n",
+      "        vf_explained_var: 0.00452190637588501\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2095962\n",
+      "    num_steps_trained: 2095962\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
+      "    cpu_util_percent: 20.197142857142858\n",
+      "    gpu_util_percent0: 0.29114285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
+      "    mean_action_processing_ms: 0.15392038983954964\n",
+      "    mean_env_wait_ms: 1.1569633633981062\n",
+      "    mean_inference_ms: 4.791379278619612\n",
+      "    mean_raw_obs_processing_ms: 0.3937311631719402\n",
+      "  time_since_restore: 318.9559681415558\n",
+      "  time_this_iter_s: 29.31809139251709\n",
+      "  time_total_s: 318.9559681415558\n",
       "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
+      "    learn_throughput: 9323.01\n",
+      "    learn_time_ms: 22481.602\n",
+      "    sample_throughput: 22522.558\n",
+      "    sample_time_ms: 9306.056\n",
+      "    update_time_ms: 44.808\n",
+      "  timestamp: 1602417002\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 2095962\n",
       "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     10 |          318.956 | 2095962 |  222.964 |              274.657 |              129.505 |            884.372 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3585.993796044979\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-50-35\n",
       "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.6283084004604\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.9485766758492\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2607\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.057764212290446\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01220239649216334\n",
       "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.03655547251303991\n",
+      "        total_loss: -0.03422076975305875\n",
+      "        vf_explained_var: 0.004498771857470274\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2306226\n",
+      "    num_steps_trained: 2306226\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
+      "    cpu_util_percent: 30.079487179487177\n",
+      "    gpu_util_percent0: 0.2520512820512821\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8769230769230782\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
+      "    mean_action_processing_ms: 0.15341774730576713\n",
+      "    mean_env_wait_ms: 1.1562202430781439\n",
+      "    mean_inference_ms: 4.760572667303618\n",
+      "    mean_raw_obs_processing_ms: 0.39219741805542485\n",
+      "  time_since_restore: 352.508731842041\n",
+      "  time_this_iter_s: 33.55276370048523\n",
+      "  time_total_s: 352.508731842041\n",
       "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
+      "    learn_throughput: 9336.916\n",
+      "    learn_time_ms: 22442.561\n",
+      "    sample_throughput: 23337.157\n",
+      "    sample_time_ms: 8978.999\n",
+      "    update_time_ms: 43.492\n",
+      "  timestamp: 1602417035\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 2306226\n",
       "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     11 |          352.509 | 2306226 |  222.949 |              274.657 |              123.444 |            884.628 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3585.416903409091\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-51-05\n",
       "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.5847398030942\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.99155052636047\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0487373749415079\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013711805579562981\n",
       "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.03558352831751108\n",
+      "        total_loss: -0.03294604104012251\n",
+      "        vf_explained_var: 0.004443577956408262\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2515759\n",
+      "    num_steps_trained: 2515759\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
+      "    cpu_util_percent: 20.88529411764706\n",
+      "    gpu_util_percent0: 0.27764705882352947\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8852941176470597\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
+      "    mean_action_processing_ms: 0.1529802643731159\n",
+      "    mean_env_wait_ms: 1.1555617141401107\n",
+      "    mean_inference_ms: 4.733817050752962\n",
+      "    mean_raw_obs_processing_ms: 0.39096315453997343\n",
+      "  time_since_restore: 381.7114312648773\n",
+      "  time_this_iter_s: 29.202699422836304\n",
+      "  time_total_s: 381.7114312648773\n",
       "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
+      "    learn_throughput: 9356.622\n",
+      "    learn_time_ms: 22376.27\n",
+      "    sample_throughput: 23221.036\n",
+      "    sample_time_ms: 9016.234\n",
+      "    update_time_ms: 38.55\n",
+      "  timestamp: 1602417065\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 2515759\n",
       "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     12 |          381.711 | 2515759 |  222.992 |              274.657 |              123.444 |            884.585 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3583.670160497871\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-51-38\n",
       "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 883.5699448231094\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.30827259941165\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.037754726409912\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012784661290546258\n",
       "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.03867535578707854\n",
+      "        total_loss: -0.0362221988538901\n",
+      "        vf_explained_var: 0.004530946258455515\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2722279\n",
+      "    num_steps_trained: 2722279\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
+      "    cpu_util_percent: 29.40769230769231\n",
+      "    gpu_util_percent0: 0.23179487179487177\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8743589743589757\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
+      "    mean_action_processing_ms: 0.15258750220895162\n",
+      "    mean_env_wait_ms: 1.1550136761051824\n",
+      "    mean_inference_ms: 4.70990938387223\n",
+      "    mean_raw_obs_processing_ms: 0.3897614970753449\n",
+      "  time_since_restore: 415.17905950546265\n",
+      "  time_this_iter_s: 33.46762824058533\n",
+      "  time_total_s: 415.17905950546265\n",
       "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
+      "    learn_throughput: 9342.752\n",
+      "    learn_time_ms: 22372.456\n",
+      "    sample_throughput: 23405.862\n",
+      "    sample_time_ms: 8930.254\n",
+      "    update_time_ms: 39.067\n",
+      "  timestamp: 1602417098\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 2722279\n",
       "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     13 |          415.179 | 2722279 |  223.308 |              274.657 |              123.444 |             883.57 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3581.2051671732524\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-52-07\n",
       "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 882.2272453285111\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.52833031946935\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.031781538327535\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014422734640538693\n",
       "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.038801763827602066\n",
+      "        total_loss: -0.03602039503554503\n",
+      "        vf_explained_var: 0.004225671291351318\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2927230\n",
+      "    num_steps_trained: 2927230\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
+      "    cpu_util_percent: 20.302941176470586\n",
+      "    gpu_util_percent0: 0.26676470588235296\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8911764705882357\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
+      "    mean_action_processing_ms: 0.15223626672918422\n",
+      "    mean_env_wait_ms: 1.1545856441162181\n",
+      "    mean_inference_ms: 4.688645556180501\n",
+      "    mean_raw_obs_processing_ms: 0.38876734649354316\n",
+      "  time_since_restore: 443.92309951782227\n",
+      "  time_this_iter_s: 28.74404001235962\n",
+      "  time_total_s: 443.92309951782227\n",
       "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
+      "    learn_throughput: 9349.416\n",
+      "    learn_time_ms: 22294.429\n",
+      "    sample_throughput: 23308.931\n",
+      "    sample_time_ms: 8942.491\n",
+      "    update_time_ms: 37.278\n",
+      "  timestamp: 1602417127\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 2927230\n",
       "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     14 |          443.923 | 2927230 |  223.528 |              274.657 |              123.444 |            882.227 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3579.850014176354\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-52-40\n",
       "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 881.0486638537271\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.70937220304288\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0202627897262573\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01260025588174661\n",
       "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03989621177315712\n",
+      "        total_loss: -0.03747818768024445\n",
+      "        vf_explained_var: 0.0042155226692557335\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3132128\n",
+      "    num_steps_trained: 3132128\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
+      "    cpu_util_percent: 28.925641025641028\n",
+      "    gpu_util_percent0: 0.26538461538461544\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.874358974358975\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
+      "    mean_action_processing_ms: 0.15191691646680128\n",
+      "    mean_env_wait_ms: 1.1542151412118906\n",
+      "    mean_inference_ms: 4.669274829623884\n",
+      "    mean_raw_obs_processing_ms: 0.38778296009932195\n",
+      "  time_since_restore: 477.0645468235016\n",
+      "  time_this_iter_s: 33.14144730567932\n",
+      "  time_total_s: 477.0645468235016\n",
       "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
+      "    learn_throughput: 9341.245\n",
+      "    learn_time_ms: 22267.332\n",
+      "    sample_throughput: 23333.802\n",
+      "    sample_time_ms: 8914.304\n",
+      "    update_time_ms: 38.076\n",
+      "  timestamp: 1602417160\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 3132128\n",
       "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     15 |          477.065 | 3132128 |  223.709 |              274.657 |              123.444 |            881.049 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3577.9782146652497\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-53-09\n",
       "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 879.95305907173\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.97786408387654\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0082921346028646\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014132832487424215\n",
       "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.03908525543908278\n",
+      "        total_loss: -0.03635951802134514\n",
+      "        vf_explained_var: 0.0040289959870278835\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3336782\n",
+      "    num_steps_trained: 3336782\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
+      "    cpu_util_percent: 20.542424242424243\n",
+      "    gpu_util_percent0: 0.2412121212121212\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.881818181818182\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
+      "    mean_action_processing_ms: 0.15162673205272575\n",
+      "    mean_env_wait_ms: 1.1539161632482724\n",
+      "    mean_inference_ms: 4.651769602705972\n",
+      "    mean_raw_obs_processing_ms: 0.38694791347460933\n",
+      "  time_since_restore: 505.45633029937744\n",
+      "  time_this_iter_s: 28.391783475875854\n",
+      "  time_total_s: 505.45633029937744\n",
       "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
+      "    learn_throughput: 9360.179\n",
+      "    learn_time_ms: 22180.389\n",
+      "    sample_throughput: 23253.448\n",
+      "    sample_time_ms: 8928.241\n",
+      "    update_time_ms: 37.841\n",
+      "  timestamp: 1602417189\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 3336782\n",
       "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     16 |          505.456 | 3336782 |  223.978 |              274.657 |              123.444 |            879.953 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3575.7503124218947\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-53-42\n",
       "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 878.3544303797469\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 224.32612047504063\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4029\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9905219038327535\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012447120373447735\n",
       "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.040780336658159895\n",
+      "        total_loss: -0.03838996427754561\n",
+      "        vf_explained_var: 0.004459810443222523\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3538890\n",
+      "    num_steps_trained: 3538890\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
+      "    cpu_util_percent: 29.444736842105247\n",
+      "    gpu_util_percent0: 0.23631578947368423\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8815789473684217\n",
+      "    vram_util_percent0: 0.08854067770278436\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
+      "    mean_action_processing_ms: 0.15135937917121595\n",
+      "    mean_env_wait_ms: 1.153707712687943\n",
+      "    mean_inference_ms: 4.635683081493371\n",
+      "    mean_raw_obs_processing_ms: 0.3861319659741516\n",
+      "  time_since_restore: 537.8191299438477\n",
+      "  time_this_iter_s: 32.362799644470215\n",
+      "  time_total_s: 537.8191299438477\n",
       "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
+      "    learn_throughput: 9389.236\n",
+      "    learn_time_ms: 22040.515\n",
+      "    sample_throughput: 23315.521\n",
+      "    sample_time_ms: 8875.787\n",
+      "    update_time_ms: 38.941\n",
+      "  timestamp: 1602417222\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 3538890\n",
       "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     17 |          537.819 | 3538890 |  224.326 |              274.657 |              123.444 |            878.354 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3575.6833411986786\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-54-10\n",
       "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 877.0180496952648\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.28740286124236\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9774724404017131\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014146901729206244\n",
       "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.03988467852274577\n",
+      "        total_loss: -0.03715304508805275\n",
+      "        vf_explained_var: 0.004186526872217655\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3741359\n",
+      "    num_steps_trained: 3741359\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
+      "    cpu_util_percent: 21.02727272727273\n",
+      "    gpu_util_percent0: 0.29666666666666663\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.881818181818182\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
+      "    mean_action_processing_ms: 0.1511129665760311\n",
+      "    mean_env_wait_ms: 1.1535582536116709\n",
+      "    mean_inference_ms: 4.6209747339090015\n",
+      "    mean_raw_obs_processing_ms: 0.3854260879618885\n",
+      "  time_since_restore: 566.2206976413727\n",
+      "  time_this_iter_s: 28.401567697525024\n",
+      "  time_total_s: 566.2206976413727\n",
       "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
+      "    learn_throughput: 9379.571\n",
+      "    learn_time_ms: 22000.569\n",
+      "    sample_throughput: 23171.728\n",
+      "    sample_time_ms: 8905.503\n",
+      "    update_time_ms: 39.081\n",
+      "  timestamp: 1602417250\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 3741359\n",
       "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     18 |          566.221 | 3741359 |  224.287 |              277.232 |              85.2626 |            877.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3576.516648044693\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-54-43\n",
       "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 875.4774594714635\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.30696707245656\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4503\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9596413969993591\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012607416386405628\n",
       "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.041707259913285576\n",
+      "        total_loss: -0.039281741032997766\n",
+      "        vf_explained_var: 0.004265586379915476\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3942275\n",
+      "    num_steps_trained: 3942275\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
+      "    cpu_util_percent: 29.307894736842105\n",
+      "    gpu_util_percent0: 0.23526315789473687\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8789473684210534\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
+      "    mean_action_processing_ms: 0.15088223990719662\n",
+      "    mean_env_wait_ms: 1.1534698963592904\n",
+      "    mean_inference_ms: 4.607334057130936\n",
+      "    mean_raw_obs_processing_ms: 0.3847355330367429\n",
+      "  time_since_restore: 598.7950792312622\n",
+      "  time_this_iter_s: 32.574381589889526\n",
+      "  time_total_s: 598.7950792312622\n",
       "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
+      "    learn_throughput: 9372.684\n",
+      "    learn_time_ms: 21936.833\n",
+      "    sample_throughput: 23204.865\n",
+      "    sample_time_ms: 8860.513\n",
+      "    update_time_ms: 39.379\n",
+      "  timestamp: 1602417283\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 3942275\n",
       "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     19 |          598.795 | 3942275 |  224.307 |              277.232 |              85.2626 |            875.477 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
-      "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3576.162351443124\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-55-11\n",
+      "  done: true\n",
+      "  episode_len_mean: 874.2567510548523\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.31393044367707\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9481419285138448\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014482068829238415\n",
       "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.039214026927947995\n",
+      "        total_loss: -0.03641242695351442\n",
+      "        vf_explained_var: 0.0043367864564061165\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4143977\n",
+      "    num_steps_trained: 4143977\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
+      "    cpu_util_percent: 20.25882352941177\n",
+      "    gpu_util_percent0: 0.28382352941176475\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.870588235294118\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
+      "    mean_action_processing_ms: 0.15066801098261368\n",
+      "    mean_env_wait_ms: 1.1534095476745612\n",
+      "    mean_inference_ms: 4.594729781957195\n",
+      "    mean_raw_obs_processing_ms: 0.38413356668145165\n",
+      "  time_since_restore: 626.9753849506378\n",
+      "  time_this_iter_s: 28.18030571937561\n",
+      "  time_total_s: 626.9753849506378\n",
       "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
+      "    learn_throughput: 9385.705\n",
+      "    learn_time_ms: 21820.576\n",
+      "    sample_throughput: 23107.018\n",
+      "    sample_time_ms: 8863.173\n",
+      "    update_time_ms: 37.45\n",
+      "  timestamp: 1602417311\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 4143977\n",
       "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
-      "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
-      "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
-      "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
-      "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 21705\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_114430-8599p7pd/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_114430-8599p7pd/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3226\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 642\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602417312\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4493\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3575.68334\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 277.23232\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 85.26263\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 224.2874\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4266\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
@@ -4455,3045 +3776,1569 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevoted-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/8599p7pd\u001b[0m\n",
+      "2020-10-11 11:55:20,487 - wandb.wandb_agent - INFO - Cleaning up finished run: 8599p7pd\n",
+      "2020-10-11 11:55:20,800 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:55:20,800 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\tnum_envs_per_worker: 3\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "2020-10-11 11:55:20,804 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=3 --sgd_minibatch_size=12112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 11:55:25,822 - wandb.wandb_agent - INFO - Running runs: ['obb14m0m']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mautumn-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/obb14m0m\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_115522-obb14m0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
+      "2020-10-11 11:55:26,506\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
-      "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
-      "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
-      "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
-      "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
-      "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
-      "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
-      "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
-      "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
-      "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
-      "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
-      "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
-      "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
-      "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "\u001b[2m\u001b[36m(pid=44179)\u001b[0m 2020-10-11 11:55:29,202\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=44167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44049)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44049)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44061)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44061)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4030\n",
+      "    time_step_mean: 3583.3056768558954\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-56-20\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 888.3607594936709\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.509269914333\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
+      "        entropy: 1.1498889724413555\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011335016034233073\n",
       "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.023215793664955225\n",
+      "        total_loss: -0.02106377975724172\n",
+      "        vf_explained_var: 0.004248450044542551\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 280722\n",
+      "    num_steps_trained: 280722\n",
+      "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 31.034545454545455\n",
+      "    gpu_util_percent0: 0.2714545454545455\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.6727272727272737\n",
+      "    vram_util_percent0: 0.06951161334565732\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.1850455764296597\n",
+      "    mean_env_wait_ms: 1.6345806157514586\n",
+      "    mean_inference_ms: 5.489245068106794\n",
+      "    mean_raw_obs_processing_ms: 0.5145279632159141\n",
+      "  time_since_restore: 46.30164980888367\n",
+      "  time_this_iter_s: 46.30164980888367\n",
+      "  time_total_s: 46.30164980888367\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 9169.182\n",
+      "    learn_time_ms: 30615.816\n",
+      "    sample_throughput: 17982.282\n",
+      "    sample_time_ms: 15611.033\n",
+      "    update_time_ms: 43.374\n",
+      "  timestamp: 1602417380\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 280722\n",
+      "  training_iteration: 1\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 29.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      1 |          46.3016 | 280722 |  221.509 |              278.747 |              128.444 |            888.361 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4101\n",
+      "    time_step_mean: 3603.748623853211\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-56-58\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 888.5395569620254\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 219.77595576013275\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
+      "        entropy: 1.1453350683053334\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011886718644139668\n",
       "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.022168729240850855\n",
+      "        total_loss: -0.01990591855913711\n",
+      "        vf_explained_var: 0.0040741912089288235\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 561557\n",
+      "    num_steps_trained: 561557\n",
+      "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 17.58\n",
+      "    gpu_util_percent0: 0.2866666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.075555555555554\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.18290251589096432\n",
+      "    mean_env_wait_ms: 1.6364947535024328\n",
+      "    mean_inference_ms: 5.2985479191377545\n",
+      "    mean_raw_obs_processing_ms: 0.5149596544375026\n",
+      "  time_since_restore: 83.94077706336975\n",
+      "  time_this_iter_s: 37.639127254486084\n",
+      "  time_total_s: 83.94077706336975\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 9208.084\n",
+      "    learn_time_ms: 30492.609\n",
+      "    sample_throughput: 24737.194\n",
+      "    sample_time_ms: 11350.459\n",
+      "    update_time_ms: 69.95\n",
+      "  timestamp: 1602417418\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 561557\n",
+      "  training_iteration: 2\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      2 |          83.9408 | 561557 |  219.776 |              278.747 |              128.444 |             888.54 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4101\n",
+      "    time_step_mean: 3606.842044134727\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-57-36\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.9483122362869\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 219.88895281933233\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        entropy: 1.137641355395317\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011534631601534784\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.024592714238679036\n",
+      "        total_loss: -0.02239955239807993\n",
+      "        vf_explained_var: 0.004056716803461313\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 840827\n",
+      "    num_steps_trained: 840827\n",
+      "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 17.897727272727273\n",
+      "    gpu_util_percent0: 0.28818181818181815\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.093181818181818\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.18135088547015082\n",
+      "    mean_env_wait_ms: 1.6367931106358595\n",
+      "    mean_inference_ms: 5.164214978272677\n",
+      "    mean_raw_obs_processing_ms: 0.5141169991422323\n",
+      "  time_since_restore: 121.53825998306274\n",
+      "  time_this_iter_s: 37.59748291969299\n",
+      "  time_total_s: 121.53825998306274\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 9189.836\n",
+      "    learn_time_ms: 30498.44\n",
+      "    sample_throughput: 28315.706\n",
+      "    sample_time_ms: 9898.24\n",
+      "    update_time_ms: 52.945\n",
+      "  timestamp: 1602417456\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 840827\n",
+      "  training_iteration: 3\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      3 |          121.538 | 840827 |  219.889 |              278.747 |              128.444 |            886.948 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3601.833474936279\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-58-19\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 887.1408227848101\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.29247378851787\n",
+      "  episode_reward_min: 124.80808080808065\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        entropy: 1.1203653862078984\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.010973249096423388\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.03036655376975735\n",
+      "        total_loss: -0.028283940434145432\n",
+      "        vf_explained_var: 0.004029279109090567\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1121346\n",
+      "    num_steps_trained: 1121346\n",
+      "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 26.041176470588233\n",
+      "    gpu_util_percent0: 0.23823529411764702\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.099999999999999\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.17996506470235132\n",
+      "    mean_env_wait_ms: 1.635602059522103\n",
+      "    mean_inference_ms: 5.047362666044733\n",
+      "    mean_raw_obs_processing_ms: 0.5090124430096958\n",
+      "  time_since_restore: 164.9662103652954\n",
+      "  time_this_iter_s: 43.427950382232666\n",
+      "  time_total_s: 164.9662103652954\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 9170.835\n",
+      "    learn_time_ms: 30568.262\n",
+      "    sample_throughput: 26541.764\n",
+      "    sample_time_ms: 10562.09\n",
+      "    update_time_ms: 46.098\n",
+      "  timestamp: 1602417499\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1121346\n",
+      "  training_iteration: 4\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      4 |          164.966 | 1121346 |  220.292 |              278.747 |              124.808 |            887.141 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3602.5679839249833\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-58-57\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.823417721519\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.4628564122233\n",
+      "  episode_reward_min: 124.80808080808065\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        entropy: 1.1207567701737087\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012464039997818569\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.028533178808478016\n",
+      "        total_loss: -0.026152446788425248\n",
+      "        vf_explained_var: 0.0040006861090660095\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1401181\n",
+      "    num_steps_trained: 1401181\n",
+      "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 17.902272727272727\n",
+      "    gpu_util_percent0: 0.30113636363636365\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.111363636363635\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.17896383302840074\n",
+      "    mean_env_wait_ms: 1.6350190478699875\n",
+      "    mean_inference_ms: 4.964221066545625\n",
+      "    mean_raw_obs_processing_ms: 0.5061447750001521\n",
+      "  time_since_restore: 202.75674152374268\n",
+      "  time_this_iter_s: 37.790531158447266\n",
+      "  time_total_s: 202.75674152374268\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 9167.956\n",
+      "    learn_time_ms: 30566.922\n",
+      "    sample_throughput: 28416.145\n",
+      "    sample_time_ms: 9861.866\n",
+      "    update_time_ms: 45.846\n",
+      "  timestamp: 1602417537\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1401181\n",
+      "  training_iteration: 5\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      5 |          202.757 | 1401181 |  220.463 |              278.747 |              124.808 |            886.823 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3601.0978441127695\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-59-35\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.2916666666666\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.40846758726482\n",
+      "  episode_reward_min: 124.80808080808048\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        entropy: 1.1137165029843648\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012430400781643888\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.02917195561652382\n",
+      "        total_loss: -0.0267972470416377\n",
+      "        vf_explained_var: 0.0038985435385257006\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1680409\n",
+      "    num_steps_trained: 1680409\n",
+      "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 17.397826086956524\n",
+      "    gpu_util_percent0: 0.3254347826086956\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.097826086956521\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.17819279339593588\n",
+      "    mean_env_wait_ms: 1.6347406486892524\n",
+      "    mean_inference_ms: 4.9006176255791685\n",
+      "    mean_raw_obs_processing_ms: 0.5043547185293912\n",
+      "  time_since_restore: 240.989196062088\n",
+      "  time_this_iter_s: 38.23245453834534\n",
+      "  time_total_s: 240.989196062088\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 9142.204\n",
+      "    learn_time_ms: 30634.646\n",
+      "    sample_throughput: 29764.438\n",
+      "    sample_time_ms: 9409.49\n",
+      "    update_time_ms: 44.075\n",
+      "  timestamp: 1602417575\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1680409\n",
+      "  training_iteration: 6\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      6 |          240.989 | 1680409 |  220.408 |              278.747 |              124.808 |            886.292 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3597.1651764705884\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-00-18\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 885.2793851717902\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.5339424991322\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.1002877328706824\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.011325264592533526\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.0335009365706988\n",
+      "        total_loss: -0.031345912822238774\n",
+      "        vf_explained_var: 0.004416672978550196\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1958238\n",
+      "    num_steps_trained: 1958238\n",
+      "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 26.717999999999996\n",
+      "    gpu_util_percent0: 0.2668\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.1\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.17755901687885098\n",
+      "    mean_env_wait_ms: 1.6345007099975517\n",
+      "    mean_inference_ms: 4.846980159516488\n",
+      "    mean_raw_obs_processing_ms: 0.501987014030854\n",
+      "  time_since_restore: 283.8285620212555\n",
+      "  time_this_iter_s: 42.83936595916748\n",
+      "  time_total_s: 283.8285620212555\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 9143.769\n",
+      "    learn_time_ms: 30594.416\n",
+      "    sample_throughput: 28443.563\n",
+      "    sample_time_ms: 9835.206\n",
+      "    update_time_ms: 40.913\n",
+      "  timestamp: 1602417618\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1958238\n",
+      "  training_iteration: 7\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      7 |          283.829 | 1958238 |  220.534 |              278.747 |              113.747 |            885.279 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3598.7140516181894\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-00-56\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 884.4426424050633\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.35858186293294\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.096877756326095\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013676803640049437\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
+      "        policy_loss: -0.03535164293387662\n",
+      "        total_loss: -0.03272597078719865\n",
+      "        vf_explained_var: 0.004257147666066885\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2235871\n",
+      "    num_steps_trained: 2235871\n",
+      "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 17.831818181818182\n",
+      "    gpu_util_percent0: 0.32431818181818184\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.104545454545454\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.17704713608540304\n",
+      "    mean_env_wait_ms: 1.6344888227484144\n",
+      "    mean_inference_ms: 4.803596154650865\n",
+      "    mean_raw_obs_processing_ms: 0.5003498748897143\n",
+      "  time_since_restore: 321.2174234390259\n",
+      "  time_this_iter_s: 37.388861417770386\n",
+      "  time_total_s: 321.2174234390259\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 9157.908\n",
+      "    learn_time_ms: 30518.312\n",
+      "    sample_throughput: 29360.764\n",
+      "    sample_time_ms: 9518.958\n",
+      "    update_time_ms: 38.595\n",
+      "  timestamp: 1602417656\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2235871\n",
+      "  training_iteration: 8\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      8 |          321.217 | 2235871 |  220.359 |              278.747 |              113.747 |            884.443 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3597.656510700036\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-01-33\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 883.0225035161744\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.68462046626584\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0881383056225984\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013585189438384512\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.03852763828700003\n",
+      "        total_loss: -0.035919415238110916\n",
+      "        vf_explained_var: 0.004540689755231142\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2511316\n",
+      "    num_steps_trained: 2511316\n",
+      "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 17.75227272727273\n",
+      "    gpu_util_percent0: 0.2977272727272728\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.106818181818181\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.1766138932899392\n",
+      "    mean_env_wait_ms: 1.634674117929501\n",
+      "    mean_inference_ms: 4.76731635971916\n",
+      "    mean_raw_obs_processing_ms: 0.49918007428137373\n",
+      "  time_since_restore: 358.6906907558441\n",
+      "  time_this_iter_s: 37.47326731681824\n",
+      "  time_total_s: 358.6906907558441\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 9150.076\n",
+      "    learn_time_ms: 30495.388\n",
+      "    sample_throughput: 30182.062\n",
+      "    sample_time_ms: 9245.064\n",
+      "    update_time_ms: 37.106\n",
+      "  timestamp: 1602417693\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2511316\n",
+      "  training_iteration: 9\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      9 |          358.691 | 2511316 |  220.685 |              278.747 |              113.747 |            883.023 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4215\n",
+      "    time_step_mean: 3595.9176700292874\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-02-16\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 881.9107594936709\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.00126262626245\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0710049815799878\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.012879531061195808\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.04008249347300633\n",
+      "        total_loss: -0.037613687874830284\n",
+      "        vf_explained_var: 0.004218658898025751\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2786838\n",
+      "    num_steps_trained: 2786838\n",
+      "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 25.368\n",
+      "    gpu_util_percent0: 0.269\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.155999999999999\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.17623708404107602\n",
+      "    mean_env_wait_ms: 1.6348585510257612\n",
+      "    mean_inference_ms: 4.735462499354929\n",
+      "    mean_raw_obs_processing_ms: 0.497773293456692\n",
+      "  time_since_restore: 401.416556596756\n",
+      "  time_this_iter_s: 42.725865840911865\n",
+      "  time_total_s: 401.416556596756\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 9134.744\n",
+      "    learn_time_ms: 30508.114\n",
+      "    sample_throughput: 29272.763\n",
+      "    sample_time_ms: 9520.242\n",
+      "    update_time_ms: 35.492\n",
+      "  timestamp: 1602417736\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2786838\n",
+      "  training_iteration: 10\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     10 |          401.417 | 2786838 |  221.001 |              278.747 |              113.747 |            881.911 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3597.9442313366776\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-02-54\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.8322784810126\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.01004579744492\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0614151177198992\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.014598483422204205\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
-      "  iterations_since_restore: 26\n",
+      "        policy_loss: -0.03986798469787058\n",
+      "        total_loss: -0.037054427939912545\n",
+      "        vf_explained_var: 0.00464921398088336\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3065249\n",
+      "    num_steps_trained: 3065249\n",
+      "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 17.67954545454546\n",
+      "    gpu_util_percent0: 0.2990909090909091\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.118181818181816\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.1759128481241497\n",
+      "    mean_env_wait_ms: 1.6349725954603482\n",
+      "    mean_inference_ms: 4.708035359948134\n",
+      "    mean_raw_obs_processing_ms: 0.49670862692783685\n",
+      "  time_since_restore: 438.9541721343994\n",
+      "  time_this_iter_s: 37.53761553764343\n",
+      "  time_total_s: 438.9541721343994\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 9141.009\n",
+      "    learn_time_ms: 30461.921\n",
+      "    sample_throughput: 32056.087\n",
+      "    sample_time_ms: 8686.422\n",
+      "    update_time_ms: 33.186\n",
+      "  timestamp: 1602417774\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
-      "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 3065249\n",
+      "  training_iteration: 11\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     11 |          438.954 | 3065249 |   221.01 |              278.747 |              113.747 |            881.832 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3598.570310391363\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-03-32\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.9841772151899\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 220.9960682777137\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
+      "        entropy: 1.050734743475914\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014976095058955252\n",
       "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.03998108487576246\n",
+      "        total_loss: -0.037090940323347844\n",
+      "        vf_explained_var: 0.004644361790269613\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3344484\n",
+      "    num_steps_trained: 3344484\n",
+      "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 17.486666666666668\n",
+      "    gpu_util_percent0: 0.3002222222222223\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 4.1\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.17562744223374796\n",
+      "    mean_env_wait_ms: 1.6350209431082054\n",
+      "    mean_inference_ms: 4.684033724789287\n",
+      "    mean_raw_obs_processing_ms: 0.4958815130032957\n",
+      "  time_since_restore: 477.21140122413635\n",
+      "  time_this_iter_s: 38.25722908973694\n",
+      "  time_total_s: 477.21140122413635\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 9121.507\n",
+      "    learn_time_ms: 30509.51\n",
+      "    sample_throughput: 31961.597\n",
+      "    sample_time_ms: 8707.096\n",
+      "    update_time_ms: 26.986\n",
+      "  timestamp: 1602417812\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3344484\n",
+      "  training_iteration: 12\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 30.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     12 |          477.211 | 3344484 |  220.996 |              280.717 |              113.747 |            881.984 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3597.3193235513554\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-04-14\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.5009737098345\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.10606552378684\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0383973173473193\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.012736773928222448\n",
       "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.04211038043317587\n",
+      "        total_loss: -0.039666864859021225\n",
+      "        vf_explained_var: 0.0047072614543139935\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3621206\n",
+      "    num_steps_trained: 3621206\n",
+      "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 25.322448979591837\n",
+      "    gpu_util_percent0: 0.25612244897959185\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.106122448979591\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.17536456076894563\n",
+      "    mean_env_wait_ms: 1.6349960887856891\n",
+      "    mean_inference_ms: 4.66228642078222\n",
+      "    mean_raw_obs_processing_ms: 0.49493808415453816\n",
+      "  time_since_restore: 518.9900712966919\n",
+      "  time_this_iter_s: 41.77867007255554\n",
+      "  time_total_s: 518.9900712966919\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 9131.167\n",
+      "    learn_time_ms: 30449.329\n",
+      "    sample_throughput: 30313.772\n",
+      "    sample_time_ms: 9171.999\n",
+      "    update_time_ms: 27.334\n",
+      "  timestamp: 1602417854\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3621206\n",
+      "  training_iteration: 13\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     13 |           518.99 | 3621206 |  221.106 |              280.717 |              113.747 |            881.501 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3597.7521328106986\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-04-52\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.2936256781194\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.04218952636654\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.027512068333833\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.01544172843189343\n",
       "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.04238511306112227\n",
+      "        total_loss: -0.03939951850992182\n",
+      "        vf_explained_var: 0.004803115967661142\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3898843\n",
+      "    num_steps_trained: 3898843\n",
+      "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 17.724999999999998\n",
+      "    gpu_util_percent0: 0.28863636363636364\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.161363636363635\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.1751304929882504\n",
+      "    mean_env_wait_ms: 1.6349970026484835\n",
+      "    mean_inference_ms: 4.642984068991798\n",
+      "    mean_raw_obs_processing_ms: 0.4941914924419409\n",
+      "  time_since_restore: 556.6893372535706\n",
+      "  time_this_iter_s: 37.69926595687866\n",
+      "  time_total_s: 556.6893372535706\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 9132.229\n",
+      "    learn_time_ms: 30414.227\n",
+      "    sample_throughput: 32191.866\n",
+      "    sample_time_ms: 8627.946\n",
+      "    update_time_ms: 28.222\n",
+      "  timestamp: 1602417892\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3898843\n",
+      "  training_iteration: 14\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 30.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     14 |          556.689 | 3898843 |  221.042 |              280.717 |              111.323 |            881.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3594.7418869546527\n",
+      "    time_step_min: 3253\n",
+      "  date: 2020-10-11_12-05-30\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 880.5643459915611\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.48219537143572\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0142047197922417\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.014221929418651955\n",
       "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.0444475347581117\n",
+      "        total_loss: -0.04170456982177237\n",
+      "        vf_explained_var: 0.004765121731907129\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4173875\n",
+      "    num_steps_trained: 4173875\n",
+      "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 17.822222222222223\n",
+      "    gpu_util_percent0: 0.29511111111111116\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.159999999999998\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.17491832227246704\n",
+      "    mean_env_wait_ms: 1.6350363873996365\n",
+      "    mean_inference_ms: 4.625660054493231\n",
+      "    mean_raw_obs_processing_ms: 0.49358376954629585\n",
+      "  time_since_restore: 594.6191325187683\n",
+      "  time_this_iter_s: 37.929795265197754\n",
+      "  time_total_s: 594.6191325187683\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 9119.693\n",
+      "    learn_time_ms: 30403.368\n",
+      "    sample_throughput: 32047.921\n",
+      "    sample_time_ms: 8651.712\n",
+      "    update_time_ms: 32.297\n",
+      "  timestamp: 1602417930\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 4173875\n",
+      "  training_iteration: 15\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     15 |          594.619 | 4173875 |  221.482 |              280.717 |              111.323 |            880.564 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3592.152747031596\n",
+      "    time_step_min: 3253\n",
+      "  date: 2020-10-11_12-06-12\n",
+      "  done: true\n",
+      "  episode_len_mean: 878.9845727848101\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.9670818149851\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 5056\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0028439604717752\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013268229997028475\n",
       "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.047741330998099366\n",
+      "        total_loss: -0.04518796819383684\n",
+      "        vf_explained_var: 0.00488576153293252\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4444146\n",
+      "    num_steps_trained: 4444146\n",
+      "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 25.287500000000005\n",
+      "    gpu_util_percent0: 0.28729166666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.145833333333333\n",
+      "    vram_util_percent0: 0.08051136984803761\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.17472513275150073\n",
+      "    mean_env_wait_ms: 1.6351745504105002\n",
+      "    mean_inference_ms: 4.6098440361146436\n",
+      "    mean_raw_obs_processing_ms: 0.4928995541379432\n",
+      "  time_since_restore: 636.0357065200806\n",
+      "  time_this_iter_s: 41.416574001312256\n",
+      "  time_total_s: 636.0357065200806\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 9127.445\n",
+      "    learn_time_ms: 30279.415\n",
+      "    sample_throughput: 30390.588\n",
+      "    sample_time_ms: 9094.056\n",
+      "    update_time_ms: 31.128\n",
+      "  timestamp: 1602417972\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 4444146\n",
+      "  training_iteration: 16\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n"
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 43934\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_115522-obb14m0m/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_115522-obb14m0m/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3253\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 650\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602417972\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4321\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3594.74189\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 280.71717\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 111.32323\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 221.4822\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4740\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 15\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mautumn-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/obb14m0m\u001b[0m\n",
+      "2020-10-11 12:06:22,676 - wandb.wandb_agent - INFO - Cleaning up finished run: obb14m0m\n",
+      "2020-10-11 12:06:22,980 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 12:06:22,980 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 3\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "2020-10-11 12:06:22,984 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=3 --sgd_minibatch_size=14112\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent e8gk51z8"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index c91ecc1..4ae84a9 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 16384,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,10 +30,10 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
-    "batch_mode": "truncate_episodes",
+    "batch_mode": "truncated_episodes",
     "observation_filter": "NoFilter",
     "simple_optimizer": False,
     "_fake_gpus": False,
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 73bfae9..d1a379e 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -29,13 +29,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -48,61 +64,30 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
     "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
-    "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
+    "                'values': [1e-4, 5e-5]\n",
     "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'num_envs_per_worker': {\n",
+    "                'values': [2, 3, 4]\n",
     "            },\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [1024, 1536]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-10-25143ac4787e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: e8gk51z8\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\n"
      ]
     }
    ],
@@ -120,1221 +105,1194 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "2020-10-11 11:33:32,913 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 11:33:33,261 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:33:33,261 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "2020-10-11 11:33:33,263 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --sgd_minibatch_size=12112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
+      "2020-10-11 11:33:38,281 - wandb.wandb_agent - INFO - Running runs: ['gyz1jmjx']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gyz1jmjx\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_113335-gyz1jmjx\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 11:33:38,953\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "\u001b[2m\u001b[36m(pid=478)\u001b[0m 2020-10-11 11:33:41,717\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=447)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=447)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=380)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=380)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=440)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=440)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=463)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=463)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=451)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=451)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=453)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=453)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=499)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=499)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=455)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=455)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=470)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=470)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=458)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=458)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=471)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=471)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=449)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=449)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=387)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=387)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=410)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=410)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=438)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=438)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=482)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=482)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=414)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=414)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=434)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=434)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=435)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=435)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=461)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=461)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=454)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=454)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=452)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=452)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=473)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=473)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=400)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=400)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=457)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=457)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=502)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=502)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=444)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=444)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=448)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=448)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=439)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=439)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=450)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=450)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=472)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=472)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=456)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=456)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=445)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=445)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=459)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=459)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=462)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=462)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=433)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=433)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=443)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=443)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=441)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=441)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=446)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=446)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=467)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=467)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=490)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=490)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=374)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=374)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=498)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=498)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.267942583732\n",
+      "    time_step_min: 3363\n",
+      "  date: 2020-10-11_11-34-25\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 889.379746835443\n",
+      "  episode_reward_max: 261.32323232323233\n",
+      "  episode_reward_mean: 217.15624600434705\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
+      "        entropy: 1.1508206791347928\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011506594562282165\n",
       "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        policy_loss: -0.024802520728877023\n",
+      "        total_loss: -0.02261628385167569\n",
+      "        vf_explained_var: 0.004114177543669939\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 210783\n",
+      "    num_steps_trained: 210783\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 33.611111111111114\n",
+      "    gpu_util_percent0: 0.22022222222222218\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.57111111111111\n",
+      "    vram_util_percent0: 0.0693761160307569\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "    mean_action_processing_ms: 0.1636744937338249\n",
+      "    mean_env_wait_ms: 1.174430520550134\n",
+      "    mean_inference_ms: 5.3161623781693\n",
+      "    mean_raw_obs_processing_ms: 0.4152495414106662\n",
+      "  time_since_restore: 37.93847155570984\n",
+      "  time_this_iter_s: 37.93847155570984\n",
+      "  time_total_s: 37.93847155570984\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 8808.281\n",
+      "    learn_time_ms: 23930.096\n",
+      "    sample_throughput: 15134.176\n",
+      "    sample_time_ms: 13927.616\n",
+      "    update_time_ms: 46.272\n",
+      "  timestamp: 1602416065\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 210783\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 27.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      1 |          37.9385 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3620.4843049327355\n",
+      "    time_step_min: 3285\n",
+      "  date: 2020-10-11_11-34-56\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 894.6962025316456\n",
+      "  episode_reward_max: 268.29292929292905\n",
+      "  episode_reward_mean: 215.82137834036547\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
+      "        entropy: 1.1413822571436565\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012332628015428782\n",
       "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02454338926408026\n",
+      "        total_loss: -0.0221910018266903\n",
+      "        vf_explained_var: 0.004096451681107283\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 424086\n",
+      "    num_steps_trained: 424086\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 19.864864864864867\n",
+      "    gpu_util_percent0: 0.2378378378378378\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.851351351351352\n",
+      "    vram_util_percent0: 0.08374256512990523\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.16101945000676418\n",
+      "    mean_env_wait_ms: 1.169159001890284\n",
+      "    mean_inference_ms: 5.163287186706875\n",
+      "    mean_raw_obs_processing_ms: 0.41340410230382457\n",
+      "  time_since_restore: 69.00788903236389\n",
+      "  time_this_iter_s: 31.069417476654053\n",
+      "  time_total_s: 69.00788903236389\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 8801.604\n",
+      "    learn_time_ms: 24091.404\n",
+      "    sample_throughput: 20553.76\n",
+      "    sample_time_ms: 10316.507\n",
+      "    update_time_ms: 44.454\n",
+      "  timestamp: 1602416096\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 424086\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      2 |          69.0079 | 424086 |  215.821 |              268.293 |              133.141 |            894.696 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3628.0805270863834\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-35-32\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 897.2475386779184\n",
+      "  episode_reward_max: 268.89898989898984\n",
+      "  episode_reward_mean: 215.26092145079465\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
+      "        entropy: 1.1282787322998047\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011565119959414005\n",
       "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.02850140682939026\n",
+      "        total_loss: -0.026301210487468377\n",
+      "        vf_explained_var: 0.004243327304720879\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 637943\n",
+      "    num_steps_trained: 637943\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 29.75\n",
+      "    gpu_util_percent0: 0.35547619047619045\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.869047619047619\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.15856108821083387\n",
+      "    mean_env_wait_ms: 1.163652462203573\n",
+      "    mean_inference_ms: 5.0243813341893615\n",
+      "    mean_raw_obs_processing_ms: 0.4064302444759944\n",
+      "  time_since_restore: 105.58087587356567\n",
+      "  time_this_iter_s: 36.57298684120178\n",
+      "  time_total_s: 105.58087587356567\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 8776.554\n",
+      "    learn_time_ms: 24229.062\n",
+      "    sample_throughput: 19555.7\n",
+      "    sample_time_ms: 10873.948\n",
+      "    update_time_ms: 36.401\n",
+      "  timestamp: 1602416132\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 637943\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      3 |          105.581 | 637943 |  215.261 |              268.899 |              133.141 |            897.248 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3626.8021739130436\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-36-04\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 898.785864978903\n",
+      "  episode_reward_max: 268.89898989898984\n",
+      "  episode_reward_mean: 215.9509973149211\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
+      "        entropy: 1.1202221711476643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012885241769254208\n",
       "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.028739885789238744\n",
+      "        total_loss: -0.026274858611739345\n",
+      "        vf_explained_var: 0.004139645025134087\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 852049\n",
+      "    num_steps_trained: 852049\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 19.299999999999997\n",
+      "    gpu_util_percent0: 0.4605263157894737\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8789473684210534\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.15698071319986298\n",
+      "    mean_env_wait_ms: 1.1601976301052868\n",
+      "    mean_inference_ms: 4.9340688951794105\n",
+      "    mean_raw_obs_processing_ms: 0.40318035135376784\n",
+      "  time_since_restore: 137.01121926307678\n",
+      "  time_this_iter_s: 31.43034338951111\n",
+      "  time_total_s: 137.01121926307678\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 8757.236\n",
+      "    learn_time_ms: 24324.143\n",
+      "    sample_throughput: 21655.065\n",
+      "    sample_time_ms: 9836.602\n",
+      "    update_time_ms: 36.012\n",
+      "  timestamp: 1602416164\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 852049\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      4 |          137.011 | 852049 |  215.951 |              268.899 |              133.141 |            898.786 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4177\n",
+      "    time_step_mean: 3627.2143474503023\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-36-40\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 897.9054852320675\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 216.19639432297637\n",
+      "  episode_reward_min: 133.14141414141423\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
+      "        entropy: 1.1091025140550401\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011930530218200551\n",
       "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.03239480613006486\n",
+      "        total_loss: -0.030119610174248617\n",
+      "        vf_explained_var: 0.004592326004058123\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1064018\n",
+      "    num_steps_trained: 1064018\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 29.214285714285708\n",
+      "    gpu_util_percent0: 0.20214285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.885714285714286\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.1557465530250387\n",
+      "    mean_env_wait_ms: 1.1574808450465757\n",
+      "    mean_inference_ms: 4.862228219797691\n",
+      "    mean_raw_obs_processing_ms: 0.39960825263491473\n",
+      "  time_since_restore: 173.09106850624084\n",
+      "  time_this_iter_s: 36.07984924316406\n",
+      "  time_total_s: 173.09106850624084\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 8741.753\n",
+      "    learn_time_ms: 24343.355\n",
+      "    sample_throughput: 20897.294\n",
+      "    sample_time_ms: 10183.309\n",
+      "    update_time_ms: 33.526\n",
+      "  timestamp: 1602416200\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 1064018\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      5 |          173.091 | 1064018 |  216.196 |              269.051 |              133.141 |            897.905 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3625.2769010043044\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-37-11\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 896.626582278481\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 216.61624685675295\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
+      "        entropy: 1.1058683726522658\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013779823668301105\n",
       "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.03383349896305137\n",
+      "        total_loss: -0.031188121686379116\n",
+      "        vf_explained_var: 0.004375427961349487\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1275003\n",
+      "    num_steps_trained: 1275003\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 19.83888888888889\n",
+      "    gpu_util_percent0: 0.32833333333333337\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8916666666666675\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.15480226438213127\n",
+      "    mean_env_wait_ms: 1.1556744661925493\n",
+      "    mean_inference_ms: 4.808124976113362\n",
+      "    mean_raw_obs_processing_ms: 0.3973575039580816\n",
+      "  time_since_restore: 203.9486174583435\n",
+      "  time_this_iter_s: 30.85754895210266\n",
+      "  time_total_s: 203.9486174583435\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 8743.977\n",
+      "    learn_time_ms: 24302.5\n",
+      "    sample_throughput: 22152.544\n",
+      "    sample_time_ms: 9592.6\n",
+      "    update_time_ms: 34.755\n",
+      "  timestamp: 1602416231\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 1275003\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      6 |          203.949 | 1275003 |  216.616 |              269.051 |              117.838 |            896.627 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3622.4530962599633\n",
+      "    time_step_min: 3281\n",
+      "  date: 2020-10-11_11-37-47\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 894.9029535864979\n",
+      "  episode_reward_max: 269.05050505050474\n",
+      "  episode_reward_mean: 217.01651232030957\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
+      "        entropy: 1.0927574502097235\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012546442604313294\n",
       "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.035685616752339736\n",
+      "        total_loss: -0.033285604065491095\n",
+      "        vf_explained_var: 0.0044588083401322365\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1484644\n",
+      "    num_steps_trained: 1484644\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 28.633333333333333\n",
+      "    gpu_util_percent0: 0.28500000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.876190476190477\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.1540133323616834\n",
+      "    mean_env_wait_ms: 1.1544321575145495\n",
+      "    mean_inference_ms: 4.763016603687438\n",
+      "    mean_raw_obs_processing_ms: 0.39503044627312545\n",
+      "  time_since_restore: 239.55271339416504\n",
+      "  time_this_iter_s: 35.60409593582153\n",
+      "  time_total_s: 239.55271339416504\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 8740.909\n",
+      "    learn_time_ms: 24264.294\n",
+      "    sample_throughput: 21534.624\n",
+      "    sample_time_ms: 9848.884\n",
+      "    update_time_ms: 35.412\n",
+      "  timestamp: 1602416267\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 1484644\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      7 |          239.553 | 1484644 |  217.017 |              269.051 |              117.838 |            894.903 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3621.7789079229124\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-38-17\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 892.9240506329114\n",
+      "  episode_reward_max: 274.3535353535355\n",
+      "  episode_reward_mean: 217.11181434599132\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
+      "        entropy: 1.0877870519955952\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014053100616567664\n",
       "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.036782152795543276\n",
+      "        total_loss: -0.03408031062119537\n",
+      "        vf_explained_var: 0.004147387109696865\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1692984\n",
+      "    num_steps_trained: 1692984\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 19.683333333333334\n",
+      "    gpu_util_percent0: 0.30944444444444447\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8916666666666675\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.15337511452129216\n",
+      "    mean_env_wait_ms: 1.1536417821691023\n",
+      "    mean_inference_ms: 4.726508534969858\n",
+      "    mean_raw_obs_processing_ms: 0.39338917198844775\n",
+      "  time_since_restore: 270.2423267364502\n",
+      "  time_this_iter_s: 30.689613342285156\n",
+      "  time_total_s: 270.2423267364502\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 8734.946\n",
+      "    learn_time_ms: 24227.168\n",
+      "    sample_throughput: 22406.357\n",
+      "    sample_time_ms: 9444.775\n",
+      "    update_time_ms: 36.407\n",
+      "  timestamp: 1602416297\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 1692984\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      8 |          270.242 | 1692984 |  217.112 |              274.354 |              117.838 |            892.924 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3619.964370546318\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-38-53\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 892.0590717299579\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.23367287502285\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
+      "        entropy: 1.0724814070595636\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012386405995736519\n",
       "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03819261729303333\n",
+      "        total_loss: -0.03582258429378271\n",
+      "        vf_explained_var: 0.0043792459182441235\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1902762\n",
+      "    num_steps_trained: 1902762\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 29.034146341463412\n",
+      "    gpu_util_percent0: 0.23902439024390246\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.880487804878049\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.1528267206439357\n",
+      "    mean_env_wait_ms: 1.153000049259824\n",
+      "    mean_inference_ms: 4.695004094684524\n",
+      "    mean_raw_obs_processing_ms: 0.39174524064795563\n",
+      "  time_since_restore: 305.92427682876587\n",
+      "  time_this_iter_s: 35.681950092315674\n",
+      "  time_total_s: 305.92427682876587\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 8726.411\n",
+      "    learn_time_ms: 24227.372\n",
+      "    sample_throughput: 21896.229\n",
+      "    sample_time_ms: 9655.452\n",
+      "    update_time_ms: 37.204\n",
+      "  timestamp: 1602416333\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 1902762\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.9/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |      9 |          305.924 | 1902762 |  217.234 |               276.02 |              117.838 |            892.059 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3621.0990606319383\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-39-24\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 891.0700421940928\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.2751566295868\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
+      "        entropy: 1.0645562211672466\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013964535668492317\n",
       "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03785448128150569\n",
+      "        total_loss: -0.03516803009228574\n",
+      "        vf_explained_var: 0.004580974578857422\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2111836\n",
+      "    num_steps_trained: 2111836\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 19.80833333333333\n",
+      "    gpu_util_percent0: 0.3402777777777778\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8888888888888897\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.15236541509539533\n",
+      "    mean_env_wait_ms: 1.1525677384010393\n",
+      "    mean_inference_ms: 4.668415033559\n",
+      "    mean_raw_obs_processing_ms: 0.39051778190252684\n",
+      "  time_since_restore: 336.3577198982239\n",
+      "  time_this_iter_s: 30.433443069458008\n",
+      "  time_total_s: 336.3577198982239\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 8737.509\n",
+      "    learn_time_ms: 24169.773\n",
+      "    sample_throughput: 22569.624\n",
+      "    sample_time_ms: 9356.984\n",
+      "    update_time_ms: 37.424\n",
+      "  timestamp: 1602416364\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 2111836\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     10 |          336.358 | 2111836 |  217.275 |               276.02 |              117.838 |             891.07 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3620.0957735556417\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-39-59\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 889.4353663214423\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.5044344480476\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2607\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
+      "        entropy: 1.0534564057985942\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012721320200297568\n",
       "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.041706488778193794\n",
+      "        total_loss: -0.03926757205691603\n",
+      "        vf_explained_var: 0.0045647090300917625\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2318758\n",
+      "    num_steps_trained: 2318758\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 28.419512195121946\n",
+      "    gpu_util_percent0: 0.2424390243902439\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8756097560975613\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.1519518673022639\n",
+      "    mean_env_wait_ms: 1.152256679175318\n",
+      "    mean_inference_ms: 4.645006252307939\n",
+      "    mean_raw_obs_processing_ms: 0.38928804389411903\n",
+      "  time_since_restore: 371.5491871833801\n",
+      "  time_this_iter_s: 35.19146728515625\n",
+      "  time_total_s: 371.5491871833801\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 8728.437\n",
+      "    learn_time_ms: 24150.659\n",
+      "    sample_throughput: 23167.734\n",
+      "    sample_time_ms: 9098.753\n",
+      "    update_time_ms: 37.269\n",
+      "  timestamp: 1602416399\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 2318758\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     11 |          371.549 | 2318758 |  217.504 |               276.02 |              117.838 |            889.435 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3619.186434659091\n",
+      "    time_step_min: 3245\n",
+      "  date: 2020-10-11_11-40-30\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 887.9982419127989\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.57792055576846\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
+      "        entropy: 1.0404738320244684\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014134101724872986\n",
       "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.03792600789003902\n",
+      "        total_loss: -0.03520323522388935\n",
+      "        vf_explained_var: 0.0047518182545900345\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2525467\n",
+      "    num_steps_trained: 2525467\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 19.44054054054054\n",
+      "    gpu_util_percent0: 0.31675675675675674\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.88918918918919\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.1515918898863825\n",
+      "    mean_env_wait_ms: 1.152054790422858\n",
+      "    mean_inference_ms: 4.624642872725377\n",
+      "    mean_raw_obs_processing_ms: 0.38831806674843455\n",
+      "  time_since_restore: 402.2105643749237\n",
+      "  time_this_iter_s: 30.66137719154358\n",
+      "  time_total_s: 402.2105643749237\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 8716.718\n",
+      "    learn_time_ms: 24107.479\n",
+      "    sample_throughput: 23087.081\n",
+      "    sample_time_ms: 9101.978\n",
+      "    update_time_ms: 36.772\n",
+      "  timestamp: 1602416430\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 2525467\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     12 |          402.211 | 2525467 |  217.578 |               276.02 |              117.838 |            887.998 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3617.957746478873\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-41-04\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 886.2528399870172\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 217.87575855930265\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1343,82 +1301,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
+      "        entropy: 1.0285753292195938\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011995552655528574\n",
       "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.03939158841967583\n",
+      "        total_loss: -0.03709533503826927\n",
+      "        vf_explained_var: 0.004629951901733875\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2730545\n",
+      "    num_steps_trained: 2730545\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 28.517499999999995\n",
+      "    gpu_util_percent0: 0.15775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8875\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.15126712051208008\n",
+      "    mean_env_wait_ms: 1.1519746175500274\n",
+      "    mean_inference_ms: 4.606332420711713\n",
+      "    mean_raw_obs_processing_ms: 0.3873457283671401\n",
+      "  time_since_restore: 436.7092037200928\n",
+      "  time_this_iter_s: 34.49863934516907\n",
+      "  time_total_s: 436.7092037200928\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 8713.26\n",
+      "    learn_time_ms: 24016.292\n",
+      "    sample_throughput: 23298.0\n",
+      "    sample_time_ms: 8981.896\n",
+      "    update_time_ms: 39.203\n",
+      "  timestamp: 1602416464\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 2730545\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     13 |          436.709 | 2730545 |  217.876 |               276.02 |              117.838 |            886.253 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4278\n",
+      "    time_step_mean: 3615.473556231003\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-41-34\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 884.6006630500301\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.18630244579595\n",
+      "  episode_reward_min: 117.83838383838362\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1427,166 +1383,162 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
+      "        entropy: 1.0195737656425028\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014620853204499273\n",
       "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.040181194815565556\n",
+      "        total_loss: -0.03735898172154146\n",
+      "        vf_explained_var: 0.0048517691902816296\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2935105\n",
+      "    num_steps_trained: 2935105\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 20.248571428571434\n",
+      "    gpu_util_percent0: 0.2117142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.15097851241621377\n",
+      "    mean_env_wait_ms: 1.151986226839648\n",
+      "    mean_inference_ms: 4.59004149259784\n",
+      "    mean_raw_obs_processing_ms: 0.38655923185663227\n",
+      "  time_since_restore: 466.56523871421814\n",
+      "  time_this_iter_s: 29.856034994125366\n",
+      "  time_total_s: 466.56523871421814\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 8727.576\n",
+      "    learn_time_ms: 23867.521\n",
+      "    sample_throughput: 23216.942\n",
+      "    sample_time_ms: 8972.138\n",
+      "    update_time_ms: 39.799\n",
+      "  timestamp: 1602416494\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 2935105\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     14 |          466.565 | 2935105 |  218.186 |               276.02 |              117.838 |            884.601 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3615.3926850014177\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-42-09\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 883.6264416315049\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.1418403443718\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
+      "        entropy: 1.0012975103325314\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014535996855960952\n",
       "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03526349003530211\n",
+      "        total_loss: -0.032456420879397124\n",
+      "        vf_explained_var: 0.00504864938557148\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3141292\n",
+      "    num_steps_trained: 3141292\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 28.37317073170731\n",
+      "    gpu_util_percent0: 0.16682926829268294\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.890243902439025\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.1507143981115296\n",
+      "    mean_env_wait_ms: 1.1520130121453596\n",
+      "    mean_inference_ms: 4.575249397096355\n",
+      "    mean_raw_obs_processing_ms: 0.385776842638709\n",
+      "  time_since_restore: 501.3796808719635\n",
+      "  time_this_iter_s: 34.81444215774536\n",
+      "  time_total_s: 501.3796808719635\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 8733.554\n",
+      "    learn_time_ms: 23784.979\n",
+      "    sample_throughput: 23270.813\n",
+      "    sample_time_ms: 8926.521\n",
+      "    update_time_ms: 40.872\n",
+      "  timestamp: 1602416529\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 3141292\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     15 |           501.38 | 3141292 |  218.142 |               276.02 |              115.414 |            883.626 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3615.337407013815\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-42-40\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 882.57805907173\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.2741097685716\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1595,82 +1547,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
+      "        entropy: 0.9924393120933982\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013116635984795936\n",
       "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.036610624479020346\n",
+      "        total_loss: -0.03408654198488768\n",
+      "        vf_explained_var: 0.005047868471592665\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3346736\n",
+      "    num_steps_trained: 3346736\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 19.352777777777778\n",
+      "    gpu_util_percent0: 0.2844444444444444\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8972222222222226\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.15047497998216566\n",
+      "    mean_env_wait_ms: 1.1520761809338669\n",
+      "    mean_inference_ms: 4.561845659716743\n",
+      "    mean_raw_obs_processing_ms: 0.3851282199475179\n",
+      "  time_since_restore: 531.4751350879669\n",
+      "  time_this_iter_s: 30.095454216003418\n",
+      "  time_total_s: 531.4751350879669\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 8734.893\n",
+      "    learn_time_ms: 23717.899\n",
+      "    sample_throughput: 23225.831\n",
+      "    sample_time_ms: 8919.952\n",
+      "    update_time_ms: 38.881\n",
+      "  timestamp: 1602416560\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 3346736\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.9/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     16 |          531.475 | 3346736 |  218.274 |               276.02 |              115.414 |            882.578 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3613.5941014746313\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-43-14\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 881.4896996773393\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.48013267447354\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4029\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1679,82 +1629,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
+      "        entropy: 0.9786315595402437\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012351499815635821\n",
       "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.04146460597129429\n",
+      "        total_loss: -0.03909216941717793\n",
+      "        vf_explained_var: 0.005017775110900402\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3551522\n",
+      "    num_steps_trained: 3551522\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 28.402499999999996\n",
+      "    gpu_util_percent0: 0.28675\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.88\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.15025081057749468\n",
+      "    mean_env_wait_ms: 1.1521409602354007\n",
+      "    mean_inference_ms: 4.549440483702669\n",
+      "    mean_raw_obs_processing_ms: 0.38447308950954834\n",
+      "  time_since_restore: 565.6918759346008\n",
+      "  time_this_iter_s: 34.21674084663391\n",
+      "  time_total_s: 565.6918759346008\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 8753.328\n",
+      "    learn_time_ms: 23612.482\n",
+      "    sample_throughput: 23253.61\n",
+      "    sample_time_ms: 8888.418\n",
+      "    update_time_ms: 36.842\n",
+      "  timestamp: 1602416594\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 3551522\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     17 |          565.692 | 3551522 |   218.48 |               276.02 |              115.414 |             881.49 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3612.9728645587543\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-43-44\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 880.2920768870136\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.76413217974383\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1763,82 +1711,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
+      "        entropy: 0.9642671241479761\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014467166462803589\n",
       "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.041976395227453285\n",
+      "        total_loss: -0.03917938941980109\n",
+      "        vf_explained_var: 0.005014840513467789\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3755326\n",
+      "    num_steps_trained: 3755326\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 19.957142857142856\n",
+      "    gpu_util_percent0: 0.36085714285714293\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.08469990160708428\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.15004368629945075\n",
+      "    mean_env_wait_ms: 1.152218182465942\n",
+      "    mean_inference_ms: 4.53807491236111\n",
+      "    mean_raw_obs_processing_ms: 0.3839184638798795\n",
+      "  time_since_restore: 595.9380519390106\n",
+      "  time_this_iter_s: 30.24617600440979\n",
+      "  time_total_s: 595.9380519390106\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 8751.49\n",
+      "    learn_time_ms: 23565.61\n",
+      "    sample_throughput: 23196.739\n",
+      "    sample_time_ms: 8890.655\n",
+      "    update_time_ms: 36.326\n",
+      "  timestamp: 1602416624\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 3755326\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | RUNNING  | 172.17.0.4:478 |     18 |          595.938 | 3755326 |  218.764 |               276.02 |              115.414 |            880.292 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_9c2e6_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4294\n",
+      "    time_step_mean: 3611.5343016759775\n",
+      "    time_step_min: 3240\n",
+      "  date: 2020-10-11_11-44-18\n",
+      "  done: true\n",
+      "  episode_len_mean: 879.0453031312459\n",
+      "  episode_reward_max: 276.02020202020157\n",
+      "  episode_reward_mean: 218.88085384154653\n",
+      "  episode_reward_min: 115.41414141414138\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4503\n",
+      "  experiment_id: df1157d3fdda43dcb890a3196b2b9b86\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1847,270 +1793,104 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
+      "        entropy: 0.9430958418285146\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.013297418954179567\n",
       "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.04472087937242845\n",
+      "        total_loss: -0.04215570407755235\n",
+      "        vf_explained_var: 0.004909925628453493\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3958341\n",
+      "    num_steps_trained: 3958341\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 27.860000000000003\n",
+      "    gpu_util_percent0: 0.26749999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.8775000000000004\n",
+      "    vram_util_percent0: 0.0846999016070843\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 478\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.1498507029804729\n",
+      "    mean_env_wait_ms: 1.1523313063198106\n",
+      "    mean_inference_ms: 4.527459740401997\n",
+      "    mean_raw_obs_processing_ms: 0.38335573474692985\n",
+      "  time_since_restore: 629.5950663089752\n",
+      "  time_this_iter_s: 33.6570143699646\n",
+      "  time_total_s: 629.5950663089752\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 8771.996\n",
+      "    learn_time_ms: 23433.423\n",
+      "    sample_throughput: 23320.558\n",
+      "    sample_time_ms: 8814.45\n",
+      "    update_time_ms: 41.147\n",
+      "  timestamp: 1602416658\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 3958341\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 9c2e6_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
-      "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
-      "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
+      "| PPO_jss_env_9c2e6_00000 | TERMINATED |       |     19 |          629.595 | 3958341 |  218.881 |               276.02 |              115.414 |            879.045 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 266\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_113335-gyz1jmjx/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_113335-gyz1jmjx/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3245\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 643\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602416658\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4278\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3619.96437\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 276.0202\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 117.83838\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 217.23367\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 2133\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
@@ -2119,2334 +1899,1875 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mspring-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/gyz1jmjx\u001b[0m\n",
+      "2020-10-11 11:44:27,155 - wandb.wandb_agent - INFO - Cleaning up finished run: gyz1jmjx\n",
+      "2020-10-11 11:44:28,704 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:44:28,704 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "2020-10-11 11:44:28,708 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=2 --sgd_minibatch_size=14112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 11:44:33,727 - wandb.wandb_agent - INFO - Running runs: ['8599p7pd']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevoted-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/8599p7pd\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_114430-8599p7pd\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
+      "2020-10-11 11:44:34,497\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "\u001b[2m\u001b[36m(pid=21893)\u001b[0m 2020-10-11 11:44:37,217\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=21919)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21919)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21915)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21915)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21906)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21906)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21925)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21925)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21937)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21937)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21940)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21940)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21932)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21932)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21899)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21899)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21933)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21933)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21926)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21926)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=21878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=21878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.267942583732\n",
+      "    time_step_min: 3363\n",
+      "  date: 2020-10-11_11-45-19\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 889.379746835443\n",
+      "  episode_reward_max: 261.32323232323233\n",
+      "  episode_reward_mean: 217.15624600434705\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1515328645706178\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010727026065190633\n",
       "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        policy_loss: -0.02324618815133969\n",
+      "        total_loss: -0.02121593654155731\n",
+      "        vf_explained_var: 0.0041161575354635715\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 210783\n",
+      "    num_steps_trained: 210783\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
+      "    cpu_util_percent: 35.288636363636364\n",
+      "    gpu_util_percent0: 0.2252272727272727\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5636363636363626\n",
+      "    vram_util_percent0: 0.07299710784459884\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
+      "    mean_action_processing_ms: 0.16648777601686732\n",
+      "    mean_env_wait_ms: 1.172007982092815\n",
+      "    mean_inference_ms: 5.605068870778583\n",
+      "    mean_raw_obs_processing_ms: 0.42467628377691685\n",
+      "  time_since_restore: 37.207940340042114\n",
+      "  time_this_iter_s: 37.207940340042114\n",
+      "  time_total_s: 37.207940340042114\n",
       "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
+      "    learn_throughput: 9291.256\n",
+      "    learn_time_ms: 22686.169\n",
+      "    sample_throughput: 14599.192\n",
+      "    sample_time_ms: 14437.991\n",
+      "    update_time_ms: 40.941\n",
+      "  timestamp: 1602416719\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 210783\n",
       "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 27.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      1 |          37.2079 | 210783 |  217.156 |              261.323 |              145.717 |             889.38 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3621.2399103139014\n",
+      "    time_step_min: 3316\n",
+      "  date: 2020-10-11_11-45-49\n",
       "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 890.4978902953586\n",
+      "  episode_reward_max: 265.2626262626267\n",
+      "  episode_reward_mean: 217.21218514256464\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1433068990707398\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01189851804325978\n",
       "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        policy_loss: -0.02315738166992863\n",
+      "        total_loss: -0.02089200944950183\n",
+      "        vf_explained_var: 0.004307313822209835\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 422096\n",
+      "    num_steps_trained: 422096\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
+      "    cpu_util_percent: 21.04571428571429\n",
+      "    gpu_util_percent0: 0.27942857142857147\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.851428571428572\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
+      "    mean_action_processing_ms: 0.16371548482521198\n",
+      "    mean_env_wait_ms: 1.1686532604347295\n",
+      "    mean_inference_ms: 5.420568834611119\n",
+      "    mean_raw_obs_processing_ms: 0.4220212101908426\n",
+      "  time_since_restore: 66.73374390602112\n",
+      "  time_this_iter_s: 29.525803565979004\n",
+      "  time_total_s: 66.73374390602112\n",
       "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
+      "    learn_throughput: 9293.709\n",
+      "    learn_time_ms: 22708.694\n",
+      "    sample_throughput: 20029.689\n",
+      "    sample_time_ms: 10536.759\n",
+      "    update_time_ms: 64.624\n",
+      "  timestamp: 1602416749\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 422096\n",
       "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      2 |          66.7337 | 422096 |  217.212 |              265.263 |               131.02 |            890.498 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3612.7730600292825\n",
+      "    time_step_min: 3316\n",
+      "  date: 2020-10-11_11-46-23\n",
       "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 888.9957805907173\n",
+      "  episode_reward_max: 265.2626262626267\n",
+      "  episode_reward_mean: 219.07969995311745\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1310136556625365\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.010968415128688017\n",
       "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        policy_loss: -0.026474943245799902\n",
+      "        total_loss: -0.024394361876572172\n",
+      "        vf_explained_var: 0.0043815732933580875\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 632076\n",
+      "    num_steps_trained: 632076\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
+      "    cpu_util_percent: 31.284615384615392\n",
+      "    gpu_util_percent0: 0.2474358974358974\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8717948717948727\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
+      "    mean_action_processing_ms: 0.16112216399976034\n",
+      "    mean_env_wait_ms: 1.165414661820334\n",
+      "    mean_inference_ms: 5.249603295063079\n",
+      "    mean_raw_obs_processing_ms: 0.41388107167270655\n",
+      "  time_since_restore: 101.0947494506836\n",
+      "  time_this_iter_s: 34.361005544662476\n",
+      "  time_total_s: 101.0947494506836\n",
       "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
+      "    learn_throughput: 9336.421\n",
+      "    learn_time_ms: 22566.678\n",
+      "    sample_throughput: 19127.495\n",
+      "    sample_time_ms: 11015.138\n",
+      "    update_time_ms: 54.743\n",
+      "  timestamp: 1602416783\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 632076\n",
       "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      3 |          101.095 | 632076 |   219.08 |              265.263 |               131.02 |            888.996 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3606.198913043478\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-46-53\n",
       "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 889.0622362869199\n",
+      "  episode_reward_max: 272.38383838383766\n",
+      "  episode_reward_mean: 220.0991241529214\n",
+      "  episode_reward_min: 131.02020202020205\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1246707757314047\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012073339087267716\n",
       "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        policy_loss: -0.027101184924443564\n",
+      "        total_loss: -0.024798984949787457\n",
+      "        vf_explained_var: 0.0042299311608076096\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 842831\n",
+      "    num_steps_trained: 842831\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
+      "    cpu_util_percent: 20.19428571428571\n",
+      "    gpu_util_percent0: 0.28\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.882857142857143\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
+      "    mean_action_processing_ms: 0.1594245792140959\n",
+      "    mean_env_wait_ms: 1.1635538804000238\n",
+      "    mean_inference_ms: 5.137971799065908\n",
+      "    mean_raw_obs_processing_ms: 0.40978856844149203\n",
+      "  time_since_restore: 130.50831294059753\n",
+      "  time_this_iter_s: 29.41356348991394\n",
+      "  time_total_s: 130.50831294059753\n",
       "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
+      "    learn_throughput: 9324.53\n",
+      "    learn_time_ms: 22597.143\n",
+      "    sample_throughput: 21248.889\n",
+      "    sample_time_ms: 9916.177\n",
+      "    update_time_ms: 52.503\n",
+      "  timestamp: 1602416813\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 842831\n",
       "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      4 |          130.508 | 842831 |  220.099 |              272.384 |               131.02 |            889.062 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3600.3318928262747\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-47-27\n",
       "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 887.8329113924051\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 220.93338447768807\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1125795602798463\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011277629248797893\n",
       "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        policy_loss: -0.02982374553879102\n",
+      "        total_loss: -0.027679476700723172\n",
+      "        vf_explained_var: 0.004315233323723078\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1052082\n",
+      "    num_steps_trained: 1052082\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
+      "    cpu_util_percent: 30.494871794871795\n",
+      "    gpu_util_percent0: 0.26461538461538464\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.86923076923077\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
+      "    mean_action_processing_ms: 0.15798279899678966\n",
+      "    mean_env_wait_ms: 1.161820158517753\n",
+      "    mean_inference_ms: 5.045335862584878\n",
+      "    mean_raw_obs_processing_ms: 0.4053292285015951\n",
+      "  time_since_restore: 164.11815762519836\n",
+      "  time_this_iter_s: 33.60984468460083\n",
+      "  time_total_s: 164.11815762519836\n",
       "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
+      "    learn_throughput: 9337.496\n",
+      "    learn_time_ms: 22534.565\n",
+      "    sample_throughput: 20668.109\n",
+      "    sample_time_ms: 10180.728\n",
+      "    update_time_ms: 47.822\n",
+      "  timestamp: 1602416847\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 1052082\n",
       "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      5 |          164.118 | 1052082 |  220.933 |              274.657 |              129.505 |            887.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3593.0911047345767\n",
+      "    time_step_min: 3275\n",
+      "  date: 2020-10-11_11-47-56\n",
       "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 886.5386779184248\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 221.70511017346442\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.1075134913126627\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012626525262991588\n",
       "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        policy_loss: -0.029389831672112145\n",
+      "        total_loss: -0.02697527843217055\n",
+      "        vf_explained_var: 0.0045168716460466385\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1260658\n",
+      "    num_steps_trained: 1260658\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
+      "    cpu_util_percent: 19.840000000000003\n",
+      "    gpu_util_percent0: 0.29114285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
+      "    mean_action_processing_ms: 0.15687991735644435\n",
+      "    mean_env_wait_ms: 1.1606285217815193\n",
+      "    mean_inference_ms: 4.975068831532567\n",
+      "    mean_raw_obs_processing_ms: 0.40238811926569734\n",
+      "  time_since_restore: 193.20886325836182\n",
+      "  time_this_iter_s: 29.090705633163452\n",
+      "  time_total_s: 193.20886325836182\n",
       "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
+      "    learn_throughput: 9324.379\n",
+      "    learn_time_ms: 22533.369\n",
+      "    sample_throughput: 21975.909\n",
+      "    sample_time_ms: 9560.909\n",
+      "    update_time_ms: 46.818\n",
+      "  timestamp: 1602416876\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 1260658\n",
       "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      6 |          193.209 | 1260658 |  221.705 |              274.657 |              129.505 |            886.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3591.814837522992\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-48-30\n",
       "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 885.746835443038\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.2184411931245\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0938406944274903\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.011840906552970409\n",
       "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        policy_loss: -0.032349477522075176\n",
+      "        total_loss: -0.030090681153039138\n",
+      "        vf_explained_var: 0.004780403804033995\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1469454\n",
+      "    num_steps_trained: 1469454\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
+      "    cpu_util_percent: 29.6325\n",
+      "    gpu_util_percent0: 0.24625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.88\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
+      "    mean_action_processing_ms: 0.15593363019005474\n",
+      "    mean_env_wait_ms: 1.159485525524178\n",
+      "    mean_inference_ms: 4.915902748379981\n",
+      "    mean_raw_obs_processing_ms: 0.3994958671193922\n",
+      "  time_since_restore: 227.4704246520996\n",
+      "  time_this_iter_s: 34.26156139373779\n",
+      "  time_total_s: 227.4704246520996\n",
       "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
+      "    learn_throughput: 9297.743\n",
+      "    learn_time_ms: 22577.737\n",
+      "    sample_throughput: 21395.999\n",
+      "    sample_time_ms: 9811.274\n",
+      "    update_time_ms: 46.483\n",
+      "  timestamp: 1602416910\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 1469454\n",
       "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      7 |           227.47 | 1469454 |  222.218 |              274.657 |              129.505 |            885.747 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3588.4202355460384\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-48-59\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.915611814346\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.8558048842857\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0879791339238485\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013443161174654961\n",
       "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        policy_loss: -0.032103987659017244\n",
+      "        total_loss: -0.029524152725934984\n",
+      "        vf_explained_var: 0.004608952905982733\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1677800\n",
+      "    num_steps_trained: 1677800\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
+      "    cpu_util_percent: 21.242424242424242\n",
+      "    gpu_util_percent0: 0.2706060606060606\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.884848484848485\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
+      "    mean_action_processing_ms: 0.15516089886252904\n",
+      "    mean_env_wait_ms: 1.1585878747820224\n",
+      "    mean_inference_ms: 4.867907119534596\n",
+      "    mean_raw_obs_processing_ms: 0.39737886686803015\n",
+      "  time_since_restore: 255.9719376564026\n",
+      "  time_this_iter_s: 28.50151300430298\n",
+      "  time_total_s: 255.9719376564026\n",
       "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
+      "    learn_throughput: 9322.664\n",
+      "    learn_time_ms: 22496.253\n",
+      "    sample_throughput: 22327.089\n",
+      "    sample_time_ms: 9393.298\n",
+      "    update_time_ms: 45.451\n",
+      "  timestamp: 1602416939\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 1677800\n",
       "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      8 |          255.972 | 1677800 |  222.856 |              274.657 |              129.505 |            884.916 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3586.915914489311\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-49-32\n",
       "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.29676511955\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.9680205713959\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0769737402598063\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01233778204768896\n",
       "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        policy_loss: -0.03488614509503047\n",
+      "        total_loss: -0.0325262863188982\n",
+      "        vf_explained_var: 0.00442349910736084\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1886205\n",
+      "    num_steps_trained: 1886205\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
+      "    cpu_util_percent: 29.876923076923084\n",
+      "    gpu_util_percent0: 0.22282051282051277\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.882051282051283\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
+      "    mean_action_processing_ms: 0.1544875213558879\n",
+      "    mean_env_wait_ms: 1.1577098829011632\n",
+      "    mean_inference_ms: 4.8263615190470395\n",
+      "    mean_raw_obs_processing_ms: 0.3953101185725302\n",
+      "  time_since_restore: 289.6378767490387\n",
+      "  time_this_iter_s: 33.66593909263611\n",
+      "  time_total_s: 289.6378767490387\n",
       "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
+      "    learn_throughput: 9319.587\n",
+      "    learn_time_ms: 22487.942\n",
+      "    sample_throughput: 21862.84\n",
+      "    sample_time_ms: 9586.053\n",
+      "    update_time_ms: 44.77\n",
+      "  timestamp: 1602416972\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 1886205\n",
       "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |      9 |          289.638 | 1886205 |  222.968 |              274.657 |              129.505 |            884.297 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
+      "    time_step_max: 4191\n",
+      "    time_step_mean: 3585.0764304013665\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-50-02\n",
       "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.3721518987342\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.96387929932214\n",
+      "  episode_reward_min: 129.5050505050504\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0696190357208253\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013751295581459998\n",
       "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        policy_loss: -0.03426021374762058\n",
+      "        total_loss: -0.031616917625069615\n",
+      "        vf_explained_var: 0.00452190637588501\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2095962\n",
+      "    num_steps_trained: 2095962\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
+      "    cpu_util_percent: 20.197142857142858\n",
+      "    gpu_util_percent0: 0.29114285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8885714285714292\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
+      "    mean_action_processing_ms: 0.15392038983954964\n",
+      "    mean_env_wait_ms: 1.1569633633981062\n",
+      "    mean_inference_ms: 4.791379278619612\n",
+      "    mean_raw_obs_processing_ms: 0.3937311631719402\n",
+      "  time_since_restore: 318.9559681415558\n",
+      "  time_this_iter_s: 29.31809139251709\n",
+      "  time_total_s: 318.9559681415558\n",
       "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
+      "    learn_throughput: 9323.01\n",
+      "    learn_time_ms: 22481.602\n",
+      "    sample_throughput: 22522.558\n",
+      "    sample_time_ms: 9306.056\n",
+      "    update_time_ms: 44.808\n",
+      "  timestamp: 1602417002\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 2095962\n",
       "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     10 |          318.956 | 2095962 |  222.964 |              274.657 |              129.505 |            884.372 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3585.993796044979\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-50-35\n",
       "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.6283084004604\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.9485766758492\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2607\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.057764212290446\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01220239649216334\n",
       "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        policy_loss: -0.03655547251303991\n",
+      "        total_loss: -0.03422076975305875\n",
+      "        vf_explained_var: 0.004498771857470274\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2306226\n",
+      "    num_steps_trained: 2306226\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
+      "    cpu_util_percent: 30.079487179487177\n",
+      "    gpu_util_percent0: 0.2520512820512821\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8769230769230782\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
+      "    mean_action_processing_ms: 0.15341774730576713\n",
+      "    mean_env_wait_ms: 1.1562202430781439\n",
+      "    mean_inference_ms: 4.760572667303618\n",
+      "    mean_raw_obs_processing_ms: 0.39219741805542485\n",
+      "  time_since_restore: 352.508731842041\n",
+      "  time_this_iter_s: 33.55276370048523\n",
+      "  time_total_s: 352.508731842041\n",
       "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
+      "    learn_throughput: 9336.916\n",
+      "    learn_time_ms: 22442.561\n",
+      "    sample_throughput: 23337.157\n",
+      "    sample_time_ms: 8978.999\n",
+      "    update_time_ms: 43.492\n",
+      "  timestamp: 1602417035\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 2306226\n",
       "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     11 |          352.509 | 2306226 |  222.949 |              274.657 |              123.444 |            884.628 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3585.416903409091\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-51-05\n",
       "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 884.5847398030942\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 222.99155052636047\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0487373749415079\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.013711805579562981\n",
       "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        policy_loss: -0.03558352831751108\n",
+      "        total_loss: -0.03294604104012251\n",
+      "        vf_explained_var: 0.004443577956408262\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2515759\n",
+      "    num_steps_trained: 2515759\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
+      "    cpu_util_percent: 20.88529411764706\n",
+      "    gpu_util_percent0: 0.27764705882352947\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8852941176470597\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
+      "    mean_action_processing_ms: 0.1529802643731159\n",
+      "    mean_env_wait_ms: 1.1555617141401107\n",
+      "    mean_inference_ms: 4.733817050752962\n",
+      "    mean_raw_obs_processing_ms: 0.39096315453997343\n",
+      "  time_since_restore: 381.7114312648773\n",
+      "  time_this_iter_s: 29.202699422836304\n",
+      "  time_total_s: 381.7114312648773\n",
       "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
+      "    learn_throughput: 9356.622\n",
+      "    learn_time_ms: 22376.27\n",
+      "    sample_throughput: 23221.036\n",
+      "    sample_time_ms: 9016.234\n",
+      "    update_time_ms: 38.55\n",
+      "  timestamp: 1602417065\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 2515759\n",
       "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     12 |          381.711 | 2515759 |  222.992 |              274.657 |              123.444 |            884.585 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3583.670160497871\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-51-38\n",
       "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 883.5699448231094\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.30827259941165\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.037754726409912\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012784661290546258\n",
       "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        policy_loss: -0.03867535578707854\n",
+      "        total_loss: -0.0362221988538901\n",
+      "        vf_explained_var: 0.004530946258455515\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2722279\n",
+      "    num_steps_trained: 2722279\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
+      "    cpu_util_percent: 29.40769230769231\n",
+      "    gpu_util_percent0: 0.23179487179487177\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8743589743589757\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
+      "    mean_action_processing_ms: 0.15258750220895162\n",
+      "    mean_env_wait_ms: 1.1550136761051824\n",
+      "    mean_inference_ms: 4.70990938387223\n",
+      "    mean_raw_obs_processing_ms: 0.3897614970753449\n",
+      "  time_since_restore: 415.17905950546265\n",
+      "  time_this_iter_s: 33.46762824058533\n",
+      "  time_total_s: 415.17905950546265\n",
       "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
+      "    learn_throughput: 9342.752\n",
+      "    learn_time_ms: 22372.456\n",
+      "    sample_throughput: 23405.862\n",
+      "    sample_time_ms: 8930.254\n",
+      "    update_time_ms: 39.067\n",
+      "  timestamp: 1602417098\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 2722279\n",
       "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     13 |          415.179 | 2722279 |  223.308 |              274.657 |              123.444 |             883.57 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3581.2051671732524\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-52-07\n",
       "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 882.2272453285111\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.52833031946935\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.031781538327535\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014422734640538693\n",
       "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        policy_loss: -0.038801763827602066\n",
+      "        total_loss: -0.03602039503554503\n",
+      "        vf_explained_var: 0.004225671291351318\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2927230\n",
+      "    num_steps_trained: 2927230\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
+      "    cpu_util_percent: 20.302941176470586\n",
+      "    gpu_util_percent0: 0.26676470588235296\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8911764705882357\n",
+      "    vram_util_percent0: 0.0879796654640866\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
+      "    mean_action_processing_ms: 0.15223626672918422\n",
+      "    mean_env_wait_ms: 1.1545856441162181\n",
+      "    mean_inference_ms: 4.688645556180501\n",
+      "    mean_raw_obs_processing_ms: 0.38876734649354316\n",
+      "  time_since_restore: 443.92309951782227\n",
+      "  time_this_iter_s: 28.74404001235962\n",
+      "  time_total_s: 443.92309951782227\n",
       "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
+      "    learn_throughput: 9349.416\n",
+      "    learn_time_ms: 22294.429\n",
+      "    sample_throughput: 23308.931\n",
+      "    sample_time_ms: 8942.491\n",
+      "    update_time_ms: 37.278\n",
+      "  timestamp: 1602417127\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 2927230\n",
       "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     14 |          443.923 | 2927230 |  223.528 |              274.657 |              123.444 |            882.227 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3579.850014176354\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-52-40\n",
       "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 881.0486638537271\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.70937220304288\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0202627897262573\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.01260025588174661\n",
       "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        policy_loss: -0.03989621177315712\n",
+      "        total_loss: -0.03747818768024445\n",
+      "        vf_explained_var: 0.0042155226692557335\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3132128\n",
+      "    num_steps_trained: 3132128\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
+      "    cpu_util_percent: 28.925641025641028\n",
+      "    gpu_util_percent0: 0.26538461538461544\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.874358974358975\n",
+      "    vram_util_percent0: 0.08797966546408661\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
+      "    mean_action_processing_ms: 0.15191691646680128\n",
+      "    mean_env_wait_ms: 1.1542151412118906\n",
+      "    mean_inference_ms: 4.669274829623884\n",
+      "    mean_raw_obs_processing_ms: 0.38778296009932195\n",
+      "  time_since_restore: 477.0645468235016\n",
+      "  time_this_iter_s: 33.14144730567932\n",
+      "  time_total_s: 477.0645468235016\n",
       "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
+      "    learn_throughput: 9341.245\n",
+      "    learn_time_ms: 22267.332\n",
+      "    sample_throughput: 23333.802\n",
+      "    sample_time_ms: 8914.304\n",
+      "    update_time_ms: 38.076\n",
+      "  timestamp: 1602417160\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 3132128\n",
       "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     15 |          477.065 | 3132128 |  223.709 |              274.657 |              123.444 |            881.049 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3577.9782146652497\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-53-09\n",
       "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 879.95305907173\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 223.97786408387654\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 1.0082921346028646\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014132832487424215\n",
       "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        policy_loss: -0.03908525543908278\n",
+      "        total_loss: -0.03635951802134514\n",
+      "        vf_explained_var: 0.0040289959870278835\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3336782\n",
+      "    num_steps_trained: 3336782\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
+      "    cpu_util_percent: 20.542424242424243\n",
+      "    gpu_util_percent0: 0.2412121212121212\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.881818181818182\n",
+      "    vram_util_percent0: 0.08797966546408659\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
+      "    mean_action_processing_ms: 0.15162673205272575\n",
+      "    mean_env_wait_ms: 1.1539161632482724\n",
+      "    mean_inference_ms: 4.651769602705972\n",
+      "    mean_raw_obs_processing_ms: 0.38694791347460933\n",
+      "  time_since_restore: 505.45633029937744\n",
+      "  time_this_iter_s: 28.391783475875854\n",
+      "  time_total_s: 505.45633029937744\n",
       "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
+      "    learn_throughput: 9360.179\n",
+      "    learn_time_ms: 22180.389\n",
+      "    sample_throughput: 23253.448\n",
+      "    sample_time_ms: 8928.241\n",
+      "    update_time_ms: 37.841\n",
+      "  timestamp: 1602417189\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 3336782\n",
       "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     16 |          505.456 | 3336782 |  223.978 |              274.657 |              123.444 |            879.953 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
+      "    time_step_max: 4241\n",
+      "    time_step_mean: 3575.7503124218947\n",
+      "    time_step_min: 3247\n",
+      "  date: 2020-10-11_11-53-42\n",
       "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 878.3544303797469\n",
+      "  episode_reward_max: 274.65656565656576\n",
+      "  episode_reward_mean: 224.32612047504063\n",
+      "  episode_reward_min: 123.44444444444436\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4029\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9905219038327535\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012447120373447735\n",
       "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        policy_loss: -0.040780336658159895\n",
+      "        total_loss: -0.03838996427754561\n",
+      "        vf_explained_var: 0.004459810443222523\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3538890\n",
+      "    num_steps_trained: 3538890\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
+      "    cpu_util_percent: 29.444736842105247\n",
+      "    gpu_util_percent0: 0.23631578947368423\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8815789473684217\n",
+      "    vram_util_percent0: 0.08854067770278436\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
+      "    mean_action_processing_ms: 0.15135937917121595\n",
+      "    mean_env_wait_ms: 1.153707712687943\n",
+      "    mean_inference_ms: 4.635683081493371\n",
+      "    mean_raw_obs_processing_ms: 0.3861319659741516\n",
+      "  time_since_restore: 537.8191299438477\n",
+      "  time_this_iter_s: 32.362799644470215\n",
+      "  time_total_s: 537.8191299438477\n",
       "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
+      "    learn_throughput: 9389.236\n",
+      "    learn_time_ms: 22040.515\n",
+      "    sample_throughput: 23315.521\n",
+      "    sample_time_ms: 8875.787\n",
+      "    update_time_ms: 38.941\n",
+      "  timestamp: 1602417222\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 3538890\n",
       "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     17 |          537.819 | 3538890 |  224.326 |              274.657 |              123.444 |            878.354 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3575.6833411986786\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-54-10\n",
       "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 877.0180496952648\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.28740286124236\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9774724404017131\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014146901729206244\n",
       "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.03988467852274577\n",
+      "        total_loss: -0.03715304508805275\n",
+      "        vf_explained_var: 0.004186526872217655\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3741359\n",
+      "    num_steps_trained: 3741359\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
+      "    cpu_util_percent: 21.02727272727273\n",
+      "    gpu_util_percent0: 0.29666666666666663\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.881818181818182\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
+      "    mean_action_processing_ms: 0.1511129665760311\n",
+      "    mean_env_wait_ms: 1.1535582536116709\n",
+      "    mean_inference_ms: 4.6209747339090015\n",
+      "    mean_raw_obs_processing_ms: 0.3854260879618885\n",
+      "  time_since_restore: 566.2206976413727\n",
+      "  time_this_iter_s: 28.401567697525024\n",
+      "  time_total_s: 566.2206976413727\n",
       "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
+      "    learn_throughput: 9379.571\n",
+      "    learn_time_ms: 22000.569\n",
+      "    sample_throughput: 23171.728\n",
+      "    sample_time_ms: 8905.503\n",
+      "    update_time_ms: 39.081\n",
+      "  timestamp: 1602417250\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 3741359\n",
       "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 28.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     18 |          566.221 | 3741359 |  224.287 |              277.232 |              85.2626 |            877.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3576.516648044693\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-54-43\n",
       "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 875.4774594714635\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.30696707245656\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4503\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9596413969993591\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.012607416386405628\n",
       "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.041707259913285576\n",
+      "        total_loss: -0.039281741032997766\n",
+      "        vf_explained_var: 0.004265586379915476\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3942275\n",
+      "    num_steps_trained: 3942275\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
+      "    cpu_util_percent: 29.307894736842105\n",
+      "    gpu_util_percent0: 0.23526315789473687\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.8789473684210534\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
+      "    mean_action_processing_ms: 0.15088223990719662\n",
+      "    mean_env_wait_ms: 1.1534698963592904\n",
+      "    mean_inference_ms: 4.607334057130936\n",
+      "    mean_raw_obs_processing_ms: 0.3847355330367429\n",
+      "  time_since_restore: 598.7950792312622\n",
+      "  time_this_iter_s: 32.574381589889526\n",
+      "  time_total_s: 598.7950792312622\n",
       "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
+      "    learn_throughput: 9372.684\n",
+      "    learn_time_ms: 21936.833\n",
+      "    sample_throughput: 23204.865\n",
+      "    sample_time_ms: 8860.513\n",
+      "    update_time_ms: 39.379\n",
+      "  timestamp: 1602417283\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 3942275\n",
       "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_22e7e_00000 | RUNNING  | 172.17.0.4:21893 |     19 |          598.795 | 3942275 |  224.307 |              277.232 |              85.2626 |            875.477 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_22e7e_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
-      "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "    time_step_max: 4493\n",
+      "    time_step_mean: 3576.162351443124\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_11-55-11\n",
+      "  done: true\n",
+      "  episode_len_mean: 874.2567510548523\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 224.31393044367707\n",
+      "  episode_reward_min: 85.26262626262591\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 84f55d03837049678ee3f548fd31feed\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 0.00010000000000000002\n",
+      "        entropy: 0.9481419285138448\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.014482068829238415\n",
       "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.039214026927947995\n",
+      "        total_loss: -0.03641242695351442\n",
+      "        vf_explained_var: 0.0043367864564061165\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4143977\n",
+      "    num_steps_trained: 4143977\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
+      "    cpu_util_percent: 20.25882352941177\n",
+      "    gpu_util_percent0: 0.28382352941176475\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.870588235294118\n",
+      "    vram_util_percent0: 0.08879960642833716\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 21893\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
+      "    mean_action_processing_ms: 0.15066801098261368\n",
+      "    mean_env_wait_ms: 1.1534095476745612\n",
+      "    mean_inference_ms: 4.594729781957195\n",
+      "    mean_raw_obs_processing_ms: 0.38413356668145165\n",
+      "  time_since_restore: 626.9753849506378\n",
+      "  time_this_iter_s: 28.18030571937561\n",
+      "  time_total_s: 626.9753849506378\n",
       "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
+      "    learn_throughput: 9385.705\n",
+      "    learn_time_ms: 21820.576\n",
+      "    sample_throughput: 23107.018\n",
+      "    sample_time_ms: 8863.173\n",
+      "    update_time_ms: 37.45\n",
+      "  timestamp: 1602417311\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 4143977\n",
       "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
-      "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
-      "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
-      "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
-      "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
-      "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
-      "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
-      "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
+      "  trial_id: 22e7e_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 28.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_22e7e_00000 | TERMINATED |       |     20 |          626.975 | 4143977 |  224.314 |              277.232 |              85.2626 |            874.257 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 21705\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_114430-8599p7pd/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_114430-8599p7pd/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3226\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 642\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602417312\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4493\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3575.68334\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 277.23232\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 85.26263\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 224.2874\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4266\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
@@ -4455,3045 +3776,1569 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevoted-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/8599p7pd\u001b[0m\n",
+      "2020-10-11 11:55:20,487 - wandb.wandb_agent - INFO - Cleaning up finished run: 8599p7pd\n",
+      "2020-10-11 11:55:20,800 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 11:55:20,800 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\tnum_envs_per_worker: 3\n",
+      "\tsgd_minibatch_size: 12112\n",
+      "2020-10-11 11:55:20,804 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=3 --sgd_minibatch_size=12112\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 11:55:25,822 - wandb.wandb_agent - INFO - Running runs: ['obb14m0m']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mautumn-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/e8gk51z8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/obb14m0m\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_115522-obb14m0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
+      "2020-10-11 11:55:26,506\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
-      "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
-      "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
-      "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
-      "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
-      "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
-      "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
-      "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
-      "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
-      "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
-      "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
-      "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
-      "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
-      "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
-      "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
-      "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "\u001b[2m\u001b[36m(pid=44179)\u001b[0m 2020-10-11 11:55:29,202\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=44167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44069)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44049)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44049)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44061)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44061)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44148)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=44178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=44178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4030\n",
+      "    time_step_mean: 3583.3056768558954\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-56-20\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 888.3607594936709\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.509269914333\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
+      "        entropy: 1.1498889724413555\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011335016034233073\n",
       "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.023215793664955225\n",
+      "        total_loss: -0.02106377975724172\n",
+      "        vf_explained_var: 0.004248450044542551\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 280722\n",
+      "    num_steps_trained: 280722\n",
+      "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 31.034545454545455\n",
+      "    gpu_util_percent0: 0.2714545454545455\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.6727272727272737\n",
+      "    vram_util_percent0: 0.06951161334565732\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.1850455764296597\n",
+      "    mean_env_wait_ms: 1.6345806157514586\n",
+      "    mean_inference_ms: 5.489245068106794\n",
+      "    mean_raw_obs_processing_ms: 0.5145279632159141\n",
+      "  time_since_restore: 46.30164980888367\n",
+      "  time_this_iter_s: 46.30164980888367\n",
+      "  time_total_s: 46.30164980888367\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 9169.182\n",
+      "    learn_time_ms: 30615.816\n",
+      "    sample_throughput: 17982.282\n",
+      "    sample_time_ms: 15611.033\n",
+      "    update_time_ms: 43.374\n",
+      "  timestamp: 1602417380\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 280722\n",
+      "  training_iteration: 1\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 29.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      1 |          46.3016 | 280722 |  221.509 |              278.747 |              128.444 |            888.361 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4101\n",
+      "    time_step_mean: 3603.748623853211\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-56-58\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 888.5395569620254\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 219.77595576013275\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
+      "        entropy: 1.1453350683053334\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011886718644139668\n",
       "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.022168729240850855\n",
+      "        total_loss: -0.01990591855913711\n",
+      "        vf_explained_var: 0.0040741912089288235\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 561557\n",
+      "    num_steps_trained: 561557\n",
+      "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 17.58\n",
+      "    gpu_util_percent0: 0.2866666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.075555555555554\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.18290251589096432\n",
+      "    mean_env_wait_ms: 1.6364947535024328\n",
+      "    mean_inference_ms: 5.2985479191377545\n",
+      "    mean_raw_obs_processing_ms: 0.5149596544375026\n",
+      "  time_since_restore: 83.94077706336975\n",
+      "  time_this_iter_s: 37.639127254486084\n",
+      "  time_total_s: 83.94077706336975\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 9208.084\n",
+      "    learn_time_ms: 30492.609\n",
+      "    sample_throughput: 24737.194\n",
+      "    sample_time_ms: 11350.459\n",
+      "    update_time_ms: 69.95\n",
+      "  timestamp: 1602417418\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 561557\n",
+      "  training_iteration: 2\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      2 |          83.9408 | 561557 |  219.776 |              278.747 |              128.444 |             888.54 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4101\n",
+      "    time_step_mean: 3606.842044134727\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-57-36\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.9483122362869\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 219.88895281933233\n",
+      "  episode_reward_min: 128.4444444444439\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        entropy: 1.137641355395317\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011534631601534784\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.024592714238679036\n",
+      "        total_loss: -0.02239955239807993\n",
+      "        vf_explained_var: 0.004056716803461313\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 840827\n",
+      "    num_steps_trained: 840827\n",
+      "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 17.897727272727273\n",
+      "    gpu_util_percent0: 0.28818181818181815\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.093181818181818\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.18135088547015082\n",
+      "    mean_env_wait_ms: 1.6367931106358595\n",
+      "    mean_inference_ms: 5.164214978272677\n",
+      "    mean_raw_obs_processing_ms: 0.5141169991422323\n",
+      "  time_since_restore: 121.53825998306274\n",
+      "  time_this_iter_s: 37.59748291969299\n",
+      "  time_total_s: 121.53825998306274\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 9189.836\n",
+      "    learn_time_ms: 30498.44\n",
+      "    sample_throughput: 28315.706\n",
+      "    sample_time_ms: 9898.24\n",
+      "    update_time_ms: 52.945\n",
+      "  timestamp: 1602417456\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 840827\n",
+      "  training_iteration: 3\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      3 |          121.538 | 840827 |  219.889 |              278.747 |              128.444 |            886.948 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3601.833474936279\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-58-19\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 887.1408227848101\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.29247378851787\n",
+      "  episode_reward_min: 124.80808080808065\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        entropy: 1.1203653862078984\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.010973249096423388\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.03036655376975735\n",
+      "        total_loss: -0.028283940434145432\n",
+      "        vf_explained_var: 0.004029279109090567\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1121346\n",
+      "    num_steps_trained: 1121346\n",
+      "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 26.041176470588233\n",
+      "    gpu_util_percent0: 0.23823529411764702\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.099999999999999\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.17996506470235132\n",
+      "    mean_env_wait_ms: 1.635602059522103\n",
+      "    mean_inference_ms: 5.047362666044733\n",
+      "    mean_raw_obs_processing_ms: 0.5090124430096958\n",
+      "  time_since_restore: 164.9662103652954\n",
+      "  time_this_iter_s: 43.427950382232666\n",
+      "  time_total_s: 164.9662103652954\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 9170.835\n",
+      "    learn_time_ms: 30568.262\n",
+      "    sample_throughput: 26541.764\n",
+      "    sample_time_ms: 10562.09\n",
+      "    update_time_ms: 46.098\n",
+      "  timestamp: 1602417499\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1121346\n",
+      "  training_iteration: 4\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      4 |          164.966 | 1121346 |  220.292 |              278.747 |              124.808 |            887.141 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3602.5679839249833\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-58-57\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.823417721519\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.4628564122233\n",
+      "  episode_reward_min: 124.80808080808065\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        entropy: 1.1207567701737087\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012464039997818569\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.028533178808478016\n",
+      "        total_loss: -0.026152446788425248\n",
+      "        vf_explained_var: 0.0040006861090660095\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1401181\n",
+      "    num_steps_trained: 1401181\n",
+      "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 17.902272727272727\n",
+      "    gpu_util_percent0: 0.30113636363636365\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.111363636363635\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.17896383302840074\n",
+      "    mean_env_wait_ms: 1.6350190478699875\n",
+      "    mean_inference_ms: 4.964221066545625\n",
+      "    mean_raw_obs_processing_ms: 0.5061447750001521\n",
+      "  time_since_restore: 202.75674152374268\n",
+      "  time_this_iter_s: 37.790531158447266\n",
+      "  time_total_s: 202.75674152374268\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 9167.956\n",
+      "    learn_time_ms: 30566.922\n",
+      "    sample_throughput: 28416.145\n",
+      "    sample_time_ms: 9861.866\n",
+      "    update_time_ms: 45.846\n",
+      "  timestamp: 1602417537\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1401181\n",
+      "  training_iteration: 5\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      5 |          202.757 | 1401181 |  220.463 |              278.747 |              124.808 |            886.823 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3601.0978441127695\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_11-59-35\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.2916666666666\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.40846758726482\n",
+      "  episode_reward_min: 124.80808080808048\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        entropy: 1.1137165029843648\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.012430400781643888\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.02917195561652382\n",
+      "        total_loss: -0.0267972470416377\n",
+      "        vf_explained_var: 0.0038985435385257006\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1680409\n",
+      "    num_steps_trained: 1680409\n",
+      "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 17.397826086956524\n",
+      "    gpu_util_percent0: 0.3254347826086956\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.097826086956521\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.17819279339593588\n",
+      "    mean_env_wait_ms: 1.6347406486892524\n",
+      "    mean_inference_ms: 4.9006176255791685\n",
+      "    mean_raw_obs_processing_ms: 0.5043547185293912\n",
+      "  time_since_restore: 240.989196062088\n",
+      "  time_this_iter_s: 38.23245453834534\n",
+      "  time_total_s: 240.989196062088\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 9142.204\n",
+      "    learn_time_ms: 30634.646\n",
+      "    sample_throughput: 29764.438\n",
+      "    sample_time_ms: 9409.49\n",
+      "    update_time_ms: 44.075\n",
+      "  timestamp: 1602417575\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1680409\n",
+      "  training_iteration: 6\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      6 |          240.989 | 1680409 |  220.408 |              278.747 |              124.808 |            886.292 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3597.1651764705884\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-00-18\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 885.2793851717902\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.5339424991322\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.1002877328706824\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.011325264592533526\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.0335009365706988\n",
+      "        total_loss: -0.031345912822238774\n",
+      "        vf_explained_var: 0.004416672978550196\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 1958238\n",
+      "    num_steps_trained: 1958238\n",
+      "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 26.717999999999996\n",
+      "    gpu_util_percent0: 0.2668\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.1\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.17755901687885098\n",
+      "    mean_env_wait_ms: 1.6345007099975517\n",
+      "    mean_inference_ms: 4.846980159516488\n",
+      "    mean_raw_obs_processing_ms: 0.501987014030854\n",
+      "  time_since_restore: 283.8285620212555\n",
+      "  time_this_iter_s: 42.83936595916748\n",
+      "  time_total_s: 283.8285620212555\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 9143.769\n",
+      "    learn_time_ms: 30594.416\n",
+      "    sample_throughput: 28443.563\n",
+      "    sample_time_ms: 9835.206\n",
+      "    update_time_ms: 40.913\n",
+      "  timestamp: 1602417618\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 1958238\n",
+      "  training_iteration: 7\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      7 |          283.829 | 1958238 |  220.534 |              278.747 |              113.747 |            885.279 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3598.7140516181894\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-00-56\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 884.4426424050633\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.35858186293294\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.096877756326095\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013676803640049437\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
+      "        policy_loss: -0.03535164293387662\n",
+      "        total_loss: -0.03272597078719865\n",
+      "        vf_explained_var: 0.004257147666066885\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2235871\n",
+      "    num_steps_trained: 2235871\n",
+      "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 17.831818181818182\n",
+      "    gpu_util_percent0: 0.32431818181818184\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.104545454545454\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.17704713608540304\n",
+      "    mean_env_wait_ms: 1.6344888227484144\n",
+      "    mean_inference_ms: 4.803596154650865\n",
+      "    mean_raw_obs_processing_ms: 0.5003498748897143\n",
+      "  time_since_restore: 321.2174234390259\n",
+      "  time_this_iter_s: 37.388861417770386\n",
+      "  time_total_s: 321.2174234390259\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 9157.908\n",
+      "    learn_time_ms: 30518.312\n",
+      "    sample_throughput: 29360.764\n",
+      "    sample_time_ms: 9518.958\n",
+      "    update_time_ms: 38.595\n",
+      "  timestamp: 1602417656\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2235871\n",
+      "  training_iteration: 8\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      8 |          321.217 | 2235871 |  220.359 |              278.747 |              113.747 |            884.443 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4160\n",
+      "    time_step_mean: 3597.656510700036\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-11_12-01-33\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 883.0225035161744\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 220.68462046626584\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0881383056225984\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013585189438384512\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.03852763828700003\n",
+      "        total_loss: -0.035919415238110916\n",
+      "        vf_explained_var: 0.004540689755231142\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2511316\n",
+      "    num_steps_trained: 2511316\n",
+      "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 17.75227272727273\n",
+      "    gpu_util_percent0: 0.2977272727272728\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.106818181818181\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.1766138932899392\n",
+      "    mean_env_wait_ms: 1.634674117929501\n",
+      "    mean_inference_ms: 4.76731635971916\n",
+      "    mean_raw_obs_processing_ms: 0.49918007428137373\n",
+      "  time_since_restore: 358.6906907558441\n",
+      "  time_this_iter_s: 37.47326731681824\n",
+      "  time_total_s: 358.6906907558441\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 9150.076\n",
+      "    learn_time_ms: 30495.388\n",
+      "    sample_throughput: 30182.062\n",
+      "    sample_time_ms: 9245.064\n",
+      "    update_time_ms: 37.106\n",
+      "  timestamp: 1602417693\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2511316\n",
+      "  training_iteration: 9\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |      9 |          358.691 | 2511316 |  220.685 |              278.747 |              113.747 |            883.023 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4215\n",
+      "    time_step_mean: 3595.9176700292874\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-02-16\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 881.9107594936709\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.00126262626245\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0710049815799878\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.012879531061195808\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.04008249347300633\n",
+      "        total_loss: -0.037613687874830284\n",
+      "        vf_explained_var: 0.004218658898025751\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 2786838\n",
+      "    num_steps_trained: 2786838\n",
+      "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 25.368\n",
+      "    gpu_util_percent0: 0.269\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.155999999999999\n",
+      "    vram_util_percent0: 0.0802722204001312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.17623708404107602\n",
+      "    mean_env_wait_ms: 1.6348585510257612\n",
+      "    mean_inference_ms: 4.735462499354929\n",
+      "    mean_raw_obs_processing_ms: 0.497773293456692\n",
+      "  time_since_restore: 401.416556596756\n",
+      "  time_this_iter_s: 42.725865840911865\n",
+      "  time_total_s: 401.416556596756\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 9134.744\n",
+      "    learn_time_ms: 30508.114\n",
+      "    sample_throughput: 29272.763\n",
+      "    sample_time_ms: 9520.242\n",
+      "    update_time_ms: 35.492\n",
+      "  timestamp: 1602417736\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 2786838\n",
+      "  training_iteration: 10\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 30.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     10 |          401.417 | 2786838 |  221.001 |              278.747 |              113.747 |            881.911 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3597.9442313366776\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-02-54\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.8322784810126\n",
+      "  episode_reward_max: 278.74747474747426\n",
+      "  episode_reward_mean: 221.01004579744492\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0614151177198992\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.014598483422204205\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
-      "  iterations_since_restore: 26\n",
+      "        policy_loss: -0.03986798469787058\n",
+      "        total_loss: -0.037054427939912545\n",
+      "        vf_explained_var: 0.00464921398088336\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3065249\n",
+      "    num_steps_trained: 3065249\n",
+      "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 17.67954545454546\n",
+      "    gpu_util_percent0: 0.2990909090909091\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 4.118181818181816\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.1759128481241497\n",
+      "    mean_env_wait_ms: 1.6349725954603482\n",
+      "    mean_inference_ms: 4.708035359948134\n",
+      "    mean_raw_obs_processing_ms: 0.49670862692783685\n",
+      "  time_since_restore: 438.9541721343994\n",
+      "  time_this_iter_s: 37.53761553764343\n",
+      "  time_total_s: 438.9541721343994\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 9141.009\n",
+      "    learn_time_ms: 30461.921\n",
+      "    sample_throughput: 32056.087\n",
+      "    sample_time_ms: 8686.422\n",
+      "    update_time_ms: 33.186\n",
+      "  timestamp: 1602417774\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
-      "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  timesteps_total: 3065249\n",
+      "  training_iteration: 11\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     11 |          438.954 | 3065249 |   221.01 |              278.747 |              113.747 |            881.832 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3598.570310391363\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-03-32\n",
       "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.9841772151899\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 220.9960682777137\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
+      "        entropy: 1.050734743475914\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.014976095058955252\n",
       "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.03998108487576246\n",
+      "        total_loss: -0.037090940323347844\n",
+      "        vf_explained_var: 0.004644361790269613\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3344484\n",
+      "    num_steps_trained: 3344484\n",
+      "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 17.486666666666668\n",
+      "    gpu_util_percent0: 0.3002222222222223\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 4.1\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.17562744223374796\n",
+      "    mean_env_wait_ms: 1.6350209431082054\n",
+      "    mean_inference_ms: 4.684033724789287\n",
+      "    mean_raw_obs_processing_ms: 0.4958815130032957\n",
+      "  time_since_restore: 477.21140122413635\n",
+      "  time_this_iter_s: 38.25722908973694\n",
+      "  time_total_s: 477.21140122413635\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 9121.507\n",
+      "    learn_time_ms: 30509.51\n",
+      "    sample_throughput: 31961.597\n",
+      "    sample_time_ms: 8707.096\n",
+      "    update_time_ms: 26.986\n",
+      "  timestamp: 1602417812\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3344484\n",
+      "  training_iteration: 12\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 30.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     12 |          477.211 | 3344484 |  220.996 |              280.717 |              113.747 |            881.984 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4277\n",
+      "    time_step_mean: 3597.3193235513554\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-04-14\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.5009737098345\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.10606552378684\n",
+      "  episode_reward_min: 113.74747474747444\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0383973173473193\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.012736773928222448\n",
       "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.04211038043317587\n",
+      "        total_loss: -0.039666864859021225\n",
+      "        vf_explained_var: 0.0047072614543139935\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3621206\n",
+      "    num_steps_trained: 3621206\n",
+      "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 25.322448979591837\n",
+      "    gpu_util_percent0: 0.25612244897959185\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.106122448979591\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.17536456076894563\n",
+      "    mean_env_wait_ms: 1.6349960887856891\n",
+      "    mean_inference_ms: 4.66228642078222\n",
+      "    mean_raw_obs_processing_ms: 0.49493808415453816\n",
+      "  time_since_restore: 518.9900712966919\n",
+      "  time_this_iter_s: 41.77867007255554\n",
+      "  time_total_s: 518.9900712966919\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 9131.167\n",
+      "    learn_time_ms: 30449.329\n",
+      "    sample_throughput: 30313.772\n",
+      "    sample_time_ms: 9171.999\n",
+      "    update_time_ms: 27.334\n",
+      "  timestamp: 1602417854\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3621206\n",
+      "  training_iteration: 13\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     13 |           518.99 | 3621206 |  221.106 |              280.717 |              113.747 |            881.501 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3597.7521328106986\n",
+      "    time_step_min: 3255\n",
+      "  date: 2020-10-11_12-04-52\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 881.2936256781194\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.04218952636654\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.027512068333833\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.01544172843189343\n",
       "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.04238511306112227\n",
+      "        total_loss: -0.03939951850992182\n",
+      "        vf_explained_var: 0.004803115967661142\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 3898843\n",
+      "    num_steps_trained: 3898843\n",
+      "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 17.724999999999998\n",
+      "    gpu_util_percent0: 0.28863636363636364\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.161363636363635\n",
+      "    vram_util_percent0: 0.08027222040013121\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.1751304929882504\n",
+      "    mean_env_wait_ms: 1.6349970026484835\n",
+      "    mean_inference_ms: 4.642984068991798\n",
+      "    mean_raw_obs_processing_ms: 0.4941914924419409\n",
+      "  time_since_restore: 556.6893372535706\n",
+      "  time_this_iter_s: 37.69926595687866\n",
+      "  time_total_s: 556.6893372535706\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 9132.229\n",
+      "    learn_time_ms: 30414.227\n",
+      "    sample_throughput: 32191.866\n",
+      "    sample_time_ms: 8627.946\n",
+      "    update_time_ms: 28.222\n",
+      "  timestamp: 1602417892\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 3898843\n",
+      "  training_iteration: 14\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 30.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     14 |          556.689 | 3898843 |  221.042 |              280.717 |              111.323 |            881.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3594.7418869546527\n",
+      "    time_step_min: 3253\n",
+      "  date: 2020-10-11_12-05-30\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 880.5643459915611\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.48219537143572\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0142047197922417\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.014221929418651955\n",
       "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.0444475347581117\n",
+      "        total_loss: -0.04170456982177237\n",
+      "        vf_explained_var: 0.004765121731907129\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4173875\n",
+      "    num_steps_trained: 4173875\n",
+      "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 17.822222222222223\n",
+      "    gpu_util_percent0: 0.29511111111111116\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.159999999999998\n",
+      "    vram_util_percent0: 0.08027222040013123\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.17491832227246704\n",
+      "    mean_env_wait_ms: 1.6350363873996365\n",
+      "    mean_inference_ms: 4.625660054493231\n",
+      "    mean_raw_obs_processing_ms: 0.49358376954629585\n",
+      "  time_since_restore: 594.6191325187683\n",
+      "  time_this_iter_s: 37.929795265197754\n",
+      "  time_total_s: 594.6191325187683\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 9119.693\n",
+      "    learn_time_ms: 30403.368\n",
+      "    sample_throughput: 32047.921\n",
+      "    sample_time_ms: 8651.712\n",
+      "    update_time_ms: 32.297\n",
+      "  timestamp: 1602417930\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 4173875\n",
+      "  training_iteration: 15\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | RUNNING  | 172.17.0.4:44179 |     15 |          594.619 | 4173875 |  221.482 |              280.717 |              111.323 |            880.564 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_a7863_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "    time_step_max: 4321\n",
+      "    time_step_mean: 3592.152747031596\n",
+      "    time_step_min: 3253\n",
+      "  date: 2020-10-11_12-06-12\n",
+      "  done: true\n",
+      "  episode_len_mean: 878.9845727848101\n",
+      "  episode_reward_max: 280.7171717171717\n",
+      "  episode_reward_mean: 221.9670818149851\n",
+      "  episode_reward_min: 111.32323232323223\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 5056\n",
+      "  experiment_id: 4edd8c230375465cb0cfd8b8cad86c2d\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
+      "        cur_kl_coeff: 0.20000000000000007\n",
+      "        cur_lr: 9.999999999999998e-05\n",
+      "        entropy: 1.0028439604717752\n",
+      "        entropy_coeff: 9.999999999999998e-05\n",
+      "        kl: 0.013268229997028475\n",
       "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.047741330998099366\n",
+      "        total_loss: -0.04518796819383684\n",
+      "        vf_explained_var: 0.00488576153293252\n",
+      "        vf_loss: 0.0\n",
+      "    num_steps_sampled: 4444146\n",
+      "    num_steps_trained: 4444146\n",
+      "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 25.287500000000005\n",
+      "    gpu_util_percent0: 0.28729166666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 4.145833333333333\n",
+      "    vram_util_percent0: 0.08051136984803761\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 44179\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.17472513275150073\n",
+      "    mean_env_wait_ms: 1.6351745504105002\n",
+      "    mean_inference_ms: 4.6098440361146436\n",
+      "    mean_raw_obs_processing_ms: 0.4928995541379432\n",
+      "  time_since_restore: 636.0357065200806\n",
+      "  time_this_iter_s: 41.416574001312256\n",
+      "  time_total_s: 636.0357065200806\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 9127.445\n",
+      "    learn_time_ms: 30279.415\n",
+      "    sample_throughput: 30390.588\n",
+      "    sample_time_ms: 9094.056\n",
+      "    update_time_ms: 31.128\n",
+      "  timestamp: 1602417972\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 4444146\n",
+      "  training_iteration: 16\n",
+      "  trial_id: a7863_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 30.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a7863_00000 | TERMINATED |       |     16 |          636.036 | 4444146 |  221.967 |              280.717 |              111.323 |            878.985 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n"
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 43934\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_115522-obb14m0m/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_115522-obb14m0m/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3253\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 650\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602417972\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4321\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3594.74189\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 280.71717\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 111.32323\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 221.4822\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4740\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 15\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mautumn-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/obb14m0m\u001b[0m\n",
+      "2020-10-11 12:06:22,676 - wandb.wandb_agent - INFO - Cleaning up finished run: obb14m0m\n",
+      "2020-10-11 12:06:22,980 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 12:06:22,980 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 3\n",
+      "\tsgd_minibatch_size: 14112\n",
+      "2020-10-11 12:06:22,984 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --lr=0.0001 --num_envs_per_worker=3 --sgd_minibatch_size=14112\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent e8gk51z8"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index 768b7fd..86b66e4 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index c91ecc1..4ae84a9 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 16384,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,10 +30,10 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
-    "batch_mode": "truncate_episodes",
+    "batch_mode": "truncated_episodes",
     "observation_filter": "NoFilter",
     "simple_optimizer": False,
     "_fake_gpus": False,
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 593fb77..513886b 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug-internal.log
\ No newline at end of file
+run-20201011_120830-s80df03h/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4ee8a74..5a195d1 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug.log
\ No newline at end of file
+run-20201011_120830-s80df03h/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 086031d..7f12a26 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef
\ No newline at end of file
+run-20201011_120830-s80df03h
\ No newline at end of file
