2020-10-11 23:41:16,622	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_422e5_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=74870)[0m 2020-10-11 23:41:19,385	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=74876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=74810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=74810)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_23-41-57
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1749379734198253
        entropy_coeff: 0.0005000000000000001
        kl: 0.014915107749402523
        model: {}
        policy_loss: -0.012841106062599769
        total_loss: 502.2347869873047
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.01578947368421
    gpu_util_percent0: 0.2763157894736842
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.573684210526315
    vram_util_percent0: 0.08826448706219472
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17036038145823185
    mean_env_wait_ms: 1.1712881207797363
    mean_inference_ms: 6.047083668298064
    mean_raw_obs_processing_ms: 0.4565913914971677
  time_since_restore: 32.34275722503662
  time_this_iter_s: 32.34275722503662
  time_total_s: 32.34275722503662
  timers:
    learn_throughput: 7105.739
    learn_time_ms: 22769.2
    sample_throughput: 17058.606
    sample_time_ms: 9484.479
    update_time_ms: 53.791
  timestamp: 1602459717
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      1 |          32.3428 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3628.097222222222
    time_step_min: 3331
  date: 2020-10-11_23-42-27
  done: false
  episode_len_mean: 887.8607594936709
  episode_reward_max: 261.323232323232
  episode_reward_mean: 215.8763585219279
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.139811744292577
        entropy_coeff: 0.0005000000000000001
        kl: 0.017986326788862545
        model: {}
        policy_loss: -0.013638543197885156
        total_loss: 127.81331125895183
        vf_explained_var: 0.8170010447502136
        vf_loss: 127.82571792602539
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.6
    gpu_util_percent0: 0.4122857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7628571428571433
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.166454355222357
    mean_env_wait_ms: 1.1689178776375595
    mean_inference_ms: 5.768923029413746
    mean_raw_obs_processing_ms: 0.44770385556880093
  time_since_restore: 62.72855734825134
  time_this_iter_s: 30.38580012321472
  time_total_s: 62.72855734825134
  timers:
    learn_throughput: 7167.509
    learn_time_ms: 22572.976
    sample_throughput: 18582.355
    sample_time_ms: 8706.755
    update_time_ms: 40.265
  timestamp: 1602459747
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      2 |          62.7286 | 323584 |  215.876 |              261.323 |              113.444 |            887.861 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3621.6681614349777
    time_step_min: 3331
  date: 2020-10-11_23-42-57
  done: false
  episode_len_mean: 882.0316455696203
  episode_reward_max: 261.323232323232
  episode_reward_mean: 216.40538294335738
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1197276711463928
        entropy_coeff: 0.0005000000000000001
        kl: 0.022316985297948122
        model: {}
        policy_loss: -0.018337606607625883
        total_loss: 51.719415028889976
        vf_explained_var: 0.9125759601593018
        vf_loss: 51.73607953389486
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.17714285714286
    gpu_util_percent0: 0.29571428571428576
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16369164109558906
    mean_env_wait_ms: 1.1696337831020505
    mean_inference_ms: 5.5616207472519505
    mean_raw_obs_processing_ms: 0.4392472224647995
  time_since_restore: 92.70779371261597
  time_this_iter_s: 29.979236364364624
  time_total_s: 92.70779371261597
  timers:
    learn_throughput: 7163.447
    learn_time_ms: 22585.774
    sample_throughput: 19658.292
    sample_time_ms: 8230.216
    update_time_ms: 41.063
  timestamp: 1602459777
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      3 |          92.7078 | 485376 |  216.405 |              261.323 |              113.444 |            882.032 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3612.3509933774835
    time_step_min: 3318
  date: 2020-10-11_23-43-27
  done: false
  episode_len_mean: 878.3164556962025
  episode_reward_max: 266.7777777777775
  episode_reward_mean: 217.76646208924672
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.09677458802859
        entropy_coeff: 0.0005000000000000001
        kl: 0.015250708364571134
        model: {}
        policy_loss: -0.018054722885911662
        total_loss: 36.57729307810465
        vf_explained_var: 0.9356148838996887
        vf_loss: 36.59360980987549
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.894285714285715
    gpu_util_percent0: 0.32800000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428567
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16157008646882237
    mean_env_wait_ms: 1.1700769183804967
    mean_inference_ms: 5.40397915750753
    mean_raw_obs_processing_ms: 0.43203178311261764
  time_since_restore: 122.32512521743774
  time_this_iter_s: 29.617331504821777
  time_total_s: 122.32512521743774
  timers:
    learn_throughput: 7169.859
    learn_time_ms: 22565.575
    sample_throughput: 20458.319
    sample_time_ms: 7908.372
    update_time_ms: 39.695
  timestamp: 1602459807
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      4 |          122.325 | 647168 |  217.766 |              266.778 |              113.444 |            878.316 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3605.799738219895
    time_step_min: 3318
  date: 2020-10-11_23-43-56
  done: false
  episode_len_mean: 872.5593434343434
  episode_reward_max: 272.686868686868
  episode_reward_mean: 219.6181129476582
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 160
  episodes_total: 792
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0487651030222576
        entropy_coeff: 0.0005000000000000001
        kl: 0.014568340964615345
        model: {}
        policy_loss: -0.016317967597084742
        total_loss: 31.082906087239582
        vf_explained_var: 0.9520482420921326
        vf_loss: 31.09756326675415
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.179411764705883
    gpu_util_percent0: 0.33
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1599197395050162
    mean_env_wait_ms: 1.1717233170670964
    mean_inference_ms: 5.280967212690017
    mean_raw_obs_processing_ms: 0.4261519590028104
  time_since_restore: 151.74910163879395
  time_this_iter_s: 29.4239764213562
  time_total_s: 151.74910163879395
  timers:
    learn_throughput: 7169.515
    learn_time_ms: 22566.659
    sample_throughput: 21068.636
    sample_time_ms: 7679.282
    update_time_ms: 39.479
  timestamp: 1602459836
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      5 |          151.749 | 808960 |  219.618 |              272.687 |              113.444 |            872.559 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3578.4554730983305
    time_step_min: 3239
  date: 2020-10-11_23-44-26
  done: false
  episode_len_mean: 860.9285714285714
  episode_reward_max: 280.11111111111114
  episode_reward_mean: 224.2211993351232
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 314
  episodes_total: 1106
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0329186220963795
        entropy_coeff: 0.0005000000000000001
        kl: 0.012543960862482587
        model: {}
        policy_loss: -0.017247718967458543
        total_loss: 24.60704771677653
        vf_explained_var: 0.9674283862113953
        vf_loss: 24.62293020884196
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.741176470588236
    gpu_util_percent0: 0.2723529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294118
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576837837105046
    mean_env_wait_ms: 1.1758510426859312
    mean_inference_ms: 5.115442332814513
    mean_raw_obs_processing_ms: 0.41842623886544245
  time_since_restore: 181.1036195755005
  time_this_iter_s: 29.354517936706543
  time_total_s: 181.1036195755005
  timers:
    learn_throughput: 7176.203
    learn_time_ms: 22545.626
    sample_throughput: 21472.933
    sample_time_ms: 7534.695
    update_time_ms: 39.285
  timestamp: 1602459866
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      6 |          181.104 | 970752 |  224.221 |              280.111 |              113.444 |            860.929 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3565.2710355987056
    time_step_min: 3239
  date: 2020-10-11_23-44-55
  done: false
  episode_len_mean: 855.056170886076
  episode_reward_max: 280.11111111111114
  episode_reward_mean: 226.3022551464006
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 1.0148684581120808
        entropy_coeff: 0.0005000000000000001
        kl: 0.012296080977345506
        model: {}
        policy_loss: -0.01417262714918858
        total_loss: 14.94414766629537
        vf_explained_var: 0.971426784992218
        vf_loss: 14.956983009974161
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.68529411764706
    gpu_util_percent0: 0.3391176470588236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15687019840658484
    mean_env_wait_ms: 1.1778235752842148
    mean_inference_ms: 5.05497176970267
    mean_raw_obs_processing_ms: 0.41558267556717643
  time_since_restore: 210.46036410331726
  time_this_iter_s: 29.356744527816772
  time_total_s: 210.46036410331726
  timers:
    learn_throughput: 7180.436
    learn_time_ms: 22532.337
    sample_throughput: 21764.087
    sample_time_ms: 7433.898
    update_time_ms: 36.531
  timestamp: 1602459895
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      7 |           210.46 | 1132544 |  226.302 |              280.111 |              113.444 |            855.056 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3552.641319942611
    time_step_min: 3239
  date: 2020-10-11_23-45-24
  done: false
  episode_len_mean: 849.6364275668074
  episode_reward_max: 280.11111111111114
  episode_reward_mean: 228.12820184972068
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9781733254591624
        entropy_coeff: 0.0005000000000000001
        kl: 0.01218931896922489
        model: {}
        policy_loss: -0.017550693242810667
        total_loss: 14.27057965596517
        vf_explained_var: 0.9708757400512695
        vf_loss: 14.28679084777832
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.758823529411767
    gpu_util_percent0: 0.39
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15617550477986009
    mean_env_wait_ms: 1.1797380898214689
    mean_inference_ms: 5.002465934795379
    mean_raw_obs_processing_ms: 0.4130529688400258
  time_since_restore: 239.58223724365234
  time_this_iter_s: 29.121873140335083
  time_total_s: 239.58223724365234
  timers:
    learn_throughput: 7193.035
    learn_time_ms: 22492.869
    sample_throughput: 21985.656
    sample_time_ms: 7358.98
    update_time_ms: 34.45
  timestamp: 1602459924
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      8 |          239.582 | 1294336 |  228.128 |              280.111 |              113.444 |            849.636 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3539.7421383647797
    time_step_min: 3196
  date: 2020-10-11_23-45-54
  done: false
  episode_len_mean: 843.791718170581
  episode_reward_max: 281.77777777777743
  episode_reward_mean: 230.00697956074947
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 196
  episodes_total: 1618
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.926913266380628
        entropy_coeff: 0.0005000000000000001
        kl: 0.011109292041510344
        model: {}
        policy_loss: -0.014818127026956063
        total_loss: 18.62913449605306
        vf_explained_var: 0.9720422625541687
        vf_loss: 18.642749786376953
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.02352941176471
    gpu_util_percent0: 0.30470588235294116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7676470588235293
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15543265715259413
    mean_env_wait_ms: 1.1821795047397505
    mean_inference_ms: 4.946523569485682
    mean_raw_obs_processing_ms: 0.41027311915558295
  time_since_restore: 268.8486797809601
  time_this_iter_s: 29.26644253730774
  time_total_s: 268.8486797809601
  timers:
    learn_throughput: 7196.114
    learn_time_ms: 22483.245
    sample_throughput: 22177.308
    sample_time_ms: 7295.385
    update_time_ms: 32.744
  timestamp: 1602459954
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |      9 |          268.849 | 1456128 |  230.007 |              281.778 |              113.444 |            843.792 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3523.5331905781586
    time_step_min: 3196
  date: 2020-10-11_23-46-23
  done: false
  episode_len_mean: 838.0806962025316
  episode_reward_max: 287.2323232323235
  episode_reward_mean: 232.57123449686725
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 278
  episodes_total: 1896
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.9132000654935837
        entropy_coeff: 0.0005000000000000001
        kl: 0.013285659408817688
        model: {}
        policy_loss: -0.015034273523876132
        total_loss: 13.321046431859335
        vf_explained_var: 0.979250431060791
        vf_loss: 13.33454426129659
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.242857142857147
    gpu_util_percent0: 0.38371428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545816231129358
    mean_env_wait_ms: 1.1853057198404884
    mean_inference_ms: 4.882843092271689
    mean_raw_obs_processing_ms: 0.4072222108143166
  time_since_restore: 298.3449590206146
  time_this_iter_s: 29.49627923965454
  time_total_s: 298.3449590206146
  timers:
    learn_throughput: 7193.893
    learn_time_ms: 22490.187
    sample_throughput: 22335.733
    sample_time_ms: 7243.64
    update_time_ms: 39.29
  timestamp: 1602459983
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     10 |          298.345 | 1617920 |  232.571 |              287.232 |              113.444 |            838.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3513.452615992103
    time_step_min: 3155
  date: 2020-10-11_23-46-53
  done: false
  episode_len_mean: 834.6694255111977
  episode_reward_max: 287.9898989898984
  episode_reward_mean: 234.1128372330903
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8984085917472839
        entropy_coeff: 0.0005000000000000001
        kl: 0.010885702368492881
        model: {}
        policy_loss: -0.01437823004865398
        total_loss: 10.744627396265665
        vf_explained_var: 0.9777135848999023
        vf_loss: 10.757821957270304
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.829411764705885
    gpu_util_percent0: 0.31499999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541740683572244
    mean_env_wait_ms: 1.1868563356067825
    mean_inference_ms: 4.852278875809161
    mean_raw_obs_processing_ms: 0.40573986056107697
  time_since_restore: 327.7750360965729
  time_this_iter_s: 29.430077075958252
  time_total_s: 327.7750360965729
  timers:
    learn_throughput: 7205.035
    learn_time_ms: 22455.409
    sample_throughput: 23157.088
    sample_time_ms: 6986.716
    update_time_ms: 37.824
  timestamp: 1602460013
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     11 |          327.775 | 1779712 |  234.113 |               287.99 |              113.444 |            834.669 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3504.481684981685
    time_step_min: 3155
  date: 2020-10-11_23-47-22
  done: false
  episode_len_mean: 832.0230560578661
  episode_reward_max: 287.9898989898984
  episode_reward_mean: 235.55223117248423
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8614880988995234
        entropy_coeff: 0.0005000000000000001
        kl: 0.011757834969709316
        model: {}
        policy_loss: -0.015917484464201454
        total_loss: 10.498374064763388
        vf_explained_var: 0.9781190752983093
        vf_loss: 10.512958208719889
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.61764705882353
    gpu_util_percent0: 0.3273529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15380347757065452
    mean_env_wait_ms: 1.188335581422615
    mean_inference_ms: 4.824516967690941
    mean_raw_obs_processing_ms: 0.4043692011770034
  time_since_restore: 357.12086272239685
  time_this_iter_s: 29.345826625823975
  time_total_s: 357.12086272239685
  timers:
    learn_throughput: 7205.673
    learn_time_ms: 22453.419
    sample_throughput: 23505.841
    sample_time_ms: 6883.055
    update_time_ms: 39.173
  timestamp: 1602460042
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     12 |          357.121 | 1941504 |  235.552 |               287.99 |              113.444 |            832.023 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3489.232997987928
    time_step_min: 3155
  date: 2020-10-11_23-47-52
  done: false
  episode_len_mean: 826.8722642260246
  episode_reward_max: 287.9898989898984
  episode_reward_mean: 237.81402565246566
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 301
  episodes_total: 2513
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8278060158093771
        entropy_coeff: 0.0005000000000000001
        kl: 0.010167833495264253
        model: {}
        policy_loss: -0.012999054762379577
        total_loss: 17.325045903523762
        vf_explained_var: 0.9754905104637146
        vf_loss: 17.336933771769207
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.211764705882356
    gpu_util_percent0: 0.3020588235294118
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647054
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531889424914404
    mean_env_wait_ms: 1.191078993214599
    mean_inference_ms: 4.779031461121335
    mean_raw_obs_processing_ms: 0.40214720256550157
  time_since_restore: 386.33181834220886
  time_this_iter_s: 29.21095561981201
  time_total_s: 386.33181834220886
  timers:
    learn_throughput: 7214.222
    learn_time_ms: 22426.813
    sample_throughput: 23679.329
    sample_time_ms: 6832.626
    update_time_ms: 38.355
  timestamp: 1602460072
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     13 |          386.332 | 2103296 |  237.814 |               287.99 |              113.444 |            826.872 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3481.4778028592928
    time_step_min: 3155
  date: 2020-10-11_23-48-21
  done: false
  episode_len_mean: 824.2457185405808
  episode_reward_max: 287.9898989898984
  episode_reward_mean: 238.94101476417177
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 173
  episodes_total: 2686
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8320326705773672
        entropy_coeff: 0.0005000000000000001
        kl: 0.010923507856205106
        model: {}
        policy_loss: -0.016439030955856044
        total_loss: 9.48443857828776
        vf_explained_var: 0.9803946018218994
        vf_loss: 9.4996550877889
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.01764705882353
    gpu_util_percent0: 0.43264705882352933
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15288939019220435
    mean_env_wait_ms: 1.1925017758618155
    mean_inference_ms: 4.756481954584599
    mean_raw_obs_processing_ms: 0.4010493313359154
  time_since_restore: 415.34853625297546
  time_this_iter_s: 29.0167179107666
  time_total_s: 415.34853625297546
  timers:
    learn_throughput: 7225.501
    learn_time_ms: 22391.803
    sample_throughput: 23741.012
    sample_time_ms: 6814.874
    update_time_ms: 38.67
  timestamp: 1602460101
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     14 |          415.349 | 2265088 |  238.941 |               287.99 |              113.444 |            824.246 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3475.0308948863635
    time_step_min: 3155
  date: 2020-10-11_23-48-50
  done: false
  episode_len_mean: 822.1241209563995
  episode_reward_max: 287.9898989898984
  episode_reward_mean: 239.92240975152356
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.8091300874948502
        entropy_coeff: 0.0005000000000000001
        kl: 0.011478488023082415
        model: {}
        policy_loss: -0.01686601507632683
        total_loss: 8.980401436487833
        vf_explained_var: 0.9794749617576599
        vf_loss: 8.99595053990682
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.602941176470587
    gpu_util_percent0: 0.46529411764705886
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15263526072769967
    mean_env_wait_ms: 1.193720565720452
    mean_inference_ms: 4.737550103401881
    mean_raw_obs_processing_ms: 0.40010720483273027
  time_since_restore: 444.3322629928589
  time_this_iter_s: 28.983726739883423
  time_total_s: 444.3322629928589
  timers:
    learn_throughput: 7241.364
    learn_time_ms: 22342.751
    sample_throughput: 23728.574
    sample_time_ms: 6818.446
    update_time_ms: 39.336
  timestamp: 1602460130
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     15 |          444.332 | 2426880 |  239.922 |               287.99 |              113.444 |            822.124 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3464.857934180515
    time_step_min: 3124
  date: 2020-10-11_23-49-19
  done: false
  episode_len_mean: 818.9741685502099
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 241.42455227117793
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 253
  episodes_total: 3097
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7593703716993332
        entropy_coeff: 0.0005000000000000001
        kl: 0.010592118992159763
        model: {}
        policy_loss: -0.013380727226225039
        total_loss: 11.530811866124472
        vf_explained_var: 0.9818038940429688
        vf_loss: 11.542983293533325
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.291176470588237
    gpu_util_percent0: 0.42382352941176465
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15226709468440602
    mean_env_wait_ms: 1.195611786917215
    mean_inference_ms: 4.710363021216364
    mean_raw_obs_processing_ms: 0.3987530541968514
  time_since_restore: 473.4510192871094
  time_this_iter_s: 29.11875629425049
  time_total_s: 473.4510192871094
  timers:
    learn_throughput: 7249.436
    learn_time_ms: 22317.874
    sample_throughput: 23720.528
    sample_time_ms: 6820.759
    update_time_ms: 38.967
  timestamp: 1602460159
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     16 |          473.451 | 2588672 |  241.425 |              292.687 |              113.444 |            818.974 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3458.47491638796
    time_step_min: 3124
  date: 2020-10-11_23-49-48
  done: false
  episode_len_mean: 817.0732589689478
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 242.39795300000293
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 220
  episodes_total: 3317
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7682176729043325
        entropy_coeff: 0.0005000000000000001
        kl: 0.009309212987621626
        model: {}
        policy_loss: -0.014434428433257077
        total_loss: 10.328804731369019
        vf_explained_var: 0.9819441437721252
        vf_loss: 10.342227220535278
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.66470588235294
    gpu_util_percent0: 0.4244117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151983597808363
    mean_env_wait_ms: 1.1970981427861862
    mean_inference_ms: 4.689256188648879
    mean_raw_obs_processing_ms: 0.39772355050448777
  time_since_restore: 502.4399528503418
  time_this_iter_s: 28.988933563232422
  time_total_s: 502.4399528503418
  timers:
    learn_throughput: 7260.719
    learn_time_ms: 22283.193
    sample_throughput: 23735.797
    sample_time_ms: 6816.371
    update_time_ms: 40.595
  timestamp: 1602460188
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     17 |           502.44 | 2750464 |  242.398 |              292.687 |              113.444 |            817.073 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3452.8227958236657
    time_step_min: 3124
  date: 2020-10-11_23-50-17
  done: false
  episode_len_mean: 815.8443613348677
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 243.22379723588
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7617949992418289
        entropy_coeff: 0.0005000000000000001
        kl: 0.01077734826443096
        model: {}
        policy_loss: -0.014197270773972074
        total_loss: 7.387121478716533
        vf_explained_var: 0.983557939529419
        vf_loss: 7.400083144505818
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.91176470588235
    gpu_util_percent0: 0.4264705882352941
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15179353446022564
    mean_env_wait_ms: 1.1980720053000673
    mean_inference_ms: 4.675280036248703
    mean_raw_obs_processing_ms: 0.3970352125795983
  time_since_restore: 531.4323678016663
  time_this_iter_s: 28.992414951324463
  time_total_s: 531.4323678016663
  timers:
    learn_throughput: 7261.84
    learn_time_ms: 22279.754
    sample_throughput: 23772.184
    sample_time_ms: 6805.938
    update_time_ms: 40.559
  timestamp: 1602460217
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     18 |          531.432 | 2912256 |  243.224 |              292.687 |              113.444 |            815.844 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3446.954657873042
    time_step_min: 3124
  date: 2020-10-11_23-50-46
  done: false
  episode_len_mean: 814.3228797382056
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 244.06963554277425
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 191
  episodes_total: 3667
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.709365169207255
        entropy_coeff: 0.0005000000000000001
        kl: 0.010744190076366067
        model: {}
        policy_loss: -0.01513387062974895
        total_loss: 9.64358933766683
        vf_explained_var: 0.9829058647155762
        vf_loss: 9.657467206319174
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.53235294117647
    gpu_util_percent0: 0.4702941176470588
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15158566732397502
    mean_env_wait_ms: 1.199226101658318
    mean_inference_ms: 4.65966399202281
    mean_raw_obs_processing_ms: 0.3962606856799563
  time_since_restore: 560.4259107112885
  time_this_iter_s: 28.993542909622192
  time_total_s: 560.4259107112885
  timers:
    learn_throughput: 7272.385
    learn_time_ms: 22247.446
    sample_throughput: 23785.585
    sample_time_ms: 6802.103
    update_time_ms: 40.564
  timestamp: 1602460246
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     19 |          560.426 | 3074048 |   244.07 |              292.687 |              113.444 |            814.323 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3437.808114314876
    time_step_min: 3124
  date: 2020-10-11_23-51-16
  done: false
  episode_len_mean: 812.0777805928553
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 245.4762138742376
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 280
  episodes_total: 3947
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.7060993711153666
        entropy_coeff: 0.0005000000000000001
        kl: 0.009266526205465198
        model: {}
        policy_loss: -0.01530453966309627
        total_loss: 9.481341679890951
        vf_explained_var: 0.9845563769340515
        vf_loss: 9.495609601338705
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.43823529411765
    gpu_util_percent0: 0.425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15130194434738425
    mean_env_wait_ms: 1.2007500565877982
    mean_inference_ms: 4.638942949552524
    mean_raw_obs_processing_ms: 0.39525083223924
  time_since_restore: 589.6353049278259
  time_this_iter_s: 29.209394216537476
  time_total_s: 589.6353049278259
  timers:
    learn_throughput: 7279.841
    learn_time_ms: 22224.66
    sample_throughput: 23780.026
    sample_time_ms: 6803.693
    update_time_ms: 33.512
  timestamp: 1602460276
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | RUNNING  | 172.17.0.4:74870 |     20 |          589.635 | 3235840 |  245.476 |              292.687 |              113.444 |            812.078 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_422e5_00000:
  custom_metrics:
    time_step_max: 4307
    time_step_mean: 3433.3708333333334
    time_step_min: 3124
  date: 2020-10-11_23-51-45
  done: true
  episode_len_mean: 810.8366601752678
  episode_reward_max: 292.6868686868685
  episode_reward_mean: 246.1808641428894
  episode_reward_min: 113.44444444444365
  episodes_this_iter: 161
  episodes_total: 4108
  experiment_id: f5163b2f3cb443c294e36f03b38e2946
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.15
        cur_lr: 5.0e-05
        entropy: 0.711797962586085
        entropy_coeff: 0.0005000000000000001
        kl: 0.011316760210320354
        model: {}
        policy_loss: -0.01475863583618775
        total_loss: 7.301508943239848
        vf_explained_var: 0.9838337302207947
        vf_loss: 7.3149259487787885
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.558823529411764
    gpu_util_percent0: 0.4191176470588236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 74870
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115226403437093
    mean_env_wait_ms: 1.201558997231142
    mean_inference_ms: 4.628034990460741
    mean_raw_obs_processing_ms: 0.39471608148515097
  time_since_restore: 619.0818808078766
  time_this_iter_s: 29.44657588005066
  time_total_s: 619.0818808078766
  timers:
    learn_throughput: 7276.448
    learn_time_ms: 22235.025
    sample_throughput: 23816.404
    sample_time_ms: 6793.301
    update_time_ms: 33.345
  timestamp: 1602460305
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 422e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | TERMINATED |       |     21 |          619.082 | 3397632 |  246.181 |              292.687 |              113.444 |            810.837 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_422e5_00000 | TERMINATED |       |     21 |          619.082 | 3397632 |  246.181 |              292.687 |              113.444 |            810.837 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


