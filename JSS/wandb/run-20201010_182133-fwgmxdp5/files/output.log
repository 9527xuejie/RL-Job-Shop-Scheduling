2020-10-10 18:21:35,905	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_6f3a3_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=30594)[0m 2020-10-10 18:21:38,831	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=30573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30461)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30461)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30525)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30525)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30530)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30530)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30459)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-22-24
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.184571853705815
        entropy_coeff: 0.0
        kl: 0.00429063180594572
        model: {}
        policy_loss: -0.014881657004090292
        total_loss: 496.40624564034596
        vf_explained_var: 0.5996591448783875
        vf_loss: 496.4202641078404
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.504255319148935
    gpu_util_percent0: 0.31148936170212765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.306382978723401
    vram_util_percent0: 0.19440276895808178
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17489848147207077
    mean_env_wait_ms: 1.2041492762481698
    mean_inference_ms: 5.765604400163671
    mean_raw_obs_processing_ms: 0.4667055183592017
  time_since_restore: 40.02420949935913
  time_this_iter_s: 40.02420949935913
  time_total_s: 40.02420949935913
  timers:
    learn_throughput: 5241.291
    learn_time_ms: 30868.728
    sample_throughput: 17812.466
    sample_time_ms: 9083.077
    update_time_ms: 33.707
  timestamp: 1602354144
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      1 |          40.0242 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4106
    time_step_mean: 3609.309027777778
    time_step_min: 3338
  date: 2020-10-10_18-23-03
  done: false
  episode_len_mean: 890.5
  episode_reward_max: 261.47474747474683
  episode_reward_mean: 217.9045518475896
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1563879762377058
        entropy_coeff: 0.0
        kl: 0.005475713804896388
        model: {}
        policy_loss: -0.01502255180717579
        total_loss: 107.79195022583008
        vf_explained_var: 0.8411927223205566
        vf_loss: 107.80642536708287
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.255555555555553
    gpu_util_percent0: 0.2942222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475555555555555
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17026825219221065
    mean_env_wait_ms: 1.1988544184247385
    mean_inference_ms: 5.581694859604387
    mean_raw_obs_processing_ms: 0.459153323926896
  time_since_restore: 78.73160886764526
  time_this_iter_s: 38.70739936828613
  time_total_s: 78.73160886764526
  timers:
    learn_throughput: 5260.9
    learn_time_ms: 30753.675
    sample_throughput: 18940.571
    sample_time_ms: 8542.087
    update_time_ms: 26.202
  timestamp: 1602354183
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      2 |          78.7316 | 323584 |  217.905 |              261.475 |               126.02 |              890.5 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3608.2600896860986
    time_step_min: 3259
  date: 2020-10-10_18-23-41
  done: false
  episode_len_mean: 888.1793248945148
  episode_reward_max: 281.474747474747
  episode_reward_mean: 218.79222605804864
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1494224922997611
        entropy_coeff: 0.0
        kl: 0.005971001560932824
        model: {}
        policy_loss: -0.01713816951710864
        total_loss: 37.288308007376536
        vf_explained_var: 0.9359025955200195
        vf_loss: 37.30484880719866
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.926666666666666
    gpu_util_percent0: 0.3248888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4911111111111115
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1670001653203853
    mean_env_wait_ms: 1.1957304627916252
    mean_inference_ms: 5.415849014881044
    mean_raw_obs_processing_ms: 0.4513061446972472
  time_since_restore: 117.03877520561218
  time_this_iter_s: 38.30716633796692
  time_total_s: 117.03877520561218
  timers:
    learn_throughput: 5269.549
    learn_time_ms: 30703.195
    sample_throughput: 19652.356
    sample_time_ms: 8232.703
    update_time_ms: 31.124
  timestamp: 1602354221
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      3 |          117.039 | 485376 |  218.792 |              281.475 |               126.02 |            888.179 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3602.7582781456954
    time_step_min: 3259
  date: 2020-10-10_18-24-19
  done: false
  episode_len_mean: 885.6867088607595
  episode_reward_max: 281.474747474747
  episode_reward_mean: 219.57817095000615
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.132673706327166
        entropy_coeff: 0.0
        kl: 0.006258420080744794
        model: {}
        policy_loss: -0.019153817889413664
        total_loss: 24.736762046813965
        vf_explained_var: 0.9561432600021362
        vf_loss: 24.75529044015067
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.786666666666665
    gpu_util_percent0: 0.42444444444444446
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484444444444445
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16466812398953118
    mean_env_wait_ms: 1.193738563346103
    mean_inference_ms: 5.289186452781908
    mean_raw_obs_processing_ms: 0.44482791888414813
  time_since_restore: 155.27101516723633
  time_this_iter_s: 38.232239961624146
  time_total_s: 155.27101516723633
  timers:
    learn_throughput: 5268.568
    learn_time_ms: 30708.912
    sample_throughput: 20148.307
    sample_time_ms: 8030.054
    update_time_ms: 32.899
  timestamp: 1602354259
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      4 |          155.271 | 647168 |  219.578 |              281.475 |               126.02 |            885.687 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3594.92782152231
    time_step_min: 3259
  date: 2020-10-10_18-24-58
  done: false
  episode_len_mean: 882.9
  episode_reward_max: 281.474747474747
  episode_reward_mean: 221.04014831862912
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1129137022154671
        entropy_coeff: 0.0
        kl: 0.005886524616341505
        model: {}
        policy_loss: -0.017274155680622374
        total_loss: 18.597988401140487
        vf_explained_var: 0.9673697352409363
        vf_loss: 18.61467375074114
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.562222222222225
    gpu_util_percent0: 0.27866666666666673
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4911111111111115
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629036068444486
    mean_env_wait_ms: 1.192718284456533
    mean_inference_ms: 5.191486545756059
    mean_raw_obs_processing_ms: 0.4394638069521
  time_since_restore: 193.59464812278748
  time_this_iter_s: 38.32363295555115
  time_total_s: 193.59464812278748
  timers:
    learn_throughput: 5262.293
    learn_time_ms: 30745.535
    sample_throughput: 20496.268
    sample_time_ms: 7893.73
    update_time_ms: 30.547
  timestamp: 1602354298
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      5 |          193.595 | 808960 |   221.04 |              281.475 |               126.02 |              882.9 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3580.807915057915
    time_step_min: 3259
  date: 2020-10-10_18-25-36
  done: false
  episode_len_mean: 874.8477443609023
  episode_reward_max: 281.474747474747
  episode_reward_mean: 222.99858547884847
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 274
  episodes_total: 1064
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0953281266348702
        entropy_coeff: 0.0
        kl: 0.005936307366937399
        model: {}
        policy_loss: -0.01621486022694236
        total_loss: 26.678502900259836
        vf_explained_var: 0.9698354601860046
        vf_loss: 26.69412394932338
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.755555555555556
    gpu_util_percent0: 0.3055555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484444444444445
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16080531839631276
    mean_env_wait_ms: 1.1935826915048968
    mean_inference_ms: 5.070795469246928
    mean_raw_obs_processing_ms: 0.4328440214774855
  time_since_restore: 231.52696895599365
  time_this_iter_s: 37.93232083320618
  time_total_s: 231.52696895599365
  timers:
    learn_throughput: 5268.282
    learn_time_ms: 30710.581
    sample_throughput: 20751.278
    sample_time_ms: 7796.725
    update_time_ms: 31.349
  timestamp: 1602354336
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      6 |          231.527 | 970752 |  222.999 |              281.475 |               126.02 |            874.848 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3573.8349514563106
    time_step_min: 3259
  date: 2020-10-10_18-26-14
  done: false
  episode_len_mean: 869.6455696202531
  episode_reward_max: 281.474747474747
  episode_reward_mean: 224.43324862549528
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 200
  episodes_total: 1264
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1034024868692671
        entropy_coeff: 0.0
        kl: 0.00536777578028185
        model: {}
        policy_loss: -0.017882596468552947
        total_loss: 15.745723520006452
        vf_explained_var: 0.9729281663894653
        vf_loss: 15.76306962966919
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.70888888888889
    gpu_util_percent0: 0.3393333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15965473500230526
    mean_env_wait_ms: 1.1942815672061684
    mean_inference_ms: 5.00736244600623
    mean_raw_obs_processing_ms: 0.4291473138894198
  time_since_restore: 269.6092195510864
  time_this_iter_s: 38.08225059509277
  time_total_s: 269.6092195510864
  timers:
    learn_throughput: 5270.578
    learn_time_ms: 30697.2
    sample_throughput: 20906.555
    sample_time_ms: 7738.817
    update_time_ms: 30.174
  timestamp: 1602354374
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      7 |          269.609 | 1132544 |  224.433 |              281.475 |               126.02 |            869.646 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3565.45193687231
    time_step_min: 3259
  date: 2020-10-10_18-26-52
  done: false
  episode_len_mean: 866.3755274261604
  episode_reward_max: 281.474747474747
  episode_reward_mean: 225.52740485018947
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0883538808141435
        entropy_coeff: 0.0
        kl: 0.005960137383746249
        model: {}
        policy_loss: -0.017626609719757522
        total_loss: 12.36479445866176
        vf_explained_var: 0.9781728386878967
        vf_loss: 12.381825651441302
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.35454545454546
    gpu_util_percent0: 0.29363636363636364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497727272727274
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15890874075222525
    mean_env_wait_ms: 1.1949003757407395
    mean_inference_ms: 4.964967517728496
    mean_raw_obs_processing_ms: 0.4267069497179916
  time_since_restore: 307.40310168266296
  time_this_iter_s: 37.79388213157654
  time_total_s: 307.40310168266296
  timers:
    learn_throughput: 5275.825
    learn_time_ms: 30666.675
    sample_throughput: 21065.663
    sample_time_ms: 7680.366
    update_time_ms: 28.601
  timestamp: 1602354412
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      8 |          307.403 | 1294336 |  225.527 |              281.475 |               126.02 |            866.376 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3558.3086340206187
    time_step_min: 3214
  date: 2020-10-10_18-27-30
  done: false
  episode_len_mean: 863.0721518987342
  episode_reward_max: 281.474747474747
  episode_reward_mean: 226.78286024804996
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.069465662751879
        entropy_coeff: 0.0
        kl: 0.005794129600482327
        model: {}
        policy_loss: -0.018824712240270207
        total_loss: 11.670457908085414
        vf_explained_var: 0.9775874018669128
        vf_loss: 11.688703332628522
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.861363636363635
    gpu_util_percent0: 0.3163636363636364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.493181818181818
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15826681527535855
    mean_env_wait_ms: 1.1955058062525352
    mean_inference_ms: 4.927743039368654
    mean_raw_obs_processing_ms: 0.4245105464676818
  time_since_restore: 345.2486879825592
  time_this_iter_s: 37.84558629989624
  time_total_s: 345.2486879825592
  timers:
    learn_throughput: 5278.535
    learn_time_ms: 30650.926
    sample_throughput: 21198.158
    sample_time_ms: 7632.361
    update_time_ms: 27.966
  timestamp: 1602354450
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |      9 |          345.249 | 1456128 |  226.783 |              281.475 |               126.02 |            863.072 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3550.4110854503465
    time_step_min: 3214
  date: 2020-10-10_18-28-08
  done: false
  episode_len_mean: 859.5005681818182
  episode_reward_max: 281.474747474747
  episode_reward_mean: 227.86799816345254
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 180
  episodes_total: 1760
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0308445010866438
        entropy_coeff: 0.0
        kl: 0.00581325198124562
        model: {}
        policy_loss: -0.016573202763018862
        total_loss: 15.439563001905169
        vf_explained_var: 0.9785926938056946
        vf_loss: 15.455555098397392
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.464444444444442
    gpu_util_percent0: 0.3399999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484444444444444
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15762398895391086
    mean_env_wait_ms: 1.1963890578866943
    mean_inference_ms: 4.890472642836072
    mean_raw_obs_processing_ms: 0.42227327012941773
  time_since_restore: 383.030868768692
  time_this_iter_s: 37.78218078613281
  time_total_s: 383.030868768692
  timers:
    learn_throughput: 5281.374
    learn_time_ms: 30634.454
    sample_throughput: 21337.229
    sample_time_ms: 7582.615
    update_time_ms: 35.129
  timestamp: 1602354488
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     10 |          383.031 | 1617920 |  227.868 |              281.475 |               126.02 |            859.501 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3542.0695952615993
    time_step_min: 3213
  date: 2020-10-10_18-28-46
  done: false
  episode_len_mean: 854.4182083739046
  episode_reward_max: 281.474747474747
  episode_reward_mean: 229.39772112556906
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 294
  episodes_total: 2054
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.045348584651947
        entropy_coeff: 0.0
        kl: 0.00553806232554572
        model: {}
        policy_loss: -0.017226254900119135
        total_loss: 17.30461093357631
        vf_explained_var: 0.9767717719078064
        vf_loss: 17.32128347669329
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.727272727272723
    gpu_util_percent0: 0.2809090909090909
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490909090909091
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15678741548547773
    mean_env_wait_ms: 1.1979050933364774
    mean_inference_ms: 4.84119687034865
    mean_raw_obs_processing_ms: 0.4193391157435615
  time_since_restore: 421.0840449333191
  time_this_iter_s: 38.053176164627075
  time_total_s: 421.0840449333191
  timers:
    learn_throughput: 5286.175
    learn_time_ms: 30606.63
    sample_throughput: 21829.213
    sample_time_ms: 7411.719
    update_time_ms: 35.191
  timestamp: 1602354526
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     11 |          421.084 | 1779712 |  229.398 |              281.475 |               126.02 |            854.418 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3534.782967032967
    time_step_min: 3213
  date: 2020-10-10_18-29-24
  done: false
  episode_len_mean: 851.9471066907776
  episode_reward_max: 281.474747474747
  episode_reward_mean: 230.48695362302942
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0258809924125671
        entropy_coeff: 0.0
        kl: 0.005530576886875289
        model: {}
        policy_loss: -0.019115123149406697
        total_loss: 11.42626885005406
        vf_explained_var: 0.979430615901947
        vf_loss: 11.444830894470215
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.54888888888889
    gpu_util_percent0: 0.3208888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4911111111111115
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15639940446755426
    mean_env_wait_ms: 1.1986339812215998
    mean_inference_ms: 4.81867953194529
    mean_raw_obs_processing_ms: 0.41799098110439836
  time_since_restore: 459.1310577392578
  time_this_iter_s: 38.04701280593872
  time_total_s: 459.1310577392578
  timers:
    learn_throughput: 5287.633
    learn_time_ms: 30598.192
    sample_throughput: 22003.665
    sample_time_ms: 7352.957
    update_time_ms: 35.598
  timestamp: 1602354564
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     12 |          459.131 | 1941504 |  230.487 |              281.475 |               126.02 |            851.947 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3529.0849701110164
    time_step_min: 3213
  date: 2020-10-10_18-30-02
  done: false
  episode_len_mean: 849.5603375527426
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 231.4865746068276
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0105551481246948
        entropy_coeff: 0.0
        kl: 0.0058199151951287475
        model: {}
        policy_loss: -0.019343618802460178
        total_loss: 11.528972557612828
        vf_explained_var: 0.9775827527046204
        vf_loss: 11.5477340562003
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.90909090909091
    gpu_util_percent0: 0.2765909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.506818181818184
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15604748079194788
    mean_env_wait_ms: 1.1993330589331495
    mean_inference_ms: 4.798242897104143
    mean_raw_obs_processing_ms: 0.4167409727407673
  time_since_restore: 497.05449628829956
  time_this_iter_s: 37.92343854904175
  time_total_s: 497.05449628829956
  timers:
    learn_throughput: 5287.905
    learn_time_ms: 30596.619
    sample_throughput: 22111.652
    sample_time_ms: 7317.047
    update_time_ms: 33.645
  timestamp: 1602354602
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     13 |          497.054 | 2103296 |  231.487 |              283.444 |               126.02 |             849.56 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3521.654602675059
    time_step_min: 3213
  date: 2020-10-10_18-30-40
  done: false
  episode_len_mean: 846.8280155642024
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 232.5874700310497
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 200
  episodes_total: 2570
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9764345330851418
        entropy_coeff: 0.0
        kl: 0.00600036493103419
        model: {}
        policy_loss: -0.01851524060059871
        total_loss: 13.282404558999199
        vf_explained_var: 0.9807733297348022
        vf_loss: 13.300319467272077
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.691111111111105
    gpu_util_percent0: 0.30777777777777776
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486666666666666
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15563689485045273
    mean_env_wait_ms: 1.2002729640450192
    mean_inference_ms: 4.77467411278211
    mean_raw_obs_processing_ms: 0.41527344226585955
  time_since_restore: 535.032154083252
  time_this_iter_s: 37.97765779495239
  time_total_s: 535.032154083252
  timers:
    learn_throughput: 5291.528
    learn_time_ms: 30575.669
    sample_throughput: 22127.552
    sample_time_ms: 7311.789
    update_time_ms: 31.592
  timestamp: 1602354640
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     14 |          535.032 | 2265088 |  232.587 |              283.444 |               126.02 |            846.828 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3511.5745738636365
    time_step_min: 3213
  date: 2020-10-10_18-31-18
  done: false
  episode_len_mean: 843.7914908579465
  episode_reward_max: 283.4444444444445
  episode_reward_mean: 234.04645612240537
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 274
  episodes_total: 2844
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9815114651407514
        entropy_coeff: 0.0
        kl: 0.005483298163328852
        model: {}
        policy_loss: -0.01731880641143237
        total_loss: 11.971384457179479
        vf_explained_var: 0.9820483922958374
        vf_loss: 11.988154683794294
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.484444444444442
    gpu_util_percent0: 0.34711111111111115
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15517908518541498
    mean_env_wait_ms: 1.2015244235787037
    mean_inference_ms: 4.747124365345799
    mean_raw_obs_processing_ms: 0.4135563550920008
  time_since_restore: 573.2252593040466
  time_this_iter_s: 38.19310522079468
  time_total_s: 573.2252593040466
  timers:
    learn_throughput: 5291.307
    learn_time_ms: 30576.943
    sample_throughput: 22177.082
    sample_time_ms: 7295.459
    update_time_ms: 33.214
  timestamp: 1602354678
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | RUNNING  | 172.17.0.4:30594 |     15 |          573.225 | 2426880 |  234.046 |              283.444 |               126.02 |            843.791 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_6f3a3_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3505.3722259583055
    time_step_min: 3182
  date: 2020-10-10_18-31-56
  done: true
  episode_len_mean: 842.1325782811459
  episode_reward_max: 283.89898989899007
  episode_reward_mean: 234.93067584573237
  episode_reward_min: 126.0202020202021
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 1e26f1172d7b4007a64a17dd9233f29c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.965128059898104
        entropy_coeff: 0.0
        kl: 0.005700613305504833
        model: {}
        policy_loss: -0.017847898848620907
        total_loss: 9.162920883723668
        vf_explained_var: 0.9824723601341248
        vf_loss: 9.180198737553187
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.052272727272722
    gpu_util_percent0: 0.3315909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49090909090909
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 30594
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1549371392007745
    mean_env_wait_ms: 1.2021849164201128
    mean_inference_ms: 4.732872242335074
    mean_raw_obs_processing_ms: 0.41267917593801917
  time_since_restore: 610.9641313552856
  time_this_iter_s: 37.738872051239014
  time_total_s: 610.9641313552856
  timers:
    learn_throughput: 5294.625
    learn_time_ms: 30557.785
    sample_throughput: 22204.899
    sample_time_ms: 7286.32
    update_time_ms: 31.761
  timestamp: 1602354716
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 6f3a3_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | TERMINATED |       |     16 |          610.964 | 2588672 |  234.931 |              283.899 |               126.02 |            842.133 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_6f3a3_00000 | TERMINATED |       |     16 |          610.964 | 2588672 |  234.931 |              283.899 |               126.02 |            842.133 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


