2020-10-12 09:09:42,767	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ab0cc_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=11539)[0m F1012 09:09:44.974668 11539 11539 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247
[2m[36m(pid=11539)[0m *** Check failure stack trace: ***
[2m[36m(pid=11518)[0m F1012 09:09:44.974699 11518 11518 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247
[2m[36m(pid=11518)[0m *** Check failure stack trace: ***
[2m[36m(pid=11518)[0m     @     0x7f61268a26ed  google::LogMessage::Fail()
[2m[36m(pid=11521)[0m F1012 09:09:44.974720 11521 11521 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247
[2m[36m(pid=11521)[0m *** Check failure stack trace: ***
[2m[36m(pid=11521)[0m     @     0x7fd20b9096ed  google::LogMessage::Fail()
[2m[36m(pid=11541)[0m F1012 09:09:44.974675 11541 11541 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247
[2m[36m(pid=11541)[0m *** Check failure stack trace: ***
[2m[36m(pid=11541)[0m     @     0x7f4e23e256ed  google::LogMessage::Fail()
[2m[36m(pid=11539)[0m     @     0x7f0bf39896ed  google::LogMessage::Fail()
[2m[36m(pid=11539)[0m     @     0x7f0bf398a84c  google::LogMessage::SendToLog()
[2m[36m(pid=11518)[0m     @     0x7f61268a384c  google::LogMessage::SendToLog()
[2m[36m(pid=11521)[0m     @     0x7fd20b90a84c  google::LogMessage::SendToLog()
[2m[36m(pid=11521)[0m     @     0x7fd20b9093c9  google::LogMessage::Flush()
[2m[36m(pid=11541)[0m     @     0x7f4e23e2684c  google::LogMessage::SendToLog()
[2m[36m(pid=11541)[0m     @     0x7f4e23e253c9  google::LogMessage::Flush()
[2m[36m(pid=11539)[0m     @     0x7f0bf39893c9  google::LogMessage::Flush()
[2m[36m(pid=11539)[0m     @     0x7f0bf39895e1  google::LogMessage::~LogMessage()
[2m[36m(pid=11539)[0m     @     0x7f0bf3940789  ray::RayLog::~RayLog()
[2m[36m(pid=11518)[0m     @     0x7f61268a23c9  google::LogMessage::Flush()
[2m[36m(pid=11518)[0m     @     0x7f61268a25e1  google::LogMessage::~LogMessage()
[2m[36m(pid=11518)[0m     @     0x7f6126859789  ray::RayLog::~RayLog()
[2m[36m(pid=11521)[0m     @     0x7fd20b9095e1  google::LogMessage::~LogMessage()
[2m[36m(pid=11541)[0m     @     0x7f4e23e255e1  google::LogMessage::~LogMessage()
[2m[36m(pid=11541)[0m     @     0x7f4e23ddc789  ray::RayLog::~RayLog()
[2m[36m(pid=11539)[0m     @     0x7f0bf36841ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=11539)[0m     @     0x7f0bf36842ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=11518)[0m     @     0x7f612659d1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=11518)[0m     @     0x7f612659d2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=11521)[0m     @     0x7fd20b8c0789  ray::RayLog::~RayLog()
[2m[36m(pid=11521)[0m     @     0x7fd20b6041ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=11521)[0m     @     0x7fd20b6042ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=11541)[0m     @     0x7f4e23b201ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=11541)[0m     @     0x7f4e23b202ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=11541)[0m     @     0x7f4e23b20491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=11539)[0m     @     0x7f0bf3684491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=11539)[0m     @     0x7f0bf3686801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=11518)[0m     @     0x7f612659d491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=11518)[0m     @     0x7f612659f801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=11518)[0m     @     0x7f61264ae7a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=11521)[0m     @     0x7fd20b604491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=11521)[0m     @     0x7fd20b606801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=11541)[0m     @     0x7f4e23b22801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=11541)[0m     @     0x7f4e23aa3ed6  ray::CoreWorker::CoreWorker()
[2m[36m(pid=11539)[0m     @     0x7f0bf3607ed6  ray::CoreWorker::CoreWorker()
[2m[36m(pid=11539)[0m     @     0x7f0bf360bc14  ray::CoreWorkerProcess::CreateWorker()
[2m[36m(pid=11518)[0m     @     0x7f612641fa2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=11518)[0m     @     0x56500f4aa98a  method_vectorcall_NOARGS
[2m[36m(pid=11518)[0m     @     0x56500f43ab08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11518)[0m     @     0x56500f4c56a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11518)[0m     @     0x56500f4c6a20  method_vectorcall
[2m[36m(pid=11518)[0m     @     0x56500f43bde6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11518)[0m     @     0x56500f4c5baf  _PyEval_EvalCodeWithName
[2m[36m(pid=11518)[0m     @     0x56500f4c6643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=11518)[0m     @     0x56500f43bde6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11518)[0m     @     0x56500f4c56a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11518)[0m     @     0x56500f4c6454  PyEval_EvalCodeEx
[2m[36m(pid=11518)[0m     @     0x56500f554bbc  PyEval_EvalCode
[2m[36m(pid=11518)[0m     @     0x56500f554c64  run_eval_code_obj
[2m[36m(pid=11521)[0m     @     0x7fd20b5157a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=11521)[0m     @     0x7fd20b486a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=11521)[0m     @     0x5583054c398a  method_vectorcall_NOARGS
[2m[36m(pid=11521)[0m     @     0x558305453b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11521)[0m     @     0x5583054de6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11521)[0m     @     0x5583054dfa20  method_vectorcall
[2m[36m(pid=11521)[0m     @     0x558305454de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11521)[0m     @     0x5583054debaf  _PyEval_EvalCodeWithName
[2m[36m(pid=11521)[0m     @     0x5583054df643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=11521)[0m     @     0x558305454de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11521)[0m     @     0x5583054de6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11541)[0m     @     0x7f4e23aa7c14  ray::CoreWorkerProcess::CreateWorker()
[2m[36m(pid=11541)[0m     @     0x7f4e23aa8e82  ray::CoreWorkerProcess::CoreWorkerProcess()
[2m[36m(pid=11539)[0m     @     0x7f0bf360ce82  ray::CoreWorkerProcess::CoreWorkerProcess()
[2m[36m(pid=11539)[0m     @     0x7f0bf360d84b  ray::CoreWorkerProcess::Initialize()
[2m[36m(pid=11518)[0m     @     0x56500f586d14  run_mod
[2m[36m(pid=11518)[0m     @     0x56500f44f625  PyRun_FileExFlags
[2m[36m(pid=11518)[0m     @     0x56500f44fa0a  PyRun_SimpleFileExFlags
[2m[36m(pid=11518)[0m     @     0x56500f4508cf  Py_RunMain.cold.2911
[2m[36m(pid=11518)[0m     @     0x56500f589829  Py_BytesMain
[2m[36m(pid=11518)[0m     @     0x7f6127ba7840  __libc_start_main
[2m[36m(pid=11518)[0m     @     0x56500f519b33  (unknown)
[2m[36m(pid=11521)[0m     @     0x5583054df454  PyEval_EvalCodeEx
[2m[36m(pid=11521)[0m     @     0x55830556dbbc  PyEval_EvalCode
[2m[36m(pid=11521)[0m     @     0x55830556dc64  run_eval_code_obj
[2m[36m(pid=11521)[0m     @     0x55830559fd14  run_mod
[2m[36m(pid=11521)[0m     @     0x558305468625  PyRun_FileExFlags
[2m[36m(pid=11521)[0m     @     0x558305468a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=11521)[0m     @     0x5583054698cf  Py_RunMain.cold.2911
[2m[36m(pid=11521)[0m     @     0x5583055a2829  Py_BytesMain
[2m[36m(pid=11541)[0m     @     0x7f4e23aa984b  ray::CoreWorkerProcess::Initialize()
[2m[36m(pid=11541)[0m     @     0x7f4e239e7448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
[2m[36m(pid=11539)[0m     @     0x7f0bf354b448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
[2m[36m(pid=11539)[0m     @     0x7f0bf354cba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()
[2m[36m(pid=11539)[0m     @     0x55e42b88f37d  _PyObject_MakeTpCall
[2m[36m(pid=11539)[0m     @     0x55e42b917d09  _PyEval_EvalFrameDefault
[2m[36m(pid=11539)[0m     @     0x55e42b8dcbaf  _PyEval_EvalCodeWithName
[2m[36m(pid=11539)[0m     @     0x55e42b8dd643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=11539)[0m     @     0x55e42b852de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11521)[0m     @     0x7fd20cc0e840  __libc_start_main
[2m[36m(pid=11521)[0m     @     0x558305532b33  (unknown)
[2m[36m(pid=11541)[0m     @     0x7f4e239e8ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()
[2m[36m(pid=11541)[0m     @     0x564bc062137d  _PyObject_MakeTpCall
[2m[36m(pid=11541)[0m     @     0x564bc06a9d09  _PyEval_EvalFrameDefault
[2m[36m(pid=11541)[0m     @     0x564bc066ebaf  _PyEval_EvalCodeWithName
[2m[36m(pid=11541)[0m     @     0x564bc066f643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=11541)[0m     @     0x564bc05e4de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=11541)[0m     @     0x564bc066e6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11541)[0m     @     0x564bc066f454  PyEval_EvalCodeEx
[2m[36m(pid=11539)[0m     @     0x55e42b8dc6a2  _PyEval_EvalCodeWithName
[2m[36m(pid=11539)[0m     @     0x55e42b8dd454  PyEval_EvalCodeEx
[2m[36m(pid=11539)[0m     @     0x55e42b96bbbc  PyEval_EvalCode
[2m[36m(pid=11539)[0m     @     0x55e42b96bc64  run_eval_code_obj
[2m[36m(pid=11539)[0m     @     0x55e42b99dd14  run_mod
[2m[36m(pid=11539)[0m     @     0x55e42b866625  PyRun_FileExFlags
[2m[36m(pid=11539)[0m     @     0x55e42b866a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=11539)[0m     @     0x55e42b8678cf  Py_RunMain.cold.2911
[2m[36m(pid=11539)[0m     @     0x55e42b9a0829  Py_BytesMain
[2m[36m(pid=11541)[0m     @     0x564bc06fdbbc  PyEval_EvalCode
[2m[36m(pid=11541)[0m     @     0x564bc06fdc64  run_eval_code_obj
[2m[36m(pid=11541)[0m     @     0x564bc072fd14  run_mod
[2m[36m(pid=11541)[0m     @     0x564bc05f8625  PyRun_FileExFlags
[2m[36m(pid=11541)[0m     @     0x564bc05f8a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=11541)[0m     @     0x564bc05f98cf  Py_RunMain.cold.2911
[2m[36m(pid=11541)[0m     @     0x564bc0732829  Py_BytesMain
[2m[36m(pid=11539)[0m     @     0x7f0bf4c8e840  __libc_start_main
[2m[36m(pid=11539)[0m     @     0x55e42b930b33  (unknown)
[2m[36m(pid=11541)[0m     @     0x7f4e2512a840  __libc_start_main
[2m[36m(pid=11541)[0m     @     0x564bc06c2b33  (unknown)
[2m[33m(pid=raylet)[0m E1012 09:09:45.152127 11475 11475 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed
[2m[33m(pid=raylet)[0m E1012 09:09:45.187711 11475 11475 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed
[2m[36m(pid=11639)[0m 2020-10-12 09:09:45,605	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=11607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11529)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11529)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11533)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11533)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11531)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11531)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11520)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11520)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11614)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11522)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11522)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11629)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11629)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11601)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11601)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=11578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=11578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=12929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=12929)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_09-10-19
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.182355095942815
        entropy_coeff: 0.0010000000000000002
        kl: 0.006899550712356965
        model: {}
        policy_loss: -0.009150916089614233
        total_loss: 507.0743637084961
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.500000000000004
    gpu_util_percent0: 0.27060606060606057
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5757575757575757
    vram_util_percent0: 0.08736346740610434
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1709314554184445
    mean_env_wait_ms: 1.1781879618198061
    mean_inference_ms: 5.888402364106044
    mean_raw_obs_processing_ms: 0.4616009846775942
  time_since_restore: 28.510921239852905
  time_this_iter_s: 28.510921239852905
  time_total_s: 28.510921239852905
  timers:
    learn_throughput: 8407.548
    learn_time_ms: 19243.66
    sample_throughput: 17607.121
    sample_time_ms: 9189.009
    update_time_ms: 44.64
  timestamp: 1602493819
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      1 |          28.5109 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3608.8263888888887
    time_step_min: 3346
  date: 2020-10-12_09-10-46
  done: false
  episode_len_mean: 892.506329113924
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 218.37156373865213
  episode_reward_min: 143.74747474747463
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.149287035067876
        entropy_coeff: 0.0010000000000000002
        kl: 0.007768862143469353
        model: {}
        policy_loss: -0.011663281096844003
        total_loss: 125.33597246805827
        vf_explained_var: 0.8107926249504089
        vf_loss: 125.34722963968913
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.083870967741934
    gpu_util_percent0: 0.2783870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16605058809426132
    mean_env_wait_ms: 1.1724585850409024
    mean_inference_ms: 5.608469227957835
    mean_raw_obs_processing_ms: 0.44818381015639347
  time_since_restore: 55.49300575256348
  time_this_iter_s: 26.98208451271057
  time_total_s: 55.49300575256348
  timers:
    learn_throughput: 8410.298
    learn_time_ms: 19237.369
    sample_throughput: 19205.99
    sample_time_ms: 8424.038
    update_time_ms: 41.79
  timestamp: 1602493846
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      2 |           55.493 | 323584 |  218.372 |              264.354 |              143.747 |            892.506 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3600.177130044843
    time_step_min: 3312
  date: 2020-10-12_09-11-13
  done: false
  episode_len_mean: 888.2679324894515
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 220.42245237181922
  episode_reward_min: 143.74747474747463
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1440819799900055
        entropy_coeff: 0.0010000000000000002
        kl: 0.012469007167965174
        model: {}
        policy_loss: -0.013894526307315877
        total_loss: 55.279540061950684
        vf_explained_var: 0.8949055075645447
        vf_loss: 55.29208596547445
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.58709677419355
    gpu_util_percent0: 0.4445161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790322580645162
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16301342233903654
    mean_env_wait_ms: 1.1710658606447342
    mean_inference_ms: 5.413075620264339
    mean_raw_obs_processing_ms: 0.43901216608845256
  time_since_restore: 82.09788537025452
  time_this_iter_s: 26.60487961769104
  time_total_s: 82.09788537025452
  timers:
    learn_throughput: 8409.789
    learn_time_ms: 19238.532
    sample_throughput: 20121.751
    sample_time_ms: 8040.652
    update_time_ms: 41.813
  timestamp: 1602493873
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      3 |          82.0979 | 485376 |  220.422 |              264.354 |              143.747 |            888.268 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3592.248344370861
    time_step_min: 3229
  date: 2020-10-12_09-11-39
  done: false
  episode_len_mean: 887.4762658227849
  episode_reward_max: 276.7777777777773
  episode_reward_mean: 221.1168169032091
  episode_reward_min: 143.74747474747463
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1269059876600902
        entropy_coeff: 0.0010000000000000002
        kl: 0.0107233178957055
        model: {}
        policy_loss: -0.013501833062036894
        total_loss: 41.97398853302002
        vf_explained_var: 0.9246423840522766
        vf_loss: 41.98647212982178
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.654838709677417
    gpu_util_percent0: 0.3119354838709677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7967741935483863
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16088157000858677
    mean_env_wait_ms: 1.1702201553059415
    mean_inference_ms: 5.271199229980809
    mean_raw_obs_processing_ms: 0.4321947251479392
  time_since_restore: 108.49108576774597
  time_this_iter_s: 26.393200397491455
  time_total_s: 108.49108576774597
  timers:
    learn_throughput: 8419.173
    learn_time_ms: 19217.089
    sample_throughput: 20743.31
    sample_time_ms: 7799.719
    update_time_ms: 57.526
  timestamp: 1602493899
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      4 |          108.491 | 647168 |  221.117 |              276.778 |              143.747 |            887.476 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3590.7965879265093
    time_step_min: 3229
  date: 2020-10-12_09-12-05
  done: false
  episode_len_mean: 883.4784810126582
  episode_reward_max: 276.7777777777773
  episode_reward_mean: 222.1676895537653
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.099730372428894
        entropy_coeff: 0.0010000000000000002
        kl: 0.010723261473079523
        model: {}
        policy_loss: -0.01573065633419901
        total_loss: 36.1703904469808
        vf_explained_var: 0.9362662434577942
        vf_loss: 36.18507480621338
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.289999999999996
    gpu_util_percent0: 0.37566666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15926300672453003
    mean_env_wait_ms: 1.1702455143397732
    mean_inference_ms: 5.164355253128473
    mean_raw_obs_processing_ms: 0.4266825704252954
  time_since_restore: 134.8220145702362
  time_this_iter_s: 26.330928802490234
  time_total_s: 134.8220145702362
  timers:
    learn_throughput: 8424.121
    learn_time_ms: 19205.801
    sample_throughput: 21124.398
    sample_time_ms: 7659.011
    update_time_ms: 51.085
  timestamp: 1602493925
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      5 |          134.822 | 808960 |  222.168 |              276.778 |              123.293 |            883.478 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3577.4291300097752
    time_step_min: 3229
  date: 2020-10-12_09-12-32
  done: false
  episode_len_mean: 876.5889628924833
  episode_reward_max: 276.7777777777773
  episode_reward_mean: 224.38236792280537
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 261
  episodes_total: 1051
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0695344706376393
        entropy_coeff: 0.0010000000000000002
        kl: 0.011311198429514965
        model: {}
        policy_loss: -0.013925497497742375
        total_loss: 34.00605169932047
        vf_explained_var: 0.9589201807975769
        vf_loss: 34.018784523010254
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.090322580645154
    gpu_util_percent0: 0.2767741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573920417937042
    mean_env_wait_ms: 1.172214831327009
    mean_inference_ms: 5.040071713656986
    mean_raw_obs_processing_ms: 0.4202543153320228
  time_since_restore: 161.29357409477234
  time_this_iter_s: 26.471559524536133
  time_total_s: 161.29357409477234
  timers:
    learn_throughput: 8421.719
    learn_time_ms: 19211.279
    sample_throughput: 21366.692
    sample_time_ms: 7572.16
    update_time_ms: 49.828
  timestamp: 1602493952
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      6 |          161.294 | 970752 |  224.382 |              276.778 |              123.293 |            876.589 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3570.6642394822006
    time_step_min: 3229
  date: 2020-10-12_09-12-58
  done: false
  episode_len_mean: 873.5340189873418
  episode_reward_max: 276.7777777777773
  episode_reward_mean: 225.2434471295229
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 213
  episodes_total: 1264
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.074757029612859
        entropy_coeff: 0.0010000000000000002
        kl: 0.009882260967666904
        model: {}
        policy_loss: -0.0106422333434845
        total_loss: 24.986013253529865
        vf_explained_var: 0.9613370895385742
        vf_loss: 24.99575424194336
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.040000000000003
    gpu_util_percent0: 0.33499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8033333333333337
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15627850769846607
    mean_env_wait_ms: 1.173120070322761
    mean_inference_ms: 4.965893468385096
    mean_raw_obs_processing_ms: 0.4164646233124774
  time_since_restore: 187.7696831226349
  time_this_iter_s: 26.47610902786255
  time_total_s: 187.7696831226349
  timers:
    learn_throughput: 8413.946
    learn_time_ms: 19229.029
    sample_throughput: 21590.852
    sample_time_ms: 7493.544
    update_time_ms: 48.386
  timestamp: 1602493978
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      7 |           187.77 | 1132544 |  225.243 |              276.778 |              123.293 |            873.534 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3562.3916786226687
    time_step_min: 3229
  date: 2020-10-12_09-13-25
  done: false
  episode_len_mean: 870.5189873417721
  episode_reward_max: 280.26262626262564
  episode_reward_mean: 226.60186250692564
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0478589634100597
        entropy_coeff: 0.0010000000000000002
        kl: 0.01174442881407837
        model: {}
        policy_loss: -0.014641193168548247
        total_loss: 17.139351685841877
        vf_explained_var: 0.9697672724723816
        vf_loss: 17.152692159016926
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.78064516129032
    gpu_util_percent0: 0.4012903225806452
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7935483870967737
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15561437925844776
    mean_env_wait_ms: 1.1739122541840687
    mean_inference_ms: 4.9212315832210916
    mean_raw_obs_processing_ms: 0.41412802790411113
  time_since_restore: 214.15947604179382
  time_this_iter_s: 26.389792919158936
  time_total_s: 214.15947604179382
  timers:
    learn_throughput: 8413.294
    learn_time_ms: 19230.517
    sample_throughput: 21749.461
    sample_time_ms: 7438.897
    update_time_ms: 47.571
  timestamp: 1602494005
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      8 |          214.159 | 1294336 |  226.602 |              280.263 |              123.293 |            870.519 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3553.064432989691
    time_step_min: 3210
  date: 2020-10-12_09-13-51
  done: false
  episode_len_mean: 866.9943037974683
  episode_reward_max: 280.26262626262564
  episode_reward_mean: 228.16375783147922
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0198639531930287
        entropy_coeff: 0.0010000000000000002
        kl: 0.011228926635036865
        model: {}
        policy_loss: -0.013478583695056537
        total_loss: 16.173202673594158
        vf_explained_var: 0.9687080383300781
        vf_loss: 16.185454845428467
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.146666666666665
    gpu_util_percent0: 0.29933333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.796666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550431438401806
    mean_env_wait_ms: 1.1747210313127066
    mean_inference_ms: 4.882125370722626
    mean_raw_obs_processing_ms: 0.4120349560638267
  time_since_restore: 240.35650873184204
  time_this_iter_s: 26.197032690048218
  time_total_s: 240.35650873184204
  timers:
    learn_throughput: 8413.229
    learn_time_ms: 19230.667
    sample_throughput: 21937.656
    sample_time_ms: 7375.081
    update_time_ms: 46.434
  timestamp: 1602494031
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      9 |          240.357 | 1456128 |  228.164 |              280.263 |              123.293 |            866.994 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3544.88450377249
    time_step_min: 3210
  date: 2020-10-12_09-14-18
  done: false
  episode_len_mean: 863.3375214163335
  episode_reward_max: 281.1717171717168
  episode_reward_mean: 229.46619824746594
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 171
  episodes_total: 1751
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9780503561099371
        entropy_coeff: 0.0010000000000000002
        kl: 0.009758495492860675
        model: {}
        policy_loss: -0.0139435965490217
        total_loss: 17.738577047983807
        vf_explained_var: 0.9718084931373596
        vf_loss: 17.75154670079549
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.190000000000005
    gpu_util_percent0: 0.3986666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.793333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545050007526534
    mean_env_wait_ms: 1.1757773298552918
    mean_inference_ms: 4.8451503884978555
    mean_raw_obs_processing_ms: 0.4100415540938448
  time_since_restore: 266.710839509964
  time_this_iter_s: 26.35433077812195
  time_total_s: 266.710839509964
  timers:
    learn_throughput: 8408.138
    learn_time_ms: 19242.311
    sample_throughput: 22075.475
    sample_time_ms: 7329.038
    update_time_ms: 45.726
  timestamp: 1602494058
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     10 |          266.711 | 1617920 |  229.466 |              281.172 |              123.293 |            863.338 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3534.246778989098
    time_step_min: 3210
  date: 2020-10-12_09-14-44
  done: false
  episode_len_mean: 858.5786901270773
  episode_reward_max: 286.77777777777817
  episode_reward_mean: 230.9822121508337
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 295
  episodes_total: 2046
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9707790662844976
        entropy_coeff: 0.0010000000000000002
        kl: 0.009111629178126654
        model: {}
        policy_loss: -0.01193074702132435
        total_loss: 21.812623182932537
        vf_explained_var: 0.972846269607544
        vf_loss: 21.82370201746623
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.64999999999999
    gpu_util_percent0: 0.261
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15373903338701672
    mean_env_wait_ms: 1.1774911722734291
    mean_inference_ms: 4.792413567775025
    mean_raw_obs_processing_ms: 0.4072536118481191
  time_since_restore: 292.91805124282837
  time_this_iter_s: 26.20721173286438
  time_total_s: 292.91805124282837
  timers:
    learn_throughput: 8409.23
    learn_time_ms: 19239.812
    sample_throughput: 22791.619
    sample_time_ms: 7098.75
    update_time_ms: 45.649
  timestamp: 1602494084
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     11 |          292.918 | 1779712 |  230.982 |              286.778 |              123.293 |            858.579 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3527.223443223443
    time_step_min: 3200
  date: 2020-10-12_09-15-11
  done: false
  episode_len_mean: 856.6713381555154
  episode_reward_max: 286.77777777777817
  episode_reward_mean: 232.1279339507186
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 166
  episodes_total: 2212
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9551966488361359
        entropy_coeff: 0.0010000000000000002
        kl: 0.009806284758572778
        model: {}
        policy_loss: -0.013617369385125736
        total_loss: 13.879839897155762
        vf_explained_var: 0.9759161472320557
        vf_loss: 13.8924511273702
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.677419354838708
    gpu_util_percent0: 0.36967741935483867
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15338491645842753
    mean_env_wait_ms: 1.1783542788983006
    mean_inference_ms: 4.767533848675805
    mean_raw_obs_processing_ms: 0.40595214319690065
  time_since_restore: 319.4405264854431
  time_this_iter_s: 26.522475242614746
  time_total_s: 319.4405264854431
  timers:
    learn_throughput: 8401.506
    learn_time_ms: 19257.501
    sample_throughput: 22995.188
    sample_time_ms: 7035.907
    update_time_ms: 44.501
  timestamp: 1602494111
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     12 |          319.441 | 1941504 |  232.128 |              286.778 |              123.293 |            856.671 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3521.5333048676343
    time_step_min: 3200
  date: 2020-10-12_09-15-37
  done: false
  episode_len_mean: 854.5388185654008
  episode_reward_max: 286.77777777777817
  episode_reward_mean: 233.08355708988609
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9413289129734039
        entropy_coeff: 0.0010000000000000002
        kl: 0.008010121838500103
        model: {}
        policy_loss: -0.01172462550069516
        total_loss: 15.081488529841105
        vf_explained_var: 0.972363293170929
        vf_loss: 15.092552741368612
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.846666666666668
    gpu_util_percent0: 0.28733333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000003
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15307903200662712
    mean_env_wait_ms: 1.179158797690685
    mean_inference_ms: 4.746250296736081
    mean_raw_obs_processing_ms: 0.4048109758123445
  time_since_restore: 345.8816432952881
  time_this_iter_s: 26.44111680984497
  time_total_s: 345.8816432952881
  timers:
    learn_throughput: 8395.135
    learn_time_ms: 19272.114
    sample_throughput: 23094.095
    sample_time_ms: 7005.774
    update_time_ms: 42.498
  timestamp: 1602494137
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     13 |          345.882 | 2103296 |  233.084 |              286.778 |              123.293 |            854.539 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3515.089207487057
    time_step_min: 3200
  date: 2020-10-12_09-16-04
  done: false
  episode_len_mean: 852.2583694367861
  episode_reward_max: 286.77777777777817
  episode_reward_mean: 234.0807603407051
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 169
  episodes_total: 2539
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9056168496608734
        entropy_coeff: 0.0010000000000000002
        kl: 0.009796336991712451
        model: {}
        policy_loss: -0.013294228323502466
        total_loss: 13.875916957855225
        vf_explained_var: 0.9769673347473145
        vf_loss: 13.88815744717916
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.880000000000003
    gpu_util_percent0: 0.31666666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.806666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15277447557429397
    mean_env_wait_ms: 1.1800135637448719
    mean_inference_ms: 4.72551806953912
    mean_raw_obs_processing_ms: 0.4036840813331012
  time_since_restore: 372.2597620487213
  time_this_iter_s: 26.378118753433228
  time_total_s: 372.2597620487213
  timers:
    learn_throughput: 8391.326
    learn_time_ms: 19280.862
    sample_throughput: 23106.345
    sample_time_ms: 7002.059
    update_time_ms: 35.618
  timestamp: 1602494164
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     14 |           372.26 | 2265088 |  234.081 |              286.778 |              123.293 |            852.258 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3502.648426323319
    time_step_min: 3160
  date: 2020-10-12_09-16-30
  done: false
  episode_len_mean: 848.600566572238
  episode_reward_max: 287.2323232323233
  episode_reward_mean: 235.92292972215057
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 285
  episodes_total: 2824
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8858138074477514
        entropy_coeff: 0.0010000000000000002
        kl: 0.008729042252525687
        model: {}
        policy_loss: -0.01212932908674702
        total_loss: 15.029687325159708
        vf_explained_var: 0.9797885417938232
        vf_loss: 15.040957053502401
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.80322580645161
    gpu_util_percent0: 0.3496774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15233331834828823
    mean_env_wait_ms: 1.1814026695620998
    mean_inference_ms: 4.695138773537019
    mean_raw_obs_processing_ms: 0.40202783416969384
  time_since_restore: 398.7684223651886
  time_this_iter_s: 26.508660316467285
  time_total_s: 398.7684223651886
  timers:
    learn_throughput: 8385.521
    learn_time_ms: 19294.21
    sample_throughput: 23098.392
    sample_time_ms: 7004.47
    update_time_ms: 36.796
  timestamp: 1602494190
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     15 |          398.768 | 2426880 |  235.923 |              287.232 |              123.293 |            848.601 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3495.150975117687
    time_step_min: 3160
  date: 2020-10-12_09-16-57
  done: false
  episode_len_mean: 846.7524983344437
  episode_reward_max: 287.2323232323233
  episode_reward_mean: 236.98188413111785
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 178
  episodes_total: 3002
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.873380055030187
        entropy_coeff: 0.0010000000000000002
        kl: 0.009605405774588386
        model: {}
        policy_loss: -0.014174769399687648
        total_loss: 8.852904081344604
        vf_explained_var: 0.9842066168785095
        vf_loss: 8.866031328837076
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.716666666666665
    gpu_util_percent0: 0.3466666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000003
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15209292308422775
    mean_env_wait_ms: 1.1821958954982226
    mean_inference_ms: 4.6787285721858725
    mean_raw_obs_processing_ms: 0.401153686184005
  time_since_restore: 425.24342155456543
  time_this_iter_s: 26.47499918937683
  time_total_s: 425.24342155456543
  timers:
    learn_throughput: 8380.352
    learn_time_ms: 19306.111
    sample_throughput: 23138.248
    sample_time_ms: 6992.405
    update_time_ms: 36.347
  timestamp: 1602494217
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     16 |          425.243 | 2588672 |  236.982 |              287.232 |              123.293 |            846.752 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3489.791826309068
    time_step_min: 3160
  date: 2020-10-12_09-17-23
  done: false
  episode_len_mean: 845.1911392405063
  episode_reward_max: 287.2323232323233
  episode_reward_mean: 237.82586945403386
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8668454786141714
        entropy_coeff: 0.0010000000000000002
        kl: 0.008814893662929535
        model: {}
        policy_loss: -0.011805401959766945
        total_loss: 10.369755109151205
        vf_explained_var: 0.980014979839325
        vf_loss: 10.380664348602295
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.633333333333333
    gpu_util_percent0: 0.30433333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8033333333333337
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518939132452068
    mean_env_wait_ms: 1.1828715767868674
    mean_inference_ms: 4.665102003707222
    mean_raw_obs_processing_ms: 0.4004250767522837
  time_since_restore: 451.46355152130127
  time_this_iter_s: 26.22012996673584
  time_total_s: 451.46355152130127
  timers:
    learn_throughput: 8377.898
    learn_time_ms: 19311.765
    sample_throughput: 23233.435
    sample_time_ms: 6963.757
    update_time_ms: 36.044
  timestamp: 1602494243
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     17 |          451.464 | 2750464 |  237.826 |              287.232 |              123.293 |            845.191 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3482.9842995169083
    time_step_min: 3160
  date: 2020-10-12_09-17-49
  done: false
  episode_len_mean: 843.6434131736527
  episode_reward_max: 287.2323232323233
  episode_reward_mean: 238.74125990443346
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 180
  episodes_total: 3340
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8216705471277237
        entropy_coeff: 0.0010000000000000002
        kl: 0.008909148629754782
        model: {}
        policy_loss: -0.013433378713671118
        total_loss: 8.975247144699097
        vf_explained_var: 0.9846148490905762
        vf_loss: 8.987720568974813
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.03103448275862
    gpu_util_percent0: 0.2879310344827586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8034482758620682
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516824536319952
    mean_env_wait_ms: 1.183662094655912
    mean_inference_ms: 4.650801891684328
    mean_raw_obs_processing_ms: 0.39965731772831625
  time_since_restore: 477.3016357421875
  time_this_iter_s: 25.83808422088623
  time_total_s: 477.3016357421875
  timers:
    learn_throughput: 8387.159
    learn_time_ms: 19290.441
    sample_throughput: 23349.348
    sample_time_ms: 6929.187
    update_time_ms: 35.786
  timestamp: 1602494269
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     18 |          477.302 | 2912256 |  238.741 |              287.232 |              123.293 |            843.643 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3473.5977139671036
    time_step_min: 3150
  date: 2020-10-12_09-18-16
  done: false
  episode_len_mean: 841.0929460580913
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 240.02900373024843
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 275
  episodes_total: 3615
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8049357434113821
        entropy_coeff: 0.0010000000000000002
        kl: 0.008266594493761659
        model: {}
        policy_loss: -0.011415963868785184
        total_loss: 11.906183878580729
        vf_explained_var: 0.9831228852272034
        vf_loss: 11.916751384735107
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.87096774193548
    gpu_util_percent0: 0.38064516129032255
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419344
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15140022504781708
    mean_env_wait_ms: 1.1847662527935785
    mean_inference_ms: 4.630730531528002
    mean_raw_obs_processing_ms: 0.3985929411459491
  time_since_restore: 503.61667227745056
  time_this_iter_s: 26.31503653526306
  time_total_s: 503.61667227745056
  timers:
    learn_throughput: 8379.397
    learn_time_ms: 19308.31
    sample_throughput: 23394.279
    sample_time_ms: 6915.879
    update_time_ms: 41.848
  timestamp: 1602494296
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     19 |          503.617 | 3074048 |  240.029 |              288.747 |              123.293 |            841.093 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3469.2547821466524
    time_step_min: 3150
  date: 2020-10-12_09-18-42
  done: false
  episode_len_mean: 839.415611814346
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 240.75353215701304
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 177
  episodes_total: 3792
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7987531820933024
        entropy_coeff: 0.0010000000000000002
        kl: 0.009079231104503075
        model: {}
        policy_loss: -0.01224838827814286
        total_loss: 7.98631485303243
        vf_explained_var: 0.9849869608879089
        vf_loss: 7.997546116511027
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.95862068965517
    gpu_util_percent0: 0.42896551724137927
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512318108286515
    mean_env_wait_ms: 1.1854403616712963
    mean_inference_ms: 4.619308581693827
    mean_raw_obs_processing_ms: 0.39798201719273574
  time_since_restore: 529.7231526374817
  time_this_iter_s: 26.106480360031128
  time_total_s: 529.7231526374817
  timers:
    learn_throughput: 8384.536
    learn_time_ms: 19296.475
    sample_throughput: 23441.212
    sample_time_ms: 6902.032
    update_time_ms: 41.797
  timestamp: 1602494322
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     20 |          529.723 | 3235840 |  240.754 |              288.747 |              123.293 |            839.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3465.1249044098904
    time_step_min: 3150
  date: 2020-10-12_09-19-08
  done: false
  episode_len_mean: 837.9002784105289
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 241.3841681814346
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 159
  episodes_total: 3951
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7892453173796335
        entropy_coeff: 0.0010000000000000002
        kl: 0.008678884012624621
        model: {}
        policy_loss: -0.013489016583965471
        total_loss: 8.202074805895487
        vf_explained_var: 0.9837081432342529
        vf_loss: 8.214617093404135
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.576666666666664
    gpu_util_percent0: 0.33299999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8100000000000005
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510910394398947
    mean_env_wait_ms: 1.1860755375048555
    mean_inference_ms: 4.609591237803295
    mean_raw_obs_processing_ms: 0.39746154916894355
  time_since_restore: 555.8554036617279
  time_this_iter_s: 26.132251024246216
  time_total_s: 555.8554036617279
  timers:
    learn_throughput: 8384.49
    learn_time_ms: 19296.582
    sample_throughput: 23466.212
    sample_time_ms: 6894.679
    update_time_ms: 40.938
  timestamp: 1602494348
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     21 |          555.855 | 3397632 |  241.384 |              288.747 |              123.293 |              837.9 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3459.7059956657836
    time_step_min: 3150
  date: 2020-10-12_09-19-34
  done: false
  episode_len_mean: 835.4640038268357
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 242.1401312817241
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 230
  episodes_total: 4181
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7601525833209356
        entropy_coeff: 0.0010000000000000002
        kl: 0.009010187815874815
        model: {}
        policy_loss: -0.012391658771472672
        total_loss: 10.299412171045939
        vf_explained_var: 0.9842986464500427
        vf_loss: 10.31076200803121
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.053333333333338
    gpu_util_percent0: 0.3506666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.796666666666667
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1509019954239079
    mean_env_wait_ms: 1.1870673081191399
    mean_inference_ms: 4.596511436234388
    mean_raw_obs_processing_ms: 0.3967569355943852
  time_since_restore: 582.0722694396973
  time_this_iter_s: 26.21686577796936
  time_total_s: 582.0722694396973
  timers:
    learn_throughput: 8389.319
    learn_time_ms: 19285.474
    sample_throughput: 23539.335
    sample_time_ms: 6873.261
    update_time_ms: 42.019
  timestamp: 1602494374
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     22 |          582.072 | 3559424 |   242.14 |              288.747 |              123.293 |            835.464 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ab0cc_00000:
  custom_metrics:
    time_step_max: 4242
    time_step_mean: 3454.6921501706483
    time_step_min: 3150
  date: 2020-10-12_09-20-01
  done: true
  episode_len_mean: 832.845127741352
  episode_reward_max: 288.7474747474747
  episode_reward_mean: 242.9193312277191
  episode_reward_min: 123.29292929292922
  episodes_this_iter: 242
  episodes_total: 4423
  experiment_id: 106c69a97c93469e859f3a7e2b7f731c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7429485023021698
        entropy_coeff: 0.0010000000000000002
        kl: 0.008412127305443088
        model: {}
        policy_loss: -0.013832842392730527
        total_loss: 9.076472520828247
        vf_explained_var: 0.9854559302330017
        vf_loss: 9.08936619758606
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.276666666666667
    gpu_util_percent0: 0.3273333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.803333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 11639
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507183214765464
    mean_env_wait_ms: 1.1880050261807538
    mean_inference_ms: 4.583941039758726
    mean_raw_obs_processing_ms: 0.39609077607755505
  time_since_restore: 608.0814437866211
  time_this_iter_s: 26.009174346923828
  time_total_s: 608.0814437866211
  timers:
    learn_throughput: 8399.918
    learn_time_ms: 19261.14
    sample_throughput: 23606.525
    sample_time_ms: 6853.698
    update_time_ms: 42.01
  timestamp: 1602494401
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: ab0cc_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | TERMINATED |       |     23 |          608.081 | 3721216 |  242.919 |              288.747 |              123.293 |            832.845 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ab0cc_00000 | TERMINATED |       |     23 |          608.081 | 3721216 |  242.919 |              288.747 |              123.293 |            832.845 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


