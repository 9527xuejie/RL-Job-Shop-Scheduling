2020-10-12 15:43:52,890	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_bba05_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=29107)[0m 2020-10-12 15:43:55,692	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=29109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29076)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29076)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29137)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29137)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29089)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29089)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=28999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=28999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29115)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3522.9508196721313
    time_step_min: 3235
  date: 2020-10-12_15-44-29
  done: false
  episode_len_mean: 892.2341772151899
  episode_reward_max: 254.5757575757571
  episode_reward_mean: 208.69735327963153
  episode_reward_min: 139.27272727272737
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1810161769390106
        entropy_coeff: 0.0005000000000000001
        kl: 0.003497340988057355
        model: {}
        policy_loss: -0.007581961224786937
        total_loss: 425.68299611409503
        vf_explained_var: 0.5529740452766418
        vf_loss: 425.6904652913411
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.545714285714283
    gpu_util_percent0: 0.27228571428571424
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5571428571428574
    vram_util_percent0: 0.08551047181745773
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.172160008175206
    mean_env_wait_ms: 1.169943083727496
    mean_inference_ms: 5.813265176568733
    mean_raw_obs_processing_ms: 0.4620507250011759
  time_since_restore: 28.73671007156372
  time_this_iter_s: 28.73671007156372
  time_total_s: 28.73671007156372
  timers:
    learn_throughput: 8288.966
    learn_time_ms: 19518.961
    sample_throughput: 17700.838
    sample_time_ms: 9140.358
    update_time_ms: 49.141
  timestamp: 1602517469
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      1 |          28.7367 | 161792 |  208.697 |              254.576 |              139.273 |            892.234 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3532.1642857142856
    time_step_min: 3205
  date: 2020-10-12_15-44-57
  done: false
  episode_len_mean: 889.6677215189874
  episode_reward_max: 259.1212121212121
  episode_reward_mean: 208.27157652474088
  episode_reward_min: 139.27272727272737
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1515157421429951
        entropy_coeff: 0.0005000000000000001
        kl: 0.008129845761383573
        model: {}
        policy_loss: -0.010888179541022206
        total_loss: 106.39584986368816
        vf_explained_var: 0.8193144202232361
        vf_loss: 106.40650304158528
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.615151515151517
    gpu_util_percent0: 0.2933333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.754545454545455
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16804248511463626
    mean_env_wait_ms: 1.1667348894590563
    mean_inference_ms: 5.617111911177464
    mean_raw_obs_processing_ms: 0.4511138093812267
  time_since_restore: 55.94376277923584
  time_this_iter_s: 27.20705270767212
  time_total_s: 55.94376277923584
  timers:
    learn_throughput: 8342.193
    learn_time_ms: 19394.421
    sample_throughput: 19048.95
    sample_time_ms: 8493.486
    update_time_ms: 45.507
  timestamp: 1602517497
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      2 |          55.9438 | 323584 |  208.272 |              259.121 |              139.273 |            889.668 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3539.1141552511417
    time_step_min: 3205
  date: 2020-10-12_15-45-23
  done: false
  episode_len_mean: 883.3628691983122
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 208.68073136427546
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1436680853366852
        entropy_coeff: 0.0005000000000000001
        kl: 0.008007710915990174
        model: {}
        policy_loss: -0.011135648053217059
        total_loss: 57.12984085083008
        vf_explained_var: 0.8894199728965759
        vf_loss: 57.1407470703125
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.19375
    gpu_util_percent0: 0.289375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1649454940126926
    mean_env_wait_ms: 1.1668115933399774
    mean_inference_ms: 5.443061731700323
    mean_raw_obs_processing_ms: 0.4419186137585663
  time_since_restore: 82.46803975105286
  time_this_iter_s: 26.524276971817017
  time_total_s: 82.46803975105286
  timers:
    learn_throughput: 8364.965
    learn_time_ms: 19341.623
    sample_throughput: 20064.879
    sample_time_ms: 8063.442
    update_time_ms: 43.126
  timestamp: 1602517523
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      3 |           82.468 | 485376 |  208.681 |                  267 |              136.242 |            883.363 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3544.412751677852
    time_step_min: 3205
  date: 2020-10-12_15-45-49
  done: false
  episode_len_mean: 879.0142405063291
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 207.51759685462198
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1258440613746643
        entropy_coeff: 0.0005000000000000001
        kl: 0.008104618444728354
        model: {}
        policy_loss: -0.012452503734190637
        total_loss: 42.44776312510172
        vf_explained_var: 0.9244468212127686
        vf_loss: 42.45996824900309
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.43225806451613
    gpu_util_percent0: 0.412258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16262551780048315
    mean_env_wait_ms: 1.167972284535896
    mean_inference_ms: 5.306148022197708
    mean_raw_obs_processing_ms: 0.4346386131434353
  time_since_restore: 108.58362817764282
  time_this_iter_s: 26.115588426589966
  time_total_s: 108.58362817764282
  timers:
    learn_throughput: 8393.784
    learn_time_ms: 19275.217
    sample_throughput: 20784.432
    sample_time_ms: 7784.288
    update_time_ms: 42.363
  timestamp: 1602517549
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      4 |          108.584 | 647168 |  207.518 |                  267 |              136.242 |            879.014 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3537.816976127321
    time_step_min: 3205
  date: 2020-10-12_15-46-16
  done: false
  episode_len_mean: 873.3012658227848
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 208.89221327195992
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0834401945273082
        entropy_coeff: 0.0005000000000000001
        kl: 0.008102510396080712
        model: {}
        policy_loss: -0.0116378908775611
        total_loss: 34.47308222452799
        vf_explained_var: 0.941558837890625
        vf_loss: 34.48445192972819
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.615625
    gpu_util_percent0: 0.353125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16084746185719212
    mean_env_wait_ms: 1.169844770588879
    mean_inference_ms: 5.198641765441218
    mean_raw_obs_processing_ms: 0.4287843597640836
  time_since_restore: 135.03057408332825
  time_this_iter_s: 26.446945905685425
  time_total_s: 135.03057408332825
  timers:
    learn_throughput: 8392.057
    learn_time_ms: 19279.184
    sample_throughput: 21165.389
    sample_time_ms: 7644.178
    update_time_ms: 37.661
  timestamp: 1602517576
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      5 |          135.031 | 808960 |  208.892 |                  267 |              136.242 |            873.301 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3512.602432179607
    time_step_min: 3204
  date: 2020-10-12_15-46-42
  done: false
  episode_len_mean: 862.558371040724
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 212.5103523927052
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0828134020169575
        entropy_coeff: 0.0005000000000000001
        kl: 0.007772813783958554
        model: {}
        policy_loss: -0.010905310687424693
        total_loss: 29.839585304260254
        vf_explained_var: 0.9594511389732361
        vf_loss: 29.85025469462077
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.612499999999997
    gpu_util_percent0: 0.296875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15844786316619539
    mean_env_wait_ms: 1.1734900952417473
    mean_inference_ms: 5.051226136576032
    mean_raw_obs_processing_ms: 0.42103086704729165
  time_since_restore: 161.5325698852539
  time_this_iter_s: 26.50199580192566
  time_total_s: 161.5325698852539
  timers:
    learn_throughput: 8380.862
    learn_time_ms: 19304.936
    sample_throughput: 21476.086
    sample_time_ms: 7533.589
    update_time_ms: 37.498
  timestamp: 1602517602
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      6 |          161.533 | 970752 |   212.51 |                  267 |              136.242 |            862.558 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3501.2597719869705
    time_step_min: 3175
  date: 2020-10-12_15-47-09
  done: false
  episode_len_mean: 857.7254746835443
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 214.3693421557344
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0574177900950115
        entropy_coeff: 0.0005000000000000001
        kl: 0.00769848582179596
        model: {}
        policy_loss: -0.01350904762512073
        total_loss: 17.78907855351766
        vf_explained_var: 0.9648939967155457
        vf_loss: 17.802346070607502
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.6
    gpu_util_percent0: 0.2525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875000000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758623435789765
    mean_env_wait_ms: 1.1750356710034693
    mean_inference_ms: 4.997312867874082
    mean_raw_obs_processing_ms: 0.41817171641331563
  time_since_restore: 187.98207116127014
  time_this_iter_s: 26.449501276016235
  time_total_s: 187.98207116127014
  timers:
    learn_throughput: 8369.46
    learn_time_ms: 19331.236
    sample_throughput: 21748.302
    sample_time_ms: 7439.294
    update_time_ms: 37.712
  timestamp: 1602517629
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      7 |          187.982 | 1132544 |  214.369 |                  267 |              136.242 |            857.725 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3493.8376623376626
    time_step_min: 3158
  date: 2020-10-12_15-47-36
  done: false
  episode_len_mean: 853.4549929676512
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 215.6040787623065
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0409260789553325
        entropy_coeff: 0.0005000000000000001
        kl: 0.00779755685168008
        model: {}
        policy_loss: -0.011598864497500472
        total_loss: 19.022697925567627
        vf_explained_var: 0.9629490971565247
        vf_loss: 19.03403838475545
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.299999999999997
    gpu_util_percent0: 0.315625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15685328253870606
    mean_env_wait_ms: 1.1764615222523243
    mean_inference_ms: 4.950501714371985
    mean_raw_obs_processing_ms: 0.41565139305652077
  time_since_restore: 214.50245141983032
  time_this_iter_s: 26.52038025856018
  time_total_s: 214.50245141983032
  timers:
    learn_throughput: 8366.214
    learn_time_ms: 19338.735
    sample_throughput: 21894.907
    sample_time_ms: 7389.481
    update_time_ms: 37.391
  timestamp: 1602517656
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      8 |          214.502 | 1294336 |  215.604 |                  267 |              136.242 |            853.455 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3486.4576051779936
    time_step_min: 3158
  date: 2020-10-12_15-48-02
  done: false
  episode_len_mean: 850.1170145477546
  episode_reward_max: 267.00000000000045
  episode_reward_mean: 216.83727215226253
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0032605528831482
        entropy_coeff: 0.0005000000000000001
        kl: 0.007478718568260471
        model: {}
        policy_loss: -0.013388285306670392
        total_loss: 17.289390722910564
        vf_explained_var: 0.9693426489830017
        vf_loss: 17.302532354990642
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.60625
    gpu_util_percent0: 0.3840625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15621132050769543
    mean_env_wait_ms: 1.177827681183549
    mean_inference_ms: 4.9093305963231355
    mean_raw_obs_processing_ms: 0.41337959427272913
  time_since_restore: 240.83976912498474
  time_this_iter_s: 26.33731770515442
  time_total_s: 240.83976912498474
  timers:
    learn_throughput: 8362.522
    learn_time_ms: 19347.273
    sample_throughput: 22075.016
    sample_time_ms: 7329.191
    update_time_ms: 35.484
  timestamp: 1602517682
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |      9 |           240.84 | 1456128 |  216.837 |                  267 |              136.242 |            850.117 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3468.207212055974
    time_step_min: 3158
  date: 2020-10-12_15-48-29
  done: false
  episode_len_mean: 843.5290390707497
  episode_reward_max: 268.96969696969654
  episode_reward_mean: 219.8268695401746
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 313
  episodes_total: 1894
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9728382378816605
        entropy_coeff: 0.0005000000000000001
        kl: 0.0068471186483899755
        model: {}
        policy_loss: -0.010848217488576969
        total_loss: 18.585219701131184
        vf_explained_var: 0.9735828042030334
        vf_loss: 18.595869382222492
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.653125
    gpu_util_percent0: 0.3465625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15517929168914635
    mean_env_wait_ms: 1.1804612047530476
    mean_inference_ms: 4.843155319210949
    mean_raw_obs_processing_ms: 0.4098508470882135
  time_since_restore: 267.34905219078064
  time_this_iter_s: 26.5092830657959
  time_total_s: 267.34905219078064
  timers:
    learn_throughput: 8358.843
    learn_time_ms: 19355.788
    sample_throughput: 22180.014
    sample_time_ms: 7294.495
    update_time_ms: 35.852
  timestamp: 1602517709
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     10 |          267.349 | 1617920 |  219.827 |               268.97 |              136.242 |            843.529 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3459.940039643211
    time_step_min: 3149
  date: 2020-10-12_15-48-55
  done: false
  episode_len_mean: 840.819376825706
  episode_reward_max: 268.96969696969654
  episode_reward_mean: 221.11539936856386
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.952570786078771
        entropy_coeff: 0.0005000000000000001
        kl: 0.006939189663777749
        model: {}
        policy_loss: -0.01326275585355082
        total_loss: 12.24478809038798
        vf_explained_var: 0.9761103987693787
        vf_loss: 12.257833242416382
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.190322580645166
    gpu_util_percent0: 0.2767741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1547489208133425
    mean_env_wait_ms: 1.181599824524856
    mean_inference_ms: 4.815546130157901
    mean_raw_obs_processing_ms: 0.408363265238068
  time_since_restore: 293.6315941810608
  time_this_iter_s: 26.28254199028015
  time_total_s: 293.6315941810608
  timers:
    learn_throughput: 8363.601
    learn_time_ms: 19344.777
    sample_throughput: 22920.096
    sample_time_ms: 7058.958
    update_time_ms: 34.559
  timestamp: 1602517735
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     11 |          293.632 | 1779712 |  221.115 |               268.97 |              136.242 |            840.819 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3451.996783088235
    time_step_min: 3149
  date: 2020-10-12_15-49-21
  done: false
  episode_len_mean: 838.5524412296564
  episode_reward_max: 276.5454545454551
  episode_reward_mean: 222.440161104718
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.93861157198747
        entropy_coeff: 0.0005000000000000001
        kl: 0.0065783633617684245
        model: {}
        policy_loss: -0.01096414635533923
        total_loss: 11.370628595352173
        vf_explained_var: 0.9759250283241272
        vf_loss: 11.381404479344686
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.196875
    gpu_util_percent0: 0.29375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7906250000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1543609998270237
    mean_env_wait_ms: 1.1826205863412682
    mean_inference_ms: 4.790618387088332
    mean_raw_obs_processing_ms: 0.40700249179404313
  time_since_restore: 320.02651262283325
  time_this_iter_s: 26.39491844177246
  time_total_s: 320.02651262283325
  timers:
    learn_throughput: 8362.935
    learn_time_ms: 19346.317
    sample_throughput: 23185.176
    sample_time_ms: 6978.252
    update_time_ms: 32.3
  timestamp: 1602517761
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     12 |          320.027 | 1941504 |   222.44 |              276.545 |              136.242 |            838.552 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3441.9974768713205
    time_step_min: 3121
  date: 2020-10-12_15-49-48
  done: false
  episode_len_mean: 835.330985915493
  episode_reward_max: 276.5454545454551
  episode_reward_mean: 223.75008159473768
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 202
  episodes_total: 2414
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8984403163194656
        entropy_coeff: 0.0005000000000000001
        kl: 0.006221253269662459
        model: {}
        policy_loss: -0.009880342788771182
        total_loss: 16.48670530319214
        vf_explained_var: 0.974186360836029
        vf_loss: 16.49641251564026
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.434375000000003
    gpu_util_percent0: 0.41250000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1539123211939552
    mean_env_wait_ms: 1.1840104793698365
    mean_inference_ms: 4.761840630861421
    mean_raw_obs_processing_ms: 0.405416402709353
  time_since_restore: 346.3722634315491
  time_this_iter_s: 26.34575080871582
  time_total_s: 346.3722634315491
  timers:
    learn_throughput: 8361.525
    learn_time_ms: 19349.58
    sample_throughput: 23273.228
    sample_time_ms: 6951.85
    update_time_ms: 36.262
  timestamp: 1602517788
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     13 |          346.372 | 2103296 |   223.75 |              276.545 |              136.242 |            835.331 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3429.613061532654
    time_step_min: 3121
  date: 2020-10-12_15-50-14
  done: false
  episode_len_mean: 831.2167597765363
  episode_reward_max: 276.5454545454553
  episode_reward_mean: 225.59765250268038
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 271
  episodes_total: 2685
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8792577832937241
        entropy_coeff: 0.0005000000000000001
        kl: 0.006186536280438304
        model: {}
        policy_loss: -0.009713826865966743
        total_loss: 12.887195348739624
        vf_explained_var: 0.9778575897216797
        vf_loss: 12.896730581919352
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.016129032258064
    gpu_util_percent0: 0.31677419354838715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534028739480966
    mean_env_wait_ms: 1.185681789859447
    mean_inference_ms: 4.728879633681253
    mean_raw_obs_processing_ms: 0.4036090429675461
  time_since_restore: 372.76343393325806
  time_this_iter_s: 26.391170501708984
  time_total_s: 372.76343393325806
  timers:
    learn_throughput: 8344.571
    learn_time_ms: 19388.894
    sample_throughput: 23309.245
    sample_time_ms: 6941.109
    update_time_ms: 34.375
  timestamp: 1602517814
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     14 |          372.763 | 2265088 |  225.598 |              276.545 |              136.242 |            831.217 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3422.2681623931626
    time_step_min: 3121
  date: 2020-10-12_15-50-41
  done: false
  episode_len_mean: 829.1111111111111
  episode_reward_max: 276.5454545454553
  episode_reward_mean: 226.5676170992626
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8780574252208074
        entropy_coeff: 0.0005000000000000001
        kl: 0.006002183809566001
        model: {}
        policy_loss: -0.010840655624633655
        total_loss: 10.460712591807047
        vf_explained_var: 0.9777989387512207
        vf_loss: 10.471392234166464
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.50625
    gpu_util_percent0: 0.279375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15313695941945013
    mean_env_wait_ms: 1.1865845758351525
    mean_inference_ms: 4.711786251297194
    mean_raw_obs_processing_ms: 0.40265741742314637
  time_since_restore: 399.3269395828247
  time_this_iter_s: 26.56350564956665
  time_total_s: 399.3269395828247
  timers:
    learn_throughput: 8336.011
    learn_time_ms: 19408.803
    sample_throughput: 23346.481
    sample_time_ms: 6930.038
    update_time_ms: 36.469
  timestamp: 1602517841
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     15 |          399.327 | 2426880 |  226.568 |              276.545 |              136.242 |            829.111 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3415.3331087908387
    time_step_min: 3112
  date: 2020-10-12_15-51-07
  done: false
  episode_len_mean: 826.9144758735441
  episode_reward_max: 279.42424242424227
  episode_reward_mean: 227.6205818585186
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 161
  episodes_total: 3005
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8447853823502859
        entropy_coeff: 0.0005000000000000001
        kl: 0.0059578693471848965
        model: {}
        policy_loss: -0.009374744794816555
        total_loss: 11.64163851737976
        vf_explained_var: 0.9763595461845398
        vf_loss: 11.650839964548746
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.459375
    gpu_util_percent0: 0.3209375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528852748033761
    mean_env_wait_ms: 1.1875081900142226
    mean_inference_ms: 4.6956509005051785
    mean_raw_obs_processing_ms: 0.4017426785495079
  time_since_restore: 425.56263399124146
  time_this_iter_s: 26.235694408416748
  time_total_s: 425.56263399124146
  timers:
    learn_throughput: 8346.025
    learn_time_ms: 19385.516
    sample_throughput: 23360.701
    sample_time_ms: 6925.82
    update_time_ms: 36.358
  timestamp: 1602517867
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     16 |          425.563 | 2588672 |  227.621 |              279.424 |              136.242 |            826.914 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3404.028981086028
    time_step_min: 3093
  date: 2020-10-12_15-51-34
  done: false
  episode_len_mean: 823.415509957755
  episode_reward_max: 279.42424242424227
  episode_reward_mean: 229.41505276055662
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 309
  episodes_total: 3314
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8260619839032491
        entropy_coeff: 0.0005000000000000001
        kl: 0.006421650837485989
        model: {}
        policy_loss: -0.009145767389175793
        total_loss: 13.133175134658813
        vf_explained_var: 0.9803077578544617
        vf_loss: 13.142091671625773
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.10322580645161
    gpu_util_percent0: 0.3667741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15245966793847177
    mean_env_wait_ms: 1.1892310955614251
    mean_inference_ms: 4.6681874946673
    mean_raw_obs_processing_ms: 0.40022353458061416
  time_since_restore: 451.86275935173035
  time_this_iter_s: 26.30012536048889
  time_total_s: 451.86275935173035
  timers:
    learn_throughput: 8359.445
    learn_time_ms: 19354.394
    sample_throughput: 23311.313
    sample_time_ms: 6940.493
    update_time_ms: 36.481
  timestamp: 1602517894
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     17 |          451.863 | 2750464 |  229.415 |              279.424 |              136.242 |            823.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3398.445930232558
    time_step_min: 3088
  date: 2020-10-12_15-52-01
  done: false
  episode_len_mean: 821.7310126582279
  episode_reward_max: 279.42424242424227
  episode_reward_mean: 230.2455887993862
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 162
  episodes_total: 3476
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7999657342831293
        entropy_coeff: 0.0005000000000000001
        kl: 0.005766421129616599
        model: {}
        policy_loss: -0.012520057265646756
        total_loss: 8.275206168492636
        vf_explained_var: 0.9822821617126465
        vf_loss: 8.28754965464274
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.124242424242425
    gpu_util_percent0: 0.3612121212121212
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7818181818181817
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15225596005139935
    mean_env_wait_ms: 1.190015248844769
    mean_inference_ms: 4.655339196476377
    mean_raw_obs_processing_ms: 0.3995090954299829
  time_since_restore: 478.59441590309143
  time_this_iter_s: 26.731656551361084
  time_total_s: 478.59441590309143
  timers:
    learn_throughput: 8355.491
    learn_time_ms: 19363.554
    sample_throughput: 23277.47
    sample_time_ms: 6950.583
    update_time_ms: 37.139
  timestamp: 1602517921
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     18 |          478.594 | 2912256 |  230.246 |              279.424 |              136.242 |            821.731 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3392.4371873262926
    time_step_min: 3088
  date: 2020-10-12_15-52-27
  done: false
  episode_len_mean: 820.1821684094662
  episode_reward_max: 279.42424242424227
  episode_reward_mean: 231.0936608795717
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7937028606732687
        entropy_coeff: 0.0005000000000000001
        kl: 0.005935679965962966
        model: {}
        policy_loss: -0.012428551142268892
        total_loss: 9.381741841634115
        vf_explained_var: 0.978752613067627
        vf_loss: 9.393973429997763
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.99354838709678
    gpu_util_percent0: 0.37290322580645163
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15207228948968107
    mean_env_wait_ms: 1.1907745189490146
    mean_inference_ms: 4.64358099690356
    mean_raw_obs_processing_ms: 0.3988437093492569
  time_since_restore: 504.8883903026581
  time_this_iter_s: 26.29397439956665
  time_total_s: 504.8883903026581
  timers:
    learn_throughput: 8362.646
    learn_time_ms: 19346.986
    sample_throughput: 23239.602
    sample_time_ms: 6961.909
    update_time_ms: 37.156
  timestamp: 1602517947
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     19 |          504.888 | 3074048 |  231.094 |              279.424 |              136.242 |            820.182 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3384.686385946784
    time_step_min: 3076
  date: 2020-10-12_15-52-54
  done: false
  episode_len_mean: 817.9669823393908
  episode_reward_max: 280.181818181819
  episode_reward_mean: 232.309545415765
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 273
  episodes_total: 3907
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7688640058040619
        entropy_coeff: 0.0005000000000000001
        kl: 0.005751285973625879
        model: {}
        policy_loss: -0.008068479248322546
        total_loss: 13.53387713432312
        vf_explained_var: 0.9797406196594238
        vf_loss: 13.541754881540934
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.721875
    gpu_util_percent0: 0.364375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517785616581238
    mean_env_wait_ms: 1.1920648853891491
    mean_inference_ms: 4.625039677733243
    mean_raw_obs_processing_ms: 0.3978073437170143
  time_since_restore: 531.4615414142609
  time_this_iter_s: 26.573151111602783
  time_total_s: 531.4615414142609
  timers:
    learn_throughput: 8370.365
    learn_time_ms: 19329.146
    sample_throughput: 23154.493
    sample_time_ms: 6987.499
    update_time_ms: 35.4
  timestamp: 1602517974
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     20 |          531.462 | 3235840 |   232.31 |              280.182 |              136.242 |            817.967 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3378.114931237721
    time_step_min: 3076
  date: 2020-10-12_15-53-20
  done: false
  episode_len_mean: 816.805988315482
  episode_reward_max: 282.0000000000004
  episode_reward_mean: 233.28526009855122
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 201
  episodes_total: 4108
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7478803247213364
        entropy_coeff: 0.0005000000000000001
        kl: 0.005493286298587918
        model: {}
        policy_loss: -0.009481565718791293
        total_loss: 8.676706790924072
        vf_explained_var: 0.9827273488044739
        vf_loss: 8.686012983322144
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.771875
    gpu_util_percent0: 0.36406249999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15158864864935168
    mean_env_wait_ms: 1.1928740074053141
    mean_inference_ms: 4.612583226291723
    mean_raw_obs_processing_ms: 0.3971228046087983
  time_since_restore: 557.9242601394653
  time_this_iter_s: 26.462718725204468
  time_total_s: 557.9242601394653
  timers:
    learn_throughput: 8374.368
    learn_time_ms: 19319.905
    sample_throughput: 23064.464
    sample_time_ms: 7014.774
    update_time_ms: 33.897
  timestamp: 1602518000
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     21 |          557.924 | 3397632 |  233.285 |                  282 |              136.242 |            816.806 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3372.9333333333334
    time_step_min: 3076
  date: 2020-10-12_15-53-47
  done: false
  episode_len_mean: 815.9709329582747
  episode_reward_max: 282.0000000000004
  episode_reward_mean: 234.00482319680629
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7441265483697256
        entropy_coeff: 0.0005000000000000001
        kl: 0.006011400294179718
        model: {}
        policy_loss: -0.012443608846903468
        total_loss: 8.12285848458608
        vf_explained_var: 0.981548547744751
        vf_loss: 8.135072708129883
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.41875
    gpu_util_percent0: 0.29593749999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15144668489007349
    mean_env_wait_ms: 1.1934656867694324
    mean_inference_ms: 4.603463436301153
    mean_raw_obs_processing_ms: 0.39661383171793446
  time_since_restore: 584.3881635665894
  time_this_iter_s: 26.463903427124023
  time_total_s: 584.3881635665894
  timers:
    learn_throughput: 8367.515
    learn_time_ms: 19335.729
    sample_throughput: 23099.569
    sample_time_ms: 7004.113
    update_time_ms: 34.053
  timestamp: 1602518027
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | RUNNING  | 172.17.0.4:29107 |     22 |          584.388 | 3559424 |  234.005 |                  282 |              136.242 |            815.971 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_bba05_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3366.973940629957
    time_step_min: 3076
  date: 2020-10-12_15-54-13
  done: true
  episode_len_mean: 815.1571139581929
  episode_reward_max: 282.0000000000004
  episode_reward_mean: 234.8332890605311
  episode_reward_min: 136.24242424242374
  episodes_this_iter: 183
  episodes_total: 4449
  experiment_id: 999d4a81dafd4bec8bb61ec945f9b4c8
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7222094535827637
        entropy_coeff: 0.0005000000000000001
        kl: 0.005956807329008977
        model: {}
        policy_loss: -0.009062373486813158
        total_loss: 8.264012813568115
        vf_explained_var: 0.9844412207603455
        vf_loss: 8.27284061908722
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.440624999999997
    gpu_util_percent0: 0.34875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29107
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15129255122381483
    mean_env_wait_ms: 1.1941179839859726
    mean_inference_ms: 4.5935160062929485
    mean_raw_obs_processing_ms: 0.3960567982197601
  time_since_restore: 610.4675097465515
  time_this_iter_s: 26.079346179962158
  time_total_s: 610.4675097465515
  timers:
    learn_throughput: 8374.812
    learn_time_ms: 19318.882
    sample_throughput: 23115.198
    sample_time_ms: 6999.378
    update_time_ms: 28.42
  timestamp: 1602518053
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: bba05_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | TERMINATED |       |     23 |          610.468 | 3721216 |  234.833 |                  282 |              136.242 |            815.157 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_bba05_00000 | TERMINATED |       |     23 |          610.468 | 3721216 |  234.833 |                  282 |              136.242 |            815.157 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


