2020-10-11 00:02:38,195	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_13abf_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=48933)[0m 2020-10-11 00:02:41,065	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=48884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=48903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=48903)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_00-03-23
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1820176243782043
        entropy_coeff: 0.00010000000000000002
        kl: 0.0069598543590732986
        model: {}
        policy_loss: -0.004741866765211203
        total_loss: 16.360084329332626
        vf_explained_var: 0.5462602972984314
        vf_loss: 16.36355229786464
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.088636363636365
    gpu_util_percent0: 0.34727272727272723
    gpu_util_percent1: 0.00022727272727272727
    gpu_util_percent2: 0.0
    ram_util_percent: 6.293181818181816
    vram_util_percent0: 0.1927084886251826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17012563742543121
    mean_env_wait_ms: 1.1865874446811187
    mean_inference_ms: 5.590354934744203
    mean_raw_obs_processing_ms: 0.4577178960966822
  time_since_restore: 36.228994846343994
  time_this_iter_s: 36.228994846343994
  time_total_s: 36.228994846343994
  timers:
    learn_throughput: 5950.752
    learn_time_ms: 27188.497
    sample_throughput: 18045.399
    sample_time_ms: 8965.831
    update_time_ms: 25.859
  timestamp: 1602374603
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      1 |           36.229 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3605.3958333333335
    time_step_min: 3335
  date: 2020-10-11_00-03-58
  done: false
  episode_len_mean: 880.2341772151899
  episode_reward_max: 261.77777777777743
  episode_reward_mean: 219.23078890167477
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1475532140050615
        entropy_coeff: 0.00010000000000000002
        kl: 0.009957194793969393
        model: {}
        policy_loss: -0.0077176482107980905
        total_loss: 11.147395542689733
        vf_explained_var: 0.8114591836929321
        vf_loss: 11.153236661638532
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.55581395348837
    gpu_util_percent0: 0.3441860465116279
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.469767441860465
    vram_util_percent0: 0.2046572646769432
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16587181209266447
    mean_env_wait_ms: 1.1888910336251888
    mean_inference_ms: 5.409540104846532
    mean_raw_obs_processing_ms: 0.4467268533843856
  time_since_restore: 71.5466856956482
  time_this_iter_s: 35.3176908493042
  time_total_s: 71.5466856956482
  timers:
    learn_throughput: 5953.644
    learn_time_ms: 27175.29
    sample_throughput: 19049.998
    sample_time_ms: 8493.019
    update_time_ms: 53.902
  timestamp: 1602374638
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      2 |          71.5467 | 323584 |  219.231 |              261.778 |              145.717 |            880.234 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3590.8004484304934
    time_step_min: 3246
  date: 2020-10-11_00-04-32
  done: false
  episode_len_mean: 869.3059071729958
  episode_reward_max: 274.2020202020199
  episode_reward_mean: 220.93037974683526
  episode_reward_min: 143.44444444444454
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1334496651376997
        entropy_coeff: 0.00010000000000000002
        kl: 0.006775797577574849
        model: {}
        policy_loss: -0.006553133447076627
        total_loss: 13.065423148018974
        vf_explained_var: 0.8745900988578796
        vf_loss: 13.070734637124199
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.0
    gpu_util_percent0: 0.36048780487804877
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.490243902439025
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16310291437929825
    mean_env_wait_ms: 1.1919049006977378
    mean_inference_ms: 5.2576320255806275
    mean_raw_obs_processing_ms: 0.4386287034939578
  time_since_restore: 105.99318027496338
  time_this_iter_s: 34.446494579315186
  time_total_s: 105.99318027496338
  timers:
    learn_throughput: 5972.325
    learn_time_ms: 27090.288
    sample_throughput: 19858.27
    sample_time_ms: 8147.336
    update_time_ms: 42.653
  timestamp: 1602374672
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      3 |          105.993 | 485376 |   220.93 |              274.202 |              143.444 |            869.306 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3582.162251655629
    time_step_min: 3246
  date: 2020-10-11_00-05-07
  done: false
  episode_len_mean: 860.2610759493671
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 221.9988172867918
  episode_reward_min: 143.44444444444454
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1033346567835127
        entropy_coeff: 0.00010000000000000002
        kl: 0.005734119664079377
        model: {}
        policy_loss: -0.005027659308065527
        total_loss: 14.594031946999687
        vf_explained_var: 0.9078501462936401
        vf_loss: 14.598022597176689
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.688095238095237
    gpu_util_percent0: 0.34833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16118452113986315
    mean_env_wait_ms: 1.1960090228587035
    mean_inference_ms: 5.146276153552044
    mean_raw_obs_processing_ms: 0.43272438269919933
  time_since_restore: 140.5677297115326
  time_this_iter_s: 34.574549436569214
  time_total_s: 140.5677297115326
  timers:
    learn_throughput: 5965.187
    learn_time_ms: 27122.703
    sample_throughput: 20410.475
    sample_time_ms: 7926.91
    update_time_ms: 41.884
  timestamp: 1602374707
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      4 |          140.568 | 647168 |  221.999 |              279.051 |              143.444 |            860.261 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3584.2070098576123
    time_step_min: 3246
  date: 2020-10-11_00-05-42
  done: false
  episode_len_mean: 846.2072263549416
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 221.84508206399795
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 309
  episodes_total: 941
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0758123738425118
        entropy_coeff: 0.00010000000000000002
        kl: 0.005940954832892332
        model: {}
        policy_loss: -0.006455366062125124
        total_loss: 21.154108592442103
        vf_explained_var: 0.9423086047172546
        vf_loss: 21.159483364650182
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.165853658536584
    gpu_util_percent0: 0.32
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.485365853658536
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15881069851633003
    mean_env_wait_ms: 1.2050976551711607
    mean_inference_ms: 5.005165344868187
    mean_raw_obs_processing_ms: 0.4254501902405021
  time_since_restore: 174.97063660621643
  time_this_iter_s: 34.40290689468384
  time_total_s: 174.97063660621643
  timers:
    learn_throughput: 5971.406
    learn_time_ms: 27094.456
    sample_throughput: 20711.924
    sample_time_ms: 7811.539
    update_time_ms: 37.532
  timestamp: 1602374742
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      5 |          174.971 | 808960 |  221.845 |              279.051 |              81.9293 |            846.207 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3582.1549165120596
    time_step_min: 3246
  date: 2020-10-11_00-06-16
  done: false
  episode_len_mean: 840.0714285714286
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 222.51370851370837
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 165
  episodes_total: 1106
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0598390102386475
        entropy_coeff: 0.00010000000000000002
        kl: 0.0073557150816278795
        model: {}
        policy_loss: -0.005962101098183277
        total_loss: 13.38794572012765
        vf_explained_var: 0.9523463249206543
        vf_loss: 13.392542294093541
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.758536585365857
    gpu_util_percent0: 0.33804878048780485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975609756097565
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15798973275484135
    mean_env_wait_ms: 1.2090044500230928
    mean_inference_ms: 4.953288778189945
    mean_raw_obs_processing_ms: 0.4228071551926504
  time_since_restore: 208.97268795967102
  time_this_iter_s: 34.00205135345459
  time_total_s: 208.97268795967102
  timers:
    learn_throughput: 5986.173
    learn_time_ms: 27027.617
    sample_throughput: 20970.604
    sample_time_ms: 7715.181
    update_time_ms: 34.869
  timestamp: 1602374776
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      6 |          208.973 | 970752 |  222.514 |              279.051 |              81.9293 |            840.071 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3581.470873786408
    time_step_min: 3246
  date: 2020-10-11_00-06-50
  done: false
  episode_len_mean: 834.6400316455696
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 222.94207102672277
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0283911398478918
        entropy_coeff: 0.00010000000000000002
        kl: 0.006219951236354453
        model: {}
        policy_loss: -0.004737772833323106
        total_loss: 11.314220973423549
        vf_explained_var: 0.9675159454345703
        vf_loss: 11.31781782422747
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.28333333333333
    gpu_util_percent0: 0.39785714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488095238095238
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15729770607986893
    mean_env_wait_ms: 1.2122057221828133
    mean_inference_ms: 4.91028780370698
    mean_raw_obs_processing_ms: 0.42055466438160816
  time_since_restore: 243.62513947486877
  time_this_iter_s: 34.652451515197754
  time_total_s: 243.62513947486877
  timers:
    learn_throughput: 5989.119
    learn_time_ms: 27014.322
    sample_throughput: 21024.373
    sample_time_ms: 7695.449
    update_time_ms: 42.126
  timestamp: 1602374810
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      7 |          243.625 | 1132544 |  222.942 |              279.051 |              81.9293 |             834.64 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4115
    time_step_mean: 3579.067431850789
    time_step_min: 3246
  date: 2020-10-11_00-07-25
  done: false
  episode_len_mean: 830.3129395218003
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 223.2276136896389
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9636454965387072
        entropy_coeff: 0.00010000000000000002
        kl: 0.006638339620881847
        model: {}
        policy_loss: -0.004844950647176509
        total_loss: 10.614839008876256
        vf_explained_var: 0.9777140617370605
        vf_loss: 10.618452617100306
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.717073170731705
    gpu_util_percent0: 0.36634146341463414
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1567094921003425
    mean_env_wait_ms: 1.2155526207337193
    mean_inference_ms: 4.872920335272326
    mean_raw_obs_processing_ms: 0.41849440084452294
  time_since_restore: 278.03785371780396
  time_this_iter_s: 34.41271424293518
  time_total_s: 278.03785371780396
  timers:
    learn_throughput: 5988.816
    learn_time_ms: 27015.69
    sample_throughput: 21157.116
    sample_time_ms: 7647.167
    update_time_ms: 40.658
  timestamp: 1602374845
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      8 |          278.038 | 1294336 |  223.228 |              279.051 |              81.9293 |            830.313 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3579.730409356725
    time_step_min: 3246
  date: 2020-10-11_00-07-59
  done: false
  episode_len_mean: 823.0828538550057
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 223.3428822168752
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9320426200117383
        entropy_coeff: 0.00010000000000000002
        kl: 0.00629029526109142
        model: {}
        policy_loss: -0.005366985827484834
        total_loss: 11.697356428418841
        vf_explained_var: 0.9824801087379456
        vf_loss: 11.701558317456927
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.168292682926825
    gpu_util_percent0: 0.36073170731707316
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480487804878049
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15578536738315846
    mean_env_wait_ms: 1.221685316485309
    mean_inference_ms: 4.813646776681262
    mean_raw_obs_processing_ms: 0.4153832517937352
  time_since_restore: 312.06745290756226
  time_this_iter_s: 34.0295991897583
  time_total_s: 312.06745290756226
  timers:
    learn_throughput: 5993.185
    learn_time_ms: 26995.997
    sample_throughput: 21321.408
    sample_time_ms: 7588.242
    update_time_ms: 38.799
  timestamp: 1602374879
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |      9 |          312.067 | 1456128 |  223.343 |              279.051 |              81.9293 |            823.083 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3582.7767665952892
    time_step_min: 3246
  date: 2020-10-11_00-08-33
  done: false
  episode_len_mean: 820.125
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 223.35550121467833
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8944336942264012
        entropy_coeff: 0.00010000000000000002
        kl: 0.005758017567651612
        model: {}
        policy_loss: -0.005924022995584112
        total_loss: 6.229271071297782
        vf_explained_var: 0.9881458878517151
        vf_loss: 6.234132868903024
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.897560975609757
    gpu_util_percent0: 0.37097560975609756
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4902439024390235
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15540808049792562
    mean_env_wait_ms: 1.2242473264113167
    mean_inference_ms: 4.7895379625493035
    mean_raw_obs_processing_ms: 0.4140842446207045
  time_since_restore: 346.5591218471527
  time_this_iter_s: 34.491668939590454
  time_total_s: 346.5591218471527
  timers:
    learn_throughput: 5992.157
    learn_time_ms: 27000.626
    sample_throughput: 21382.095
    sample_time_ms: 7566.705
    update_time_ms: 36.869
  timestamp: 1602374913
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     10 |          346.559 | 1617920 |  223.356 |              279.051 |              81.9293 |            820.125 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3581.3923988153997
    time_step_min: 3246
  date: 2020-10-11_00-09-08
  done: false
  episode_len_mean: 817.537487828627
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 223.5092109016159
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8519032597541809
        entropy_coeff: 0.00010000000000000002
        kl: 0.005229554604738951
        model: {}
        policy_loss: -0.00531569288328423
        total_loss: 5.3119844027927945
        vf_explained_var: 0.990203857421875
        vf_loss: 5.3163392543792725
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.261904761904763
    gpu_util_percent0: 0.3645238095238095
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15506643114646962
    mean_env_wait_ms: 1.22671601518555
    mean_inference_ms: 4.767740897936148
    mean_raw_obs_processing_ms: 0.41284899636698263
  time_since_restore: 381.26447653770447
  time_this_iter_s: 34.70535469055176
  time_total_s: 381.26447653770447
  timers:
    learn_throughput: 5994.937
    learn_time_ms: 26988.106
    sample_throughput: 21790.454
    sample_time_ms: 7424.903
    update_time_ms: 38.276
  timestamp: 1602374948
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     11 |          381.264 | 1779712 |  223.509 |              279.051 |              81.9293 |            817.537 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3576.407090986758
    time_step_min: 3246
  date: 2020-10-11_00-09-43
  done: false
  episode_len_mean: 813.242718446602
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 224.1509821729323
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 315
  episodes_total: 2369
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8196450557027545
        entropy_coeff: 0.00010000000000000002
        kl: 0.004613416468990701
        model: {}
        policy_loss: -0.0037671777099603787
        total_loss: 6.480540411812918
        vf_explained_var: 0.9922000765800476
        vf_loss: 6.48346699987139
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.4
    gpu_util_percent0: 0.32404761904761903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15447962199514587
    mean_env_wait_ms: 1.2313371157910251
    mean_inference_ms: 4.730672710951884
    mean_raw_obs_processing_ms: 0.4108018778252209
  time_since_restore: 416.01243591308594
  time_this_iter_s: 34.74795937538147
  time_total_s: 416.01243591308594
  timers:
    learn_throughput: 5992.677
    learn_time_ms: 26998.283
    sample_throughput: 21973.479
    sample_time_ms: 7363.058
    update_time_ms: 32.389
  timestamp: 1602374983
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     12 |          416.012 | 1941504 |  224.151 |              279.051 |              81.9293 |            813.243 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3574.1276
    time_step_min: 3246
  date: 2020-10-11_00-10-18
  done: false
  episode_len_mean: 811.248417721519
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 224.63211226185905
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 159
  episodes_total: 2528
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7592620168413434
        entropy_coeff: 0.00010000000000000002
        kl: 0.006721934004287634
        model: {}
        policy_loss: -0.004931115994362959
        total_loss: 3.8912049531936646
        vf_explained_var: 0.9931047558784485
        vf_loss: 3.895539811679295
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.597560975609756
    gpu_util_percent0: 0.37902439024390244
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15422686922506643
    mean_env_wait_ms: 1.233408706048709
    mean_inference_ms: 4.714595758238992
    mean_raw_obs_processing_ms: 0.4099134353513115
  time_since_restore: 450.3980062007904
  time_this_iter_s: 34.38557028770447
  time_total_s: 450.3980062007904
  timers:
    learn_throughput: 5989.489
    learn_time_ms: 27012.655
    sample_throughput: 22038.189
    sample_time_ms: 7341.438
    update_time_ms: 32.719
  timestamp: 1602375018
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     13 |          450.398 | 2103296 |  224.632 |              279.051 |              81.9293 |            811.248 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3570.8615500376222
    time_step_min: 3246
  date: 2020-10-11_00-10-52
  done: false
  episode_len_mean: 809.4173492181683
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 225.1318132930195
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7363480499812535
        entropy_coeff: 0.00010000000000000002
        kl: 0.005853402727682676
        model: {}
        policy_loss: -0.002718209072814456
        total_loss: 3.6041321754455566
        vf_explained_var: 0.9931531548500061
        vf_loss: 3.6063387393951416
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.297560975609755
    gpu_util_percent0: 0.3397560975609756
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502439024390244
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15399477179270002
    mean_env_wait_ms: 1.2353973254088635
    mean_inference_ms: 4.699841522454852
    mean_raw_obs_processing_ms: 0.40908156140878826
  time_since_restore: 484.749329328537
  time_this_iter_s: 34.35132312774658
  time_total_s: 484.749329328537
  timers:
    learn_throughput: 5993.167
    learn_time_ms: 26996.076
    sample_throughput: 22053.223
    sample_time_ms: 7336.433
    update_time_ms: 31.086
  timestamp: 1602375052
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     14 |          484.749 | 2265088 |  225.132 |              279.051 |              81.9293 |            809.417 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3564.906408952187
    time_step_min: 3246
  date: 2020-10-11_00-11-27
  done: false
  episode_len_mean: 806.485387974471
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 226.05084095913787
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 291
  episodes_total: 2977
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.7023474276065826
        entropy_coeff: 0.00010000000000000002
        kl: 0.005382358728508864
        model: {}
        policy_loss: -0.0028152257229001926
        total_loss: 4.32114120892116
        vf_explained_var: 0.9943504333496094
        vf_loss: 4.323488337653024
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.497560975609755
    gpu_util_percent0: 0.41121951219512193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480487804878049
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15360020315407633
    mean_env_wait_ms: 1.238928599822238
    mean_inference_ms: 4.675309063295611
    mean_raw_obs_processing_ms: 0.40770360643565046
  time_since_restore: 519.3888158798218
  time_this_iter_s: 34.63948655128479
  time_total_s: 519.3888158798218
  timers:
    learn_throughput: 5988.279
    learn_time_ms: 27018.112
    sample_throughput: 22051.06
    sample_time_ms: 7337.153
    update_time_ms: 31.342
  timestamp: 1602375087
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     15 |          519.389 | 2426880 |  226.051 |              279.051 |              81.9293 |            806.485 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3560.501277139208
    time_step_min: 3246
  date: 2020-10-11_00-12-01
  done: false
  episode_len_mean: 804.8300632911393
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 226.75198184375398
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 183
  episodes_total: 3160
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.66109699010849
        entropy_coeff: 0.00010000000000000002
        kl: 0.004631662142596075
        model: {}
        policy_loss: -0.0050587570118035986
        total_loss: 3.0414798940931047
        vf_explained_var: 0.9943700432777405
        vf_loss: 3.0461416244506836
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.14146341463415
    gpu_util_percent0: 0.34585365853658534
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497560975609756
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15340126738495427
    mean_env_wait_ms: 1.240913032538954
    mean_inference_ms: 4.662144935875801
    mean_raw_obs_processing_ms: 0.40696412636446644
  time_since_restore: 553.6906659603119
  time_this_iter_s: 34.30185008049011
  time_total_s: 553.6906659603119
  timers:
    learn_throughput: 5981.066
    learn_time_ms: 27050.696
    sample_throughput: 22063.049
    sample_time_ms: 7333.166
    update_time_ms: 32.305
  timestamp: 1602375121
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     16 |          553.691 | 2588672 |  226.752 |              279.051 |              81.9293 |             804.83 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3556.5838905775076
    time_step_min: 3246
  date: 2020-10-11_00-12-36
  done: false
  episode_len_mean: 803.4159132007234
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 227.3082178018887
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.647197812795639
        entropy_coeff: 0.00010000000000000002
        kl: 0.0059461207461676425
        model: {}
        policy_loss: -0.004620252684357443
        total_loss: 2.6572485991886685
        vf_explained_var: 0.9944009780883789
        vf_loss: 2.661636301449367
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.442857142857143
    gpu_util_percent0: 0.34833333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15323350696570526
    mean_env_wait_ms: 1.2425418573524412
    mean_inference_ms: 4.651331920746692
    mean_raw_obs_processing_ms: 0.4063509099436541
  time_since_restore: 588.1213257312775
  time_this_iter_s: 34.430659770965576
  time_total_s: 588.1213257312775
  timers:
    learn_throughput: 5978.287
    learn_time_ms: 27063.271
    sample_throughput: 22150.942
    sample_time_ms: 7304.068
    update_time_ms: 25.621
  timestamp: 1602375156
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | RUNNING  | 172.17.0.4:48933 |     17 |          588.121 | 2750464 |  227.308 |              279.051 |              81.9293 |            803.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13abf_00000:
  custom_metrics:
    time_step_max: 4378
    time_step_mean: 3549.5276211950395
    time_step_min: 3238
  date: 2020-10-11_00-13-10
  done: true
  episode_len_mean: 801.1277964205816
  episode_reward_max: 279.0505050505051
  episode_reward_mean: 228.2979289539692
  episode_reward_min: 81.92929292929283
  episodes_this_iter: 258
  episodes_total: 3576
  experiment_id: 8945cea8b50746c1922ecf3b79283cec
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.6165429268564496
        entropy_coeff: 0.00010000000000000002
        kl: 0.005042581419859614
        model: {}
        policy_loss: -0.0032659050650961164
        total_loss: 3.3520610332489014
        vf_explained_var: 0.9947509169578552
        vf_loss: 3.355136445590428
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.778048780487804
    gpu_util_percent0: 0.35585365853658535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.492682926829268
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 48933
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15298016622988256
    mean_env_wait_ms: 1.2451654362418898
    mean_inference_ms: 4.635160351296437
    mean_raw_obs_processing_ms: 0.4054294303569258
  time_since_restore: 622.5005345344543
  time_this_iter_s: 34.37920880317688
  time_total_s: 622.5005345344543
  timers:
    learn_throughput: 5976.73
    learn_time_ms: 27070.321
    sample_throughput: 22184.528
    sample_time_ms: 7293.011
    update_time_ms: 24.714
  timestamp: 1602375190
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 13abf_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | TERMINATED |       |     18 |          622.501 | 2912256 |  228.298 |              279.051 |              81.9293 |            801.128 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.21 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13abf_00000 | TERMINATED |       |     18 |          622.501 | 2912256 |  228.298 |              279.051 |              81.9293 |            801.128 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


