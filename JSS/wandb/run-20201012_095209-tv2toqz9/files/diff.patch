diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index d0ca168..d9fd4a8 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -67,14 +67,11 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
     "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
+    "                'values': [1e-3, 5e-4, 1e-4]\n",
     "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [20, 25]\n",
     "            }\n",
     "        }\n",
     "    }"
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index d0ca168..6224e68 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 11,
    "metadata": {},
    "outputs": [
     {
@@ -67,14 +67,11 @@
     "            'clip_param': {\n",
     "                'values': [0.3, 0.5]\n",
     "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
     "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
+    "                'values': [1e-3, 5e-4, 1e-4]\n",
     "            },\n",
     "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "                'values': [20, 25]\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +79,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 12,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: q78e25ms\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\n"
      ]
     }
    ],
@@ -108,203 +105,235 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-12 07:55:17,807 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 07:55:18,127 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 07:55:18,127 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 07:55:18,129 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.001 --num_sgd_iter=20\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/oa6h6n34\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_075519-oa6h6n34\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 07:55:23,142 - wandb.wandb_agent - INFO - Running runs: ['oa6h6n34']\n",
+      "2020-10-12 07:55:23,655\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m F1012 07:55:25.842725 47316 47316 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:35227\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1296ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a12a84c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1293c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a1295e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050a0e0789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e241ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e242ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e24491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509e26801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509da7ed6  ray::CoreWorker::CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dabc14  ray::CoreWorkerProcess::CreateWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dace82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509dad84b  ray::CoreWorkerProcess::Initialize()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509ceb448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f0509cecba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df60137d  _PyObject_MakeTpCall\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df689d09  _PyEval_EvalFrameDefault\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64ebaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64f643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5c4de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64e6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df64f454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6ddbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6ddc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df70fd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d8625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d8a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df5d98cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df712829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x7f050b42e840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=47316)\u001b[0m     @     0x5624df6a2b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=47416)\u001b[0m 2020-10-12 07:55:26,358\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=47424)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47424)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47415)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47415)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47401)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47401)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47419)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47419)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47295)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47295)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47399)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47399)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47420)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47420)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47396)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47396)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47296)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47296)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47374)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47374)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47293)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47293)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47291)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47291)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47302)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47302)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47367)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47367)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47403)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47403)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=47363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=47363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=48709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=48709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_07-55-56\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,23 +341,23 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        entropy: 1.1858798464139302\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004064181082261105\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
+      "        policy_loss: -0.006395086013526452\n",
+      "        total_loss: 514.7333170572916\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -336,65 +365,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 33.325\n",
+      "    gpu_util_percent0: 0.2092857142857143\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.521428571428572\n",
+      "    vram_util_percent0: 0.0827847537834419\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.1714163571458129\n",
+      "    mean_env_wait_ms: 1.1807994247771\n",
+      "    mean_inference_ms: 6.147634724696208\n",
+      "    mean_raw_obs_processing_ms: 0.4624706714673703\n",
+      "  time_since_restore: 24.50074791908264\n",
+      "  time_this_iter_s: 24.50074791908264\n",
+      "  time_total_s: 24.50074791908264\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 10802.415\n",
+      "    learn_time_ms: 14977.391\n",
+      "    sample_throughput: 17107.315\n",
+      "    sample_time_ms: 9457.475\n",
+      "    update_time_ms: 31.281\n",
+      "  timestamp: 1602489356\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      1 |          24.5007 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3627.0208333333335\n",
+      "    time_step_min: 3371\n",
+      "  date: 2020-10-12_07-56-18\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 890.1550632911392\n",
+      "  episode_reward_max: 261.3232323232323\n",
+      "  episode_reward_mean: 216.59365809998698\n",
+      "  episode_reward_min: 136.92929292929247\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -403,14 +432,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        entropy: 1.1566268702348073\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0074133020437632995\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.006318914315973719\n",
+      "        total_loss: 150.94015757242838\n",
+      "        vf_explained_var: 0.7832780480384827\n",
+      "        vf_loss: 150.94689814249674\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,65 +447,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 30.403846153846153\n",
+      "    gpu_util_percent0: 0.2919230769230769\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.738461538461538\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.16644640977929873\n",
+      "    mean_env_wait_ms: 1.1752532318633375\n",
+      "    mean_inference_ms: 5.803889831603577\n",
+      "    mean_raw_obs_processing_ms: 0.44867825635494135\n",
+      "  time_since_restore: 46.78164482116699\n",
+      "  time_this_iter_s: 22.28089690208435\n",
+      "  time_total_s: 46.78164482116699\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 10923.565\n",
+      "    learn_time_ms: 14811.282\n",
+      "    sample_throughput: 19007.513\n",
+      "    sample_time_ms: 8512.003\n",
+      "    update_time_ms: 24.435\n",
+      "  timestamp: 1602489378\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      2 |          46.7816 | 323584 |  216.594 |              261.323 |              136.929 |            890.155 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3626.109865470852\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-56-40\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 884.9831223628692\n",
+      "  episode_reward_max: 270.2626262626259\n",
+      "  episode_reward_mean: 216.85513361462705\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -485,14 +514,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        entropy: 1.1470215519269307\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00852755201049149\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.009047169092809781\n",
+      "        total_loss: 76.8135159810384\n",
+      "        vf_explained_var: 0.8726572394371033\n",
+      "        vf_loss: 76.82285753885905\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,65 +529,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 29.192000000000004\n",
+      "    gpu_util_percent0: 0.3004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16333984937915608\n",
+      "    mean_env_wait_ms: 1.1739520111463604\n",
+      "    mean_inference_ms: 5.565249658448001\n",
+      "    mean_raw_obs_processing_ms: 0.4384964806056524\n",
+      "  time_since_restore: 68.35362577438354\n",
+      "  time_this_iter_s: 21.571980953216553\n",
+      "  time_total_s: 68.35362577438354\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 11013.223\n",
+      "    learn_time_ms: 14690.705\n",
+      "    sample_throughput: 20158.612\n",
+      "    sample_time_ms: 8025.949\n",
+      "    update_time_ms: 22.645\n",
+      "  timestamp: 1602489400\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      3 |          68.3536 | 485376 |  216.855 |              270.263 |              131.475 |            884.983 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3616.112582781457\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-57-01\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 880.873417721519\n",
+      "  episode_reward_max: 270.2626262626259\n",
+      "  episode_reward_mean: 217.44137578314778\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -567,14 +596,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        entropy: 1.1285836795965831\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00767273692569385\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.010500759337446652\n",
+      "        total_loss: 59.14047654469808\n",
+      "        vf_explained_var: 0.8996696472167969\n",
+      "        vf_loss: 59.15133762359619\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,65 +611,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 28.415999999999993\n",
+      "    gpu_util_percent0: 0.2936\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.16111490150136074\n",
+      "    mean_env_wait_ms: 1.1737004337712953\n",
+      "    mean_inference_ms: 5.3947826177609235\n",
+      "    mean_raw_obs_processing_ms: 0.430652089513709\n",
+      "  time_since_restore: 89.98465132713318\n",
+      "  time_this_iter_s: 21.631025552749634\n",
+      "  time_total_s: 89.98465132713318\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 10998.429\n",
+      "    learn_time_ms: 14710.464\n",
+      "    sample_throughput: 20976.687\n",
+      "    sample_time_ms: 7712.944\n",
+      "    update_time_ms: 25.621\n",
+      "  timestamp: 1602489421\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      4 |          89.9847 | 647168 |  217.441 |              270.263 |              131.475 |            880.873 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4152\n",
+      "    time_step_mean: 3609.715223097113\n",
+      "    time_step_min: 3272\n",
+      "  date: 2020-10-12_07-57-23\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 876.7126582278481\n",
+      "  episode_reward_max: 270.86868686868655\n",
+      "  episode_reward_mean: 219.01483186293294\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -649,14 +678,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        entropy: 1.0982058942317963\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007201045867986977\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.010341917989232266\n",
+      "        total_loss: 42.64804267883301\n",
+      "        vf_explained_var: 0.9292742609977722\n",
+      "        vf_loss: 42.65876293182373\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,65 +693,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 28.268\n",
+      "    gpu_util_percent0: 0.41200000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.15946129373348403\n",
+      "    mean_env_wait_ms: 1.1745178858430907\n",
+      "    mean_inference_ms: 5.267336295216427\n",
+      "    mean_raw_obs_processing_ms: 0.42471797495802377\n",
+      "  time_since_restore: 111.63249826431274\n",
+      "  time_this_iter_s: 21.647846937179565\n",
+      "  time_total_s: 111.63249826431274\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 10988.215\n",
+      "    learn_time_ms: 14724.138\n",
+      "    sample_throughput: 21486.438\n",
+      "    sample_time_ms: 7529.959\n",
+      "    update_time_ms: 24.854\n",
+      "  timestamp: 1602489443\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      5 |          111.632 | 808960 |  219.015 |              270.869 |              131.475 |            876.713 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3587.309412861137\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-57-45\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 867.2933696639419\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 222.83136542537073\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 311\n",
+      "  episodes_total: 1101\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -731,14 +760,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        entropy: 1.089649925629298\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007361165403078\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.009514839436936503\n",
+      "        total_loss: 46.27031675974528\n",
+      "        vf_explained_var: 0.943225085735321\n",
+      "        vf_loss: 46.28018538157145\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,65 +775,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 27.864000000000004\n",
+      "    gpu_util_percent0: 0.3748\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15725032607004152\n",
+      "    mean_env_wait_ms: 1.1776184097035538\n",
+      "    mean_inference_ms: 5.098571486930799\n",
+      "    mean_raw_obs_processing_ms: 0.4170828285387513\n",
+      "  time_since_restore: 133.61357593536377\n",
+      "  time_this_iter_s: 21.981077671051025\n",
+      "  time_total_s: 133.61357593536377\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 10942.983\n",
+      "    learn_time_ms: 14784.999\n",
+      "    sample_throughput: 21830.619\n",
+      "    sample_time_ms: 7411.242\n",
+      "    update_time_ms: 23.625\n",
+      "  timestamp: 1602489465\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      6 |          133.614 | 970752 |  222.831 |               279.96 |              131.475 |            867.293 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3576.204692556634\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-07\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 863.2911392405064\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 224.62120412990652\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 163\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -813,14 +842,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        entropy: 1.078253577152888\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00760688950928549\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.00808424704397718\n",
+      "        total_loss: 24.090112050374348\n",
+      "        vf_explained_var: 0.9561929702758789\n",
+      "        vf_loss: 24.098513921101887\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,65 +857,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 28.566666666666666\n",
+      "    gpu_util_percent0: 0.29375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.1564654163893213\n",
+      "    mean_env_wait_ms: 1.1790260759751634\n",
+      "    mean_inference_ms: 5.035471631648462\n",
+      "    mean_raw_obs_processing_ms: 0.4142370056618957\n",
+      "  time_since_restore: 155.21138048171997\n",
+      "  time_this_iter_s: 21.5978045463562\n",
+      "  time_total_s: 155.21138048171997\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 10958.033\n",
+      "    learn_time_ms: 14764.693\n",
+      "    sample_throughput: 22056.652\n",
+      "    sample_time_ms: 7335.293\n",
+      "    update_time_ms: 23.414\n",
+      "  timestamp: 1602489487\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      7 |          155.211 | 1132544 |  224.621 |               279.96 |              131.475 |            863.291 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3563.761836441894\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-28\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 859.7215189873418\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 226.28391510037065\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -895,14 +924,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        entropy: 1.0665611525376637\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007063437098016341\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.011236034988542087\n",
+      "        total_loss: 23.269086996714275\n",
+      "        vf_explained_var: 0.9564061164855957\n",
+      "        vf_loss: 23.280683676401775\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,65 +939,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 28.136\n",
+      "    gpu_util_percent0: 0.2932\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.15580133340075322\n",
+      "    mean_env_wait_ms: 1.180217866621754\n",
+      "    mean_inference_ms: 4.983044491631497\n",
+      "    mean_raw_obs_processing_ms: 0.411793605828682\n",
+      "  time_since_restore: 176.72998452186584\n",
+      "  time_this_iter_s: 21.518604040145874\n",
+      "  time_total_s: 176.72998452186584\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 10960.775\n",
+      "    learn_time_ms: 14761.0\n",
+      "    sample_throughput: 22300.07\n",
+      "    sample_time_ms: 7255.224\n",
+      "    update_time_ms: 25.162\n",
+      "  timestamp: 1602489508\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      8 |           176.73 | 1294336 |  226.284 |               279.96 |              131.475 |            859.722 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3554.637886597938\n",
+      "    time_step_min: 3208\n",
+      "  date: 2020-10-12_07-58-50\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 856.3879746835443\n",
+      "  episode_reward_max: 279.95959595959596\n",
+      "  episode_reward_mean: 227.5292162127604\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -977,14 +1006,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        entropy: 1.0308950543403625\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0075525245629251\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.009404902209401675\n",
+      "        total_loss: 19.759908358256023\n",
+      "        vf_explained_var: 0.9632963538169861\n",
+      "        vf_loss: 19.769589106241863\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,65 +1021,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 27.592\n",
+      "    gpu_util_percent0: 0.4132\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7640000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15522609255515757\n",
+      "    mean_env_wait_ms: 1.1813788429250602\n",
+      "    mean_inference_ms: 4.93757485426149\n",
+      "    mean_raw_obs_processing_ms: 0.4096284903807881\n",
+      "  time_since_restore: 198.41875982284546\n",
+      "  time_this_iter_s: 21.688775300979614\n",
+      "  time_total_s: 198.41875982284546\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 10952.147\n",
+      "    learn_time_ms: 14772.628\n",
+      "    sample_throughput: 22477.809\n",
+      "    sample_time_ms: 7197.855\n",
+      "    update_time_ms: 25.989\n",
+      "  timestamp: 1602489530\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |      9 |          198.419 | 1456128 |  227.529 |               279.96 |              131.475 |            856.388 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3536.35698808234\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-12\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 849.9642475987193\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 230.30434548257375\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 294\n",
+      "  episodes_total: 1874\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1059,14 +1088,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        entropy: 1.0002753188212712\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007455945403004686\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.010204158699101148\n",
+      "        total_loss: 24.197932084401447\n",
+      "        vf_explained_var: 0.9683513641357422\n",
+      "        vf_loss: 24.208391030629475\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,65 +1103,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 27.928\n",
+      "    gpu_util_percent0: 0.29960000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15436430506291107\n",
+      "    mean_env_wait_ms: 1.1838305992833973\n",
+      "    mean_inference_ms: 4.868544754944554\n",
+      "    mean_raw_obs_processing_ms: 0.4063909084512901\n",
+      "  time_since_restore: 220.12364220619202\n",
+      "  time_this_iter_s: 21.704882383346558\n",
+      "  time_total_s: 220.12364220619202\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 10949.037\n",
+      "    learn_time_ms: 14776.825\n",
+      "    sample_throughput: 22602.127\n",
+      "    sample_time_ms: 7158.264\n",
+      "    update_time_ms: 26.962\n",
+      "  timestamp: 1602489552\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     10 |          220.124 | 1617920 |  230.304 |              288.596 |              131.475 |            849.964 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3525.1461006910167\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-34\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 846.1324245374879\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 232.04503162098086\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 180\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1141,14 +1170,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        entropy: 0.9904046803712845\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00673914875369519\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.00991532149297806\n",
+      "        total_loss: 13.990095853805542\n",
+      "        vf_explained_var: 0.9738118648529053\n",
+      "        vf_loss: 14.000327746073404\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,65 +1185,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 28.933333333333334\n",
+      "    gpu_util_percent0: 0.29000000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.775\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.15391489145310477\n",
+      "    mean_env_wait_ms: 1.1852050260285005\n",
+      "    mean_inference_ms: 4.834181265578874\n",
+      "    mean_raw_obs_processing_ms: 0.4047779605513047\n",
+      "  time_since_restore: 241.79468941688538\n",
+      "  time_this_iter_s: 21.67104721069336\n",
+      "  time_total_s: 241.79468941688538\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 10963.723\n",
+      "    learn_time_ms: 14757.031\n",
+      "    sample_throughput: 23472.344\n",
+      "    sample_time_ms: 6892.878\n",
+      "    update_time_ms: 27.456\n",
+      "  timestamp: 1602489574\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     11 |          241.795 | 1779712 |  232.045 |              288.596 |              131.475 |            846.132 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3516.3241758241757\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_07-59-56\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 843.4877938517179\n",
+      "  episode_reward_max: 288.59595959595976\n",
+      "  episode_reward_mean: 233.29224432388978\n",
+      "  episode_reward_min: 131.47474747474718\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1223,14 +1252,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        entropy: 0.9801873713731766\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006010051351040602\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.009126228047534823\n",
+      "        total_loss: 15.280177116394043\n",
+      "        vf_explained_var: 0.97007817029953\n",
+      "        vf_loss: 15.289682388305664\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,65 +1267,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 27.676923076923075\n",
+      "    gpu_util_percent0: 0.3492307692307693\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7576923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15356980009174312\n",
+      "    mean_env_wait_ms: 1.1862927867683948\n",
+      "    mean_inference_ms: 4.807153098875207\n",
+      "    mean_raw_obs_processing_ms: 0.40347536671037615\n",
+      "  time_since_restore: 263.58598041534424\n",
+      "  time_this_iter_s: 21.791290998458862\n",
+      "  time_total_s: 263.58598041534424\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 10959.991\n",
+      "    learn_time_ms: 14762.056\n",
+      "    sample_throughput: 23687.883\n",
+      "    sample_time_ms: 6830.159\n",
+      "    update_time_ms: 27.684\n",
+      "  timestamp: 1602489596\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     12 |          263.586 | 1941504 |  233.292 |              288.596 |              131.475 |            843.488 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3509.2247334754798\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-00-17\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 841.2806573957016\n",
+      "  episode_reward_max: 289.2020202020203\n",
+      "  episode_reward_mean: 234.43851919958107\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 2373\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1305,14 +1334,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        entropy: 0.9412872145573298\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006324911878133814\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.009316468562853212\n",
+      "        total_loss: 15.226327737172445\n",
+      "        vf_explained_var: 0.9722931385040283\n",
+      "        vf_loss: 15.235953092575073\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,65 +1349,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 28.983333333333334\n",
+      "    gpu_util_percent0: 0.27166666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15325367165896728\n",
+      "    mean_env_wait_ms: 1.187351681010106\n",
+      "    mean_inference_ms: 4.7823496059783706\n",
+      "    mean_raw_obs_processing_ms: 0.4022524139138643\n",
+      "  time_since_restore: 285.0491192340851\n",
+      "  time_this_iter_s: 21.463138818740845\n",
+      "  time_total_s: 285.0491192340851\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 10948.329\n",
+      "    learn_time_ms: 14777.781\n",
+      "    sample_throughput: 23786.854\n",
+      "    sample_time_ms: 6801.74\n",
+      "    update_time_ms: 29.054\n",
+      "  timestamp: 1602489617\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     13 |          285.049 | 2103296 |  234.439 |              289.202 |              131.475 |            841.281 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3494.709811320755\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-00-39\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 837.9985063480209\n",
+      "  episode_reward_max: 289.2020202020203\n",
+      "  episode_reward_mean: 236.4201499686936\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 305\n",
+      "  episodes_total: 2678\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1387,14 +1416,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        entropy: 0.9193607121706009\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005588505533523858\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.008722007876106849\n",
+      "        total_loss: 18.580758730570476\n",
+      "        vf_explained_var: 0.9753453135490417\n",
+      "        vf_loss: 18.589841842651367\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,65 +1431,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 28.628\n",
+      "    gpu_util_percent0: 0.2636\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.748\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.1527339914723438\n",
+      "    mean_env_wait_ms: 1.1892359688684517\n",
+      "    mean_inference_ms: 4.741593468063049\n",
+      "    mean_raw_obs_processing_ms: 0.40029834826674837\n",
+      "  time_since_restore: 306.7374804019928\n",
+      "  time_this_iter_s: 21.688361167907715\n",
+      "  time_total_s: 306.7374804019928\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 10956.442\n",
+      "    learn_time_ms: 14766.838\n",
+      "    sample_throughput: 23724.753\n",
+      "    sample_time_ms: 6819.544\n",
+      "    update_time_ms: 27.668\n",
+      "  timestamp: 1602489639\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     14 |          306.737 | 2265088 |   236.42 |              289.202 |              131.475 |            837.999 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3488.3952414772725\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-01\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 836.292194092827\n",
+      "  episode_reward_max: 289.35353535353516\n",
+      "  episode_reward_mean: 237.4111686485104\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1469,14 +1498,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        entropy: 0.9131054629882177\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005497211551604171\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.007378635054919869\n",
+      "        total_loss: 11.72153385480245\n",
+      "        vf_explained_var: 0.9775063991546631\n",
+      "        vf_loss: 11.729275782903036\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,65 +1513,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 27.951999999999998\n",
+      "    gpu_util_percent0: 0.30200000000000005\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7720000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.1524858565651682\n",
+      "    mean_env_wait_ms: 1.1901572464312566\n",
+      "    mean_inference_ms: 4.7225269139524615\n",
+      "    mean_raw_obs_processing_ms: 0.39938440810721976\n",
+      "  time_since_restore: 328.52804470062256\n",
+      "  time_this_iter_s: 21.79056429862976\n",
+      "  time_total_s: 328.52804470062256\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 10963.331\n",
+      "    learn_time_ms: 14757.558\n",
+      "    sample_throughput: 23645.81\n",
+      "    sample_time_ms: 6842.311\n",
+      "    update_time_ms: 27.3\n",
+      "  timestamp: 1602489661\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     15 |          328.528 | 2426880 |  237.411 |              289.354 |              131.475 |            836.292 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3483.3301950235373\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-23\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 834.7891405729514\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 238.28404632601823\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1551,14 +1580,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        entropy: 0.9084820051987966\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006018294564758738\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.007524173070123652\n",
+      "        total_loss: 12.962319930394491\n",
+      "        vf_explained_var: 0.9735670685768127\n",
+      "        vf_loss: 12.97015110651652\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,65 +1595,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 28.04\n",
+      "    gpu_util_percent0: 0.3156\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15227382725048905\n",
+      "    mean_env_wait_ms: 1.19098373725698\n",
+      "    mean_inference_ms: 4.705735246407954\n",
+      "    mean_raw_obs_processing_ms: 0.39857025145429437\n",
+      "  time_since_restore: 350.29178285598755\n",
+      "  time_this_iter_s: 21.76373815536499\n",
+      "  time_total_s: 350.29178285598755\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 10974.293\n",
+      "    learn_time_ms: 14742.818\n",
+      "    sample_throughput: 23676.909\n",
+      "    sample_time_ms: 6833.324\n",
+      "    update_time_ms: 29.076\n",
+      "  timestamp: 1602489683\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     16 |          350.292 | 2588672 |  238.284 |              290.566 |              131.475 |            834.789 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3477.5213404995256\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-01-45\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 832.9103729238483\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 239.1295626272122\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 189\n",
+      "  episodes_total: 3191\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1633,14 +1662,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        entropy: 0.8652510742346445\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005546345414283375\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.009394650240816796\n",
+      "        total_loss: 15.037363767623901\n",
+      "        vf_explained_var: 0.975414514541626\n",
+      "        vf_loss: 15.047069152196249\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,65 +1677,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 27.28\n",
+      "    gpu_util_percent0: 0.3452\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.152045327822301\n",
+      "    mean_env_wait_ms: 1.1919710779649575\n",
+      "    mean_inference_ms: 4.687307194280671\n",
+      "    mean_raw_obs_processing_ms: 0.39768841070955224\n",
+      "  time_since_restore: 372.28986644744873\n",
+      "  time_this_iter_s: 21.99808359146118\n",
+      "  time_total_s: 372.28986644744873\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 10951.776\n",
+      "    learn_time_ms: 14773.128\n",
+      "    sample_throughput: 23646.205\n",
+      "    sample_time_ms: 6842.197\n",
+      "    update_time_ms: 29.179\n",
+      "  timestamp: 1602489705\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     17 |           372.29 | 2750464 |   239.13 |              290.566 |              131.475 |             832.91 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3470.0330818340103\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-07\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 830.6729994242947\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 240.3484150660316\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 283\n",
+      "  episodes_total: 3474\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1715,14 +1744,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        entropy: 0.8562458703915278\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0056136711888636155\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.008814311237074435\n",
+      "        total_loss: 12.922985871632894\n",
+      "        vf_explained_var: 0.9803910255432129\n",
+      "        vf_loss: 12.932095050811768\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,65 +1759,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 28.131999999999998\n",
+      "    gpu_util_percent0: 0.3864\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.15173502064916347\n",
+      "    mean_env_wait_ms: 1.1933266139357905\n",
+      "    mean_inference_ms: 4.662769914171586\n",
+      "    mean_raw_obs_processing_ms: 0.3964979335973578\n",
+      "  time_since_restore: 394.223580121994\n",
+      "  time_this_iter_s: 21.933713674545288\n",
+      "  time_total_s: 394.223580121994\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 10942.497\n",
+      "    learn_time_ms: 14785.656\n",
+      "    sample_throughput: 23545.734\n",
+      "    sample_time_ms: 6871.393\n",
+      "    update_time_ms: 27.489\n",
+      "  timestamp: 1602489727\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     18 |          394.224 | 2912256 |  240.348 |              290.566 |              131.475 |            830.673 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3465.9986134220744\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-29\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 829.3965327462851\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 240.93648093482983\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 160\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1797,14 +1826,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        entropy: 0.8458269933859507\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005238918277124564\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.008863923489116132\n",
+      "        total_loss: 11.462480147679647\n",
+      "        vf_explained_var: 0.9772316813468933\n",
+      "        vf_loss: 11.47166625658671\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,65 +1841,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 28.348\n",
+      "    gpu_util_percent0: 0.2864\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.15157817273439375\n",
+      "    mean_env_wait_ms: 1.194051067524682\n",
+      "    mean_inference_ms: 4.650287496491038\n",
+      "    mean_raw_obs_processing_ms: 0.3958943252438647\n",
+      "  time_since_restore: 415.73195481300354\n",
+      "  time_this_iter_s: 21.50837469100952\n",
+      "  time_total_s: 415.73195481300354\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 10966.22\n",
+      "    learn_time_ms: 14753.671\n",
+      "    sample_throughput: 23498.986\n",
+      "    sample_time_ms: 6885.063\n",
+      "    update_time_ms: 26.453\n",
+      "  timestamp: 1602489749\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     19 |          415.732 | 3074048 |  240.936 |              290.566 |              131.475 |            829.397 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3461.7851261620185\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-02-51\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 828.2813076720274\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 241.56190963151147\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 3793\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1879,14 +1908,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        entropy: 0.8354400197664896\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006724536186084151\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.00911139192370077\n",
+      "        total_loss: 11.11555004119873\n",
+      "        vf_explained_var: 0.9771101474761963\n",
+      "        vf_loss: 11.1248246828715\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,65 +1923,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 27.765384615384612\n",
+      "    gpu_util_percent0: 0.42576923076923073\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15143153977037152\n",
+      "    mean_env_wait_ms: 1.19475205207732\n",
+      "    mean_inference_ms: 4.638693538397803\n",
+      "    mean_raw_obs_processing_ms: 0.39532808620572457\n",
+      "  time_since_restore: 437.7973186969757\n",
+      "  time_this_iter_s: 22.065363883972168\n",
+      "  time_total_s: 437.7973186969757\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 10956.318\n",
+      "    learn_time_ms: 14767.004\n",
+      "    sample_throughput: 23424.906\n",
+      "    sample_time_ms: 6906.837\n",
+      "    update_time_ms: 25.358\n",
+      "  timestamp: 1602489771\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     20 |          437.797 | 3235840 |  241.562 |              290.566 |              131.475 |            828.281 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3454.446708074534\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-13\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 826.1258327165062\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 242.65150393647795\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 260\n",
+      "  episodes_total: 4053\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1961,14 +1990,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        entropy: 0.8038722376028696\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005003524556135138\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.007377958051317061\n",
+      "        total_loss: 13.692698876063028\n",
+      "        vf_explained_var: 0.9796187877655029\n",
+      "        vf_loss: 13.700380086898804\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,65 +2005,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 28.34\n",
+      "    gpu_util_percent0: 0.42400000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15121696352248112\n",
+      "    mean_env_wait_ms: 1.1958913902831356\n",
+      "    mean_inference_ms: 4.621158716371925\n",
+      "    mean_raw_obs_processing_ms: 0.39449719521269605\n",
+      "  time_since_restore: 459.43015336990356\n",
+      "  time_this_iter_s: 21.632834672927856\n",
+      "  time_total_s: 459.43015336990356\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 10961.455\n",
+      "    learn_time_ms: 14760.085\n",
+      "    sample_throughput: 23418.203\n",
+      "    sample_time_ms: 6908.814\n",
+      "    update_time_ms: 25.193\n",
+      "  timestamp: 1602489793\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     21 |           459.43 | 3397632 |  242.652 |              290.566 |              131.475 |            826.126 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3448.8378952336006\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-35\n",
       "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.4301453352086\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 243.4875974939266\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2043,14 +2072,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
+      "        entropy: 0.7977566868066788\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005455355780820052\n",
       "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
+      "        policy_loss: -0.00767945071614425\n",
+      "        total_loss: 10.277512709299723\n",
+      "        vf_explained_var: 0.9814075827598572\n",
+      "        vf_loss: 10.285443782806396\n",
       "    num_steps_sampled: 3559424\n",
       "    num_steps_trained: 3559424\n",
       "  iterations_since_restore: 22\n",
@@ -2058,65 +2087,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
+      "    cpu_util_percent: 28.120000000000005\n",
+      "    gpu_util_percent0: 0.3268\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.752\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
+      "    mean_action_processing_ms: 0.15104737207579993\n",
+      "    mean_env_wait_ms: 1.1967581522595114\n",
+      "    mean_inference_ms: 4.608215003769806\n",
+      "    mean_raw_obs_processing_ms: 0.39386805388018364\n",
+      "  time_since_restore: 481.1195831298828\n",
+      "  time_this_iter_s: 21.689429759979248\n",
+      "  time_total_s: 481.1195831298828\n",
       "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
+      "    learn_throughput: 10962.993\n",
+      "    learn_time_ms: 14758.014\n",
+      "    sample_throughput: 23448.37\n",
+      "    sample_time_ms: 6899.925\n",
+      "    update_time_ms: 25.154\n",
+      "  timestamp: 1602489815\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     22 |           481.12 | 3559424 |  243.488 |              290.566 |              131.475 |             824.43 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3444.6345235387766\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-03-57\n",
       "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
-      "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 823.2205649717514\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 244.06426981681216\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 4425\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2125,14 +2154,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
+      "        entropy: 0.8060282667477926\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005679386241051058\n",
       "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
+      "        policy_loss: -0.010035674378741533\n",
+      "        total_loss: 10.034321387608847\n",
+      "        vf_explained_var: 0.978935182094574\n",
+      "        vf_loss: 10.044595638910929\n",
       "    num_steps_sampled: 3721216\n",
       "    num_steps_trained: 3721216\n",
       "  iterations_since_restore: 23\n",
@@ -2140,65 +2169,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
+      "    cpu_util_percent: 28.368000000000002\n",
+      "    gpu_util_percent0: 0.29960000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.76\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
+      "    mean_action_processing_ms: 0.15093291820308186\n",
+      "    mean_env_wait_ms: 1.1973932493733186\n",
+      "    mean_inference_ms: 4.599187677452534\n",
+      "    mean_raw_obs_processing_ms: 0.3934317186327627\n",
+      "  time_since_restore: 502.85791778564453\n",
+      "  time_this_iter_s: 21.73833465576172\n",
+      "  time_total_s: 502.85791778564453\n",
       "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
+      "    learn_throughput: 10957.609\n",
+      "    learn_time_ms: 14765.265\n",
+      "    sample_throughput: 23407.54\n",
+      "    sample_time_ms: 6911.961\n",
+      "    update_time_ms: 23.641\n",
+      "  timestamp: 1602489837\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3721216\n",
       "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     23 |          502.858 | 3721216 |  244.064 |              290.566 |              131.475 |            823.221 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3439.959219088937\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-04-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.3749460974558\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 244.75604035177128\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 4638\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2207,14 +2236,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
+      "        entropy: 0.7703086733818054\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005429171995880703\n",
       "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
+      "        policy_loss: -0.007289163496655722\n",
+      "        total_loss: 12.348905007044474\n",
+      "        vf_explained_var: 0.979224681854248\n",
+      "        vf_loss: 12.356421629587809\n",
       "    num_steps_sampled: 3883008\n",
       "    num_steps_trained: 3883008\n",
       "  iterations_since_restore: 24\n",
@@ -2222,303 +2251,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
+      "    cpu_util_percent: 28.8125\n",
+      "    gpu_util_percent0: 0.43249999999999994\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7541666666666664\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
+      "    mean_action_processing_ms: 0.15079284947059365\n",
+      "    mean_env_wait_ms: 1.1982450189298106\n",
+      "    mean_inference_ms: 4.587776541874426\n",
+      "    mean_raw_obs_processing_ms: 0.3928856835406434\n",
+      "  time_since_restore: 524.5500221252441\n",
+      "  time_this_iter_s: 21.69210433959961\n",
+      "  time_total_s: 524.5500221252441\n",
       "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
+      "    learn_throughput: 10957.433\n",
+      "    learn_time_ms: 14765.502\n",
+      "    sample_throughput: 23416.047\n",
+      "    sample_time_ms: 6909.45\n",
+      "    update_time_ms: 25.924\n",
+      "  timestamp: 1602489858\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3883008\n",
       "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     24 |           524.55 | 3883008 |  244.756 |              290.566 |              131.475 |            821.375 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3434.701314708299\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-04-41\n",
       "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 819.6397058823529\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 245.61130298078825\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 258\n",
+      "  episodes_total: 4896\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2527,408 +2318,645 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
+      "        entropy: 0.7541884630918503\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004939307885554929\n",
       "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.008982530465194335\n",
+      "        total_loss: 9.952500502268473\n",
+      "        vf_explained_var: 0.9837613105773926\n",
+      "        vf_loss: 9.961743275324503\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
+      "    cpu_util_percent: 26.99230769230769\n",
+      "    gpu_util_percent0: 0.29961538461538456\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
+      "    ram_util_percent: 3.75\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
+      "    mean_action_processing_ms: 0.15062599456951525\n",
+      "    mean_env_wait_ms: 1.1992428855480324\n",
+      "    mean_inference_ms: 4.575118912763768\n",
+      "    mean_raw_obs_processing_ms: 0.39227961602231826\n",
+      "  time_since_restore: 546.621901512146\n",
+      "  time_this_iter_s: 22.071879386901855\n",
+      "  time_total_s: 546.621901512146\n",
       "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
+      "    learn_throughput: 10944.955\n",
+      "    learn_time_ms: 14782.336\n",
+      "    sample_throughput: 23415.435\n",
+      "    sample_time_ms: 6909.63\n",
+      "    update_time_ms: 27.731\n",
+      "  timestamp: 1602489881\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     25 |          546.622 | 4044800 |  245.611 |              290.566 |              131.475 |             819.64 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3431.5177008750993\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-05-02\n",
       "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 818.6079905063291\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 246.10366121659632\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 5056\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
+      "        entropy: 0.7627150317033132\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006050152898145218\n",
       "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.009301517896043757\n",
+      "        total_loss: 8.128399848937988\n",
+      "        vf_explained_var: 0.9824613928794861\n",
+      "        vf_loss: 8.138161698977152\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
+      "    cpu_util_percent: 28.45416666666667\n",
+      "    gpu_util_percent0: 0.245\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7708333333333335\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
+      "    mean_action_processing_ms: 0.1505320904163101\n",
+      "    mean_env_wait_ms: 1.1998304190756985\n",
+      "    mean_inference_ms: 4.567782822219138\n",
+      "    mean_raw_obs_processing_ms: 0.3919296307204451\n",
+      "  time_since_restore: 568.2212522029877\n",
+      "  time_this_iter_s: 21.599350690841675\n",
+      "  time_total_s: 568.2212522029877\n",
       "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
+      "    learn_throughput: 10956.324\n",
+      "    learn_time_ms: 14766.997\n",
+      "    sample_throughput: 23417.631\n",
+      "    sample_time_ms: 6908.982\n",
+      "    update_time_ms: 26.463\n",
+      "  timestamp: 1602489902\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     26 |          568.221 | 4206592 |  246.104 |              290.566 |              131.475 |            818.608 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3428.084934665642\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_08-05-24\n",
       "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 817.4225917431193\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 246.58821008247608\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 176\n",
+      "  episodes_total: 5232\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
+      "        entropy: 0.7432082245747248\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005775055265985429\n",
       "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.009028180410192968\n",
+      "        total_loss: 9.281757434209188\n",
+      "        vf_explained_var: 0.982418954372406\n",
+      "        vf_loss: 9.291240135828653\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
+      "    cpu_util_percent: 28.484000000000005\n",
+      "    gpu_util_percent0: 0.29919999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
+      "    mean_action_processing_ms: 0.15043915088222498\n",
+      "    mean_env_wait_ms: 1.2004804583814097\n",
+      "    mean_inference_ms: 4.56007833511155\n",
+      "    mean_raw_obs_processing_ms: 0.3915655176555837\n",
+      "  time_since_restore: 589.9885222911835\n",
+      "  time_this_iter_s: 21.7672700881958\n",
+      "  time_total_s: 589.9885222911835\n",
       "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
+      "    learn_throughput: 10958.884\n",
+      "    learn_time_ms: 14763.547\n",
+      "    sample_throughput: 23485.785\n",
+      "    sample_time_ms: 6888.933\n",
+      "    update_time_ms: 26.0\n",
+      "  timestamp: 1602489924\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | RUNNING  | 172.17.0.4:47416 |     27 |          589.989 | 4368384 |  246.588 |              290.566 |              131.475 |            817.423 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_4935d_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
-      "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "    time_step_max: 4188\n",
+      "    time_step_mean: 3423.254469171835\n",
+      "    time_step_min: 3145\n",
+      "  date: 2020-10-12_08-05-46\n",
+      "  done: true\n",
+      "  episode_len_mean: 815.7878402903812\n",
+      "  episode_reward_max: 290.56565656565647\n",
+      "  episode_reward_mean: 247.24255256741642\n",
+      "  episode_reward_min: 131.47474747474718\n",
+      "  episodes_this_iter: 278\n",
+      "  episodes_total: 5510\n",
+      "  experiment_id: 6ea347bd390343169770bb0ae7eaccbd\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
+      "        entropy: 0.7183508972326914\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005954385424653689\n",
       "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.007631552017604311\n",
+      "        total_loss: 10.137248754501343\n",
+      "        vf_explained_var: 0.9847092032432556\n",
+      "        vf_loss: 10.14530062675476\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
+      "    cpu_util_percent: 28.072\n",
+      "    gpu_util_percent0: 0.36760000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
+      "    ram_util_percent: 3.756\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 47416\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
+      "    mean_action_processing_ms: 0.15029441536490598\n",
+      "    mean_env_wait_ms: 1.2014855944746754\n",
+      "    mean_inference_ms: 4.548813510251206\n",
+      "    mean_raw_obs_processing_ms: 0.39103728768479246\n",
+      "  time_since_restore: 611.7375376224518\n",
+      "  time_this_iter_s: 21.74901533126831\n",
+      "  time_total_s: 611.7375376224518\n",
       "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
+      "    learn_throughput: 10953.469\n",
+      "    learn_time_ms: 14770.846\n",
+      "    sample_throughput: 23575.025\n",
+      "    sample_time_ms: 6862.856\n",
+      "    update_time_ms: 25.694\n",
+      "  timestamp: 1602489946\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 4935d_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_4935d_00000 | TERMINATED |       |     28 |          611.738 | 4530176 |  247.243 |              290.566 |              131.475 |            815.788 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 47152\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_075519-oa6h6n34/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_075519-oa6h6n34/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3145\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602489947\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4188\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3423.25447\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.56566\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 131.47475\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.24255\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5510\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33micy-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/oa6h6n34\u001b[0m\n",
+      "2020-10-12 08:05:54,192 - wandb.wandb_agent - INFO - Cleaning up finished run: oa6h6n34\n",
+      "2020-10-12 08:05:54,502 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:05:54,503 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 08:05:54,506 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.001 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:05:59,522 - wandb.wandb_agent - INFO - Running runs: ['xgblq0zg']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfearless-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/xgblq0zg\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_080556-xgblq0zg\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:06:00,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "\u001b[2m\u001b[36m(pid=79399)\u001b[0m 2020-10-12 08:06:02,983\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79381)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79381)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79285)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79285)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79378)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79378)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79283)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79283)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79295)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79295)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-06-36\n",
       "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
+      "        entropy: 1.185120274623235\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.004055787847998242\n",
       "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.007851610066912448\n",
+      "        total_loss: 507.07507578531903\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
+      "    cpu_util_percent: 27.89090909090909\n",
+      "    gpu_util_percent0: 0.38969696969696965\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08750757824224535\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
+      "    mean_action_processing_ms: 0.1671859768298939\n",
+      "    mean_env_wait_ms: 1.1685175894218744\n",
+      "    mean_inference_ms: 5.542697244015841\n",
+      "    mean_raw_obs_processing_ms: 0.4403039149643279\n",
+      "  time_since_restore: 27.98508620262146\n",
+      "  time_this_iter_s: 27.98508620262146\n",
+      "  time_total_s: 27.98508620262146\n",
       "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
+      "    learn_throughput: 8511.254\n",
+      "    learn_time_ms: 19009.184\n",
+      "    sample_throughput: 18188.236\n",
+      "    sample_time_ms: 8895.42\n",
+      "    update_time_ms: 25.517\n",
+      "  timestamp: 1602489996\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      1 |          27.9851 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3615.2916666666665\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-03\n",
       "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 890.9303797468355\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.42123769338934\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2937,80 +2965,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
+      "        entropy: 1.15665665268898\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007565491638767223\n",
       "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
+      "        policy_loss: -0.010795095736587731\n",
+      "        total_loss: 126.37152163187663\n",
+      "        vf_explained_var: 0.8081408143043518\n",
+      "        vf_loss: 126.38271840413411\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
+      "    cpu_util_percent: 26.083870967741937\n",
+      "    gpu_util_percent0: 0.3458064516129033\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7580645161290316\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
+      "    mean_action_processing_ms: 0.1630873611830732\n",
+      "    mean_env_wait_ms: 1.1651816796611996\n",
+      "    mean_inference_ms: 5.320372510974211\n",
+      "    mean_raw_obs_processing_ms: 0.4290420705682716\n",
+      "  time_since_restore: 54.57611012458801\n",
+      "  time_this_iter_s: 26.591023921966553\n",
+      "  time_total_s: 54.57611012458801\n",
       "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
+      "    learn_throughput: 8492.107\n",
+      "    learn_time_ms: 19052.045\n",
+      "    sample_throughput: 19867.256\n",
+      "    sample_time_ms: 8143.651\n",
+      "    update_time_ms: 40.696\n",
+      "  timestamp: 1602490023\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      2 |          54.5761 | 323584 |  217.421 |              273.596 |              138.899 |             890.93 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3613.952914798206\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-29\n",
       "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 886.1983122362869\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 218.40800409154815\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3019,80 +3047,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
+      "        entropy: 1.1415385901927948\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00994268455542624\n",
       "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
+      "        policy_loss: -0.012222195859067142\n",
+      "        total_loss: 64.50122865041097\n",
+      "        vf_explained_var: 0.8894491195678711\n",
+      "        vf_loss: 64.51359748840332\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
+      "    cpu_util_percent: 24.9\n",
+      "    gpu_util_percent0: 0.34400000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.78\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
+      "    mean_action_processing_ms: 0.16056376792462443\n",
+      "    mean_env_wait_ms: 1.1654815807931842\n",
+      "    mean_inference_ms: 5.160581395537171\n",
+      "    mean_raw_obs_processing_ms: 0.4210465552605851\n",
+      "  time_since_restore: 80.85679578781128\n",
+      "  time_this_iter_s: 26.280685663223267\n",
+      "  time_total_s: 80.85679578781128\n",
       "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
+      "    learn_throughput: 8489.867\n",
+      "    learn_time_ms: 19057.072\n",
+      "    sample_throughput: 20738.298\n",
+      "    sample_time_ms: 7801.605\n",
+      "    update_time_ms: 40.121\n",
+      "  timestamp: 1602490049\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      3 |          80.8568 | 485376 |  218.408 |              273.596 |              138.899 |            886.198 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3600.026490066225\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-07-55\n",
       "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 881.0632911392405\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 220.77398989898967\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3101,80 +3129,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
+      "        entropy: 1.1262759864330292\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007932808017358184\n",
       "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
+      "        policy_loss: -0.010753356424781183\n",
+      "        total_loss: 40.0422420501709\n",
+      "        vf_explained_var: 0.9258741736412048\n",
+      "        vf_loss: 40.05332660675049\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
+      "    cpu_util_percent: 23.79666666666667\n",
+      "    gpu_util_percent0: 0.36266666666666664\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
+      "    mean_action_processing_ms: 0.15881682262783847\n",
+      "    mean_env_wait_ms: 1.1667191329418642\n",
+      "    mean_inference_ms: 5.0460795669711525\n",
+      "    mean_raw_obs_processing_ms: 0.4151562783082309\n",
+      "  time_since_restore: 106.90822958946228\n",
+      "  time_this_iter_s: 26.051433801651\n",
+      "  time_total_s: 106.90822958946228\n",
       "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
+      "    learn_throughput: 8480.346\n",
+      "    learn_time_ms: 19078.466\n",
+      "    sample_throughput: 21401.448\n",
+      "    sample_time_ms: 7559.862\n",
+      "    update_time_ms: 35.028\n",
+      "  timestamp: 1602490075\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      4 |          106.908 | 647168 |  220.774 |              273.596 |              138.899 |            881.063 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3586.272965879265\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-08-21\n",
       "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 876.5278481012658\n",
+      "  episode_reward_max: 274.35353535353505\n",
+      "  episode_reward_mean: 223.04858713719454\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3183,80 +3211,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
+      "        entropy: 1.0917210976282756\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008220920106396079\n",
       "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
+      "        policy_loss: -0.013464094430673867\n",
+      "        total_loss: 28.93033440907796\n",
+      "        vf_explained_var: 0.9479137063026428\n",
+      "        vf_loss: 28.944067160288494\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
+      "    cpu_util_percent: 24.173333333333332\n",
+      "    gpu_util_percent0: 0.33833333333333343\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
+      "    mean_action_processing_ms: 0.15751531511699007\n",
+      "    mean_env_wait_ms: 1.1684766662620152\n",
+      "    mean_inference_ms: 4.95970615273041\n",
+      "    mean_raw_obs_processing_ms: 0.4106852566028239\n",
+      "  time_since_restore: 132.92763376235962\n",
+      "  time_this_iter_s: 26.01940417289734\n",
+      "  time_total_s: 132.92763376235962\n",
       "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
+      "    learn_throughput: 8474.744\n",
+      "    learn_time_ms: 19091.079\n",
+      "    sample_throughput: 21836.933\n",
+      "    sample_time_ms: 7409.099\n",
+      "    update_time_ms: 32.404\n",
+      "  timestamp: 1602490101\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      5 |          132.928 | 808960 |  223.049 |              274.354 |              138.899 |            876.528 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3562.720930232558\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-08-47\n",
       "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 866.970988213962\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 226.50675384854873\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 313\n",
+      "  episodes_total: 1103\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3265,80 +3293,408 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
+      "        entropy: 1.0828292568524678\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007986097635390857\n",
       "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
+      "        policy_loss: -0.01176670480829974\n",
+      "        total_loss: 28.82416566212972\n",
+      "        vf_explained_var: 0.9627106189727783\n",
+      "        vf_loss: 28.836217085520428\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
+      "    cpu_util_percent: 24.993103448275857\n",
+      "    gpu_util_percent0: 0.34206896551724136\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7689655172413787\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
+      "    mean_action_processing_ms: 0.1557423331251979\n",
+      "    mean_env_wait_ms: 1.1728611992308515\n",
+      "    mean_inference_ms: 4.843886786218583\n",
+      "    mean_raw_obs_processing_ms: 0.40510099711437697\n",
+      "  time_since_restore: 158.39731907844543\n",
+      "  time_this_iter_s: 25.469685316085815\n",
+      "  time_total_s: 158.39731907844543\n",
       "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
+      "    learn_throughput: 8511.93\n",
+      "    learn_time_ms: 19007.676\n",
+      "    sample_throughput: 22135.621\n",
+      "    sample_time_ms: 7309.124\n",
+      "    update_time_ms: 29.98\n",
+      "  timestamp: 1602490127\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      6 |          158.397 | 970752 |  226.507 |              275.717 |              138.899 |            866.971 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3553.5307443365696\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-09-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.0727848101266\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 227.83155127221562\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.071872740983963\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00846466759685427\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013406029562853897\n",
+      "        total_loss: 19.26950518290202\n",
+      "        vf_explained_var: 0.9649848341941833\n",
+      "        vf_loss: 19.28313668568929\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.403225806451612\n",
+      "    gpu_util_percent0: 0.44258064516129036\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.780645161290322\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15508125173145895\n",
+      "    mean_env_wait_ms: 1.1746607097364452\n",
+      "    mean_inference_ms: 4.801153989323884\n",
+      "    mean_raw_obs_processing_ms: 0.4030365619774304\n",
+      "  time_since_restore: 184.4202537536621\n",
+      "  time_this_iter_s: 26.022934675216675\n",
+      "  time_total_s: 184.4202537536621\n",
+      "  timers:\n",
+      "    learn_throughput: 8507.604\n",
+      "    learn_time_ms: 19017.34\n",
+      "    sample_throughput: 22352.663\n",
+      "    sample_time_ms: 7238.153\n",
+      "    update_time_ms: 36.921\n",
+      "  timestamp: 1602490153\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      7 |           184.42 | 1132544 |  227.832 |              275.717 |              138.899 |            863.073 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3545.019368723099\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-09-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 860.4458509142054\n",
+      "  episode_reward_max: 275.7171717171718\n",
+      "  episode_reward_mean: 229.1102800153431\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0527766644954681\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007615982904098928\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012027044120865563\n",
+      "        total_loss: 16.963534673055012\n",
+      "        vf_explained_var: 0.9683038592338562\n",
+      "        vf_loss: 16.975852966308594\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.863333333333333\n",
+      "    gpu_util_percent0: 0.2586666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15452219062147216\n",
+      "    mean_env_wait_ms: 1.1761659446759791\n",
+      "    mean_inference_ms: 4.765321018664555\n",
+      "    mean_raw_obs_processing_ms: 0.4012817864251415\n",
+      "  time_since_restore: 210.67793703079224\n",
+      "  time_this_iter_s: 26.257683277130127\n",
+      "  time_total_s: 210.67793703079224\n",
+      "  timers:\n",
+      "    learn_throughput: 8505.771\n",
+      "    learn_time_ms: 19021.438\n",
+      "    sample_throughput: 22391.774\n",
+      "    sample_time_ms: 7225.511\n",
+      "    update_time_ms: 34.921\n",
+      "  timestamp: 1602490179\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      8 |          210.678 | 1294336 |   229.11 |              275.717 |              138.899 |            860.446 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3536.619201030928\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-12_08-10-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 857.7284810126582\n",
+      "  episode_reward_max: 281.92929292929284\n",
+      "  episode_reward_mean: 230.51368111494673\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0236333707968395\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008085604213799039\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011290598209598102\n",
+      "        total_loss: 15.170008023579916\n",
+      "        vf_explained_var: 0.970684289932251\n",
+      "        vf_loss: 15.18151330947876\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.749999999999996\n",
+      "    gpu_util_percent0: 0.251\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7733333333333334\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1540308837771974\n",
+      "    mean_env_wait_ms: 1.1774970942409586\n",
+      "    mean_inference_ms: 4.734334782954239\n",
+      "    mean_raw_obs_processing_ms: 0.3997390670523251\n",
+      "  time_since_restore: 236.742493391037\n",
+      "  time_this_iter_s: 26.06455636024475\n",
+      "  time_total_s: 236.742493391037\n",
+      "  timers:\n",
+      "    learn_throughput: 8505.518\n",
+      "    learn_time_ms: 19022.004\n",
+      "    sample_throughput: 22482.023\n",
+      "    sample_time_ms: 7196.506\n",
+      "    update_time_ms: 33.142\n",
+      "  timestamp: 1602490205\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |      9 |          236.742 | 1456128 |  230.514 |              281.929 |              138.899 |            857.728 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3519.6370656370655\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-10-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.4513851167843\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 233.1354885081119\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 261\n",
+      "  episodes_total: 1841\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9897792836030325\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008098231783757607\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010045850300230086\n",
+      "        total_loss: 20.74252223968506\n",
+      "        vf_explained_var: 0.9716846346855164\n",
+      "        vf_loss: 20.752748171488445\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.766666666666666\n",
+      "    gpu_util_percent0: 0.28366666666666673\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7633333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15336646876524834\n",
+      "    mean_env_wait_ms: 1.179771053805273\n",
+      "    mean_inference_ms: 4.691936826434794\n",
+      "    mean_raw_obs_processing_ms: 0.39762402378600903\n",
+      "  time_since_restore: 262.79794573783875\n",
+      "  time_this_iter_s: 26.055452346801758\n",
+      "  time_total_s: 262.79794573783875\n",
+      "  timers:\n",
+      "    learn_throughput: 8506.736\n",
+      "    learn_time_ms: 19019.281\n",
+      "    sample_throughput: 22547.752\n",
+      "    sample_time_ms: 7175.527\n",
+      "    update_time_ms: 31.912\n",
+      "  timestamp: 1602490231\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     10 |          262.798 | 1617920 |  233.135 |              288.747 |              138.899 |            852.451 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3509.591806515301\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-10-58\n",
       "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
+      "  episode_len_mean: 848.2750730282376\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 234.99839682118142\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 213\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3347,14 +3703,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
+      "        entropy: 0.9871509124835333\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007209118106402457\n",
       "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
+      "        policy_loss: -0.012315249536186457\n",
+      "        total_loss: 13.081322272618612\n",
+      "        vf_explained_var: 0.9765751957893372\n",
+      "        vf_loss: 13.09390377998352\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -3362,65 +3718,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
+      "    cpu_util_percent: 24.37741935483871\n",
+      "    gpu_util_percent0: 0.4119354838709678\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
+      "    mean_action_processing_ms: 0.15291547541255573\n",
+      "    mean_env_wait_ms: 1.1813891282293203\n",
+      "    mean_inference_ms: 4.663419804013761\n",
+      "    mean_raw_obs_processing_ms: 0.39626592689167284\n",
+      "  time_since_restore: 288.9913504123688\n",
+      "  time_this_iter_s: 26.19340467453003\n",
+      "  time_total_s: 288.9913504123688\n",
       "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
+      "    learn_throughput: 8502.356\n",
+      "    learn_time_ms: 19029.079\n",
+      "    sample_throughput: 23156.003\n",
+      "    sample_time_ms: 6987.043\n",
+      "    update_time_ms: 31.229\n",
+      "  timestamp: 1602490258\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     11 |          288.991 | 1779712 |  234.998 |              288.747 |              138.899 |            848.275 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3500.4253663003665\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-11-24\n",
       "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 845.25226039783\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 236.21548669333458\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3429,14 +3785,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
+      "        entropy: 0.9684580465157827\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0071360117290169\n",
       "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
+      "        policy_loss: -0.011122295356472023\n",
+      "        total_loss: 14.169920762379965\n",
+      "        vf_explained_var: 0.9724215865135193\n",
+      "        vf_loss: 14.181298096974691\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -3444,65 +3800,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
+      "    cpu_util_percent: 24.079999999999995\n",
+      "    gpu_util_percent0: 0.25166666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7766666666666664\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
+      "    mean_action_processing_ms: 0.15262288825471745\n",
+      "    mean_env_wait_ms: 1.1825289172355695\n",
+      "    mean_inference_ms: 4.645050441375069\n",
+      "    mean_raw_obs_processing_ms: 0.39535490470579415\n",
+      "  time_since_restore: 315.16404151916504\n",
+      "  time_this_iter_s: 26.172691106796265\n",
+      "  time_total_s: 315.16404151916504\n",
       "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
+      "    learn_throughput: 8504.47\n",
+      "    learn_time_ms: 19024.348\n",
+      "    sample_throughput: 23270.287\n",
+      "    sample_time_ms: 6952.729\n",
+      "    update_time_ms: 27.675\n",
+      "  timestamp: 1602490284\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     12 |          315.164 | 1941504 |  236.215 |              288.747 |              138.899 |            845.252 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3492.3398720682303\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-11-50\n",
       "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 842.0539401601349\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 237.38396608308096\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 2373\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3511,14 +3867,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
+      "        entropy: 0.9432903180519739\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0064480928316091495\n",
       "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
+      "        policy_loss: -0.010764235218327181\n",
+      "        total_loss: 13.248364766438803\n",
+      "        vf_explained_var: 0.9748766422271729\n",
+      "        vf_loss: 13.259427547454834\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -3526,65 +3882,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
+      "    cpu_util_percent: 25.170000000000005\n",
+      "    gpu_util_percent0: 0.3536666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
+      "    mean_action_processing_ms: 0.15235432334814986\n",
+      "    mean_env_wait_ms: 1.1837337370144503\n",
+      "    mean_inference_ms: 4.628123902236818\n",
+      "    mean_raw_obs_processing_ms: 0.39449204277665234\n",
+      "  time_since_restore: 341.18098974227905\n",
+      "  time_this_iter_s: 26.016948223114014\n",
+      "  time_total_s: 341.18098974227905\n",
       "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
+      "    learn_throughput: 8501.095\n",
+      "    learn_time_ms: 19031.901\n",
+      "    sample_throughput: 23383.904\n",
+      "    sample_time_ms: 6918.947\n",
+      "    update_time_ms: 27.753\n",
+      "  timestamp: 1602490310\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     13 |          341.181 | 2103296 |  237.384 |              288.747 |              138.899 |            842.054 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3480.9777358490564\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-12-16\n",
       "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 837.1299477221808\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 239.0731927188236\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 305\n",
+      "  episodes_total: 2678\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3593,14 +3949,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
+      "        entropy: 0.9245238403479258\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006356651700722675\n",
       "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
+      "        policy_loss: -0.0093736828227217\n",
+      "        total_loss: 16.56673304239909\n",
+      "        vf_explained_var: 0.977961540222168\n",
+      "        vf_loss: 16.576395829518635\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -3608,65 +3964,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
+      "    cpu_util_percent: 24.896666666666665\n",
+      "    gpu_util_percent0: 0.29466666666666674\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7633333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
+      "    mean_action_processing_ms: 0.15190957765651997\n",
+      "    mean_env_wait_ms: 1.1859752986928445\n",
+      "    mean_inference_ms: 4.600343130214659\n",
+      "    mean_raw_obs_processing_ms: 0.3931069726348402\n",
+      "  time_since_restore: 367.24762058258057\n",
+      "  time_this_iter_s: 26.066630840301514\n",
+      "  time_total_s: 367.24762058258057\n",
       "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
+      "    learn_throughput: 8501.73\n",
+      "    learn_time_ms: 19030.48\n",
+      "    sample_throughput: 23378.515\n",
+      "    sample_time_ms: 6920.542\n",
+      "    update_time_ms: 29.402\n",
+      "  timestamp: 1602490336\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     14 |          367.248 | 2265088 |  239.073 |              288.747 |              138.899 |             837.13 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3474.9868607954545\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-12-43\n",
       "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
+      "  episode_len_mean: 834.7232770745429\n",
+      "  episode_reward_max: 288.74747474747466\n",
+      "  episode_reward_mean: 239.94718279844844\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 166\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3675,14 +4031,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
+      "        entropy: 0.906185562411944\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006180410894254844\n",
       "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
+      "        policy_loss: -0.012563393373663226\n",
+      "        total_loss: 10.936929861704508\n",
+      "        vf_explained_var: 0.979099452495575\n",
+      "        vf_loss: 10.949781576792398\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -3690,65 +4046,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
+      "    cpu_util_percent: 24.083870967741934\n",
+      "    gpu_util_percent0: 0.3635483870967742\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
+      "    mean_action_processing_ms: 0.15170192871649035\n",
+      "    mean_env_wait_ms: 1.187075900566473\n",
+      "    mean_inference_ms: 4.587271974323672\n",
+      "    mean_raw_obs_processing_ms: 0.3924657739112036\n",
+      "  time_since_restore: 393.44245624542236\n",
+      "  time_this_iter_s: 26.194835662841797\n",
+      "  time_total_s: 393.44245624542236\n",
       "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
+      "    learn_throughput: 8500.238\n",
+      "    learn_time_ms: 19033.821\n",
+      "    sample_throughput: 23336.365\n",
+      "    sample_time_ms: 6933.042\n",
+      "    update_time_ms: 29.449\n",
+      "  timestamp: 1602490363\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     15 |          393.442 | 2426880 |  239.947 |              288.747 |              138.899 |            834.723 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3469.194351042367\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_08-13-09\n",
       "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 832.4070619586942\n",
+      "  episode_reward_max: 291.6262626262627\n",
+      "  episode_reward_mean: 240.8477412364819\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3757,14 +4113,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
+      "        entropy: 0.8940609991550446\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007062381831929088\n",
       "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
+      "        policy_loss: -0.01240032100273917\n",
+      "        total_loss: 9.784063498179117\n",
+      "        vf_explained_var: 0.9792147278785706\n",
+      "        vf_loss: 9.796651442845663\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -3772,65 +4128,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
+      "    cpu_util_percent: 25.439999999999998\n",
+      "    gpu_util_percent0: 0.2953333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7899999999999996\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
+      "    mean_action_processing_ms: 0.15151935101577735\n",
+      "    mean_env_wait_ms: 1.1880832907069834\n",
+      "    mean_inference_ms: 4.5757290796410865\n",
+      "    mean_raw_obs_processing_ms: 0.39187675467872235\n",
+      "  time_since_restore: 419.5664372444153\n",
+      "  time_this_iter_s: 26.12398099899292\n",
+      "  time_total_s: 419.5664372444153\n",
       "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
+      "    learn_throughput: 8475.187\n",
+      "    learn_time_ms: 19090.079\n",
+      "    sample_throughput: 23315.951\n",
+      "    sample_time_ms: 6939.112\n",
+      "    update_time_ms: 31.854\n",
+      "  timestamp: 1602490389\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     16 |          419.566 | 2588672 |  240.848 |              291.626 |              138.899 |            832.407 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3461.9522776572667\n",
+      "    time_step_min: 3146\n",
+      "  date: 2020-10-12_08-13-35\n",
       "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 829.152380952381\n",
+      "  episode_reward_max: 291.6262626262627\n",
+      "  episode_reward_mean: 241.9287808965227\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 253\n",
+      "  episodes_total: 3255\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3839,14 +4195,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
+      "        entropy: 0.8715203603108724\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0068582673169051605\n",
       "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
+      "        policy_loss: -0.009826259381952696\n",
+      "        total_loss: 13.900481621424357\n",
+      "        vf_explained_var: 0.9798092246055603\n",
+      "        vf_loss: 13.910493532816568\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -3854,65 +4210,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
+      "    cpu_util_percent: 24.28666666666667\n",
+      "    gpu_util_percent0: 0.256\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.77\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
+      "    mean_action_processing_ms: 0.15125671270769184\n",
+      "    mean_env_wait_ms: 1.1897326970724291\n",
+      "    mean_inference_ms: 4.559082586406331\n",
+      "    mean_raw_obs_processing_ms: 0.391031531764309\n",
+      "  time_since_restore: 445.54023838043213\n",
+      "  time_this_iter_s: 25.973801136016846\n",
+      "  time_total_s: 445.54023838043213\n",
       "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
+      "    learn_throughput: 8471.862\n",
+      "    learn_time_ms: 19097.573\n",
+      "    sample_throughput: 23339.019\n",
+      "    sample_time_ms: 6932.254\n",
+      "    update_time_ms: 26.287\n",
+      "  timestamp: 1602490415\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     17 |           445.54 | 2750464 |  241.929 |              291.626 |              138.899 |            829.152 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3456.317865429234\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-01\n",
       "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 826.6527617951668\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 242.82325847659547\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 221\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3921,14 +4277,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
+      "        entropy: 0.8578323672215143\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0062772125626603765\n",
       "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
+      "        policy_loss: -0.011194397937894488\n",
+      "        total_loss: 11.216416676839193\n",
+      "        vf_explained_var: 0.9811086058616638\n",
+      "        vf_loss: 11.2278413772583\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -3936,65 +4292,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
+      "    cpu_util_percent: 24.15\n",
+      "    gpu_util_percent0: 0.275\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7666666666666657\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
+      "    mean_action_processing_ms: 0.15105210665216098\n",
+      "    mean_env_wait_ms: 1.1910411370697684\n",
+      "    mean_inference_ms: 4.546026524305814\n",
+      "    mean_raw_obs_processing_ms: 0.3904015773843836\n",
+      "  time_since_restore: 471.62775897979736\n",
+      "  time_this_iter_s: 26.087520599365234\n",
+      "  time_total_s: 471.62775897979736\n",
       "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
+      "    learn_throughput: 8466.865\n",
+      "    learn_time_ms: 19108.844\n",
+      "    sample_throughput: 23450.467\n",
+      "    sample_time_ms: 6899.308\n",
+      "    update_time_ms: 28.072\n",
+      "  timestamp: 1602490441\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     18 |          471.628 | 2912256 |  242.823 |              293.293 |              138.899 |            826.653 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3451.5252357182476\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-27\n",
       "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
+      "  episode_len_mean: 825.2999449642267\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 243.52266195249118\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4003,14 +4359,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
+      "        entropy: 0.8522786746422449\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006254845376436909\n",
       "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
+      "        policy_loss: -0.012950713620133078\n",
+      "        total_loss: 9.356015682220459\n",
+      "        vf_explained_var: 0.9807977080345154\n",
+      "        vf_loss: 9.369193077087402\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -4018,65 +4374,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
+      "    cpu_util_percent: 24.18709677419354\n",
+      "    gpu_util_percent0: 0.3722580645161291\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
+      "    mean_action_processing_ms: 0.15091926952523643\n",
+      "    mean_env_wait_ms: 1.1919120175490399\n",
+      "    mean_inference_ms: 4.537482004930605\n",
+      "    mean_raw_obs_processing_ms: 0.38997728772240287\n",
+      "  time_since_restore: 497.7250077724457\n",
+      "  time_this_iter_s: 26.097248792648315\n",
+      "  time_total_s: 497.7250077724457\n",
       "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
+      "    learn_throughput: 8461.979\n",
+      "    learn_time_ms: 19119.877\n",
+      "    sample_throughput: 23489.436\n",
+      "    sample_time_ms: 6887.862\n",
+      "    update_time_ms: 30.171\n",
+      "  timestamp: 1602490467\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     19 |          497.725 | 3074048 |  243.523 |              293.293 |              138.899 |              825.3 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3446.582144743793\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-14-54\n",
       "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 823.849764027268\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 244.2001530777093\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 180\n",
+      "  episodes_total: 3814\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4085,14 +4441,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
+      "        entropy: 0.8286279241243998\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006430626187163095\n",
       "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
+      "        policy_loss: -0.012222413827354709\n",
+      "        total_loss: 9.228648900985718\n",
+      "        vf_explained_var: 0.9839107990264893\n",
+      "        vf_loss: 9.2410569190979\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -4100,65 +4456,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
+      "    cpu_util_percent: 25.133333333333333\n",
+      "    gpu_util_percent0: 0.3453333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.78\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
+      "    mean_action_processing_ms: 0.15077733023374773\n",
+      "    mean_env_wait_ms: 1.1928851969603187\n",
+      "    mean_inference_ms: 4.528347029744211\n",
+      "    mean_raw_obs_processing_ms: 0.3895120865590016\n",
+      "  time_since_restore: 523.7741742134094\n",
+      "  time_this_iter_s: 26.049166440963745\n",
+      "  time_total_s: 523.7741742134094\n",
       "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
+      "    learn_throughput: 8456.501\n",
+      "    learn_time_ms: 19132.264\n",
+      "    sample_throughput: 23545.959\n",
+      "    sample_time_ms: 6871.328\n",
+      "    update_time_ms: 32.795\n",
+      "  timestamp: 1602490494\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     20 |          523.774 | 3235840 |    244.2 |              293.293 |              138.899 |             823.85 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3438.918773006135\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-15-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.5028028271996\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 245.33389709919064\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 289\n",
+      "  episodes_total: 4103\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4167,14 +4523,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
+      "        entropy: 0.8048954059680303\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005603969019527237\n",
       "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
+      "        policy_loss: -0.013911528105381876\n",
+      "        total_loss: 11.3087530930837\n",
+      "        vf_explained_var: 0.9836416244506836\n",
+      "        vf_loss: 11.322909275690714\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -4182,82 +4538,266 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
+      "    cpu_util_percent: 24.470000000000006\n",
+      "    gpu_util_percent0: 0.2516666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 79399\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
+      "    mean_action_processing_ms: 0.1505739045388427\n",
+      "    mean_env_wait_ms: 1.1943338077267522\n",
+      "    mean_inference_ms: 4.515047112702623\n",
+      "    mean_raw_obs_processing_ms: 0.38885284610818543\n",
+      "  time_since_restore: 549.8376796245575\n",
+      "  time_this_iter_s: 26.06350541114807\n",
+      "  time_total_s: 549.8376796245575\n",
       "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
+      "    learn_throughput: 8455.134\n",
+      "    learn_time_ms: 19135.356\n",
+      "    sample_throughput: 23614.521\n",
+      "    sample_time_ms: 6851.378\n",
+      "    update_time_ms: 35.316\n",
+      "  timestamp: 1602490520\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: c49f7_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     21 |          549.838 | 3397632 |  245.334 |              293.293 |              138.899 |            821.503 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3434.6906559697973\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-15-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.2461322081575\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 245.97136626461509\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7969592610994974\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006330874321671824\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011175491047955196\n",
+      "        total_loss: 6.920762340227763\n",
+      "        vf_explained_var: 0.986197292804718\n",
+      "        vf_loss: 6.932101647059123\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.106451612903232\n",
+      "    gpu_util_percent0: 0.3683870967741936\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15046625659796298\n",
+      "    mean_env_wait_ms: 1.1950829782948686\n",
+      "    mean_inference_ms: 4.508158694182665\n",
+      "    mean_raw_obs_processing_ms: 0.3885170657875346\n",
+      "  time_since_restore: 576.0177464485168\n",
+      "  time_this_iter_s: 26.18006682395935\n",
+      "  time_total_s: 576.0177464485168\n",
+      "  timers:\n",
+      "    learn_throughput: 8446.374\n",
+      "    learn_time_ms: 19155.203\n",
+      "    sample_throughput: 23696.753\n",
+      "    sample_time_ms: 6827.602\n",
+      "    update_time_ms: 38.423\n",
+      "  timestamp: 1602490546\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | RUNNING  | 172.17.0.4:79399 |     22 |          576.018 | 3559424 |  245.971 |              293.293 |              138.899 |            820.246 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_c49f7_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3430.9893206089523\n",
+      "    time_step_min: 3120\n",
+      "  date: 2020-10-12_08-16-12\n",
+      "  done: true\n",
+      "  episode_len_mean: 818.8347256717092\n",
+      "  episode_reward_max: 293.29292929292956\n",
+      "  episode_reward_mean: 246.54997479878926\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4429\n",
+      "  experiment_id: 16a41bd98ce74d6382d0b16d541dadf6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7878765910863876\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005924326988557975\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012837671786352681\n",
+      "        total_loss: 8.265578190485636\n",
+      "        vf_explained_var: 0.9834974408149719\n",
+      "        vf_loss: 8.278611381848654\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.970000000000002\n",
+      "    gpu_util_percent0: 0.30333333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79399\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15036522832821625\n",
+      "    mean_env_wait_ms: 1.1958362960216486\n",
+      "    mean_inference_ms: 4.5016834026606345\n",
+      "    mean_raw_obs_processing_ms: 0.3881896853970501\n",
+      "  time_since_restore: 602.1439270973206\n",
+      "  time_this_iter_s: 26.12618064880371\n",
+      "  time_total_s: 602.1439270973206\n",
+      "  timers:\n",
+      "    learn_throughput: 8446.113\n",
+      "    learn_time_ms: 19155.793\n",
+      "    sample_throughput: 23657.57\n",
+      "    sample_time_ms: 6838.91\n",
+      "    update_time_ms: 36.492\n",
+      "  timestamp: 1602490572\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: c49f7_00000\n",
+      "  \n",
+      "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m 2020-10-12 08:16:13,040\tERROR worker.py:372 -- SystemExit was raised from the worker\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 553, in ray._raylet.task_execution_handler\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 440, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py\", line 553, in actor_method_executor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     return method(actor, *args, **kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 929, in __ray_terminate__\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     ray.actor.exit_actor()\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 991, in exit_actor\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     ray.state.state.disconnect()\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/state.py\", line 61, in disconnect\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     self.global_state_accessor = None\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 369, in sigterm_handler\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m     sys.exit(1)\n",
+      "\u001b[2m\u001b[36m(pid=79336)\u001b[0m SystemExit: 1\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
+      "| PPO_jss_env_c49f7_00000 | TERMINATED |       |     23 |          602.144 | 3721216 |   246.55 |              293.293 |              138.899 |            818.835 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
+      "2020-10-12 08:16:13,085\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79130\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_080556-xgblq0zg/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_080556-xgblq0zg/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3120\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 617\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602490573\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4139\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3430.98932\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.29293\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 246.54997\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4429\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -4273,204 +4813,203 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfearless-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/xgblq0zg\u001b[0m\n",
+      "2020-10-12 08:16:20,100 - wandb.wandb_agent - INFO - Cleaning up finished run: xgblq0zg\n",
+      "2020-10-12 08:16:20,408 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:16:20,408 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
       "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 08:16:20,411 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --num_sgd_iter=20\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
+      "2020-10-12 08:16:25,428 - wandb.wandb_agent - INFO - Running runs: ['6nvy6bhw']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mazure-sweep-3\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/6nvy6bhw\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_081622-6nvy6bhw\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 08:16:26,316\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=24878)\u001b[0m 2020-10-12 08:16:29,112\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=24825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24870)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24782)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24782)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24789)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24789)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=24755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=24755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
+      "  date: 2020-10-12_08-16-58\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -4478,23 +5017,23 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
+      "        entropy: 1.185864080985387\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
+      "        kl: 0.004079875051199148\n",
       "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
+      "        policy_loss: -0.006393474138045955\n",
+      "        total_loss: 514.7339019775391\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -4502,65 +5041,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
+      "    cpu_util_percent: 34.08275862068966\n",
+      "    gpu_util_percent0: 0.2706896551724137\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
+      "    ram_util_percent: 3.53448275862069\n",
+      "    vram_util_percent0: 0.08293561484262792\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
+      "    mean_action_processing_ms: 0.16959718290248305\n",
+      "    mean_env_wait_ms: 1.1668397527154708\n",
+      "    mean_inference_ms: 5.6675725838548425\n",
+      "    mean_raw_obs_processing_ms: 0.45125070049572086\n",
+      "  time_since_restore: 24.041186809539795\n",
+      "  time_this_iter_s: 24.041186809539795\n",
+      "  time_total_s: 24.041186809539795\n",
       "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
+      "    learn_throughput: 10872.209\n",
+      "    learn_time_ms: 14881.244\n",
+      "    sample_throughput: 17812.94\n",
+      "    sample_time_ms: 9082.835\n",
+      "    update_time_ms: 47.25\n",
+      "  timestamp: 1602490618\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      1 |          24.0412 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3621.2881944444443\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-17-21\n",
       "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 890.0727848101266\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 217.58521928142156\n",
+      "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4569,14 +5108,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
+      "        entropy: 1.1563906073570251\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
+      "        kl: 0.007153310541373988\n",
       "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
+      "        policy_loss: -0.006601389720647906\n",
+      "        total_loss: 148.90216318766275\n",
+      "        vf_explained_var: 0.7816783785820007\n",
+      "        vf_loss: 148.90863291422525\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -4584,65 +5123,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
+      "    cpu_util_percent: 30.835714285714285\n",
+      "    gpu_util_percent0: 0.29464285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7428571428571424\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
+      "    mean_action_processing_ms: 0.16544807941264583\n",
+      "    mean_env_wait_ms: 1.165790257442274\n",
+      "    mean_inference_ms: 5.466143985210929\n",
+      "    mean_raw_obs_processing_ms: 0.43924275373531213\n",
+      "  time_since_restore: 46.73395586013794\n",
+      "  time_this_iter_s: 22.692769050598145\n",
+      "  time_total_s: 46.73395586013794\n",
       "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
+      "    learn_throughput: 10915.082\n",
+      "    learn_time_ms: 14822.793\n",
+      "    sample_throughput: 19177.544\n",
+      "    sample_time_ms: 8436.534\n",
+      "    update_time_ms: 68.763\n",
+      "  timestamp: 1602490641\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      2 |           46.734 | 323584 |  217.585 |              271.626 |              145.717 |            890.073 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3617.560538116592\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-17-43\n",
       "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 884.5611814345991\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 217.97167881345075\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4651,14 +5190,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
+      "        entropy: 1.147742599248886\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
+      "        kl: 0.007976852473802865\n",
       "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
+      "        policy_loss: -0.010943490701417128\n",
+      "        total_loss: 72.53540929158528\n",
+      "        vf_explained_var: 0.8764762282371521\n",
+      "        vf_loss: 72.54612922668457\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -4666,65 +5205,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
+      "    cpu_util_percent: 30.673076923076923\n",
+      "    gpu_util_percent0: 0.32769230769230767\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
+      "    ram_util_percent: 3.7653846153846158\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
+      "    mean_action_processing_ms: 0.16269042725297467\n",
+      "    mean_env_wait_ms: 1.1667953562932982\n",
+      "    mean_inference_ms: 5.300973246000417\n",
+      "    mean_raw_obs_processing_ms: 0.4303547572544862\n",
+      "  time_since_restore: 68.67958068847656\n",
+      "  time_this_iter_s: 21.945624828338623\n",
+      "  time_total_s: 68.67958068847656\n",
       "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
+      "    learn_throughput: 10942.549\n",
+      "    learn_time_ms: 14785.586\n",
+      "    sample_throughput: 20197.389\n",
+      "    sample_time_ms: 8010.54\n",
+      "    update_time_ms: 55.862\n",
+      "  timestamp: 1602490663\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      3 |          68.6796 | 485376 |  217.972 |              271.626 |              118.596 |            884.561 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3614.201986754967\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-18-05\n",
       "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 878.743670886076\n",
+      "  episode_reward_max: 271.62626262626253\n",
+      "  episode_reward_mean: 219.13441375783128\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4733,14 +5272,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
+      "        entropy: 1.1307151317596436\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
+      "        kl: 0.007435552775859833\n",
       "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
+      "        policy_loss: -0.008821662476596734\n",
+      "        total_loss: 57.703648249308266\n",
+      "        vf_explained_var: 0.8985523581504822\n",
+      "        vf_loss: 57.71229076385498\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -4748,65 +5287,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
+      "    cpu_util_percent: 30.37307692307692\n",
+      "    gpu_util_percent0: 0.37769230769230766\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
+      "    ram_util_percent: 3.757692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
+      "    mean_action_processing_ms: 0.16071866402244744\n",
+      "    mean_env_wait_ms: 1.1686171756642982\n",
+      "    mean_inference_ms: 5.177265320403001\n",
+      "    mean_raw_obs_processing_ms: 0.42365264313897055\n",
+      "  time_since_restore: 90.54482674598694\n",
+      "  time_this_iter_s: 21.865246057510376\n",
+      "  time_total_s: 90.54482674598694\n",
       "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
+      "    learn_throughput: 10943.822\n",
+      "    learn_time_ms: 14783.866\n",
+      "    sample_throughput: 20855.405\n",
+      "    sample_time_ms: 7757.797\n",
+      "    update_time_ms: 51.57\n",
+      "  timestamp: 1602490685\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      4 |          90.5448 | 647168 |  219.134 |              271.626 |              118.596 |            878.744 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3603.303149606299\n",
+      "    time_step_min: 3263\n",
+      "  date: 2020-10-12_08-18-27\n",
       "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 872.032911392405\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 220.47570643140241\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4815,14 +5354,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
+      "        entropy: 1.0931349396705627\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
+      "        kl: 0.00779568237097313\n",
       "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
+      "        policy_loss: -0.008994614414405078\n",
+      "        total_loss: 45.30020809173584\n",
+      "        vf_explained_var: 0.932476282119751\n",
+      "        vf_loss: 45.30897013346354\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -4830,65 +5369,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
+      "    cpu_util_percent: 28.75925925925926\n",
+      "    gpu_util_percent0: 0.36481481481481487\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.755555555555555\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
+      "    mean_action_processing_ms: 0.15922985707676396\n",
+      "    mean_env_wait_ms: 1.1714250251780574\n",
+      "    mean_inference_ms: 5.082715379115769\n",
+      "    mean_raw_obs_processing_ms: 0.4184893832756008\n",
+      "  time_since_restore: 112.39339995384216\n",
+      "  time_this_iter_s: 21.848573207855225\n",
+      "  time_total_s: 112.39339995384216\n",
       "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
+      "    learn_throughput: 10950.47\n",
+      "    learn_time_ms: 14774.891\n",
+      "    sample_throughput: 21290.579\n",
+      "    sample_time_ms: 7599.23\n",
+      "    update_time_ms: 48.6\n",
+      "  timestamp: 1602490707\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      5 |          112.393 | 808960 |  220.476 |               277.99 |              118.596 |            872.033 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3580.025974025974\n",
+      "    time_step_min: 3252\n",
+      "  date: 2020-10-12_08-18-48\n",
       "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 859.9168173598554\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 224.50477651743455\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4897,14 +5436,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
+      "        entropy: 1.0964580277601879\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
+      "        kl: 0.0070520887384191155\n",
       "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
+      "        policy_loss: -0.009450642672769996\n",
+      "        total_loss: 36.19568475087484\n",
+      "        vf_explained_var: 0.9530174732208252\n",
+      "        vf_loss: 36.2049773534139\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -4912,65 +5451,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
+      "    cpu_util_percent: 30.42\n",
+      "    gpu_util_percent0: 0.28240000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
+      "    ram_util_percent: 3.756\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
+      "    mean_action_processing_ms: 0.15727627060891738\n",
+      "    mean_env_wait_ms: 1.176935910840223\n",
+      "    mean_inference_ms: 4.9546206565535345\n",
+      "    mean_raw_obs_processing_ms: 0.4118872265080656\n",
+      "  time_since_restore: 133.9969527721405\n",
+      "  time_this_iter_s: 21.60355281829834\n",
+      "  time_total_s: 133.9969527721405\n",
       "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
+      "    learn_throughput: 10972.109\n",
+      "    learn_time_ms: 14745.752\n",
+      "    sample_throughput: 21605.627\n",
+      "    sample_time_ms: 7488.42\n",
+      "    update_time_ms: 43.97\n",
+      "  timestamp: 1602490728\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      6 |          133.997 | 970752 |  224.505 |               277.99 |              118.596 |            859.917 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3568.9069579288025\n",
+      "    time_step_min: 3223\n",
+      "  date: 2020-10-12_08-19-11\n",
       "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
+      "  episode_len_mean: 855.3409810126582\n",
+      "  episode_reward_max: 277.989898989899\n",
+      "  episode_reward_mean: 226.3009365809997\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4979,14 +5518,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
+      "        entropy: 1.0852240125338237\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
+      "        kl: 0.006654882531923552\n",
       "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
+      "        policy_loss: -0.008402673081339648\n",
+      "        total_loss: 22.136696815490723\n",
+      "        vf_explained_var: 0.9591858386993408\n",
+      "        vf_loss: 22.1449769337972\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -4994,65 +5533,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
+      "    cpu_util_percent: 29.133333333333333\n",
+      "    gpu_util_percent0: 0.3274074074074074\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.774074074074074\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
+      "    mean_action_processing_ms: 0.15656674946834911\n",
+      "    mean_env_wait_ms: 1.1790376306777075\n",
+      "    mean_inference_ms: 4.908632400838693\n",
+      "    mean_raw_obs_processing_ms: 0.4094826609603066\n",
+      "  time_since_restore: 156.16001439094543\n",
+      "  time_this_iter_s: 22.16306161880493\n",
+      "  time_total_s: 156.16001439094543\n",
       "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
+      "    learn_throughput: 10962.953\n",
+      "    learn_time_ms: 14758.067\n",
+      "    sample_throughput: 21706.713\n",
+      "    sample_time_ms: 7453.547\n",
+      "    update_time_ms: 42.91\n",
+      "  timestamp: 1602490751\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      7 |           156.16 | 1132544 |  226.301 |               277.99 |              118.596 |            855.341 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3559.409612625538\n",
+      "    time_step_min: 3213\n",
+      "  date: 2020-10-12_08-19-33\n",
       "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 851.2285513361463\n",
+      "  episode_reward_max: 279.2020202020205\n",
+      "  episode_reward_mean: 227.61643864808408\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5061,14 +5600,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
+      "        entropy: 1.064836581548055\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
+      "        kl: 0.007024736143648624\n",
       "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
+      "        policy_loss: -0.01098796930940201\n",
+      "        total_loss: 18.97636540730794\n",
+      "        vf_explained_var: 0.9632197022438049\n",
+      "        vf_loss: 18.98718277613322\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -5076,65 +5615,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
+      "    cpu_util_percent: 29.669230769230772\n",
+      "    gpu_util_percent0: 0.38384615384615384\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
+      "    ram_util_percent: 3.773076923076923\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
+      "    mean_action_processing_ms: 0.15595891964857586\n",
+      "    mean_env_wait_ms: 1.1809454626407365\n",
+      "    mean_inference_ms: 4.868793649237494\n",
+      "    mean_raw_obs_processing_ms: 0.407373353338115\n",
+      "  time_since_restore: 178.08209371566772\n",
+      "  time_this_iter_s: 21.92207932472229\n",
+      "  time_total_s: 178.08209371566772\n",
       "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
+      "    learn_throughput: 10962.634\n",
+      "    learn_time_ms: 14758.497\n",
+      "    sample_throughput: 21846.272\n",
+      "    sample_time_ms: 7405.932\n",
+      "    update_time_ms: 42.294\n",
+      "  timestamp: 1602490773\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      8 |          178.082 | 1294336 |  227.616 |              279.202 |              118.596 |            851.229 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3544.464445868033\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-19-55\n",
       "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 847.2133417243549\n",
+      "  episode_reward_max: 282.53535353535335\n",
+      "  episode_reward_mean: 229.62328762769275\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 1589\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5143,14 +5682,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
+      "        entropy: 1.0196023285388947\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
+      "        kl: 0.006671490341735383\n",
       "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
+      "        policy_loss: -0.0071269801701419055\n",
+      "        total_loss: 18.681314945220947\n",
+      "        vf_explained_var: 0.9678203463554382\n",
+      "        vf_loss: 18.688284556070965\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -5158,65 +5697,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
+      "    cpu_util_percent: 29.38148148148148\n",
+      "    gpu_util_percent0: 0.31999999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
+      "    mean_action_processing_ms: 0.155400467758317\n",
+      "    mean_env_wait_ms: 1.183039650073914\n",
+      "    mean_inference_ms: 4.832418911477187\n",
+      "    mean_raw_obs_processing_ms: 0.40543635804228817\n",
+      "  time_since_restore: 200.01625061035156\n",
+      "  time_this_iter_s: 21.934156894683838\n",
+      "  time_total_s: 200.01625061035156\n",
       "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
+      "    learn_throughput: 10966.485\n",
+      "    learn_time_ms: 14753.314\n",
+      "    sample_throughput: 21935.371\n",
+      "    sample_time_ms: 7375.85\n",
+      "    update_time_ms: 41.465\n",
+      "  timestamp: 1602490795\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |      9 |          200.016 | 1456128 |  229.623 |              282.535 |              118.596 |            847.213 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3524.805674518201\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-20-16\n",
       "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 839.9789029535865\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 232.63740250607327\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5225,14 +5764,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
+      "        entropy: 1.0076924065748851\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
+      "        kl: 0.006664008173781137\n",
       "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
+      "        policy_loss: -0.007970896758100329\n",
+      "        total_loss: 19.40124209721883\n",
+      "        vf_explained_var: 0.9715626239776611\n",
+      "        vf_loss: 19.409050464630127\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -5240,65 +5779,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
+      "    cpu_util_percent: 29.65\n",
+      "    gpu_util_percent0: 0.3926923076923077\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
+      "    ram_util_percent: 3.761538461538461\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
+      "    mean_action_processing_ms: 0.1545620977237074\n",
+      "    mean_env_wait_ms: 1.186670827850528\n",
+      "    mean_inference_ms: 4.777711485075414\n",
+      "    mean_raw_obs_processing_ms: 0.40263050559742963\n",
+      "  time_since_restore: 221.60317945480347\n",
+      "  time_this_iter_s: 21.586928844451904\n",
+      "  time_total_s: 221.60317945480347\n",
       "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
+      "    learn_throughput: 10981.455\n",
+      "    learn_time_ms: 14733.202\n",
+      "    sample_throughput: 22066.542\n",
+      "    sample_time_ms: 7332.005\n",
+      "    update_time_ms: 41.18\n",
+      "  timestamp: 1602490816\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     10 |          221.603 | 1617920 |  232.637 |              288.141 |              118.596 |            839.979 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3515.567620927937\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_08-20-38\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
+      "  episode_len_mean: 836.7551119766309\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 234.13157377081416\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5307,14 +5846,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
+      "        entropy: 0.9877197394768397\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
+      "        kl: 0.007032672797019283\n",
       "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
+      "        policy_loss: -0.0085028958710609\n",
+      "        total_loss: 13.62386417388916\n",
+      "        vf_explained_var: 0.972416877746582\n",
+      "        vf_loss: 13.632157802581787\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -5322,65 +5861,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
+      "    cpu_util_percent: 29.884615384615383\n",
+      "    gpu_util_percent0: 0.35500000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
+      "    ram_util_percent: 3.7807692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
+      "    mean_action_processing_ms: 0.15420689223114267\n",
+      "    mean_env_wait_ms: 1.188281984880439\n",
+      "    mean_inference_ms: 4.754489900097536\n",
+      "    mean_raw_obs_processing_ms: 0.40144947710727935\n",
+      "  time_since_restore: 243.3785741329193\n",
+      "  time_this_iter_s: 21.775394678115845\n",
+      "  time_total_s: 243.3785741329193\n",
       "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
+      "    learn_throughput: 10994.005\n",
+      "    learn_time_ms: 14716.384\n",
+      "    sample_throughput: 22725.409\n",
+      "    sample_time_ms: 7119.432\n",
+      "    update_time_ms: 41.124\n",
+      "  timestamp: 1602490838\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     11 |          243.379 | 1779712 |  234.132 |              288.141 |              118.596 |            836.755 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3506.289377289377\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-00\n",
       "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 834.1546112115732\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 235.46928142181295\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5389,14 +5928,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
+      "        entropy: 0.9678831497828165\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
+      "        kl: 0.006004722556099296\n",
       "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
+      "        policy_loss: -0.009751358816477781\n",
+      "        total_loss: 12.226415316263834\n",
+      "        vf_explained_var: 0.9737133383750916\n",
+      "        vf_loss: 12.23604973157247\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -5404,65 +5943,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
+      "    cpu_util_percent: 28.969230769230776\n",
+      "    gpu_util_percent0: 0.3538461538461538\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
+      "    ram_util_percent: 3.7615384615384615\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
+      "    mean_action_processing_ms: 0.15388558015710302\n",
+      "    mean_env_wait_ms: 1.1897205745623838\n",
+      "    mean_inference_ms: 4.733412954819154\n",
+      "    mean_raw_obs_processing_ms: 0.40035092487229396\n",
+      "  time_since_restore: 265.1564075946808\n",
+      "  time_this_iter_s: 21.777833461761475\n",
+      "  time_total_s: 265.1564075946808\n",
       "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
+      "    learn_throughput: 11014.664\n",
+      "    learn_time_ms: 14688.781\n",
+      "    sample_throughput: 22915.538\n",
+      "    sample_time_ms: 7060.362\n",
+      "    update_time_ms: 35.679\n",
+      "  timestamp: 1602490860\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     12 |          265.156 | 1941504 |  235.469 |              288.141 |              118.596 |            834.155 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3491.8694060211556\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-22\n",
       "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 830.4947707160096\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 237.5231031148166\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 274\n",
+      "  episodes_total: 2486\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5471,14 +6010,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
+      "        entropy: 0.9290325542291006\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
+      "        kl: 0.006295189222631355\n",
       "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
+      "        policy_loss: -0.008376634260154484\n",
+      "        total_loss: 16.791339874267578\n",
+      "        vf_explained_var: 0.9763460755348206\n",
+      "        vf_loss: 16.799551486968994\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -5486,65 +6025,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
+      "    cpu_util_percent: 29.807692307692307\n",
+      "    gpu_util_percent0: 0.35038461538461535\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
+      "    ram_util_percent: 3.753846153846154\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
+      "    mean_action_processing_ms: 0.1534026797728033\n",
+      "    mean_env_wait_ms: 1.1921915934861729\n",
+      "    mean_inference_ms: 4.701865327501849\n",
+      "    mean_raw_obs_processing_ms: 0.39870932714343327\n",
+      "  time_since_restore: 286.9444353580475\n",
+      "  time_this_iter_s: 21.7880277633667\n",
+      "  time_total_s: 286.9444353580475\n",
       "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
+      "    learn_throughput: 11020.361\n",
+      "    learn_time_ms: 14681.189\n",
+      "    sample_throughput: 22948.562\n",
+      "    sample_time_ms: 7050.202\n",
+      "    update_time_ms: 36.619\n",
+      "  timestamp: 1602490882\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     13 |          286.944 | 2103296 |  237.523 |              288.141 |              118.596 |            830.495 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3483.349134687735\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-21-43\n",
       "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 828.1734921816828\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 238.66669675158124\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 200\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5553,14 +6092,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
+      "        entropy: 0.9232238580783209\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
+      "        kl: 0.006286289620523651\n",
       "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
+      "        policy_loss: -0.01046323703970605\n",
+      "        total_loss: 11.78066317240397\n",
+      "        vf_explained_var: 0.9783161282539368\n",
+      "        vf_loss: 11.79095975557963\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -5568,65 +6107,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
+      "    cpu_util_percent: 31.0\n",
+      "    gpu_util_percent0: 0.2956\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
+      "    ram_util_percent: 3.7799999999999994\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
+      "    mean_action_processing_ms: 0.15309949060833375\n",
+      "    mean_env_wait_ms: 1.1936688099878277\n",
+      "    mean_inference_ms: 4.68158069729053\n",
+      "    mean_raw_obs_processing_ms: 0.3976814010577938\n",
+      "  time_since_restore: 308.1764705181122\n",
+      "  time_this_iter_s: 21.232035160064697\n",
+      "  time_total_s: 308.1764705181122\n",
       "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
+      "    learn_throughput: 11062.35\n",
+      "    learn_time_ms: 14625.464\n",
+      "    sample_throughput: 22970.509\n",
+      "    sample_time_ms: 7043.466\n",
+      "    update_time_ms: 34.789\n",
+      "  timestamp: 1602490903\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     14 |          308.176 | 2265088 |  238.667 |              288.141 |              118.596 |            828.173 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3477.3824573863635\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_08-22-05\n",
       "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
+      "  episode_len_mean: 826.8424753867791\n",
+      "  episode_reward_max: 288.1414141414144\n",
+      "  episode_reward_mean: 239.64862762647567\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5635,14 +6174,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
+      "        entropy: 0.9125363181034724\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
+      "        kl: 0.00608441144383202\n",
       "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
+      "        policy_loss: -0.008707707068727663\n",
+      "        total_loss: 9.64974331855774\n",
+      "        vf_explained_var: 0.9798218607902527\n",
+      "        vf_loss: 9.65829865137736\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -5650,65 +6189,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
+      "    cpu_util_percent: 29.60769230769231\n",
+      "    gpu_util_percent0: 0.3346153846153846\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
+      "    mean_action_processing_ms: 0.15288317920572567\n",
+      "    mean_env_wait_ms: 1.194748016689442\n",
+      "    mean_inference_ms: 4.667225431805814\n",
+      "    mean_raw_obs_processing_ms: 0.3969378355610825\n",
+      "  time_since_restore: 329.7988615036011\n",
+      "  time_this_iter_s: 21.62239098548889\n",
+      "  time_total_s: 329.7988615036011\n",
       "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
+      "    learn_throughput: 11071.0\n",
+      "    learn_time_ms: 14614.036\n",
+      "    sample_throughput: 22991.378\n",
+      "    sample_time_ms: 7037.073\n",
+      "    update_time_ms: 34.298\n",
+      "  timestamp: 1602490925\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     15 |          329.799 | 2426880 |  239.649 |              288.141 |              118.596 |            826.842 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3471.586357526882\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-22-27\n",
       "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 825.6671105193076\n",
+      "  episode_reward_max: 290.11111111111103\n",
+      "  episode_reward_mean: 240.53267024438787\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 3004\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5717,14 +6256,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
+      "        entropy: 0.8860243856906891\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
+      "        kl: 0.006397477972010772\n",
       "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
+      "        policy_loss: -0.008911015300933892\n",
+      "        total_loss: 11.561505238215128\n",
+      "        vf_explained_var: 0.9785943031311035\n",
+      "        vf_loss: 11.57021967569987\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -5732,65 +6271,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
+      "    cpu_util_percent: 29.15925925925926\n",
+      "    gpu_util_percent0: 0.3262962962962963\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.77037037037037\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
+      "    mean_action_processing_ms: 0.15268173840271962\n",
+      "    mean_env_wait_ms: 1.19574489708898\n",
+      "    mean_inference_ms: 4.653763309399263\n",
+      "    mean_raw_obs_processing_ms: 0.39622961868207607\n",
+      "  time_since_restore: 351.7714014053345\n",
+      "  time_this_iter_s: 21.9725399017334\n",
+      "  time_total_s: 351.7714014053345\n",
       "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
+      "    learn_throughput: 11050.606\n",
+      "    learn_time_ms: 14641.007\n",
+      "    sample_throughput: 22973.716\n",
+      "    sample_time_ms: 7042.483\n",
+      "    update_time_ms: 36.284\n",
+      "  timestamp: 1602490947\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     16 |          351.771 | 2588672 |  240.533 |              290.111 |              118.596 |            825.667 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3461.5548112058464\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-22-49\n",
       "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 823.8010265700483\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 242.11498133508994\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 308\n",
+      "  episodes_total: 3312\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5799,14 +6338,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
+      "        entropy: 0.8602482428153356\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
+      "        kl: 0.006070932140573859\n",
       "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
+      "        policy_loss: -0.009451528991727779\n",
+      "        total_loss: 13.428233623504639\n",
+      "        vf_explained_var: 0.981722891330719\n",
+      "        vf_loss: 13.437508344650269\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -5814,65 +6353,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
+      "    cpu_util_percent: 29.77692307692308\n",
+      "    gpu_util_percent0: 0.40192307692307705\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
+      "    ram_util_percent: 3.757692307692307\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
+      "    mean_action_processing_ms: 0.1523316783764433\n",
+      "    mean_env_wait_ms: 1.197482520364091\n",
+      "    mean_inference_ms: 4.630753591799989\n",
+      "    mean_raw_obs_processing_ms: 0.39506937213176363\n",
+      "  time_since_restore: 373.392630815506\n",
+      "  time_this_iter_s: 21.62122941017151\n",
+      "  time_total_s: 373.392630815506\n",
       "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
+      "    learn_throughput: 11067.625\n",
+      "    learn_time_ms: 14618.493\n",
+      "    sample_throughput: 23078.296\n",
+      "    sample_time_ms: 7010.57\n",
+      "    update_time_ms: 35.004\n",
+      "  timestamp: 1602490969\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     17 |          373.393 | 2750464 |  242.115 |              290.414 |              118.596 |            823.801 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3455.939385150812\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 822.9513808975835\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 242.9883733770384\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 164\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -5881,14 +6420,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
+      "        entropy: 0.8480297277371088\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
+      "        kl: 0.005980685236863792\n",
       "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
+      "        policy_loss: -0.009295757947256789\n",
+      "        total_loss: 8.385785063107809\n",
+      "        vf_explained_var: 0.98355633020401\n",
+      "        vf_loss: 8.394906878471375\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -5896,385 +6435,147 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
+      "    cpu_util_percent: 29.719230769230762\n",
+      "    gpu_util_percent0: 0.38961538461538464\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
+      "    ram_util_percent: 3.776923076923077\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
+      "    mean_action_processing_ms: 0.15216380576721844\n",
+      "    mean_env_wait_ms: 1.198240484170083\n",
+      "    mean_inference_ms: 4.619870814820799\n",
+      "    mean_raw_obs_processing_ms: 0.39451138085377374\n",
+      "  time_since_restore: 394.9590709209442\n",
+      "  time_this_iter_s: 21.566440105438232\n",
+      "  time_total_s: 394.9590709209442\n",
       "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
+      "    learn_throughput: 11083.274\n",
+      "    learn_time_ms: 14597.852\n",
+      "    sample_throughput: 23126.733\n",
+      "    sample_time_ms: 6995.887\n",
+      "    update_time_ms: 33.651\n",
+      "  timestamp: 1602490991\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     18 |          394.959 | 2912256 |  242.988 |              290.414 |              118.596 |            822.951 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3450.849694952856\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-32\n",
       "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 822.1293340671436\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 243.76256789135152\n",
+      "  episode_reward_min: 118.59595959595967\n",
       "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
+      "        entropy: 0.8463053901990255\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
+      "        kl: 0.005816654340984921\n",
       "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.008370639804828292\n",
+      "        total_loss: 9.871557076772055\n",
+      "        vf_explained_var: 0.9790952801704407\n",
+      "        vf_loss: 9.879769563674927\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
+      "    cpu_util_percent: 29.973076923076924\n",
+      "    gpu_util_percent0: 0.4196153846153846\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
+      "    mean_action_processing_ms: 0.15201376411298773\n",
+      "    mean_env_wait_ms: 1.1989255429744285\n",
+      "    mean_inference_ms: 4.61002629957187\n",
+      "    mean_raw_obs_processing_ms: 0.39400633263886187\n",
+      "  time_since_restore: 416.5034601688385\n",
+      "  time_this_iter_s: 21.544389247894287\n",
+      "  time_total_s: 416.5034601688385\n",
       "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
+      "    learn_throughput: 11104.878\n",
+      "    learn_time_ms: 14569.453\n",
+      "    sample_throughput: 23182.323\n",
+      "    sample_time_ms: 6979.111\n",
+      "    update_time_ms: 32.143\n",
+      "  timestamp: 1602491012\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     19 |          416.503 | 3074048 |  243.763 |              290.414 |              118.596 |            822.129 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3444.7242281527997\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-23-54\n",
       "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  episode_len_mean: 820.728051948052\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 244.5843499934408\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 216\n",
+      "  episodes_total: 3850\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -6283,80 +6584,80 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
+      "        entropy: 0.8126419484615326\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
+      "        kl: 0.005857201875187457\n",
       "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.00785230855884341\n",
+      "        total_loss: 12.330925305684408\n",
+      "        vf_explained_var: 0.9810908436775208\n",
+      "        vf_loss: 12.338598330815634\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
+      "    cpu_util_percent: 30.684\n",
+      "    gpu_util_percent0: 0.3696\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.756\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
+      "    mean_action_processing_ms: 0.15182597036787565\n",
+      "    mean_env_wait_ms: 1.1998648566925316\n",
+      "    mean_inference_ms: 4.59769219767983\n",
+      "    mean_raw_obs_processing_ms: 0.3933754930031549\n",
+      "  time_since_restore: 437.9918293952942\n",
+      "  time_this_iter_s: 21.48836922645569\n",
+      "  time_total_s: 437.9918293952942\n",
       "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
+      "    learn_throughput: 11114.896\n",
+      "    learn_time_ms: 14556.322\n",
+      "    sample_throughput: 23172.677\n",
+      "    sample_time_ms: 6982.016\n",
+      "    update_time_ms: 32.369\n",
+      "  timestamp: 1602491034\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     20 |          437.992 | 3235840 |  244.584 |              290.414 |              118.596 |            820.728 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3437.690441176471\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-24-16\n",
       "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  episode_len_mean: 819.2585199610517\n",
+      "  episode_reward_max: 290.4141414141415\n",
+      "  episode_reward_mean: 245.53567072870865\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 258\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -6365,71 +6666,19190 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
+      "        entropy: 0.7962117195129395\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
+      "        kl: 0.004699128757541378\n",
       "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.007990811747731641\n",
+      "        total_loss: 10.702264308929443\n",
+      "        vf_explained_var: 0.9830734729766846\n",
+      "        vf_loss: 10.710183302561441\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
+      "    cpu_util_percent: 28.366666666666667\n",
+      "    gpu_util_percent0: 0.29074074074074074\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 24878\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
+      "    mean_action_processing_ms: 0.15161483382226207\n",
+      "    mean_env_wait_ms: 1.2008228195208275\n",
+      "    mean_inference_ms: 4.584031516371675\n",
+      "    mean_raw_obs_processing_ms: 0.392688806021127\n",
+      "  time_since_restore: 459.91959524154663\n",
+      "  time_this_iter_s: 21.92776584625244\n",
+      "  time_total_s: 459.91959524154663\n",
       "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
+      "    learn_throughput: 11108.902\n",
+      "    learn_time_ms: 14564.176\n",
+      "    sample_throughput: 23146.475\n",
+      "    sample_time_ms: 6989.919\n",
+      "    update_time_ms: 31.574\n",
+      "  timestamp: 1602491056\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 39cc5_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     21 |           459.92 | 3397632 |  245.536 |              290.414 |              118.596 |            819.259 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3433.871165644172\n",
+      "    time_step_min: 3141\n",
+      "  date: 2020-10-12_08-24-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.1823722456634\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 246.1614527838156\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7922417124112447\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006179819426809748\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010333442517245809\n",
+      "        total_loss: 7.185657620429993\n",
+      "        vf_explained_var: 0.9850761890411377\n",
+      "        vf_loss: 7.1960781415303545\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.17307692307692\n",
+      "    gpu_util_percent0: 0.41423076923076924\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15149682416537705\n",
+      "    mean_env_wait_ms: 1.201374445162289\n",
+      "    mean_inference_ms: 4.576403214104389\n",
+      "    mean_raw_obs_processing_ms: 0.39230323446183507\n",
+      "  time_since_restore: 481.6516396999359\n",
+      "  time_this_iter_s: 21.732044458389282\n",
+      "  time_total_s: 481.6516396999359\n",
+      "  timers:\n",
+      "    learn_throughput: 11106.817\n",
+      "    learn_time_ms: 14566.909\n",
+      "    sample_throughput: 23172.025\n",
+      "    sample_time_ms: 6982.212\n",
+      "    update_time_ms: 31.216\n",
+      "  timestamp: 1602491078\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     22 |          481.652 | 3559424 |  246.161 |              293.899 |              118.596 |            818.182 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3429.85662349466\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.115601715963\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 246.75540457635734\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 4429\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7696222414573034\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006637000245973468\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008142252181035778\n",
+      "        total_loss: 9.046889623006185\n",
+      "        vf_explained_var: 0.9829367995262146\n",
+      "        vf_loss: 9.055085023244223\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.426923076923078\n",
+      "    gpu_util_percent0: 0.32230769230769235\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15138571915254828\n",
+      "    mean_env_wait_ms: 1.2019350771701267\n",
+      "    mean_inference_ms: 4.569002703077179\n",
+      "    mean_raw_obs_processing_ms: 0.3919233349017119\n",
+      "  time_since_restore: 503.2853772640228\n",
+      "  time_this_iter_s: 21.633737564086914\n",
+      "  time_total_s: 503.2853772640228\n",
+      "  timers:\n",
+      "    learn_throughput: 11104.524\n",
+      "    learn_time_ms: 14569.917\n",
+      "    sample_throughput: 23231.381\n",
+      "    sample_time_ms: 6964.373\n",
+      "    update_time_ms: 29.524\n",
+      "  timestamp: 1602491100\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     23 |          503.285 | 3721216 |  246.755 |              293.899 |              118.596 |            817.116 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3423.16099532114\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.1300211416491\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 247.74651376342703\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 301\n",
+      "  episodes_total: 4730\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7392598738272985\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005826210797143479\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009122005936660571\n",
+      "        total_loss: 10.013187249501547\n",
+      "        vf_explained_var: 0.9857361912727356\n",
+      "        vf_loss: 10.022387663523356\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.756\n",
+      "    gpu_util_percent0: 0.36560000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7640000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15118670580087262\n",
+      "    mean_env_wait_ms: 1.2029626221917573\n",
+      "    mean_inference_ms: 4.556226465372887\n",
+      "    mean_raw_obs_processing_ms: 0.391288705553902\n",
+      "  time_since_restore: 524.8132407665253\n",
+      "  time_this_iter_s: 21.52786350250244\n",
+      "  time_total_s: 524.8132407665253\n",
+      "  timers:\n",
+      "    learn_throughput: 11072.325\n",
+      "    learn_time_ms: 14612.288\n",
+      "    sample_throughput: 23276.561\n",
+      "    sample_time_ms: 6950.855\n",
+      "    update_time_ms: 29.333\n",
+      "  timestamp: 1602491121\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     24 |          524.813 | 3883008 |  247.747 |              293.899 |              118.596 |             815.13 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3419.282751540041\n",
+      "    time_step_min: 3135\n",
+      "  date: 2020-10-12_08-25-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.100653327889\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 248.32132678355623\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 168\n",
+      "  episodes_total: 4898\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7336608171463013\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006113760716592272\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009550909734874343\n",
+      "        total_loss: 6.576909343401591\n",
+      "        vf_explained_var: 0.9865676760673523\n",
+      "        vf_loss: 6.58652130762736\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.73076923076923\n",
+      "    gpu_util_percent0: 0.32346153846153847\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15108537890214208\n",
+      "    mean_env_wait_ms: 1.2034634470979062\n",
+      "    mean_inference_ms: 4.549592354974739\n",
+      "    mean_raw_obs_processing_ms: 0.3909562190733837\n",
+      "  time_since_restore: 546.2893211841583\n",
+      "  time_this_iter_s: 21.476080417633057\n",
+      "  time_total_s: 546.2893211841583\n",
+      "  timers:\n",
+      "    learn_throughput: 11081.383\n",
+      "    learn_time_ms: 14600.343\n",
+      "    sample_throughput: 23282.075\n",
+      "    sample_time_ms: 6949.209\n",
+      "    update_time_ms: 27.926\n",
+      "  timestamp: 1602491143\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     25 |          546.289 | 4044800 |  248.321 |              293.899 |              118.596 |            814.101 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3415.8178564326904\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.1633379473997\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 248.8292395978771\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 5057\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7295501778523127\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005874564366725584\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008493003813782707\n",
+      "        total_loss: 7.950014750162761\n",
+      "        vf_explained_var: 0.983363151550293\n",
+      "        vf_loss: 7.958578626314799\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.542307692307695\n",
+      "    gpu_util_percent0: 0.3719230769230769\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7884615384615383\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1509959980043755\n",
+      "    mean_env_wait_ms: 1.2039438535670208\n",
+      "    mean_inference_ms: 4.543643745260567\n",
+      "    mean_raw_obs_processing_ms: 0.39065745577815003\n",
+      "  time_since_restore: 567.7602591514587\n",
+      "  time_this_iter_s: 21.470937967300415\n",
+      "  time_total_s: 567.7602591514587\n",
+      "  timers:\n",
+      "    learn_throughput: 11102.74\n",
+      "    learn_time_ms: 14572.258\n",
+      "    sample_throughput: 23346.655\n",
+      "    sample_time_ms: 6929.986\n",
+      "    update_time_ms: 25.614\n",
+      "  timestamp: 1602491165\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     26 |           567.76 | 4206592 |  248.829 |              293.899 |              118.596 |            813.163 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3409.7600677455775\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.4490827405466\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 249.6970396590389\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 285\n",
+      "  episodes_total: 5342\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6967413127422333\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006306514337969323\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009041692143606875\n",
+      "        total_loss: 9.368427356084188\n",
+      "        vf_explained_var: 0.9863912463188171\n",
+      "        vf_loss: 9.377501646677652\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.844\n",
+      "    gpu_util_percent0: 0.3772\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7599999999999993\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15084418754751167\n",
+      "    mean_env_wait_ms: 1.204832560302368\n",
+      "    mean_inference_ms: 4.533798639536211\n",
+      "    mean_raw_obs_processing_ms: 0.3901641161662921\n",
+      "  time_since_restore: 589.397045135498\n",
+      "  time_this_iter_s: 21.636785984039307\n",
+      "  time_total_s: 589.397045135498\n",
+      "  timers:\n",
+      "    learn_throughput: 11092.25\n",
+      "    learn_time_ms: 14586.04\n",
+      "    sample_throughput: 23395.212\n",
+      "    sample_time_ms: 6915.603\n",
+      "    update_time_ms: 27.344\n",
+      "  timestamp: 1602491186\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | RUNNING  | 172.17.0.4:24878 |     27 |          589.397 | 4368384 |  249.697 |              293.899 |              118.596 |            811.449 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_39cc5_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4134\n",
+      "    time_step_mean: 3405.737549981825\n",
+      "    time_step_min: 3128\n",
+      "  date: 2020-10-12_08-26-48\n",
+      "  done: true\n",
+      "  episode_len_mean: 810.4667269439421\n",
+      "  episode_reward_max: 293.89898989899\n",
+      "  episode_reward_mean: 250.2915045573273\n",
+      "  episode_reward_min: 118.59595959595967\n",
+      "  episodes_this_iter: 188\n",
+      "  episodes_total: 5530\n",
+      "  experiment_id: e3702cbf86eb4d62a583bd4b338bf2ac\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.675686240196228\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005107206680501501\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00786691315685554\n",
+      "        total_loss: 7.04692538579305\n",
+      "        vf_explained_var: 0.9860422015190125\n",
+      "        vf_loss: 7.054874618848165\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.199999999999996\n",
+      "    gpu_util_percent0: 0.33692307692307694\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.780769230769231\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 24878\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15074896499452803\n",
+      "    mean_env_wait_ms: 1.2053334662527855\n",
+      "    mean_inference_ms: 4.527474043839373\n",
+      "    mean_raw_obs_processing_ms: 0.3898601834278142\n",
+      "  time_since_restore: 610.9207043647766\n",
+      "  time_this_iter_s: 21.523659229278564\n",
+      "  time_total_s: 610.9207043647766\n",
+      "  timers:\n",
+      "    learn_throughput: 11086.727\n",
+      "    learn_time_ms: 14593.306\n",
+      "    sample_throughput: 23437.181\n",
+      "    sample_time_ms: 6903.219\n",
+      "    update_time_ms: 27.218\n",
+      "  timestamp: 1602491208\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 39cc5_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_39cc5_00000 | TERMINATED |       |     28 |          610.921 | 4530176 |  250.292 |              293.899 |              118.596 |            810.467 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 24616\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_081622-6nvy6bhw/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_081622-6nvy6bhw/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3128\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602491208\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4134\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3405.73755\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 118.59596\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 250.2915\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5530\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mazure-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/6nvy6bhw\u001b[0m\n",
+      "2020-10-12 08:26:56,087 - wandb.wandb_agent - INFO - Cleaning up finished run: 6nvy6bhw\n",
+      "2020-10-12 08:26:56,400 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:26:56,400 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.0005\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 08:26:56,403 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:27:01,420 - wandb.wandb_agent - INFO - Running runs: ['q0jbd5ol']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhopeful-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/q0jbd5ol\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_082658-q0jbd5ol\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:27:02,632\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=56858)\u001b[0m 2020-10-12 08:27:05,402\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=56824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56851)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56851)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56801)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56801)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56794)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56794)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56803)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56803)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56745)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56745)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=56796)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=56796)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-27-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1851047078768413\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.004071502441850801\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00785889983914482\n",
+      "        total_loss: 507.07567087809247\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.634375\n",
+      "    gpu_util_percent0: 0.26875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5718750000000004\n",
+      "    vram_util_percent0: 0.08698036241390619\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16685353344183862\n",
+      "    mean_env_wait_ms: 1.1679478021417367\n",
+      "    mean_inference_ms: 5.432594445944936\n",
+      "    mean_raw_obs_processing_ms: 0.4397812019199749\n",
+      "  time_since_restore: 27.773663997650146\n",
+      "  time_this_iter_s: 27.773663997650146\n",
+      "  time_total_s: 27.773663997650146\n",
+      "  timers:\n",
+      "    learn_throughput: 8530.856\n",
+      "    learn_time_ms: 18965.507\n",
+      "    sample_throughput: 18503.321\n",
+      "    sample_time_ms: 8743.944\n",
+      "    update_time_ms: 28.446\n",
+      "  timestamp: 1602491258\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      1 |          27.7737 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3614.4305555555557\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-28-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 890.8607594936709\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.6365234624726\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1561074058214824\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007923512797181806\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010965243893830726\n",
+      "        total_loss: 127.46906661987305\n",
+      "        vf_explained_var: 0.8076093792915344\n",
+      "        vf_loss: 127.47981770833333\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.76774193548387\n",
+      "    gpu_util_percent0: 0.25387096774193546\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7483870967741932\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16356765459772646\n",
+      "    mean_env_wait_ms: 1.1668320901532692\n",
+      "    mean_inference_ms: 5.292065685229201\n",
+      "    mean_raw_obs_processing_ms: 0.43211279746919895\n",
+      "  time_since_restore: 54.347506284713745\n",
+      "  time_this_iter_s: 26.5738422870636\n",
+      "  time_total_s: 54.347506284713745\n",
+      "  timers:\n",
+      "    learn_throughput: 8594.957\n",
+      "    learn_time_ms: 18824.062\n",
+      "    sample_throughput: 19561.031\n",
+      "    sample_time_ms: 8271.139\n",
+      "    update_time_ms: 36.678\n",
+      "  timestamp: 1602491285\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      2 |          54.3475 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3601.8677130044844\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-28-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.132911392405\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 219.87009333844756\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1456398169199626\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008224547879459957\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013529085864623388\n",
+      "        total_loss: 61.275455474853516\n",
+      "        vf_explained_var: 0.8916645646095276\n",
+      "        vf_loss: 61.28873507181803\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.589999999999996\n",
+      "    gpu_util_percent0: 0.4183333333333332\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16107501960595214\n",
+      "    mean_env_wait_ms: 1.1671126318189669\n",
+      "    mean_inference_ms: 5.153129934027859\n",
+      "    mean_raw_obs_processing_ms: 0.42528733449335054\n",
+      "  time_since_restore: 80.20835757255554\n",
+      "  time_this_iter_s: 25.860851287841797\n",
+      "  time_total_s: 80.20835757255554\n",
+      "  timers:\n",
+      "    learn_throughput: 8612.207\n",
+      "    learn_time_ms: 18786.357\n",
+      "    sample_throughput: 20559.193\n",
+      "    sample_time_ms: 7869.57\n",
+      "    update_time_ms: 35.435\n",
+      "  timestamp: 1602491311\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      3 |          80.2084 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3596.0099337748343\n",
+      "    time_step_min: 3231\n",
+      "  date: 2020-10-12_08-28-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 878.7689873417721\n",
+      "  episode_reward_max: 276.47474747474763\n",
+      "  episode_reward_mean: 220.6047340493541\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1263898611068726\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008100568510902425\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013406771836647144\n",
+      "        total_loss: 47.16934140523275\n",
+      "        vf_explained_var: 0.9198758602142334\n",
+      "        vf_loss: 47.18250052134196\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.160000000000004\n",
+      "    gpu_util_percent0: 0.3093333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15927669885835546\n",
+      "    mean_env_wait_ms: 1.1684658072392184\n",
+      "    mean_inference_ms: 5.047141820534734\n",
+      "    mean_raw_obs_processing_ms: 0.41967187543535894\n",
+      "  time_since_restore: 105.9318573474884\n",
+      "  time_this_iter_s: 25.72349977493286\n",
+      "  time_total_s: 105.9318573474884\n",
+      "  timers:\n",
+      "    learn_throughput: 8619.167\n",
+      "    learn_time_ms: 18771.187\n",
+      "    sample_throughput: 21195.516\n",
+      "    sample_time_ms: 7633.313\n",
+      "    update_time_ms: 31.747\n",
+      "  timestamp: 1602491336\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      4 |          105.932 | 647168 |  220.605 |              276.475 |              145.717 |            878.769 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3581.6985583224114\n",
+      "    time_step_min: 3204\n",
+      "  date: 2020-10-12_08-29-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 872.4867256637168\n",
+      "  episode_reward_max: 280.5656565656565\n",
+      "  episode_reward_mean: 222.48133675567283\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 791\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0873714486757915\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006956188706681132\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011262792395427823\n",
+      "        total_loss: 34.19948164621989\n",
+      "        vf_explained_var: 0.9459590911865234\n",
+      "        vf_loss: 34.2105925877889\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.229032258064517\n",
+      "    gpu_util_percent0: 0.36677419354838714\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15788454068385543\n",
+      "    mean_env_wait_ms: 1.1707007939199836\n",
+      "    mean_inference_ms: 4.964668926523751\n",
+      "    mean_raw_obs_processing_ms: 0.4151380720341482\n",
+      "  time_since_restore: 131.79730200767517\n",
+      "  time_this_iter_s: 25.865444660186768\n",
+      "  time_total_s: 131.79730200767517\n",
+      "  timers:\n",
+      "    learn_throughput: 8618.29\n",
+      "    learn_time_ms: 18773.099\n",
+      "    sample_throughput: 21581.782\n",
+      "    sample_time_ms: 7496.693\n",
+      "    update_time_ms: 29.37\n",
+      "  timestamp: 1602491362\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      5 |          131.797 | 808960 |  222.481 |              280.566 |              145.717 |            872.487 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3564.887755102041\n",
+      "    time_step_min: 3204\n",
+      "  date: 2020-10-12_08-29-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 860.6943942133815\n",
+      "  episode_reward_max: 280.5656565656565\n",
+      "  episode_reward_mean: 225.7112809834327\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 315\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0886386533578236\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007588425030310948\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01092883839737624\n",
+      "        total_loss: 30.730765342712402\n",
+      "        vf_explained_var: 0.9611188769340515\n",
+      "        vf_loss: 30.741480032602947\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.956666666666667\n",
+      "    gpu_util_percent0: 0.405\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7566666666666664\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15599735271528273\n",
+      "    mean_env_wait_ms: 1.1757357125865684\n",
+      "    mean_inference_ms: 4.853323471533123\n",
+      "    mean_raw_obs_processing_ms: 0.40931598209773395\n",
+      "  time_since_restore: 157.56571769714355\n",
+      "  time_this_iter_s: 25.768415689468384\n",
+      "  time_total_s: 157.56571769714355\n",
+      "  timers:\n",
+      "    learn_throughput: 8617.26\n",
+      "    learn_time_ms: 18775.341\n",
+      "    sample_throughput: 21904.527\n",
+      "    sample_time_ms: 7386.236\n",
+      "    update_time_ms: 29.208\n",
+      "  timestamp: 1602491388\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      6 |          157.566 | 970752 |  225.711 |              280.566 |              145.717 |            860.694 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3552.704692556634\n",
+      "    time_step_min: 3179\n",
+      "  date: 2020-10-12_08-30-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 855.0387658227849\n",
+      "  episode_reward_max: 284.35353535353545\n",
+      "  episode_reward_mean: 227.46978487405684\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0706470410029094\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007387861027382314\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013462736414415607\n",
+      "        total_loss: 19.742233912150066\n",
+      "        vf_explained_var: 0.9632093906402588\n",
+      "        vf_loss: 19.75549300511678\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.49666666666667\n",
+      "    gpu_util_percent0: 0.29433333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15530080693050297\n",
+      "    mean_env_wait_ms: 1.1778749831186706\n",
+      "    mean_inference_ms: 4.812541661631387\n",
+      "    mean_raw_obs_processing_ms: 0.40715848313222897\n",
+      "  time_since_restore: 183.37474465370178\n",
+      "  time_this_iter_s: 25.809026956558228\n",
+      "  time_total_s: 183.37474465370178\n",
+      "  timers:\n",
+      "    learn_throughput: 8610.851\n",
+      "    learn_time_ms: 18789.315\n",
+      "    sample_throughput: 22137.639\n",
+      "    sample_time_ms: 7308.458\n",
+      "    update_time_ms: 29.392\n",
+      "  timestamp: 1602491414\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      7 |          183.375 | 1132544 |   227.47 |              284.354 |              145.717 |            855.039 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3540.6398852223815\n",
+      "    time_step_min: 3179\n",
+      "  date: 2020-10-12_08-30-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 850.7552742616034\n",
+      "  episode_reward_max: 284.35353535353545\n",
+      "  episode_reward_mean: 229.23441162681647\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0475670397281647\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007399068369219701\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009183195322596779\n",
+      "        total_loss: 16.652963479359943\n",
+      "        vf_explained_var: 0.9667003154754639\n",
+      "        vf_loss: 16.661930561065674\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.59\n",
+      "    gpu_util_percent0: 0.3423333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7866666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1546926297232668\n",
+      "    mean_env_wait_ms: 1.179701493934929\n",
+      "    mean_inference_ms: 4.776937228752141\n",
+      "    mean_raw_obs_processing_ms: 0.40521504870584935\n",
+      "  time_since_restore: 209.05934143066406\n",
+      "  time_this_iter_s: 25.68459677696228\n",
+      "  time_total_s: 209.05934143066406\n",
+      "  timers:\n",
+      "    learn_throughput: 8621.673\n",
+      "    learn_time_ms: 18765.73\n",
+      "    sample_throughput: 22252.654\n",
+      "    sample_time_ms: 7270.683\n",
+      "    update_time_ms: 28.796\n",
+      "  timestamp: 1602491440\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      8 |          209.059 | 1294336 |  229.234 |              284.354 |              145.717 |            850.755 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3526.8721374045804\n",
+      "    time_step_min: 3179\n",
+      "  date: 2020-10-12_08-31-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.9875\n",
+      "  episode_reward_max: 285.7171717171716\n",
+      "  episode_reward_mean: 231.28724747474732\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 178\n",
+      "  episodes_total: 1600\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9999773452679316\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007928823702968657\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011458211791856835\n",
+      "        total_loss: 16.58501172065735\n",
+      "        vf_explained_var: 0.9729644656181335\n",
+      "        vf_loss: 16.596176783243816\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.06333333333334\n",
+      "    gpu_util_percent0: 0.36433333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1541003441512452\n",
+      "    mean_env_wait_ms: 1.1818521863514695\n",
+      "    mean_inference_ms: 4.742016009185261\n",
+      "    mean_raw_obs_processing_ms: 0.40328170614028436\n",
+      "  time_since_restore: 234.73203349113464\n",
+      "  time_this_iter_s: 25.67269206047058\n",
+      "  time_total_s: 234.73203349113464\n",
+      "  timers:\n",
+      "    learn_throughput: 8623.109\n",
+      "    learn_time_ms: 18762.607\n",
+      "    sample_throughput: 22401.496\n",
+      "    sample_time_ms: 7222.375\n",
+      "    update_time_ms: 29.742\n",
+      "  timestamp: 1602491466\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |      9 |          234.732 | 1456128 |  231.287 |              285.717 |              145.717 |            845.987 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3508.0337259100643\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-31-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.0052742616034\n",
+      "  episode_reward_max: 285.7171717171716\n",
+      "  episode_reward_mean: 234.27066551591852\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 296\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9948871235052744\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006681857941051324\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011002168253374597\n",
+      "        total_loss: 15.828110535939535\n",
+      "        vf_explained_var: 0.9757750630378723\n",
+      "        vf_loss: 15.838941733042398\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.21666666666666\n",
+      "    gpu_util_percent0: 0.2816666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7633333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15330418781933425\n",
+      "    mean_env_wait_ms: 1.185126611501359\n",
+      "    mean_inference_ms: 4.695157746382897\n",
+      "    mean_raw_obs_processing_ms: 0.40072338771829985\n",
+      "  time_since_restore: 260.7745864391327\n",
+      "  time_this_iter_s: 26.042552947998047\n",
+      "  time_total_s: 260.7745864391327\n",
+      "  timers:\n",
+      "    learn_throughput: 8621.363\n",
+      "    learn_time_ms: 18766.406\n",
+      "    sample_throughput: 22420.449\n",
+      "    sample_time_ms: 7216.269\n",
+      "    update_time_ms: 29.275\n",
+      "  timestamp: 1602491492\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     10 |          260.775 | 1617920 |  234.271 |              285.717 |              145.717 |            839.005 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3499.19842053307\n",
+      "    time_step_min: 3171\n",
+      "  date: 2020-10-12_08-31-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 835.7263875365142\n",
+      "  episode_reward_max: 294.20202020201987\n",
+      "  episode_reward_mean: 235.87525203347977\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.975288137793541\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007294710182274382\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012727556153549813\n",
+      "        total_loss: 11.962000767389933\n",
+      "        vf_explained_var: 0.9750909805297852\n",
+      "        vf_loss: 11.974486589431763\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.1448275862069\n",
+      "    gpu_util_percent0: 0.3741379310344828\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.775862068965517\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15294883238989318\n",
+      "    mean_env_wait_ms: 1.1866395067793458\n",
+      "    mean_inference_ms: 4.674182125426418\n",
+      "    mean_raw_obs_processing_ms: 0.3995715385731446\n",
+      "  time_since_restore: 286.4323949813843\n",
+      "  time_this_iter_s: 25.657808542251587\n",
+      "  time_total_s: 286.4323949813843\n",
+      "  timers:\n",
+      "    learn_throughput: 8628.498\n",
+      "    learn_time_ms: 18750.889\n",
+      "    sample_throughput: 23057.659\n",
+      "    sample_time_ms: 7016.844\n",
+      "    update_time_ms: 30.392\n",
+      "  timestamp: 1602491518\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     11 |          286.432 | 1779712 |  235.875 |              294.202 |              145.717 |            835.726 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3490.923534798535\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_08-32-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.6595840867993\n",
+      "  episode_reward_max: 294.20202020201987\n",
+      "  episode_reward_mean: 237.1319752680511\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9521185209353765\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006661186693236232\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013089668517447231\n",
+      "        total_loss: 12.603836615880331\n",
+      "        vf_explained_var: 0.9737562537193298\n",
+      "        vf_loss: 12.61673672993978\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.0\n",
+      "    gpu_util_percent0: 0.2946666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7733333333333334\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15262553899195727\n",
+      "    mean_env_wait_ms: 1.1880384910499628\n",
+      "    mean_inference_ms: 4.655044930723983\n",
+      "    mean_raw_obs_processing_ms: 0.3984844650888046\n",
+      "  time_since_restore: 312.2770745754242\n",
+      "  time_this_iter_s: 25.844679594039917\n",
+      "  time_total_s: 312.2770745754242\n",
+      "  timers:\n",
+      "    learn_throughput: 8616.967\n",
+      "    learn_time_ms: 18775.98\n",
+      "    sample_throughput: 23381.461\n",
+      "    sample_time_ms: 6919.67\n",
+      "    update_time_ms: 28.839\n",
+      "  timestamp: 1602491544\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     12 |          312.277 | 1941504 |  237.132 |              294.202 |              145.717 |             832.66 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3477.030998389694\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_08-32-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.7671178343949\n",
+      "  episode_reward_max: 294.20202020201987\n",
+      "  episode_reward_mean: 239.24816235604442\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 300\n",
+      "  episodes_total: 2512\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9211943199237188\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0069003046955913305\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011187698284629732\n",
+      "        total_loss: 15.527917702992758\n",
+      "        vf_explained_var: 0.9792836308479309\n",
+      "        vf_loss: 15.538876056671143\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.96000000000001\n",
+      "    gpu_util_percent0: 0.30400000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15209830857560627\n",
+      "    mean_env_wait_ms: 1.1906489993121385\n",
+      "    mean_inference_ms: 4.623501466732292\n",
+      "    mean_raw_obs_processing_ms: 0.39672878573513676\n",
+      "  time_since_restore: 337.9526643753052\n",
+      "  time_this_iter_s: 25.67558979988098\n",
+      "  time_total_s: 337.9526643753052\n",
+      "  timers:\n",
+      "    learn_throughput: 8613.011\n",
+      "    learn_time_ms: 18784.604\n",
+      "    sample_throughput: 23471.819\n",
+      "    sample_time_ms: 6893.032\n",
+      "    update_time_ms: 27.674\n",
+      "  timestamp: 1602491569\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     13 |          337.953 | 2103296 |  239.248 |              294.202 |              145.717 |            827.767 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3468.7953348382243\n",
+      "    time_step_min: 3151\n",
+      "  date: 2020-10-12_08-33-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.1623231571109\n",
+      "  episode_reward_max: 294.20202020201987\n",
+      "  episode_reward_mean: 240.4743300465563\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 174\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9143994450569153\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0060155229875817895\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012139652118397256\n",
+      "        total_loss: 10.54153060913086\n",
+      "        vf_explained_var: 0.979185163974762\n",
+      "        vf_loss: 10.553526004155477\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.93666666666667\n",
+      "    gpu_util_percent0: 0.36566666666666675\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1518304432787989\n",
+      "    mean_env_wait_ms: 1.1919773745862008\n",
+      "    mean_inference_ms: 4.607832873092171\n",
+      "    mean_raw_obs_processing_ms: 0.39585667669054664\n",
+      "  time_since_restore: 363.7148759365082\n",
+      "  time_this_iter_s: 25.762211561203003\n",
+      "  time_total_s: 363.7148759365082\n",
+      "  timers:\n",
+      "    learn_throughput: 8609.094\n",
+      "    learn_time_ms: 18793.15\n",
+      "    sample_throughput: 23519.949\n",
+      "    sample_time_ms: 6878.926\n",
+      "    update_time_ms: 28.481\n",
+      "  timestamp: 1602491595\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     14 |          363.715 | 2265088 |  240.474 |              294.202 |              145.717 |            825.162 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3462.4602272727275\n",
+      "    time_step_min: 3131\n",
+      "  date: 2020-10-12_08-33-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 822.9542897327707\n",
+      "  episode_reward_max: 294.20202020201987\n",
+      "  episode_reward_mean: 241.45540851553497\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9019962549209595\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006133316123547654\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012229806568939239\n",
+      "        total_loss: 9.555021127065023\n",
+      "        vf_explained_var: 0.9795403480529785\n",
+      "        vf_loss: 9.567088762919107\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.172413793103452\n",
+      "    gpu_util_percent0: 0.37551724137931036\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.786206896551724\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.151607687655734\n",
+      "    mean_env_wait_ms: 1.193090286434833\n",
+      "    mean_inference_ms: 4.5946463140143115\n",
+      "    mean_raw_obs_processing_ms: 0.3950969402364921\n",
+      "  time_since_restore: 389.2473704814911\n",
+      "  time_this_iter_s: 25.53249454498291\n",
+      "  time_total_s: 389.2473704814911\n",
+      "  timers:\n",
+      "    learn_throughput: 8613.956\n",
+      "    learn_time_ms: 18782.543\n",
+      "    sample_throughput: 23577.838\n",
+      "    sample_time_ms: 6862.037\n",
+      "    update_time_ms: 28.54\n",
+      "  timestamp: 1602491621\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     15 |          389.247 | 2426880 |  241.455 |              294.202 |              145.717 |            822.954 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3453.8821989528797\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-34-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.9792477302204\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 242.75903981448718\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 240\n",
+      "  episodes_total: 3084\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8659086326758066\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00634678197093308\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012134946203635385\n",
+      "        total_loss: 13.195513248443604\n",
+      "        vf_explained_var: 0.980156421661377\n",
+      "        vf_loss: 13.207446098327637\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.230000000000004\n",
+      "    gpu_util_percent0: 0.3093333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130438922280068\n",
+      "    mean_env_wait_ms: 1.1947834234298744\n",
+      "    mean_inference_ms: 4.576700910735796\n",
+      "    mean_raw_obs_processing_ms: 0.3940516625903479\n",
+      "  time_since_restore: 414.89031171798706\n",
+      "  time_this_iter_s: 25.64294123649597\n",
+      "  time_total_s: 414.89031171798706\n",
+      "  timers:\n",
+      "    learn_throughput: 8611.981\n",
+      "    learn_time_ms: 18786.851\n",
+      "    sample_throughput: 23612.567\n",
+      "    sample_time_ms: 6851.944\n",
+      "    update_time_ms: 27.668\n",
+      "  timestamp: 1602491647\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     16 |           414.89 | 2588672 |  242.759 |              298.899 |              145.717 |            819.979 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3445.377811550152\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-34-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.4445449065702\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 243.9846110289147\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 234\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8606445689996084\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005582816433161497\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011729711521184072\n",
+      "        total_loss: 9.780861934026083\n",
+      "        vf_explained_var: 0.9827695488929749\n",
+      "        vf_loss: 9.792463779449463\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.09310344827587\n",
+      "    gpu_util_percent0: 0.32931034482758625\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7655172413793094\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15103882590583312\n",
+      "    mean_env_wait_ms: 1.1962458333454598\n",
+      "    mean_inference_ms: 4.560733127331646\n",
+      "    mean_raw_obs_processing_ms: 0.3931480643656643\n",
+      "  time_since_restore: 440.4795105457306\n",
+      "  time_this_iter_s: 25.58919882774353\n",
+      "  time_total_s: 440.4795105457306\n",
+      "  timers:\n",
+      "    learn_throughput: 8617.68\n",
+      "    learn_time_ms: 18774.427\n",
+      "    sample_throughput: 23645.985\n",
+      "    sample_time_ms: 6842.261\n",
+      "    update_time_ms: 28.37\n",
+      "  timestamp: 1602491672\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     17 |           440.48 | 2750464 |  243.985 |              298.899 |              145.717 |            817.445 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3440.181554524362\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-34-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.873417721519\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 244.73267194383405\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8570553759733835\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00693794801676025\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012595690621916825\n",
+      "        total_loss: 9.302302360534668\n",
+      "        vf_explained_var: 0.9800246357917786\n",
+      "        vf_loss: 9.314632733662924\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.483333333333334\n",
+      "    gpu_util_percent0: 0.32566666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15087560837473593\n",
+      "    mean_env_wait_ms: 1.1971604614135072\n",
+      "    mean_inference_ms: 4.550998984301916\n",
+      "    mean_raw_obs_processing_ms: 0.3925846015008058\n",
+      "  time_since_restore: 466.1001446247101\n",
+      "  time_this_iter_s: 25.620634078979492\n",
+      "  time_total_s: 466.1001446247101\n",
+      "  timers:\n",
+      "    learn_throughput: 8609.563\n",
+      "    learn_time_ms: 18792.127\n",
+      "    sample_throughput: 23733.558\n",
+      "    sample_time_ms: 6817.014\n",
+      "    update_time_ms: 28.365\n",
+      "  timestamp: 1602491698\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     18 |            466.1 | 2912256 |  244.733 |              298.899 |              145.717 |            815.873 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3435.160891089109\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-35-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.1853165938865\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 245.55176216311577\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 188\n",
+      "  episodes_total: 3664\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8260929683844248\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00627721450291574\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010709817167177485\n",
+      "        total_loss: 11.524338483810425\n",
+      "        vf_explained_var: 0.9801642894744873\n",
+      "        vf_loss: 11.534833749135336\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.67666666666667\n",
+      "    gpu_util_percent0: 0.3486666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15069873153236457\n",
+      "    mean_env_wait_ms: 1.1982064856230281\n",
+      "    mean_inference_ms: 4.5401690055796\n",
+      "    mean_raw_obs_processing_ms: 0.3919602176683018\n",
+      "  time_since_restore: 491.7349843978882\n",
+      "  time_this_iter_s: 25.6348397731781\n",
+      "  time_total_s: 491.7349843978882\n",
+      "  timers:\n",
+      "    learn_throughput: 8607.873\n",
+      "    learn_time_ms: 18795.816\n",
+      "    sample_throughput: 23758.107\n",
+      "    sample_time_ms: 6809.97\n",
+      "    update_time_ms: 27.774\n",
+      "  timestamp: 1602491724\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     19 |          491.735 | 3074048 |  245.552 |              298.899 |              145.717 |            814.185 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3428.4441611422744\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-35-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.0630379746835\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 246.60976857179378\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 286\n",
+      "  episodes_total: 3950\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8063790599505106\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00581474454763035\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010059737542178482\n",
+      "        total_loss: 10.378987232844034\n",
+      "        vf_explained_var: 0.9842923283576965\n",
+      "        vf_loss: 10.388868490854898\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.07241379310345\n",
+      "    gpu_util_percent0: 0.3334482758620689\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.772413793103448\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15045825954287506\n",
+      "    mean_env_wait_ms: 1.1998160099735846\n",
+      "    mean_inference_ms: 4.525558072261089\n",
+      "    mean_raw_obs_processing_ms: 0.39113303459812954\n",
+      "  time_since_restore: 517.4642984867096\n",
+      "  time_this_iter_s: 25.72931408882141\n",
+      "  time_total_s: 517.4642984867096\n",
+      "  timers:\n",
+      "    learn_throughput: 8607.09\n",
+      "    learn_time_ms: 18797.525\n",
+      "    sample_throughput: 23881.611\n",
+      "    sample_time_ms: 6774.752\n",
+      "    update_time_ms: 29.275\n",
+      "  timestamp: 1602491750\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     20 |          517.464 | 3235840 |   246.61 |              298.899 |              145.717 |            812.063 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3424.633333333333\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-36-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.1747809152872\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 247.171761431255\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8050975054502487\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006411496355819206\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0109325938198405\n",
+      "        total_loss: 8.397321462631226\n",
+      "        vf_explained_var: 0.9822394847869873\n",
+      "        vf_loss: 8.408015330632528\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.076666666666668\n",
+      "    gpu_util_percent0: 0.3436666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7866666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15033854121740725\n",
+      "    mean_env_wait_ms: 1.200601038893896\n",
+      "    mean_inference_ms: 4.518158834825987\n",
+      "    mean_raw_obs_processing_ms: 0.39071788216336256\n",
+      "  time_since_restore: 543.27952003479\n",
+      "  time_this_iter_s: 25.815221548080444\n",
+      "  time_total_s: 543.27952003479\n",
+      "  timers:\n",
+      "    learn_throughput: 8602.003\n",
+      "    learn_time_ms: 18808.644\n",
+      "    sample_throughput: 23862.737\n",
+      "    sample_time_ms: 6780.111\n",
+      "    update_time_ms: 28.171\n",
+      "  timestamp: 1602491776\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     21 |           543.28 | 3397632 |  247.172 |              298.899 |              145.717 |            811.175 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3421.5082547169814\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-36-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 810.3659793814433\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 247.6299262541061\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 4268\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7943403224150339\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006092905105712513\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012508889408006022\n",
+      "        total_loss: 10.069480101267496\n",
+      "        vf_explained_var: 0.9799533486366272\n",
+      "        vf_loss: 10.08177661895752\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.833333333333336\n",
+      "    gpu_util_percent0: 0.38999999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15022548822104212\n",
+      "    mean_env_wait_ms: 1.2013670024852496\n",
+      "    mean_inference_ms: 4.5111048698298655\n",
+      "    mean_raw_obs_processing_ms: 0.39031940877553956\n",
+      "  time_since_restore: 568.987156867981\n",
+      "  time_this_iter_s: 25.707636833190918\n",
+      "  time_total_s: 568.987156867981\n",
+      "  timers:\n",
+      "    learn_throughput: 8608.305\n",
+      "    learn_time_ms: 18794.874\n",
+      "    sample_throughput: 23897.151\n",
+      "    sample_time_ms: 6770.347\n",
+      "    update_time_ms: 29.144\n",
+      "  timestamp: 1602491802\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     22 |          568.987 | 3559424 |   247.63 |              298.899 |              145.717 |            810.366 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3415.407570422535\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-37-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 808.5879265091863\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 248.62850287653427\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 304\n",
+      "  episodes_total: 4572\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7644506990909576\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.005771325357879202\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009549629636846172\n",
+      "        total_loss: 10.615382512410482\n",
+      "        vf_explained_var: 0.9846494197845459\n",
+      "        vf_loss: 10.624737024307251\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.216666666666665\n",
+      "    gpu_util_percent0: 0.4233333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15002868087968005\n",
+      "    mean_env_wait_ms: 1.20278776735838\n",
+      "    mean_inference_ms: 4.498766578182944\n",
+      "    mean_raw_obs_processing_ms: 0.3896344622864878\n",
+      "  time_since_restore: 595.0535960197449\n",
+      "  time_this_iter_s: 26.066439151763916\n",
+      "  time_total_s: 595.0535960197449\n",
+      "  timers:\n",
+      "    learn_throughput: 8596.051\n",
+      "    learn_time_ms: 18821.665\n",
+      "    sample_throughput: 23867.567\n",
+      "    sample_time_ms: 6778.739\n",
+      "    update_time_ms: 32.329\n",
+      "  timestamp: 1602491828\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | RUNNING  | 172.17.0.4:56858 |     23 |          595.054 | 3721216 |  248.629 |              298.899 |              145.717 |            808.588 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b50e2_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3412.3495331069607\n",
+      "    time_step_min: 3083\n",
+      "  date: 2020-10-12_08-37-34\n",
+      "  done: true\n",
+      "  episode_len_mean: 807.6881856540084\n",
+      "  episode_reward_max: 298.8989898989898\n",
+      "  episode_reward_mean: 249.11699271192933\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 168\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 159fbc592ed142b4b7741b1a94933f93\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7512289037307104\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006618439607943098\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011942399355272451\n",
+      "        total_loss: 7.106495062510173\n",
+      "        vf_explained_var: 0.9852812886238098\n",
+      "        vf_loss: 7.118151148160298\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.51379310344828\n",
+      "    gpu_util_percent0: 0.28172413793103457\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7896551724137932\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 56858\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14993006395150182\n",
+      "    mean_env_wait_ms: 1.2035070901630875\n",
+      "    mean_inference_ms: 4.492612595979025\n",
+      "    mean_raw_obs_processing_ms: 0.3892858976989751\n",
+      "  time_since_restore: 620.7819950580597\n",
+      "  time_this_iter_s: 25.72839903831482\n",
+      "  time_total_s: 620.7819950580597\n",
+      "  timers:\n",
+      "    learn_throughput: 8597.125\n",
+      "    learn_time_ms: 18819.315\n",
+      "    sample_throughput: 23842.836\n",
+      "    sample_time_ms: 6785.77\n",
+      "    update_time_ms: 31.534\n",
+      "  timestamp: 1602491854\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: b50e2_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | TERMINATED |       |     24 |          620.782 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b50e2_00000 | TERMINATED |       |     24 |          620.782 | 3883008 |  249.117 |              298.899 |              145.717 |            807.688 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 56597\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_082658-q0jbd5ol/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_082658-q0jbd5ol/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3083\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 636\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602491854\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4054\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3412.34953\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 145.71717\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 249.11699\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4740\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mhopeful-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/q0jbd5ol\u001b[0m\n",
+      "2020-10-12 08:37:42,989 - wandb.wandb_agent - INFO - Cleaning up finished run: q0jbd5ol\n",
+      "2020-10-12 08:37:43,337 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:37:43,337 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.0001\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 08:37:43,340 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0001 --num_sgd_iter=20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:37:48,354 - wandb.wandb_agent - INFO - Running runs: ['stb884a1']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlight-sweep-5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/stb884a1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_083745-stb884a1\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:37:49,154\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=2100)\u001b[0m 2020-10-12 08:37:51,901\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=2007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2085)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2085)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2090)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2090)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2073)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2073)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1988)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1988)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2067)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2067)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1998)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1998)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1979)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1979)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1982)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1982)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1983)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1983)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2005)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2005)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1991)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1991)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1995)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1995)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2049)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2049)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=1994)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=1994)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2047)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2047)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=2030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=2030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-38-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1858499546845753\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004094068659469485\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006398881853177348\n",
+      "        total_loss: 514.7343877156576\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.83225806451613\n",
+      "    gpu_util_percent0: 0.31935483870967746\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.529032258064517\n",
+      "    vram_util_percent0: 0.08267914387583453\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17258576383999963\n",
+      "    mean_env_wait_ms: 1.1829761753629924\n",
+      "    mean_inference_ms: 6.494177267410828\n",
+      "    mean_raw_obs_processing_ms: 0.46709867714731446\n",
+      "  time_since_restore: 25.266931295394897\n",
+      "  time_this_iter_s: 25.266931295394897\n",
+      "  time_total_s: 25.266931295394897\n",
+      "  timers:\n",
+      "    learn_throughput: 10740.473\n",
+      "    learn_time_ms: 15063.769\n",
+      "    sample_throughput: 16038.612\n",
+      "    sample_time_ms: 10087.656\n",
+      "    update_time_ms: 82.904\n",
+      "  timestamp: 1602491902\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      1 |          25.2669 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3621.3333333333335\n",
+      "    time_step_min: 3354\n",
+      "  date: 2020-10-12_08-38-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 889.8607594936709\n",
+      "  episode_reward_max: 265.2626262626262\n",
+      "  episode_reward_mean: 216.678046285641\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1562648216883342\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007113986609814067\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006645135644551677\n",
+      "        total_loss: 154.0817502339681\n",
+      "        vf_explained_var: 0.7768774628639221\n",
+      "        vf_loss: 154.08780415852866\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.881481481481483\n",
+      "    gpu_util_percent0: 0.3425925925925926\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.744444444444444\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16694925418086923\n",
+      "    mean_env_wait_ms: 1.1769385115639088\n",
+      "    mean_inference_ms: 6.042500853772362\n",
+      "    mean_raw_obs_processing_ms: 0.4504103289487157\n",
+      "  time_since_restore: 47.70790386199951\n",
+      "  time_this_iter_s: 22.440972566604614\n",
+      "  time_total_s: 47.70790386199951\n",
+      "  timers:\n",
+      "    learn_throughput: 10829.452\n",
+      "    learn_time_ms: 14939.999\n",
+      "    sample_throughput: 18339.568\n",
+      "    sample_time_ms: 8822.018\n",
+      "    update_time_ms: 50.596\n",
+      "  timestamp: 1602491925\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      2 |          47.7079 | 323584 |  216.678 |              265.263 |              135.869 |            889.861 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.932735426009\n",
+      "    time_step_min: 3329\n",
+      "  date: 2020-10-12_08-39-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.704641350211\n",
+      "  episode_reward_max: 265.2626262626262\n",
+      "  episode_reward_mean: 218.28014320419362\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1506426135698955\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007656096131540835\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009037703911114173\n",
+      "        total_loss: 65.57463296254475\n",
+      "        vf_explained_var: 0.8824062943458557\n",
+      "        vf_loss: 65.58302148183186\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.276923076923076\n",
+      "    gpu_util_percent0: 0.36076923076923073\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16357548870072489\n",
+      "    mean_env_wait_ms: 1.1747272183472945\n",
+      "    mean_inference_ms: 5.754892740266521\n",
+      "    mean_raw_obs_processing_ms: 0.4394634701846822\n",
+      "  time_since_restore: 69.77683162689209\n",
+      "  time_this_iter_s: 22.068927764892578\n",
+      "  time_total_s: 69.77683162689209\n",
+      "  timers:\n",
+      "    learn_throughput: 10855.848\n",
+      "    learn_time_ms: 14903.672\n",
+      "    sample_throughput: 19581.576\n",
+      "    sample_time_ms: 8262.46\n",
+      "    update_time_ms: 48.208\n",
+      "  timestamp: 1602491947\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      3 |          69.7768 | 485376 |   218.28 |              265.263 |              135.869 |            885.705 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3601.2201986754967\n",
+      "    time_step_min: 3262\n",
+      "  date: 2020-10-12_08-39-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.7737341772151\n",
+      "  episode_reward_max: 271.77777777777743\n",
+      "  episode_reward_mean: 219.97278161360424\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1313580671946208\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007723398506641388\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009239614970283583\n",
+      "        total_loss: 54.47336991628011\n",
+      "        vf_explained_var: 0.9014496803283691\n",
+      "        vf_loss: 54.481950441996254\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.20740740740741\n",
+      "    gpu_util_percent0: 0.2759259259259259\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7666666666666666\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16126493124675817\n",
+      "    mean_env_wait_ms: 1.174200588219917\n",
+      "    mean_inference_ms: 5.557115527329504\n",
+      "    mean_raw_obs_processing_ms: 0.4317369350133932\n",
+      "  time_since_restore: 92.07130265235901\n",
+      "  time_this_iter_s: 22.29447102546692\n",
+      "  time_total_s: 92.07130265235901\n",
+      "  timers:\n",
+      "    learn_throughput: 10833.262\n",
+      "    learn_time_ms: 14934.744\n",
+      "    sample_throughput: 20246.906\n",
+      "    sample_time_ms: 7990.949\n",
+      "    update_time_ms: 46.722\n",
+      "  timestamp: 1602491969\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      4 |          92.0713 | 647168 |  219.973 |              271.778 |              135.869 |            881.774 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3593.6023622047246\n",
+      "    time_step_min: 3262\n",
+      "  date: 2020-10-12_08-39-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.7898734177215\n",
+      "  episode_reward_max: 271.77777777777743\n",
+      "  episode_reward_mean: 221.32649277585966\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0989502271016438\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00747458190501978\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010204876113372544\n",
+      "        total_loss: 44.15726852416992\n",
+      "        vf_explained_var: 0.9253225922584534\n",
+      "        vf_loss: 44.16683801015218\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.38461538461538\n",
+      "    gpu_util_percent0: 0.41961538461538467\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.753846153846154\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.159577124214222\n",
+      "    mean_env_wait_ms: 1.174681950498461\n",
+      "    mean_inference_ms: 5.411141375472065\n",
+      "    mean_raw_obs_processing_ms: 0.4257335030475409\n",
+      "  time_since_restore: 114.01365947723389\n",
+      "  time_this_iter_s: 21.942356824874878\n",
+      "  time_total_s: 114.01365947723389\n",
+      "  timers:\n",
+      "    learn_throughput: 10837.772\n",
+      "    learn_time_ms: 14928.529\n",
+      "    sample_throughput: 20781.532\n",
+      "    sample_time_ms: 7785.374\n",
+      "    update_time_ms: 43.138\n",
+      "  timestamp: 1602491991\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      5 |          114.014 | 808960 |  221.326 |              271.778 |              135.869 |             877.79 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3582.591970121382\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-12_08-40-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 869.0391264786169\n",
+      "  episode_reward_max: 275.8686868686869\n",
+      "  episode_reward_mean: 223.00575362358785\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 309\n",
+      "  episodes_total: 1099\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0868350267410278\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006786216011581321\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0066523752466309816\n",
+      "        total_loss: 41.79396152496338\n",
+      "        vf_explained_var: 0.9526734948158264\n",
+      "        vf_loss: 41.800042152404785\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.6\n",
+      "    gpu_util_percent0: 0.34481481481481485\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.755555555555555\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1573612134680123\n",
+      "    mean_env_wait_ms: 1.177695927887752\n",
+      "    mean_inference_ms: 5.220261052750207\n",
+      "    mean_raw_obs_processing_ms: 0.4181297602212586\n",
+      "  time_since_restore: 135.98845148086548\n",
+      "  time_this_iter_s: 21.974792003631592\n",
+      "  time_total_s: 135.98845148086548\n",
+      "  timers:\n",
+      "    learn_throughput: 10831.663\n",
+      "    learn_time_ms: 14936.949\n",
+      "    sample_throughput: 21183.269\n",
+      "    sample_time_ms: 7637.726\n",
+      "    update_time_ms: 43.33\n",
+      "  timestamp: 1602492013\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      6 |          135.988 | 970752 |  223.006 |              275.869 |              135.869 |            869.039 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3574.207928802589\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-12_08-40-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 864.2927215189874\n",
+      "  episode_reward_max: 275.8686868686869\n",
+      "  episode_reward_mean: 224.54304916251107\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 165\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.081433097521464\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006580238269331555\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009145769756287336\n",
+      "        total_loss: 22.552169640858967\n",
+      "        vf_explained_var: 0.9606910347938538\n",
+      "        vf_loss: 22.560765743255615\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.06153846153846\n",
+      "    gpu_util_percent0: 0.34423076923076923\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1565262924197625\n",
+      "    mean_env_wait_ms: 1.1790704629787336\n",
+      "    mean_inference_ms: 5.147878899875807\n",
+      "    mean_raw_obs_processing_ms: 0.4152048278172211\n",
+      "  time_since_restore: 157.7657482624054\n",
+      "  time_this_iter_s: 21.777296781539917\n",
+      "  time_total_s: 157.7657482624054\n",
+      "  timers:\n",
+      "    learn_throughput: 10850.365\n",
+      "    learn_time_ms: 14911.203\n",
+      "    sample_throughput: 21469.757\n",
+      "    sample_time_ms: 7535.81\n",
+      "    update_time_ms: 42.99\n",
+      "  timestamp: 1602492035\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      7 |          157.766 | 1132544 |  224.543 |              275.869 |              135.869 |            864.293 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3562.984218077475\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-12_08-40-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 859.6540084388186\n",
+      "  episode_reward_max: 276.02020202020185\n",
+      "  episode_reward_mean: 225.97406555001476\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0650863250096638\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006993361671144764\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01039950551542764\n",
+      "        total_loss: 20.5628080368042\n",
+      "        vf_explained_var: 0.9627399444580078\n",
+      "        vf_loss: 20.572614828745525\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.646153846153844\n",
+      "    gpu_util_percent0: 0.3553846153846154\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15586201918474507\n",
+      "    mean_env_wait_ms: 1.180437252767014\n",
+      "    mean_inference_ms: 5.088810304506143\n",
+      "    mean_raw_obs_processing_ms: 0.4127548922147928\n",
+      "  time_since_restore: 179.6518850326538\n",
+      "  time_this_iter_s: 21.886136770248413\n",
+      "  time_total_s: 179.6518850326538\n",
+      "  timers:\n",
+      "    learn_throughput: 10866.77\n",
+      "    learn_time_ms: 14888.692\n",
+      "    sample_throughput: 21637.501\n",
+      "    sample_time_ms: 7477.389\n",
+      "    update_time_ms: 42.395\n",
+      "  timestamp: 1602492057\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      8 |          179.652 | 1294336 |  225.974 |               276.02 |              135.869 |            859.654 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3554.34793814433\n",
+      "    time_step_min: 3234\n",
+      "  date: 2020-10-12_08-41-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 855.3632911392405\n",
+      "  episode_reward_max: 276.02020202020185\n",
+      "  episode_reward_mean: 227.47302135276803\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0342613955338795\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007145024758453171\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012359135745403668\n",
+      "        total_loss: 16.66917912165324\n",
+      "        vf_explained_var: 0.969153881072998\n",
+      "        vf_loss: 16.68092672030131\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.53461538461539\n",
+      "    gpu_util_percent0: 0.3642307692307692\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7692307692307696\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15528183181065922\n",
+      "    mean_env_wait_ms: 1.1818439220502401\n",
+      "    mean_inference_ms: 5.0377427518753315\n",
+      "    mean_raw_obs_processing_ms: 0.4105749751688051\n",
+      "  time_since_restore: 201.43642330169678\n",
+      "  time_this_iter_s: 21.78453826904297\n",
+      "  time_total_s: 201.43642330169678\n",
+      "  timers:\n",
+      "    learn_throughput: 10877.626\n",
+      "    learn_time_ms: 14873.834\n",
+      "    sample_throughput: 21813.171\n",
+      "    sample_time_ms: 7417.17\n",
+      "    update_time_ms: 41.963\n",
+      "  timestamp: 1602492079\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      9 |          201.436 | 1456128 |  227.473 |               276.02 |              135.869 |            855.363 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3538.1871628910462\n",
+      "    time_step_min: 3230\n",
+      "  date: 2020-10-12_08-41-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.0605738575983\n",
+      "  episode_reward_max: 279.9595959595959\n",
+      "  episode_reward_mean: 229.94768084672427\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 302\n",
+      "  episodes_total: 1882\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9991929431756338\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006702322629280388\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009044580952225564\n",
+      "        total_loss: 23.912927468617756\n",
+      "        vf_explained_var: 0.9700927734375\n",
+      "        vf_loss: 23.921401182810467\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.314814814814813\n",
+      "    gpu_util_percent0: 0.367037037037037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.755555555555555\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15439027266039412\n",
+      "    mean_env_wait_ms: 1.1847406453962492\n",
+      "    mean_inference_ms: 4.959192362221115\n",
+      "    mean_raw_obs_processing_ms: 0.4073170198745893\n",
+      "  time_since_restore: 223.26062870025635\n",
+      "  time_this_iter_s: 21.82420539855957\n",
+      "  time_total_s: 223.26062870025635\n",
+      "  timers:\n",
+      "    learn_throughput: 10885.919\n",
+      "    learn_time_ms: 14862.503\n",
+      "    sample_throughput: 21962.384\n",
+      "    sample_time_ms: 7366.778\n",
+      "    update_time_ms: 41.253\n",
+      "  timestamp: 1602492101\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     10 |          223.261 | 1617920 |  229.948 |               279.96 |              135.869 |            848.061 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3528.677690029615\n",
+      "    time_step_min: 3230\n",
+      "  date: 2020-10-12_08-42-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.0929892891918\n",
+      "  episode_reward_max: 284.9595959595956\n",
+      "  episode_reward_mean: 231.38342529481758\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 172\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9863324115673701\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007253075134940445\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010080095797699565\n",
+      "        total_loss: 12.745516856511435\n",
+      "        vf_explained_var: 0.975978672504425\n",
+      "        vf_loss: 12.754970153172811\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.073076923076922\n",
+      "    gpu_util_percent0: 0.33884615384615385\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15395971112154033\n",
+      "    mean_env_wait_ms: 1.1861700352928464\n",
+      "    mean_inference_ms: 4.922337023279303\n",
+      "    mean_raw_obs_processing_ms: 0.405765973621554\n",
+      "  time_since_restore: 245.08239674568176\n",
+      "  time_this_iter_s: 21.821768045425415\n",
+      "  time_total_s: 245.08239674568176\n",
+      "  timers:\n",
+      "    learn_throughput: 10912.485\n",
+      "    learn_time_ms: 14826.321\n",
+      "    sample_throughput: 22908.63\n",
+      "    sample_time_ms: 7062.491\n",
+      "    update_time_ms: 35.215\n",
+      "  timestamp: 1602492123\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     11 |          245.082 | 1779712 |  231.383 |               284.96 |              135.869 |            845.093 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3521.334706959707\n",
+      "    time_step_min: 3230\n",
+      "  date: 2020-10-12_08-42-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.3512658227849\n",
+      "  episode_reward_max: 284.9595959595956\n",
+      "  episode_reward_mean: 232.42007324602253\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9833590139945348\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006227322039194405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00852358304352189\n",
+      "        total_loss: 14.60979151725769\n",
+      "        vf_explained_var: 0.971681535243988\n",
+      "        vf_loss: 14.617790699005127\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.46153846153846\n",
+      "    gpu_util_percent0: 0.41346153846153844\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15361216385441095\n",
+      "    mean_env_wait_ms: 1.1873319753360294\n",
+      "    mean_inference_ms: 4.892219410835038\n",
+      "    mean_raw_obs_processing_ms: 0.40448378793887574\n",
+      "  time_since_restore: 267.23646235466003\n",
+      "  time_this_iter_s: 22.15406560897827\n",
+      "  time_total_s: 267.23646235466003\n",
+      "  timers:\n",
+      "    learn_throughput: 10902.615\n",
+      "    learn_time_ms: 14839.743\n",
+      "    sample_throughput: 23052.506\n",
+      "    sample_time_ms: 7018.413\n",
+      "    update_time_ms: 36.93\n",
+      "  timestamp: 1602492145\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     12 |          267.236 | 1941504 |   232.42 |               284.96 |              135.869 |            843.351 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3515.048249359522\n",
+      "    time_step_min: 3230\n",
+      "  date: 2020-10-12_08-42-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.8481012658228\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 233.48216340621394\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9474922468264898\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006475092299903433\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009250502989743836\n",
+      "        total_loss: 14.260765393575033\n",
+      "        vf_explained_var: 0.9733137488365173\n",
+      "        vf_loss: 14.269463221232096\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.09629629629629\n",
+      "    gpu_util_percent0: 0.3014814814814815\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.77037037037037\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1532982326821362\n",
+      "    mean_env_wait_ms: 1.1883857196509395\n",
+      "    mean_inference_ms: 4.865022739372882\n",
+      "    mean_raw_obs_processing_ms: 0.40331712226024746\n",
+      "  time_since_restore: 289.2048056125641\n",
+      "  time_this_iter_s: 21.968343257904053\n",
+      "  time_total_s: 289.2048056125641\n",
+      "  timers:\n",
+      "    learn_throughput: 10891.191\n",
+      "    learn_time_ms: 14855.308\n",
+      "    sample_throughput: 23142.952\n",
+      "    sample_time_ms: 6990.984\n",
+      "    update_time_ms: 37.068\n",
+      "  timestamp: 1602492167\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     13 |          289.205 | 2103296 |  233.482 |              286.626 |              135.869 |            841.848 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3501.123633622314\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-43-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.1547929876912\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 235.55068024519713\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 311\n",
+      "  episodes_total: 2681\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9234441419442495\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006116377733026941\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008196644863346592\n",
+      "        total_loss: 19.14843002955119\n",
+      "        vf_explained_var: 0.974140465259552\n",
+      "        vf_loss: 19.15610710779826\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.373076923076926\n",
+      "    gpu_util_percent0: 0.36115384615384616\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7576923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15276546501530014\n",
+      "    mean_env_wait_ms: 1.1904107868575922\n",
+      "    mean_inference_ms: 4.8189728498329485\n",
+      "    mean_raw_obs_processing_ms: 0.4014017127349726\n",
+      "  time_since_restore: 310.99618577957153\n",
+      "  time_this_iter_s: 21.791380167007446\n",
+      "  time_total_s: 310.99618577957153\n",
+      "  timers:\n",
+      "    learn_throughput: 10904.933\n",
+      "    learn_time_ms: 14836.589\n",
+      "    sample_throughput: 23245.705\n",
+      "    sample_time_ms: 6960.082\n",
+      "    update_time_ms: 35.505\n",
+      "  timestamp: 1602492189\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     14 |          310.996 | 2265088 |  235.551 |              286.626 |              135.869 |            838.155 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3495.3238636363635\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-43-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.3660337552743\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 236.4045838128116\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.915911003947258\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0061395803932100534\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010156944151579713\n",
+      "        total_loss: 11.34574580192566\n",
+      "        vf_explained_var: 0.9787011742591858\n",
+      "        vf_loss: 11.355380455652872\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.007692307692306\n",
+      "    gpu_util_percent0: 0.33192307692307693\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1525226137968328\n",
+      "    mean_env_wait_ms: 1.191373284138838\n",
+      "    mean_inference_ms: 4.798271945270741\n",
+      "    mean_raw_obs_processing_ms: 0.40052132412082564\n",
+      "  time_since_restore: 332.7011032104492\n",
+      "  time_this_iter_s: 21.704917430877686\n",
+      "  time_total_s: 332.7011032104492\n",
+      "  timers:\n",
+      "    learn_throughput: 10917.13\n",
+      "    learn_time_ms: 14820.012\n",
+      "    sample_throughput: 23276.711\n",
+      "    sample_time_ms: 6950.81\n",
+      "    update_time_ms: 36.581\n",
+      "  timestamp: 1602492211\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     15 |          332.701 | 2426880 |  236.405 |              286.626 |              135.869 |            836.366 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3489.8749159381305\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-43-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.4490339773484\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 237.28117955033338\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9094983438650767\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006247825222089887\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0099478800984798\n",
+      "        total_loss: 12.494431257247925\n",
+      "        vf_explained_var: 0.9735568165779114\n",
+      "        vf_loss: 12.503845612208048\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.770370370370372\n",
+      "    gpu_util_percent0: 0.3325925925925926\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7666666666666666\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15230749442700836\n",
+      "    mean_env_wait_ms: 1.1922618136568186\n",
+      "    mean_inference_ms: 4.779647564940922\n",
+      "    mean_raw_obs_processing_ms: 0.39972468508854025\n",
+      "  time_since_restore: 354.660724401474\n",
+      "  time_this_iter_s: 21.95962119102478\n",
+      "  time_total_s: 354.660724401474\n",
+      "  timers:\n",
+      "    learn_throughput: 10932.893\n",
+      "    learn_time_ms: 14798.644\n",
+      "    sample_throughput: 23231.51\n",
+      "    sample_time_ms: 6964.334\n",
+      "    update_time_ms: 35.858\n",
+      "  timestamp: 1602492233\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     16 |          354.661 | 2588672 |  237.281 |              286.626 |              135.869 |            834.449 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3484.2136968928344\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-44-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.9575738529227\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 238.11965348011853\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 180\n",
+      "  episodes_total: 3182\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8757123003403345\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006264201404216389\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009777444618521258\n",
+      "        total_loss: 13.901710192362467\n",
+      "        vf_explained_var: 0.9767399430274963\n",
+      "        vf_loss: 13.910948832829794\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.515384615384615\n",
+      "    gpu_util_percent0: 0.30576923076923074\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1520823720998534\n",
+      "    mean_env_wait_ms: 1.1932319551868942\n",
+      "    mean_inference_ms: 4.760040912603402\n",
+      "    mean_raw_obs_processing_ms: 0.39888700003710004\n",
+      "  time_since_restore: 376.5495798587799\n",
+      "  time_this_iter_s: 21.888855457305908\n",
+      "  time_total_s: 376.5495798587799\n",
+      "  timers:\n",
+      "    learn_throughput: 10926.535\n",
+      "    learn_time_ms: 14807.255\n",
+      "    sample_throughput: 23218.041\n",
+      "    sample_time_ms: 6968.374\n",
+      "    update_time_ms: 34.069\n",
+      "  timestamp: 1602492255\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     17 |           376.55 | 2750464 |   238.12 |              286.626 |              135.869 |            832.958 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3476.53671988389\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-44-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.0423265188598\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 239.41880073409004\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 291\n",
+      "  episodes_total: 3473\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.862436776359876\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00582402265475442\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0065109556599054486\n",
+      "        total_loss: 16.89293646812439\n",
+      "        vf_explained_var: 0.9754787087440491\n",
+      "        vf_loss: 16.898951292037964\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.926923076923078\n",
+      "    gpu_util_percent0: 0.34500000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1517612004517305\n",
+      "    mean_env_wait_ms: 1.1946496078443667\n",
+      "    mean_inference_ms: 4.731862828478537\n",
+      "    mean_raw_obs_processing_ms: 0.39770574920140944\n",
+      "  time_since_restore: 398.4416320323944\n",
+      "  time_this_iter_s: 21.892052173614502\n",
+      "  time_total_s: 398.4416320323944\n",
+      "  timers:\n",
+      "    learn_throughput: 10918.614\n",
+      "    learn_time_ms: 14817.997\n",
+      "    sample_throughput: 23251.091\n",
+      "    sample_time_ms: 6958.469\n",
+      "    update_time_ms: 32.599\n",
+      "  timestamp: 1602492277\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     18 |          398.442 | 2912256 |  239.419 |              286.626 |              135.869 |            831.042 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3472.1566833056017\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-44-59\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.3706659328564\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 240.11061078589967\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8508865286906561\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005722010508179665\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010631043463945389\n",
+      "        total_loss: 9.665903091430664\n",
+      "        vf_explained_var: 0.9808840155601501\n",
+      "        vf_loss: 9.676047007242838\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.12962962962963\n",
+      "    gpu_util_percent0: 0.3181481481481481\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7814814814814808\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15160220027619284\n",
+      "    mean_env_wait_ms: 1.1953684893976586\n",
+      "    mean_inference_ms: 4.717913496142562\n",
+      "    mean_raw_obs_processing_ms: 0.3971194057832533\n",
+      "  time_since_restore: 420.2288022041321\n",
+      "  time_this_iter_s: 21.78717017173767\n",
+      "  time_total_s: 420.2288022041321\n",
+      "  timers:\n",
+      "    learn_throughput: 10920.147\n",
+      "    learn_time_ms: 14815.918\n",
+      "    sample_throughput: 23242.947\n",
+      "    sample_time_ms: 6960.907\n",
+      "    update_time_ms: 32.142\n",
+      "  timestamp: 1602492299\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     19 |          420.229 | 3074048 |  240.111 |              286.626 |              135.869 |            830.371 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3467.42348565356\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-45-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.4894514767932\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 240.77151259429735\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8476235717535019\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005998994805850089\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009499937470536679\n",
+      "        total_loss: 10.576106945673624\n",
+      "        vf_explained_var: 0.97751784324646\n",
+      "        vf_loss: 10.585091590881348\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.78461538461539\n",
+      "    gpu_util_percent0: 0.34807692307692306\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.784615384615385\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15145770518598975\n",
+      "    mean_env_wait_ms: 1.1960228017989614\n",
+      "    mean_inference_ms: 4.705052577742813\n",
+      "    mean_raw_obs_processing_ms: 0.39657759839835627\n",
+      "  time_since_restore: 442.2300491333008\n",
+      "  time_this_iter_s: 22.0012469291687\n",
+      "  time_total_s: 442.2300491333008\n",
+      "  timers:\n",
+      "    learn_throughput: 10912.126\n",
+      "    learn_time_ms: 14826.808\n",
+      "    sample_throughput: 23197.629\n",
+      "    sample_time_ms: 6974.506\n",
+      "    update_time_ms: 31.2\n",
+      "  timestamp: 1602492321\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     20 |           442.23 | 3235840 |  240.772 |              286.626 |              135.869 |            829.489 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3461.8119808708784\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-45-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 828.7065733566608\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 241.63679029737514\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 209\n",
+      "  episodes_total: 4001\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8073496967554092\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0053013469247768326\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007447434841499974\n",
+      "        total_loss: 13.215350230534872\n",
+      "        vf_explained_var: 0.9791877269744873\n",
+      "        vf_loss: 13.222347656885782\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.248148148148147\n",
+      "    gpu_util_percent0: 0.3062962962962963\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15128604750252658\n",
+      "    mean_env_wait_ms: 1.196811102954551\n",
+      "    mean_inference_ms: 4.689196081330257\n",
+      "    mean_raw_obs_processing_ms: 0.3959243949246973\n",
+      "  time_since_restore: 464.0425639152527\n",
+      "  time_this_iter_s: 21.812514781951904\n",
+      "  time_total_s: 464.0425639152527\n",
+      "  timers:\n",
+      "    learn_throughput: 10907.966\n",
+      "    learn_time_ms: 14832.462\n",
+      "    sample_throughput: 23243.462\n",
+      "    sample_time_ms: 6960.753\n",
+      "    update_time_ms: 30.816\n",
+      "  timestamp: 1602492343\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     21 |          464.043 | 3397632 |  241.637 |              286.626 |              135.869 |            828.707 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3454.145184135977\n",
+      "    time_step_min: 3173\n",
+      "  date: 2020-10-12_08-46-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.9786585365854\n",
+      "  episode_reward_max: 286.62626262626225\n",
+      "  episode_reward_mean: 242.722224591127\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 263\n",
+      "  episodes_total: 4264\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7928875287373861\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005559906829148531\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009087247861316428\n",
+      "        total_loss: 10.697956959406534\n",
+      "        vf_explained_var: 0.9829474091529846\n",
+      "        vf_loss: 10.706567605336508\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.349999999999998\n",
+      "    gpu_util_percent0: 0.2907692307692308\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510860289808531\n",
+      "    mean_env_wait_ms: 1.197690271183912\n",
+      "    mean_inference_ms: 4.671202928544622\n",
+      "    mean_raw_obs_processing_ms: 0.39516008240817785\n",
+      "  time_since_restore: 485.9816827774048\n",
+      "  time_this_iter_s: 21.9391188621521\n",
+      "  time_total_s: 485.9816827774048\n",
+      "  timers:\n",
+      "    learn_throughput: 10915.786\n",
+      "    learn_time_ms: 14821.837\n",
+      "    sample_throughput: 23285.007\n",
+      "    sample_time_ms: 6948.334\n",
+      "    update_time_ms: 31.259\n",
+      "  timestamp: 1602492365\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     22 |          485.982 | 3559424 |  242.722 |              286.626 |              135.869 |            827.979 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3450.070973612375\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-46-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.4380650994575\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 243.26666073026828\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7965629249811172\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004790663408736388\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008145113398010531\n",
+      "        total_loss: 10.19397759437561\n",
+      "        vf_explained_var: 0.979886531829834\n",
+      "        vf_loss: 10.201723416646322\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.873076923076926\n",
+      "    gpu_util_percent0: 0.3742307692307692\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7769230769230764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15097523831193937\n",
+      "    mean_env_wait_ms: 1.198180034212628\n",
+      "    mean_inference_ms: 4.661100264257637\n",
+      "    mean_raw_obs_processing_ms: 0.3947356773964307\n",
+      "  time_since_restore: 507.8446464538574\n",
+      "  time_this_iter_s: 21.862963676452637\n",
+      "  time_total_s: 507.8446464538574\n",
+      "  timers:\n",
+      "    learn_throughput: 10921.942\n",
+      "    learn_time_ms: 14813.483\n",
+      "    sample_throughput: 23283.338\n",
+      "    sample_time_ms: 6948.832\n",
+      "    update_time_ms: 28.976\n",
+      "  timestamp: 1602492387\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     23 |          507.845 | 3721216 |  243.267 |              291.778 |              135.869 |            827.438 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3446.520421607378\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-46-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.8005237887386\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 243.8116917758995\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4582\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7860831270615259\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006281677827549477\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008127124708456298\n",
+      "        total_loss: 9.384316762288412\n",
+      "        vf_explained_var: 0.9807237982749939\n",
+      "        vf_loss: 9.392208496729532\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.051851851851854\n",
+      "    gpu_util_percent0: 0.2914814814814815\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7851851851851848\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.150872520219993\n",
+      "    mean_env_wait_ms: 1.198637669472401\n",
+      "    mean_inference_ms: 4.651638105431035\n",
+      "    mean_raw_obs_processing_ms: 0.3943363563376779\n",
+      "  time_since_restore: 529.604768037796\n",
+      "  time_this_iter_s: 21.7601215839386\n",
+      "  time_total_s: 529.604768037796\n",
+      "  timers:\n",
+      "    learn_throughput: 10924.108\n",
+      "    learn_time_ms: 14810.546\n",
+      "    sample_throughput: 23288.432\n",
+      "    sample_time_ms: 6947.312\n",
+      "    update_time_ms: 29.667\n",
+      "  timestamp: 1602492409\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     24 |          529.605 | 3883008 |  243.812 |              291.778 |              135.869 |            826.801 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3440.437057107128\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-47-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.8632407791131\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 244.76139555522067\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 244\n",
+      "  episodes_total: 4826\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.754992201924324\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005963448085822165\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008779487393136757\n",
+      "        total_loss: 9.597943862279257\n",
+      "        vf_explained_var: 0.9848809242248535\n",
+      "        vf_loss: 9.606500705083212\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.923076923076923\n",
+      "    gpu_util_percent0: 0.3515384615384616\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.75\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15072576914319252\n",
+      "    mean_env_wait_ms: 1.1993330760083902\n",
+      "    mean_inference_ms: 4.638071597147566\n",
+      "    mean_raw_obs_processing_ms: 0.3937742830795006\n",
+      "  time_since_restore: 551.7138071060181\n",
+      "  time_this_iter_s: 22.109039068222046\n",
+      "  time_total_s: 551.7138071060181\n",
+      "  timers:\n",
+      "    learn_throughput: 10926.872\n",
+      "    learn_time_ms: 14806.8\n",
+      "    sample_throughput: 23136.794\n",
+      "    sample_time_ms: 6992.844\n",
+      "    update_time_ms: 27.45\n",
+      "  timestamp: 1602492431\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     25 |          551.714 | 4044800 |  244.761 |              291.778 |              135.869 |            825.863 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3435.615552903739\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-47-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.2846123417721\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 245.55597709691855\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 230\n",
+      "  episodes_total: 5056\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7510520567496618\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006108862425511082\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009180293748310456\n",
+      "        total_loss: 9.422614336013794\n",
+      "        vf_explained_var: 0.9839019179344177\n",
+      "        vf_loss: 9.431564490000406\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.46666666666667\n",
+      "    gpu_util_percent0: 0.32555555555555554\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15059448528084024\n",
+      "    mean_env_wait_ms: 1.19986428552713\n",
+      "    mean_inference_ms: 4.626139098768838\n",
+      "    mean_raw_obs_processing_ms: 0.39326811905687803\n",
+      "  time_since_restore: 573.6764891147614\n",
+      "  time_this_iter_s: 21.962682008743286\n",
+      "  time_total_s: 573.6764891147614\n",
+      "  timers:\n",
+      "    learn_throughput: 10916.067\n",
+      "    learn_time_ms: 14821.456\n",
+      "    sample_throughput: 23159.204\n",
+      "    sample_time_ms: 6986.078\n",
+      "    update_time_ms: 25.423\n",
+      "  timestamp: 1602492453\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     26 |          573.676 | 4206592 |  245.556 |              291.778 |              135.869 |            825.285 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3432.570381797146\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-47-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.927694668201\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 246.02223617068262\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 5214\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7519985487063726\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00578857046396782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007587263817792215\n",
+      "        total_loss: 8.542066733042398\n",
+      "        vf_explained_var: 0.9829537272453308\n",
+      "        vf_loss: 8.549439509709677\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.85769230769231\n",
+      "    gpu_util_percent0: 0.33807692307692305\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15051100010946178\n",
+      "    mean_env_wait_ms: 1.2002167686108423\n",
+      "    mean_inference_ms: 4.61849677217929\n",
+      "    mean_raw_obs_processing_ms: 0.3929485309367278\n",
+      "  time_since_restore: 595.6711790561676\n",
+      "  time_this_iter_s: 21.99468994140625\n",
+      "  time_total_s: 595.6711790561676\n",
+      "  timers:\n",
+      "    learn_throughput: 10927.326\n",
+      "    learn_time_ms: 14806.184\n",
+      "    sample_throughput: 23074.942\n",
+      "    sample_time_ms: 7011.589\n",
+      "    update_time_ms: 25.225\n",
+      "  timestamp: 1602492476\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     27 |          595.671 | 4368384 |  246.022 |              291.778 |              135.869 |            824.928 |\n",
+      "+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_36689_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4135\n",
+      "    time_step_mean: 3429.3792974588937\n",
+      "    time_step_min: 3130\n",
+      "  date: 2020-10-12_08-48-18\n",
+      "  done: true\n",
+      "  episode_len_mean: 824.468029739777\n",
+      "  episode_reward_max: 291.777777777778\n",
+      "  episode_reward_mean: 246.4583286395554\n",
+      "  episode_reward_min: 135.86868686868658\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 5380\n",
+      "  experiment_id: dc93f86da89d474f81761675826ff91a\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05000000000000001\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7269033441940943\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006252984749153256\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007048466320460041\n",
+      "        total_loss: 9.722230116526285\n",
+      "        vf_explained_var: 0.9817023277282715\n",
+      "        vf_loss: 9.729038715362549\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.3037037037037\n",
+      "    gpu_util_percent0: 0.337037037037037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7851851851851848\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 2100\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15042886996746352\n",
+      "    mean_env_wait_ms: 1.2005724653972405\n",
+      "    mean_inference_ms: 4.610864653434181\n",
+      "    mean_raw_obs_processing_ms: 0.3926279850182893\n",
+      "  time_since_restore: 617.6555559635162\n",
+      "  time_this_iter_s: 21.984376907348633\n",
+      "  time_total_s: 617.6555559635162\n",
+      "  timers:\n",
+      "    learn_throughput: 10928.071\n",
+      "    learn_time_ms: 14805.175\n",
+      "    sample_throughput: 23043.461\n",
+      "    sample_time_ms: 7021.167\n",
+      "    update_time_ms: 24.873\n",
+      "  timestamp: 1602492498\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: '36689_00000'\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | TERMINATED |       |     28 |          617.656 | 4530176 |  246.458 |              291.778 |              135.869 |            824.468 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_36689_00000 | TERMINATED |       |     28 |          617.656 | 4530176 |  246.458 |              291.778 |              135.869 |            824.468 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 1840\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_083745-stb884a1/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_083745-stb884a1/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3130\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 633\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602492498\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4135\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3429.3793\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 135.86869\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 246.45833\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5380\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlight-sweep-5\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/stb884a1\u001b[0m\n",
+      "2020-10-12 08:48:29,564 - wandb.wandb_agent - INFO - Cleaning up finished run: stb884a1\n",
+      "2020-10-12 08:48:29,947 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:48:29,947 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.3\n",
+      "\tentropy_coeff: 0.0001\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 08:48:29,950 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0001 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlunar-sweep-6\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/k19ejmk1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_084831-k19ejmk1\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:48:34,965 - wandb.wandb_agent - INFO - Running runs: ['k19ejmk1']\n",
+      "2020-10-12 08:48:35,558\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=34085)\u001b[0m 2020-10-12 08:48:38,359\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=34097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34087)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34087)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34047)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34047)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34001)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34001)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33991)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33991)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33998)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33998)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34073)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34073)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33983)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33983)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34019)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34019)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34008)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34008)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34069)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34069)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34061)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34061)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33995)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33995)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34010)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34010)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33982)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33982)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33988)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33988)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34090)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34090)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34067)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34067)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33999)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33999)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=34059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=34059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-49-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1850829323132832\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004093626630492508\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007868677183675269\n",
+      "        total_loss: 507.0761362711589\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.742857142857144\n",
+      "    gpu_util_percent0: 0.3002857142857142\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.56\n",
+      "    vram_util_percent0: 0.08552921332521203\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17007244483450748\n",
+      "    mean_env_wait_ms: 1.1758881463206599\n",
+      "    mean_inference_ms: 5.917305108683092\n",
+      "    mean_raw_obs_processing_ms: 0.4570395183180467\n",
+      "  time_since_restore: 28.66883397102356\n",
+      "  time_this_iter_s: 28.66883397102356\n",
+      "  time_total_s: 28.66883397102356\n",
+      "  timers:\n",
+      "    learn_throughput: 8378.585\n",
+      "    learn_time_ms: 19310.181\n",
+      "    sample_throughput: 17406.221\n",
+      "    sample_time_ms: 9295.067\n",
+      "    update_time_ms: 30.95\n",
+      "  timestamp: 1602492552\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      1 |          28.6688 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3608.8055555555557\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-49-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 890.7056962025316\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.07793121084234\n",
+      "  episode_reward_min: 138.89898989898958\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1567376752694447\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0070590757532045245\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010883362002156597\n",
+      "        total_loss: 129.9215234120687\n",
+      "        vf_explained_var: 0.8072310090065002\n",
+      "        vf_loss: 129.93181800842285\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.309375\n",
+      "    gpu_util_percent0: 0.3934375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.746875\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1654431794837442\n",
+      "    mean_env_wait_ms: 1.1717627648886877\n",
+      "    mean_inference_ms: 5.636689216114889\n",
+      "    mean_raw_obs_processing_ms: 0.4442287200505556\n",
+      "  time_since_restore: 55.46663856506348\n",
+      "  time_this_iter_s: 26.797804594039917\n",
+      "  time_total_s: 55.46663856506348\n",
+      "  timers:\n",
+      "    learn_throughput: 8431.924\n",
+      "    learn_time_ms: 19188.029\n",
+      "    sample_throughput: 19080.628\n",
+      "    sample_time_ms: 8479.386\n",
+      "    update_time_ms: 26.183\n",
+      "  timestamp: 1602492579\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      2 |          55.4666 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3602.798206278027\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-50-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 886.1392405063291\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 218.34343434343413\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.143834412097931\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00900065409950912\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012952111646882258\n",
+      "        total_loss: 62.266885121663414\n",
+      "        vf_explained_var: 0.8935738205909729\n",
+      "        vf_loss: 62.279051780700684\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.86969696969697\n",
+      "    gpu_util_percent0: 0.3557575757575758\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.772727272727273\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16235099515447016\n",
+      "    mean_env_wait_ms: 1.1711995477544175\n",
+      "    mean_inference_ms: 5.4315394961722845\n",
+      "    mean_raw_obs_processing_ms: 0.43519531090754504\n",
+      "  time_since_restore: 82.2608654499054\n",
+      "  time_this_iter_s: 26.79422688484192\n",
+      "  time_total_s: 82.2608654499054\n",
+      "  timers:\n",
+      "    learn_throughput: 8392.687\n",
+      "    learn_time_ms: 19277.736\n",
+      "    sample_throughput: 20060.368\n",
+      "    sample_time_ms: 8065.256\n",
+      "    update_time_ms: 31.521\n",
+      "  timestamp: 1602492606\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      3 |          82.2609 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3596.7533112582782\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_08-50-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 882.5870253164557\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 219.16725802327048\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1256821552912395\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00838832138106227\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013208418832315752\n",
+      "        total_loss: 44.44708792368571\n",
+      "        vf_explained_var: 0.9239999651908875\n",
+      "        vf_loss: 44.45957056681315\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.36875\n",
+      "    gpu_util_percent0: 0.391875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16020915492558616\n",
+      "    mean_env_wait_ms: 1.170960792081896\n",
+      "    mean_inference_ms: 5.284510582773325\n",
+      "    mean_raw_obs_processing_ms: 0.4283467072729477\n",
+      "  time_since_restore: 108.49334454536438\n",
+      "  time_this_iter_s: 26.232479095458984\n",
+      "  time_total_s: 108.49334454536438\n",
+      "  timers:\n",
+      "    learn_throughput: 8417.216\n",
+      "    learn_time_ms: 19221.558\n",
+      "    sample_throughput: 20719.894\n",
+      "    sample_time_ms: 7808.534\n",
+      "    update_time_ms: 32.449\n",
+      "  timestamp: 1602492632\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      4 |          108.493 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3591.5629921259842\n",
+      "    time_step_min: 3242\n",
+      "  date: 2020-10-12_08-50-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 878.2569620253165\n",
+      "  episode_reward_max: 274.8080808080809\n",
+      "  episode_reward_mean: 220.1586753612068\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0966354012489319\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008652650052681565\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013121832271281164\n",
+      "        total_loss: 35.068282763163246\n",
+      "        vf_explained_var: 0.9439868927001953\n",
+      "        vf_loss: 35.080649058024086\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.806451612903228\n",
+      "    gpu_util_percent0: 0.33806451612903227\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15864704471293362\n",
+      "    mean_env_wait_ms: 1.1715553513448569\n",
+      "    mean_inference_ms: 5.174791401279589\n",
+      "    mean_raw_obs_processing_ms: 0.42303087966284747\n",
+      "  time_since_restore: 134.80124497413635\n",
+      "  time_this_iter_s: 26.307900428771973\n",
+      "  time_total_s: 134.80124497413635\n",
+      "  timers:\n",
+      "    learn_throughput: 8433.414\n",
+      "    learn_time_ms: 19184.638\n",
+      "    sample_throughput: 21073.852\n",
+      "    sample_time_ms: 7677.382\n",
+      "    update_time_ms: 34.264\n",
+      "  timestamp: 1602492658\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      5 |          134.801 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3575.0697674418607\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_08-51-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 868.2937443336356\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 223.16600272901252\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 313\n",
+      "  episodes_total: 1103\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0826950172583263\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008017374784685671\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009852176726174852\n",
+      "        total_loss: 37.77317714691162\n",
+      "        vf_explained_var: 0.9565708637237549\n",
+      "        vf_loss: 37.78233687082926\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.121875000000003\n",
+      "    gpu_util_percent0: 0.27375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7687500000000003\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15658011148034967\n",
+      "    mean_env_wait_ms: 1.174675724672405\n",
+      "    mean_inference_ms: 5.028787591019388\n",
+      "    mean_raw_obs_processing_ms: 0.41624576281956216\n",
+      "  time_since_restore: 161.20420932769775\n",
+      "  time_this_iter_s: 26.4029643535614\n",
+      "  time_total_s: 161.20420932769775\n",
+      "  timers:\n",
+      "    learn_throughput: 8429.684\n",
+      "    learn_time_ms: 19193.126\n",
+      "    sample_throughput: 21351.224\n",
+      "    sample_time_ms: 7577.645\n",
+      "    update_time_ms: 35.274\n",
+      "  timestamp: 1602492685\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      6 |          161.204 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3561.846278317152\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_08-51-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 862.3742088607595\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 225.2731747858328\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 161\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0706466734409332\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007869300238477686\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013351764432930699\n",
+      "        total_loss: 18.482054869333904\n",
+      "        vf_explained_var: 0.9659532904624939\n",
+      "        vf_loss: 18.49472649892171\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.371875000000003\n",
+      "    gpu_util_percent0: 0.3028125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7843750000000003\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15583032328558655\n",
+      "    mean_env_wait_ms: 1.1762072212287429\n",
+      "    mean_inference_ms: 4.975444621996932\n",
+      "    mean_raw_obs_processing_ms: 0.41371028178839997\n",
+      "  time_since_restore: 187.448495388031\n",
+      "  time_this_iter_s: 26.244286060333252\n",
+      "  time_total_s: 187.448495388031\n",
+      "  timers:\n",
+      "    learn_throughput: 8432.115\n",
+      "    learn_time_ms: 19187.593\n",
+      "    sample_throughput: 21579.106\n",
+      "    sample_time_ms: 7497.623\n",
+      "    update_time_ms: 33.196\n",
+      "  timestamp: 1602492711\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      7 |          187.448 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3551.647776183644\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_08-52-17\n",
+      "  done: false\n",
+      "  episode_len_mean: 858.2130801687764\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 227.1781954566763\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0530053079128265\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007424288894981146\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014031020080437884\n",
+      "        total_loss: 18.28844420115153\n",
+      "        vf_explained_var: 0.9650914669036865\n",
+      "        vf_loss: 18.30183744430542\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.77741935483871\n",
+      "    gpu_util_percent0: 0.35290322580645167\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1552016030465719\n",
+      "    mean_env_wait_ms: 1.177545756181366\n",
+      "    mean_inference_ms: 4.930081334310762\n",
+      "    mean_raw_obs_processing_ms: 0.4114917803237996\n",
+      "  time_since_restore: 213.53041887283325\n",
+      "  time_this_iter_s: 26.081923484802246\n",
+      "  time_total_s: 213.53041887283325\n",
+      "  timers:\n",
+      "    learn_throughput: 8438.094\n",
+      "    learn_time_ms: 19173.999\n",
+      "    sample_throughput: 21784.1\n",
+      "    sample_time_ms: 7427.068\n",
+      "    update_time_ms: 31.904\n",
+      "  timestamp: 1602492737\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      8 |           213.53 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3540.2345360824743\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_08-52-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 854.4341772151898\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 228.90886715253788\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0118485788504283\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007579043585186203\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010258643926742176\n",
+      "        total_loss: 15.40296204884847\n",
+      "        vf_explained_var: 0.9705337882041931\n",
+      "        vf_loss: 15.412563880284628\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.028125\n",
+      "    gpu_util_percent0: 0.28875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15465717991487304\n",
+      "    mean_env_wait_ms: 1.1788196979458856\n",
+      "    mean_inference_ms: 4.890577734493217\n",
+      "    mean_raw_obs_processing_ms: 0.40947510696166484\n",
+      "  time_since_restore: 239.88541412353516\n",
+      "  time_this_iter_s: 26.354995250701904\n",
+      "  time_total_s: 239.88541412353516\n",
+      "  timers:\n",
+      "    learn_throughput: 8430.599\n",
+      "    learn_time_ms: 19191.043\n",
+      "    sample_throughput: 21948.377\n",
+      "    sample_time_ms: 7371.479\n",
+      "    update_time_ms: 32.818\n",
+      "  timestamp: 1602492764\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |      9 |          239.885 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3518.7373791621912\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_08-53-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.1243386243386\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 232.65247715247702\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 310\n",
+      "  episodes_total: 1890\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9885825465122858\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00694818701595068\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011202118165480593\n",
+      "        total_loss: 19.333553791046143\n",
+      "        vf_explained_var: 0.9741263389587402\n",
+      "        vf_loss: 19.344160079956055\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.171875000000004\n",
+      "    gpu_util_percent0: 0.366875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1537913928501555\n",
+      "    mean_env_wait_ms: 1.1815222635861933\n",
+      "    mean_inference_ms: 4.82769070236409\n",
+      "    mean_raw_obs_processing_ms: 0.40637037872756154\n",
+      "  time_since_restore: 266.2845878601074\n",
+      "  time_this_iter_s: 26.399173736572266\n",
+      "  time_total_s: 266.2845878601074\n",
+      "  timers:\n",
+      "    learn_throughput: 8422.288\n",
+      "    learn_time_ms: 19209.982\n",
+      "    sample_throughput: 22077.44\n",
+      "    sample_time_ms: 7328.386\n",
+      "    update_time_ms: 32.191\n",
+      "  timestamp: 1602492790\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     10 |          266.285 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3508.0286278381045\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_08-53-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.8758519961052\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 234.34446214825948\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 164\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9782296568155289\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0074202436953783035\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011524421182305863\n",
+      "        total_loss: 11.349893887837728\n",
+      "        vf_explained_var: 0.9778836369514465\n",
+      "        vf_loss: 11.360774596532186\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.859375\n",
+      "    gpu_util_percent0: 0.3996875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7750000000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15341298736907588\n",
+      "    mean_env_wait_ms: 1.182803549867535\n",
+      "    mean_inference_ms: 4.800486837254802\n",
+      "    mean_raw_obs_processing_ms: 0.4050289869370817\n",
+      "  time_since_restore: 292.6636288166046\n",
+      "  time_this_iter_s: 26.379040956497192\n",
+      "  time_total_s: 292.6636288166046\n",
+      "  timers:\n",
+      "    learn_throughput: 8427.411\n",
+      "    learn_time_ms: 19198.305\n",
+      "    sample_throughput: 22779.97\n",
+      "    sample_time_ms: 7102.38\n",
+      "    update_time_ms: 32.804\n",
+      "  timestamp: 1602492817\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     11 |          292.664 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3497.526098901099\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_08-54-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 840.8141952983725\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 236.0104069629385\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9659954756498337\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00687529263086617\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011743300943635404\n",
+      "        total_loss: 12.973399877548218\n",
+      "        vf_explained_var: 0.9719108939170837\n",
+      "        vf_loss: 12.984552383422852\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.0375\n",
+      "    gpu_util_percent0: 0.3734375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.778125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15308703300869356\n",
+      "    mean_env_wait_ms: 1.1839233426991242\n",
+      "    mean_inference_ms: 4.776752266580966\n",
+      "    mean_raw_obs_processing_ms: 0.4038223853919892\n",
+      "  time_since_restore: 319.32670307159424\n",
+      "  time_this_iter_s: 26.663074254989624\n",
+      "  time_total_s: 319.32670307159424\n",
+      "  timers:\n",
+      "    learn_throughput: 8410.676\n",
+      "    learn_time_ms: 19236.504\n",
+      "    sample_throughput: 22953.491\n",
+      "    sample_time_ms: 7048.688\n",
+      "    update_time_ms: 34.115\n",
+      "  timestamp: 1602492844\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     12 |          319.327 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3487.3178360101438\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_08-54-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.5388471177945\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 237.452001215159\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 182\n",
+      "  episodes_total: 2394\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9220593820015589\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007104225301494201\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013087665856194993\n",
+      "        total_loss: 14.173670689264933\n",
+      "        vf_explained_var: 0.976102352142334\n",
+      "        vf_loss: 14.186140378316244\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.990624999999998\n",
+      "    gpu_util_percent0: 0.41125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15275050689489206\n",
+      "    mean_env_wait_ms: 1.185314088380426\n",
+      "    mean_inference_ms: 4.752351706120319\n",
+      "    mean_raw_obs_processing_ms: 0.40256148646908374\n",
+      "  time_since_restore: 345.71136808395386\n",
+      "  time_this_iter_s: 26.38466501235962\n",
+      "  time_total_s: 345.71136808395386\n",
+      "  timers:\n",
+      "    learn_throughput: 8421.636\n",
+      "    learn_time_ms: 19211.469\n",
+      "    sample_throughput: 22999.846\n",
+      "    sample_time_ms: 7034.482\n",
+      "    update_time_ms: 32.334\n",
+      "  timestamp: 1602492870\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     13 |          345.711 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3473.3540255831454\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_08-54-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.4810126582279\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 239.5821054927532\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 292\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9201588133970896\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006468101870268583\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012541183774980405\n",
+      "        total_loss: 12.514065821965536\n",
+      "        vf_explained_var: 0.980458676815033\n",
+      "        vf_loss: 12.526052554448446\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.29032258064516\n",
+      "    gpu_util_percent0: 0.26\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.770967741935484\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15228345130729537\n",
+      "    mean_env_wait_ms: 1.187280207898762\n",
+      "    mean_inference_ms: 4.71811277229724\n",
+      "    mean_raw_obs_processing_ms: 0.40084569327447034\n",
+      "  time_since_restore: 371.8659472465515\n",
+      "  time_this_iter_s: 26.154579162597656\n",
+      "  time_total_s: 371.8659472465515\n",
+      "  timers:\n",
+      "    learn_throughput: 8414.105\n",
+      "    learn_time_ms: 19228.665\n",
+      "    sample_throughput: 23061.751\n",
+      "    sample_time_ms: 7015.599\n",
+      "    update_time_ms: 30.845\n",
+      "  timestamp: 1602492896\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     14 |          371.866 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3466.54296875\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_08-55-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.3913502109705\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 240.64524996803468\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9064158648252487\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00678737946630766\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012710827655003717\n",
+      "        total_loss: 10.679505268732706\n",
+      "        vf_explained_var: 0.9777107238769531\n",
+      "        vf_loss: 10.691628138224283\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.15625\n",
+      "    gpu_util_percent0: 0.4253125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.778125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15206312503267996\n",
+      "    mean_env_wait_ms: 1.1882550082909067\n",
+      "    mean_inference_ms: 4.702014857161813\n",
+      "    mean_raw_obs_processing_ms: 0.4000297807155428\n",
+      "  time_since_restore: 398.0466570854187\n",
+      "  time_this_iter_s: 26.180709838867188\n",
+      "  time_total_s: 398.0466570854187\n",
+      "  timers:\n",
+      "    learn_throughput: 8407.018\n",
+      "    learn_time_ms: 19244.874\n",
+      "    sample_throughput: 23146.341\n",
+      "    sample_time_ms: 6989.96\n",
+      "    update_time_ms: 29.278\n",
+      "  timestamp: 1602492923\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     15 |          398.047 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3459.892737054472\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_08-55-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.020652898068\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 241.5691289981762\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8919036090373993\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065164086408913136\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011898661767190788\n",
+      "        total_loss: 10.162490367889404\n",
+      "        vf_explained_var: 0.9785982966423035\n",
+      "        vf_loss: 10.173826615015665\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.645161290322584\n",
+      "    gpu_util_percent0: 0.2887096774193549\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.796774193548387\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15185997816865093\n",
+      "    mean_env_wait_ms: 1.189151489734091\n",
+      "    mean_inference_ms: 4.687070910686898\n",
+      "    mean_raw_obs_processing_ms: 0.3992559422384103\n",
+      "  time_since_restore: 424.27648854255676\n",
+      "  time_this_iter_s: 26.22983145713806\n",
+      "  time_total_s: 424.27648854255676\n",
+      "  timers:\n",
+      "    learn_throughput: 8405.859\n",
+      "    learn_time_ms: 19247.528\n",
+      "    sample_throughput: 23211.371\n",
+      "    sample_time_ms: 6970.377\n",
+      "    update_time_ms: 27.953\n",
+      "  timestamp: 1602492949\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     16 |          424.276 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3451.432941903585\n",
+      "    time_step_min: 3158\n",
+      "  date: 2020-10-12_08-56-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.9087009803922\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 242.70980020796188\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 262\n",
+      "  episodes_total: 3264\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8572876205046972\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006706862438780566\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011741302907466888\n",
+      "        total_loss: 15.199506441752115\n",
+      "        vf_explained_var: 0.97942715883255\n",
+      "        vf_loss: 15.210662841796875\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.09375\n",
+      "    gpu_util_percent0: 0.258125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7750000000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1515595823770812\n",
+      "    mean_env_wait_ms: 1.1906200247039116\n",
+      "    mean_inference_ms: 4.6648538886424795\n",
+      "    mean_raw_obs_processing_ms: 0.3981096057596664\n",
+      "  time_since_restore: 450.64882588386536\n",
+      "  time_this_iter_s: 26.372337341308594\n",
+      "  time_total_s: 450.64882588386536\n",
+      "  timers:\n",
+      "    learn_throughput: 8400.577\n",
+      "    learn_time_ms: 19259.63\n",
+      "    sample_throughput: 23211.151\n",
+      "    sample_time_ms: 6970.443\n",
+      "    update_time_ms: 27.937\n",
+      "  timestamp: 1602492975\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     17 |          450.649 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3445.4002320185614\n",
+      "    time_step_min: 3146\n",
+      "  date: 2020-10-12_08-56-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.5290563866513\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 243.6558072090292\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 212\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8529605269432068\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005917649987774591\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011277009830034027\n",
+      "        total_loss: 11.547587235768637\n",
+      "        vf_explained_var: 0.9794904589653015\n",
+      "        vf_loss: 11.558358192443848\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.915625\n",
+      "    gpu_util_percent0: 0.3628125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.778125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15133785103605502\n",
+      "    mean_env_wait_ms: 1.191584841695774\n",
+      "    mean_inference_ms: 4.648617413271504\n",
+      "    mean_raw_obs_processing_ms: 0.39729234515600503\n",
+      "  time_since_restore: 476.97072649002075\n",
+      "  time_this_iter_s: 26.321900606155396\n",
+      "  time_total_s: 476.97072649002075\n",
+      "  timers:\n",
+      "    learn_throughput: 8395.439\n",
+      "    learn_time_ms: 19271.416\n",
+      "    sample_throughput: 23176.748\n",
+      "    sample_time_ms: 6980.789\n",
+      "    update_time_ms: 28.097\n",
+      "  timestamp: 1602493002\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     18 |          476.971 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3440.769828064337\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_08-57-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.8247110621904\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.29612303552858\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8457075009743372\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065199139062315226\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01116289470034341\n",
+      "        total_loss: 10.043978214263916\n",
+      "        vf_explained_var: 0.9801807403564453\n",
+      "        vf_loss: 10.05457361539205\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.028125000000003\n",
+      "    gpu_util_percent0: 0.3709375\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15118726408563093\n",
+      "    mean_env_wait_ms: 1.1922445706080023\n",
+      "    mean_inference_ms: 4.637558704514457\n",
+      "    mean_raw_obs_processing_ms: 0.39672423215429875\n",
+      "  time_since_restore: 503.39529490470886\n",
+      "  time_this_iter_s: 26.42456841468811\n",
+      "  time_total_s: 503.39529490470886\n",
+      "  timers:\n",
+      "    learn_throughput: 8393.952\n",
+      "    learn_time_ms: 19274.829\n",
+      "    sample_throughput: 23160.391\n",
+      "    sample_time_ms: 6985.72\n",
+      "    update_time_ms: 26.742\n",
+      "  timestamp: 1602493029\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     19 |          503.395 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3436.3805732484075\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_08-57-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.2513171759747\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.92866228140193\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 162\n",
+      "  episodes_total: 3796\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8178661465644836\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006614145318356653\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012304873768395433\n",
+      "        total_loss: 9.505411148071289\n",
+      "        vf_explained_var: 0.9820902943611145\n",
+      "        vf_loss: 9.517136255900065\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.078125\n",
+      "    gpu_util_percent0: 0.35906249999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7750000000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510429657502081\n",
+      "    mean_env_wait_ms: 1.192856382314414\n",
+      "    mean_inference_ms: 4.62689228134805\n",
+      "    mean_raw_obs_processing_ms: 0.396167015727833\n",
+      "  time_since_restore: 530.0132410526276\n",
+      "  time_this_iter_s: 26.6179461479187\n",
+      "  time_total_s: 530.0132410526276\n",
+      "  timers:\n",
+      "    learn_throughput: 8390.823\n",
+      "    learn_time_ms: 19282.018\n",
+      "    sample_throughput: 23114.347\n",
+      "    sample_time_ms: 6999.635\n",
+      "    update_time_ms: 26.699\n",
+      "  timestamp: 1602493055\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     20 |          530.013 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3430.280848963475\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_08-58-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.5730392156863\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 245.9245023767082\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4080\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7949359466632208\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005695687839761376\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010721294248166183\n",
+      "        total_loss: 15.119903961817423\n",
+      "        vf_explained_var: 0.9795476794242859\n",
+      "        vf_loss: 15.13013505935669\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.970967741935496\n",
+      "    gpu_util_percent0: 0.2858064516129032\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.767741935483871\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15081021016993768\n",
+      "    mean_env_wait_ms: 1.1938311523447187\n",
+      "    mean_inference_ms: 4.609823498747463\n",
+      "    mean_raw_obs_processing_ms: 0.3952899981501372\n",
+      "  time_since_restore: 556.0116183757782\n",
+      "  time_this_iter_s: 25.998377323150635\n",
+      "  time_total_s: 556.0116183757782\n",
+      "  timers:\n",
+      "    learn_throughput: 8390.545\n",
+      "    learn_time_ms: 19282.656\n",
+      "    sample_throughput: 23227.118\n",
+      "    sample_time_ms: 6965.651\n",
+      "    update_time_ms: 25.037\n",
+      "  timestamp: 1602493081\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     21 |          556.012 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3425.592968381312\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_08-58-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.3506797937177\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 246.62825157339924\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 186\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7829316059748331\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006042617450778683\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012270252065112194\n",
+      "        total_loss: 7.568831443786621\n",
+      "        vf_explained_var: 0.9859895706176758\n",
+      "        vf_loss: 7.580575466156006\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.241935483870968\n",
+      "    gpu_util_percent0: 0.3670967741935484\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1506735177497089\n",
+      "    mean_env_wait_ms: 1.1943510202197607\n",
+      "    mean_inference_ms: 4.599612224692007\n",
+      "    mean_raw_obs_processing_ms: 0.39477214392820853\n",
+      "  time_since_restore: 582.0807523727417\n",
+      "  time_this_iter_s: 26.0691339969635\n",
+      "  time_total_s: 582.0807523727417\n",
+      "  timers:\n",
+      "    learn_throughput: 8398.157\n",
+      "    learn_time_ms: 19265.179\n",
+      "    sample_throughput: 23366.851\n",
+      "    sample_time_ms: 6923.997\n",
+      "    update_time_ms: 23.8\n",
+      "  timestamp: 1602493108\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | RUNNING  | 172.17.0.4:34085 |     22 |          582.081 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_b7bce_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3422.125568698817\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_08-58-54\n",
+      "  done: true\n",
+      "  episode_len_mean: 823.993444846293\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 247.1778681936909\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: bdb1a6019ef04c8e88e76bae07290266\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7830241670211157\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005572947518279155\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008857697199952478\n",
+      "        total_loss: 9.253699541091919\n",
+      "        vf_explained_var: 0.9810841679573059\n",
+      "        vf_loss: 9.262078205744425\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.900000000000002\n",
+      "    gpu_util_percent0: 0.38935483870967735\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7806451612903222\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 34085\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15056252631630285\n",
+      "    mean_env_wait_ms: 1.1947686150241412\n",
+      "    mean_inference_ms: 4.5914235205060585\n",
+      "    mean_raw_obs_processing_ms: 0.3943504348186309\n",
+      "  time_since_restore: 608.0074863433838\n",
+      "  time_this_iter_s: 25.92673397064209\n",
+      "  time_total_s: 608.0074863433838\n",
+      "  timers:\n",
+      "    learn_throughput: 8400.852\n",
+      "    learn_time_ms: 19258.999\n",
+      "    sample_throughput: 23501.826\n",
+      "    sample_time_ms: 6884.231\n",
+      "    update_time_ms: 23.432\n",
+      "  timestamp: 1602493134\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: b7bce_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | TERMINATED |       |     23 |          608.007 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_b7bce_00000 | TERMINATED |       |     23 |          608.007 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 33868\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_084831-k19ejmk1/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_084831-k19ejmk1/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3110\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 623\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602493134\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4145\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3422.12557\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 297.68687\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 137.9899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.17787\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlunar-sweep-6\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/k19ejmk1\u001b[0m\n",
+      "2020-10-12 08:59:00,730 - wandb.wandb_agent - INFO - Cleaning up finished run: k19ejmk1\n",
+      "2020-10-12 08:59:01,066 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 08:59:01,067 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 08:59:01,069 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --entropy_coeff=0.001 --num_sgd_iter=20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 08:59:06,086 - wandb.wandb_agent - INFO - Running runs: ['9p8ohhdo']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmart-sweep-7\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9p8ohhdo\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_085902-9p8ohhdo\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 08:59:06,809\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=61288)\u001b[0m 2020-10-12 08:59:09,533\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=61262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61195)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61195)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61295)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61295)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61190)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61190)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61283)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61283)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61294)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61294)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61199)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61199)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61227)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61227)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_08-59-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1827852825323741\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007252133606622617\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007616617986059282\n",
+      "        total_loss: 514.7327270507812\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.56551724137931\n",
+      "    gpu_util_percent0: 0.3324137931034483\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.53448275862069\n",
+      "    vram_util_percent0: 0.08326359122832815\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17270807500016586\n",
+      "    mean_env_wait_ms: 1.1842317012917596\n",
+      "    mean_inference_ms: 5.789950795657989\n",
+      "    mean_raw_obs_processing_ms: 0.4621999210029076\n",
+      "  time_since_restore: 24.109928607940674\n",
+      "  time_this_iter_s: 24.109928607940674\n",
+      "  time_total_s: 24.109928607940674\n",
+      "  timers:\n",
+      "    learn_throughput: 10784.327\n",
+      "    learn_time_ms: 15002.512\n",
+      "    sample_throughput: 17871.22\n",
+      "    sample_time_ms: 9053.215\n",
+      "    update_time_ms: 24.824\n",
+      "  timestamp: 1602493179\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      1 |          24.1099 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3625.784722222222\n",
+      "    time_step_min: 3334\n",
+      "  date: 2020-10-12_09-00-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1518987341772\n",
+      "  episode_reward_max: 260.86868686868667\n",
+      "  episode_reward_mean: 216.46180155990257\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.152884711821874\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00817319944811364\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0077804924512747675\n",
+      "        total_loss: 148.78453318277994\n",
+      "        vf_explained_var: 0.7891508936882019\n",
+      "        vf_loss: 148.79183705647787\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.07857142857143\n",
+      "    gpu_util_percent0: 0.32250000000000006\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.739285714285714\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1683284879878786\n",
+      "    mean_env_wait_ms: 1.178056506170735\n",
+      "    mean_inference_ms: 5.592927722285913\n",
+      "    mean_raw_obs_processing_ms: 0.45274332524737865\n",
+      "  time_since_restore: 46.81750416755676\n",
+      "  time_this_iter_s: 22.70757555961609\n",
+      "  time_total_s: 46.81750416755676\n",
+      "  timers:\n",
+      "    learn_throughput: 10943.141\n",
+      "    learn_time_ms: 14784.787\n",
+      "    sample_throughput: 18963.322\n",
+      "    sample_time_ms: 8531.838\n",
+      "    update_time_ms: 53.149\n",
+      "  timestamp: 1602493201\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      2 |          46.8175 | 323584 |  216.462 |              260.869 |              138.293 |            891.152 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3620.9910313901346\n",
+      "    time_step_min: 3288\n",
+      "  date: 2020-10-12_09-00-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 888.1940928270042\n",
+      "  episode_reward_max: 267.8383838383836\n",
+      "  episode_reward_mean: 217.42795038997548\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1462223529815674\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008821873382354775\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010471421875990927\n",
+      "        total_loss: 71.87938245137532\n",
+      "        vf_explained_var: 0.8741273880004883\n",
+      "        vf_loss: 71.88923454284668\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.51538461538462\n",
+      "    gpu_util_percent0: 0.30653846153846154\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16521501150125542\n",
+      "    mean_env_wait_ms: 1.1753342821946675\n",
+      "    mean_inference_ms: 5.414212187886819\n",
+      "    mean_raw_obs_processing_ms: 0.4433768456207202\n",
+      "  time_since_restore: 68.74056553840637\n",
+      "  time_this_iter_s: 21.92306137084961\n",
+      "  time_total_s: 68.74056553840637\n",
+      "  timers:\n",
+      "    learn_throughput: 10970.429\n",
+      "    learn_time_ms: 14748.01\n",
+      "    sample_throughput: 20021.387\n",
+      "    sample_time_ms: 8080.958\n",
+      "    update_time_ms: 42.214\n",
+      "  timestamp: 1602493223\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      3 |          68.7406 | 485376 |  217.428 |              267.838 |              138.293 |            888.194 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3610.417218543046\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-12_09-00-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 886.4018987341772\n",
+      "  episode_reward_max: 269.95959595959573\n",
+      "  episode_reward_mean: 219.13753036696053\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.131478746732076\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009067467879503965\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011158901480181763\n",
+      "        total_loss: 52.418883641560875\n",
+      "        vf_explained_var: 0.9044191241264343\n",
+      "        vf_loss: 52.4293597539266\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.24230769230769\n",
+      "    gpu_util_percent0: 0.3303846153846154\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16294839757268015\n",
+      "    mean_env_wait_ms: 1.173896264673618\n",
+      "    mean_inference_ms: 5.278627360149862\n",
+      "    mean_raw_obs_processing_ms: 0.4360804557101574\n",
+      "  time_since_restore: 90.48964166641235\n",
+      "  time_this_iter_s: 21.74907612800598\n",
+      "  time_total_s: 90.48964166641235\n",
+      "  timers:\n",
+      "    learn_throughput: 10991.757\n",
+      "    learn_time_ms: 14719.394\n",
+      "    sample_throughput: 20693.03\n",
+      "    sample_time_ms: 7818.671\n",
+      "    update_time_ms: 37.178\n",
+      "  timestamp: 1602493245\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      4 |          90.4896 | 647168 |  219.138 |               269.96 |              138.293 |            886.402 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3601.9973753280838\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-12_09-01-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.8126582278481\n",
+      "  episode_reward_max: 269.95959595959573\n",
+      "  episode_reward_mean: 220.24689937348145\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1002709567546844\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.010285430510217944\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010795360606759155\n",
+      "        total_loss: 44.717560450236\n",
+      "        vf_explained_var: 0.9204235076904297\n",
+      "        vf_loss: 44.727399826049805\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.892307692307693\n",
+      "    gpu_util_percent0: 0.2823076923076923\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761538461538461\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16124317623128723\n",
+      "    mean_env_wait_ms: 1.1728483082955226\n",
+      "    mean_inference_ms: 5.1744935019423375\n",
+      "    mean_raw_obs_processing_ms: 0.4302497501616795\n",
+      "  time_since_restore: 112.25396418571472\n",
+      "  time_this_iter_s: 21.764322519302368\n",
+      "  time_total_s: 112.25396418571472\n",
+      "  timers:\n",
+      "    learn_throughput: 11003.41\n",
+      "    learn_time_ms: 14703.805\n",
+      "    sample_throughput: 21119.87\n",
+      "    sample_time_ms: 7660.653\n",
+      "    update_time_ms: 38.54\n",
+      "  timestamp: 1602493267\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      5 |          112.254 | 808960 |  220.247 |               269.96 |              138.293 |            885.813 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3594.594566353187\n",
+      "    time_step_min: 3243\n",
+      "  date: 2020-10-12_09-01-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 883.11269035533\n",
+      "  episode_reward_max: 274.6565656565651\n",
+      "  episode_reward_mean: 221.7977747013278\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 195\n",
+      "  episodes_total: 985\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0551829834779103\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00798146337425957\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008698727258888539\n",
+      "        total_loss: 38.42673524220785\n",
+      "        vf_explained_var: 0.9503893852233887\n",
+      "        vf_loss: 38.43489201863607\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.5037037037037\n",
+      "    gpu_util_percent0: 0.3148148148148148\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7444444444444436\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15962227548441582\n",
+      "    mean_env_wait_ms: 1.1730119604201477\n",
+      "    mean_inference_ms: 5.077774301079153\n",
+      "    mean_raw_obs_processing_ms: 0.4246718082663689\n",
+      "  time_since_restore: 134.24448561668396\n",
+      "  time_this_iter_s: 21.99052143096924\n",
+      "  time_total_s: 134.24448561668396\n",
+      "  timers:\n",
+      "    learn_throughput: 10995.386\n",
+      "    learn_time_ms: 14714.536\n",
+      "    sample_throughput: 21363.685\n",
+      "    sample_time_ms: 7573.225\n",
+      "    update_time_ms: 38.728\n",
+      "  timestamp: 1602493289\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      6 |          134.244 | 970752 |  221.798 |              274.657 |              138.293 |            883.113 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3583.385922330097\n",
+      "    time_step_min: 3223\n",
+      "  date: 2020-10-12_09-01-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.7357594936709\n",
+      "  episode_reward_max: 277.68686868686825\n",
+      "  episode_reward_mean: 223.5254762818052\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 279\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0733901659647624\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009930080346142253\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010789080096098283\n",
+      "        total_loss: 27.276743412017822\n",
+      "        vf_explained_var: 0.9606603980064392\n",
+      "        vf_loss: 27.286620140075684\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.696153846153848\n",
+      "    gpu_util_percent0: 0.3926923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.753846153846154\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15799678062042052\n",
+      "    mean_env_wait_ms: 1.1736655135781597\n",
+      "    mean_inference_ms: 4.977340255902446\n",
+      "    mean_raw_obs_processing_ms: 0.4192058798222829\n",
+      "  time_since_restore: 155.88834595680237\n",
+      "  time_this_iter_s: 21.643860340118408\n",
+      "  time_total_s: 155.88834595680237\n",
+      "  timers:\n",
+      "    learn_throughput: 11010.61\n",
+      "    learn_time_ms: 14694.191\n",
+      "    sample_throughput: 21595.994\n",
+      "    sample_time_ms: 7491.76\n",
+      "    update_time_ms: 35.789\n",
+      "  timestamp: 1602493311\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      7 |          155.888 | 1132544 |  223.525 |              277.687 |              138.293 |            877.736 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3573.615494978479\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-02-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 873.8832630098453\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 224.71825853471407\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0512039462725322\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009337255420784155\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010989288333803415\n",
+      "        total_loss: 20.810040314992268\n",
+      "        vf_explained_var: 0.9638325572013855\n",
+      "        vf_loss: 20.820213794708252\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.796153846153842\n",
+      "    gpu_util_percent0: 0.3565384615384615\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15728626041931107\n",
+      "    mean_env_wait_ms: 1.174324554848766\n",
+      "    mean_inference_ms: 4.933508032757876\n",
+      "    mean_raw_obs_processing_ms: 0.41682252620248256\n",
+      "  time_since_restore: 177.49103927612305\n",
+      "  time_this_iter_s: 21.60269331932068\n",
+      "  time_total_s: 177.49103927612305\n",
+      "  timers:\n",
+      "    learn_throughput: 11029.634\n",
+      "    learn_time_ms: 14668.846\n",
+      "    sample_throughput: 21762.194\n",
+      "    sample_time_ms: 7434.545\n",
+      "    update_time_ms: 34.804\n",
+      "  timestamp: 1602493333\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      8 |          177.491 | 1294336 |  224.718 |              283.444 |              138.293 |            873.883 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3565.3086340206187\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-02-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 870.4778481012659\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 225.85602864083862\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0309100051720936\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009246378981818756\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010212190235809734\n",
+      "        total_loss: 20.242994626363117\n",
+      "        vf_explained_var: 0.9640101790428162\n",
+      "        vf_loss: 20.25238800048828\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.023076923076925\n",
+      "    gpu_util_percent0: 0.3438461538461538\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15665502644242502\n",
+      "    mean_env_wait_ms: 1.1750044143064777\n",
+      "    mean_inference_ms: 4.895217792165296\n",
+      "    mean_raw_obs_processing_ms: 0.41467795490151177\n",
+      "  time_since_restore: 199.20523238182068\n",
+      "  time_this_iter_s: 21.714193105697632\n",
+      "  time_total_s: 199.20523238182068\n",
+      "  timers:\n",
+      "    learn_throughput: 11034.172\n",
+      "    learn_time_ms: 14662.812\n",
+      "    sample_throughput: 21895.441\n",
+      "    sample_time_ms: 7389.301\n",
+      "    update_time_ms: 33.233\n",
+      "  timestamp: 1602493354\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |      9 |          199.205 | 1456128 |  225.856 |              283.444 |              138.293 |            870.478 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3557.434248977206\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-02-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 866.7343300747556\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 227.4051846817803\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 1739\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9909518311421076\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008320549929824969\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010935846860472035\n",
+      "        total_loss: 19.282020409901936\n",
+      "        vf_explained_var: 0.9666249752044678\n",
+      "        vf_loss: 19.292283693949383\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.769230769230766\n",
+      "    gpu_util_percent0: 0.3265384615384616\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15609390168678733\n",
+      "    mean_env_wait_ms: 1.1757625567836965\n",
+      "    mean_inference_ms: 4.861189757025129\n",
+      "    mean_raw_obs_processing_ms: 0.41269138624484064\n",
+      "  time_since_restore: 221.06112408638\n",
+      "  time_this_iter_s: 21.855891704559326\n",
+      "  time_total_s: 221.06112408638\n",
+      "  timers:\n",
+      "    learn_throughput: 11022.72\n",
+      "    learn_time_ms: 14678.046\n",
+      "    sample_throughput: 22023.152\n",
+      "    sample_time_ms: 7346.451\n",
+      "    update_time_ms: 32.472\n",
+      "  timestamp: 1602493376\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     10 |          221.061 | 1617920 |  227.405 |              283.444 |              138.293 |            866.734 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3539.8850916295196\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-03-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 859.5857352222765\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 229.98986938263917\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 308\n",
+      "  episodes_total: 2047\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9655184050401052\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008406333470096191\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008845852552137027\n",
+      "        total_loss: 24.37638807296753\n",
+      "        vf_explained_var: 0.9691322445869446\n",
+      "        vf_loss: 24.384517987569172\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.292307692307695\n",
+      "    gpu_util_percent0: 0.32807692307692304\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.75\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15520738844743057\n",
+      "    mean_env_wait_ms: 1.1775783706239886\n",
+      "    mean_inference_ms: 4.806573187215449\n",
+      "    mean_raw_obs_processing_ms: 0.4096107045646865\n",
+      "  time_since_restore: 242.5982792377472\n",
+      "  time_this_iter_s: 21.537155151367188\n",
+      "  time_total_s: 242.5982792377472\n",
+      "  timers:\n",
+      "    learn_throughput: 11058.94\n",
+      "    learn_time_ms: 14629.973\n",
+      "    sample_throughput: 22674.715\n",
+      "    sample_time_ms: 7135.349\n",
+      "    update_time_ms: 31.807\n",
+      "  timestamp: 1602493398\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     11 |          242.598 | 1779712 |   229.99 |              283.444 |              138.293 |            859.586 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3531.548076923077\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-03-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 856.9538878842676\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 231.21308930169675\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 165\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9565430780251821\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008191000708999733\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010603418719256297\n",
+      "        total_loss: 15.069294850031534\n",
+      "        vf_explained_var: 0.9731817245483398\n",
+      "        vf_loss: 15.079216718673706\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.942307692307686\n",
+      "    gpu_util_percent0: 0.3630769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1548116402186192\n",
+      "    mean_env_wait_ms: 1.1784918721884388\n",
+      "    mean_inference_ms: 4.782256817941978\n",
+      "    mean_raw_obs_processing_ms: 0.40823214259400425\n",
+      "  time_since_restore: 264.3383433818817\n",
+      "  time_this_iter_s: 21.74006414413452\n",
+      "  time_total_s: 264.3383433818817\n",
+      "  timers:\n",
+      "    learn_throughput: 11057.032\n",
+      "    learn_time_ms: 14632.497\n",
+      "    sample_throughput: 23009.407\n",
+      "    sample_time_ms: 7031.559\n",
+      "    update_time_ms: 25.638\n",
+      "  timestamp: 1602493420\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     12 |          264.338 | 1941504 |  231.213 |              283.444 |              138.293 |            856.954 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3523.853970964987\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-04-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 854.989029535865\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 232.36299705919947\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9362313946088155\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008440477463106314\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01189564911207223\n",
+      "        total_loss: 12.665011564890543\n",
+      "        vf_explained_var: 0.975372314453125\n",
+      "        vf_loss: 12.67615556716919\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.184615384615384\n",
+      "    gpu_util_percent0: 0.36076923076923073\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7769230769230764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15446811486850553\n",
+      "    mean_env_wait_ms: 1.1793126946849357\n",
+      "    mean_inference_ms: 4.761021532588441\n",
+      "    mean_raw_obs_processing_ms: 0.40700798732540167\n",
+      "  time_since_restore: 286.0172369480133\n",
+      "  time_this_iter_s: 21.678893566131592\n",
+      "  time_total_s: 286.0172369480133\n",
+      "  timers:\n",
+      "    learn_throughput: 11056.992\n",
+      "    learn_time_ms: 14632.552\n",
+      "    sample_throughput: 23097.527\n",
+      "    sample_time_ms: 7004.733\n",
+      "    update_time_ms: 27.304\n",
+      "  timestamp: 1602493441\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     13 |          286.017 | 2103296 |  232.363 |              283.444 |              138.293 |            854.989 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3516.10499001996\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-04-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.9842084484801\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 233.51754018670704\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 2533\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.914815291762352\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.00748422338316838\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01166970853228122\n",
+      "        total_loss: 14.907468636830648\n",
+      "        vf_explained_var: 0.9727827906608582\n",
+      "        vf_loss: 14.918556292851767\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.930769230769233\n",
+      "    gpu_util_percent0: 0.3576923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1541383191163195\n",
+      "    mean_env_wait_ms: 1.1801036537209806\n",
+      "    mean_inference_ms: 4.740986100983287\n",
+      "    mean_raw_obs_processing_ms: 0.40583169794768054\n",
+      "  time_since_restore: 307.52837777137756\n",
+      "  time_this_iter_s: 21.511140823364258\n",
+      "  time_total_s: 307.52837777137756\n",
+      "  timers:\n",
+      "    learn_throughput: 11064.872\n",
+      "    learn_time_ms: 14622.131\n",
+      "    sample_throughput: 23141.427\n",
+      "    sample_time_ms: 6991.444\n",
+      "    update_time_ms: 27.815\n",
+      "  timestamp: 1602493463\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     14 |          307.528 | 2265088 |  233.518 |              283.444 |              138.293 |            852.984 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3504.3098845598847\n",
+      "    time_step_min: 3185\n",
+      "  date: 2020-10-12_09-04-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 850.7546428571428\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 235.27869769119758\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 267\n",
+      "  episodes_total: 2800\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.878979096810023\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0076557288800055785\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008793464541668072\n",
+      "        total_loss: 14.52612074216207\n",
+      "        vf_explained_var: 0.9794191718101501\n",
+      "        vf_loss: 14.53426194190979\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.834615384615383\n",
+      "    gpu_util_percent0: 0.34461538461538466\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7461538461538457\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15366811327958144\n",
+      "    mean_env_wait_ms: 1.1812971915692976\n",
+      "    mean_inference_ms: 4.712196353201802\n",
+      "    mean_raw_obs_processing_ms: 0.40415147303757676\n",
+      "  time_since_restore: 329.0642874240875\n",
+      "  time_this_iter_s: 21.53590965270996\n",
+      "  time_total_s: 329.0642874240875\n",
+      "  timers:\n",
+      "    learn_throughput: 11080.771\n",
+      "    learn_time_ms: 14601.15\n",
+      "    sample_throughput: 23145.701\n",
+      "    sample_time_ms: 6990.153\n",
+      "    update_time_ms: 26.763\n",
+      "  timestamp: 1602493485\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     15 |          329.064 | 2426880 |  235.279 |              283.444 |              138.293 |            850.755 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3496.693678547411\n",
+      "    time_step_min: 3182\n",
+      "  date: 2020-10-12_09-05-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 849.3787475016655\n",
+      "  episode_reward_max: 291.32323232323205\n",
+      "  episode_reward_mean: 236.53021554653785\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 202\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8884957184394201\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008369801216758788\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011218314505337426\n",
+      "        total_loss: 9.95873467127482\n",
+      "        vf_explained_var: 0.9824435710906982\n",
+      "        vf_loss: 9.969167629877726\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.73076923076923\n",
+      "    gpu_util_percent0: 0.31269230769230766\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15336117339517932\n",
+      "    mean_env_wait_ms: 1.1820576545560504\n",
+      "    mean_inference_ms: 4.692950490977445\n",
+      "    mean_raw_obs_processing_ms: 0.40307043117947566\n",
+      "  time_since_restore: 350.6308124065399\n",
+      "  time_this_iter_s: 21.566524982452393\n",
+      "  time_total_s: 350.6308124065399\n",
+      "  timers:\n",
+      "    learn_throughput: 11094.652\n",
+      "    learn_time_ms: 14582.882\n",
+      "    sample_throughput: 23230.68\n",
+      "    sample_time_ms: 6964.583\n",
+      "    update_time_ms: 27.054\n",
+      "  timestamp: 1602493506\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     16 |          350.631 | 2588672 |   236.53 |              291.323 |              138.293 |            849.379 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3490.016922094508\n",
+      "    time_step_min: 3177\n",
+      "  date: 2020-10-12_09-05-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.128164556962\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 237.6207965733281\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8844639857610067\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009058436146005988\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010142707930450948\n",
+      "        total_loss: 10.037593603134155\n",
+      "        vf_explained_var: 0.9795668721199036\n",
+      "        vf_loss: 10.046809116999308\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.138461538461534\n",
+      "    gpu_util_percent0: 0.3169230769230769\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15313766348281804\n",
+      "    mean_env_wait_ms: 1.1826199558285937\n",
+      "    mean_inference_ms: 4.679197423372631\n",
+      "    mean_raw_obs_processing_ms: 0.4022791309942792\n",
+      "  time_since_restore: 372.391544342041\n",
+      "  time_this_iter_s: 21.7607319355011\n",
+      "  time_total_s: 372.391544342041\n",
+      "  timers:\n",
+      "    learn_throughput: 11083.646\n",
+      "    learn_time_ms: 14597.363\n",
+      "    sample_throughput: 23245.692\n",
+      "    sample_time_ms: 6960.085\n",
+      "    update_time_ms: 27.493\n",
+      "  timestamp: 1602493528\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     17 |          372.392 | 2750464 |  237.621 |              293.596 |              138.293 |            848.128 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3483.7223572296475\n",
+      "    time_step_min: 3177\n",
+      "  date: 2020-10-12_09-05-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.2674698795181\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 238.54772118778135\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 3320\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8548314025004705\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008516259181002775\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011190916178748012\n",
+      "        total_loss: 9.76652201016744\n",
+      "        vf_explained_var: 0.9812417030334473\n",
+      "        vf_loss: 9.776864449183146\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.88461538461539\n",
+      "    gpu_util_percent0: 0.34500000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1529240572320849\n",
+      "    mean_env_wait_ms: 1.183106468357993\n",
+      "    mean_inference_ms: 4.666240516840153\n",
+      "    mean_raw_obs_processing_ms: 0.40152035844583606\n",
+      "  time_since_restore: 394.34070897102356\n",
+      "  time_this_iter_s: 21.949164628982544\n",
+      "  time_total_s: 394.34070897102356\n",
+      "  timers:\n",
+      "    learn_throughput: 11064.223\n",
+      "    learn_time_ms: 14622.988\n",
+      "    sample_throughput: 23222.449\n",
+      "    sample_time_ms: 6967.052\n",
+      "    update_time_ms: 26.672\n",
+      "  timestamp: 1602493550\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     18 |          394.341 | 2912256 |  238.548 |              293.596 |              138.293 |            847.267 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3476.3166714001704\n",
+      "    time_step_min: 3177\n",
+      "  date: 2020-10-12_09-06-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 846.5122569737954\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 239.51551013089468\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 229\n",
+      "  episodes_total: 3549\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8149505207935969\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0059012921604638295\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00783768025454871\n",
+      "        total_loss: 12.426872173945108\n",
+      "        vf_explained_var: 0.9817931056022644\n",
+      "        vf_loss: 12.43434445063273\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.233333333333327\n",
+      "    gpu_util_percent0: 0.36777777777777776\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1526486696957768\n",
+      "    mean_env_wait_ms: 1.1837581265941555\n",
+      "    mean_inference_ms: 4.649506556049909\n",
+      "    mean_raw_obs_processing_ms: 0.40053669449346774\n",
+      "  time_since_restore: 416.0491623878479\n",
+      "  time_this_iter_s: 21.70845341682434\n",
+      "  time_total_s: 416.0491623878479\n",
+      "  timers:\n",
+      "    learn_throughput: 11075.836\n",
+      "    learn_time_ms: 14607.656\n",
+      "    sample_throughput: 23179.907\n",
+      "    sample_time_ms: 6979.838\n",
+      "    update_time_ms: 27.896\n",
+      "  timestamp: 1602493572\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     19 |          416.049 | 3074048 |  239.516 |              293.596 |              138.293 |            846.512 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3470.7743740010656\n",
+      "    time_step_min: 3177\n",
+      "  date: 2020-10-12_09-06-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.9870438921206\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 240.40188238813298\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 233\n",
+      "  episodes_total: 3782\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8266270160675049\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007779809723918636\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010379398086418709\n",
+      "        total_loss: 11.921677827835083\n",
+      "        vf_explained_var: 0.981447696685791\n",
+      "        vf_loss: 11.931328058242798\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.01538461538462\n",
+      "    gpu_util_percent0: 0.33692307692307694\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15239744721691542\n",
+      "    mean_env_wait_ms: 1.1842913223565388\n",
+      "    mean_inference_ms: 4.633907213688482\n",
+      "    mean_raw_obs_processing_ms: 0.39965976455472496\n",
+      "  time_since_restore: 437.7389130592346\n",
+      "  time_this_iter_s: 21.68975067138672\n",
+      "  time_total_s: 437.7389130592346\n",
+      "  timers:\n",
+      "    learn_throughput: 11082.98\n",
+      "    learn_time_ms: 14598.24\n",
+      "    sample_throughput: 23209.057\n",
+      "    sample_time_ms: 6971.072\n",
+      "    update_time_ms: 28.473\n",
+      "  timestamp: 1602493594\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     20 |          437.739 | 3235840 |  240.402 |              293.596 |              138.293 |            845.987 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3466.7972972972975\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_09-06-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.693417721519\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 240.8964966116864\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 168\n",
+      "  episodes_total: 3950\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8171754479408264\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0071926506934687495\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00922989979153499\n",
+      "        total_loss: 10.540773471196493\n",
+      "        vf_explained_var: 0.9810445308685303\n",
+      "        vf_loss: 10.549381573994955\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.915384615384617\n",
+      "    gpu_util_percent0: 0.39499999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.776923076923077\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1522306926361245\n",
+      "    mean_env_wait_ms: 1.1846476379178812\n",
+      "    mean_inference_ms: 4.6236738492529454\n",
+      "    mean_raw_obs_processing_ms: 0.39909001931172966\n",
+      "  time_since_restore: 459.36714267730713\n",
+      "  time_this_iter_s: 21.62822961807251\n",
+      "  time_total_s: 459.36714267730713\n",
+      "  timers:\n",
+      "    learn_throughput: 11081.903\n",
+      "    learn_time_ms: 14599.659\n",
+      "    sample_throughput: 23187.793\n",
+      "    sample_time_ms: 6977.464\n",
+      "    update_time_ms: 28.809\n",
+      "  timestamp: 1602493616\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     21 |          459.367 | 3397632 |  240.896 |              293.596 |              138.293 |            845.693 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3463.1188725490197\n",
+      "    time_step_min: 3162\n",
+      "  date: 2020-10-12_09-07-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 844.7930866601753\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 241.4936315442644\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8059266755978266\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009029871318489313\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008191939976920063\n",
+      "        total_loss: 9.447596470514933\n",
+      "        vf_explained_var: 0.9807239174842834\n",
+      "        vf_loss: 9.45478860537211\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.98076923076923\n",
+      "    gpu_util_percent0: 0.3611538461538461\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7769230769230764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15208264388982512\n",
+      "    mean_env_wait_ms: 1.1849863794656472\n",
+      "    mean_inference_ms: 4.61455209890159\n",
+      "    mean_raw_obs_processing_ms: 0.3985701308073426\n",
+      "  time_since_restore: 481.05792474746704\n",
+      "  time_this_iter_s: 21.690782070159912\n",
+      "  time_total_s: 481.05792474746704\n",
+      "  timers:\n",
+      "    learn_throughput: 11080.848\n",
+      "    learn_time_ms: 14601.049\n",
+      "    sample_throughput: 23178.999\n",
+      "    sample_time_ms: 6980.112\n",
+      "    update_time_ms: 29.432\n",
+      "  timestamp: 1602493638\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     22 |          481.058 | 3559424 |  241.494 |              293.596 |              138.293 |            844.793 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3459.0384615384614\n",
+      "    time_step_min: 3162\n",
+      "  date: 2020-10-12_09-07-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.6079203334878\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 242.17379445216403\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 210\n",
+      "  episodes_total: 4318\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7677705784638723\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008771082696815332\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009407734837926304\n",
+      "        total_loss: 12.319875399271647\n",
+      "        vf_explained_var: 0.9799962043762207\n",
+      "        vf_loss: 12.328296820322672\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.765384615384615\n",
+      "    gpu_util_percent0: 0.32230769230769235\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15189745302753577\n",
+      "    mean_env_wait_ms: 1.1854631073101427\n",
+      "    mean_inference_ms: 4.603314572970354\n",
+      "    mean_raw_obs_processing_ms: 0.3979223065249024\n",
+      "  time_since_restore: 502.7509262561798\n",
+      "  time_this_iter_s: 21.69300150871277\n",
+      "  time_total_s: 502.7509262561798\n",
+      "  timers:\n",
+      "    learn_throughput: 11086.305\n",
+      "    learn_time_ms: 14593.862\n",
+      "    sample_throughput: 23147.81\n",
+      "    sample_time_ms: 6989.517\n",
+      "    update_time_ms: 28.003\n",
+      "  timestamp: 1602493659\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     23 |          502.751 | 3721216 |  242.174 |              293.596 |              138.293 |            843.608 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3453.384700176367\n",
+      "    time_step_min: 3162\n",
+      "  date: 2020-10-12_09-08-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.4776511831726\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 243.03763754990743\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 246\n",
+      "  episodes_total: 4564\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.754533514380455\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007815885241143405\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0092500797448641\n",
+      "        total_loss: 10.229537963867188\n",
+      "        vf_explained_var: 0.9839439392089844\n",
+      "        vf_loss: 10.237979650497437\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.830769230769228\n",
+      "    gpu_util_percent0: 0.3080769230769231\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15169897381901554\n",
+      "    mean_env_wait_ms: 1.185963947492432\n",
+      "    mean_inference_ms: 4.590924580195164\n",
+      "    mean_raw_obs_processing_ms: 0.39722662264480574\n",
+      "  time_since_restore: 524.5083110332489\n",
+      "  time_this_iter_s: 21.757384777069092\n",
+      "  time_total_s: 524.5083110332489\n",
+      "  timers:\n",
+      "    learn_throughput: 11064.753\n",
+      "    learn_time_ms: 14622.287\n",
+      "    sample_throughput: 23162.686\n",
+      "    sample_time_ms: 6985.028\n",
+      "    update_time_ms: 27.57\n",
+      "  timestamp: 1602493681\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     24 |          524.508 | 3883008 |  243.038 |              293.596 |              138.293 |            842.478 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3449.6651103565364\n",
+      "    time_step_min: 3162\n",
+      "  date: 2020-10-12_09-08-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.5301687763713\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 243.61066359800532\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 176\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7572712302207947\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006765442124257485\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010398247444148486\n",
+      "        total_loss: 10.084507862726847\n",
+      "        vf_explained_var: 0.9806730151176453\n",
+      "        vf_loss: 10.094310283660889\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.67037037037037\n",
+      "    gpu_util_percent0: 0.3222222222222222\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.781481481481481\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15156971425403531\n",
+      "    mean_env_wait_ms: 1.1863243146687548\n",
+      "    mean_inference_ms: 4.582885729339996\n",
+      "    mean_raw_obs_processing_ms: 0.3967946175107939\n",
+      "  time_since_restore: 546.6698186397552\n",
+      "  time_this_iter_s: 22.161507606506348\n",
+      "  time_total_s: 546.6698186397552\n",
+      "  timers:\n",
+      "    learn_throughput: 11020.151\n",
+      "    learn_time_ms: 14681.469\n",
+      "    sample_throughput: 23152.27\n",
+      "    sample_time_ms: 6988.17\n",
+      "    update_time_ms: 26.598\n",
+      "  timestamp: 1602493704\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     25 |           546.67 | 4044800 |  243.611 |              293.596 |              138.293 |             841.53 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3446.0199096880133\n",
+      "    time_step_min: 3143\n",
+      "  date: 2020-10-12_09-08-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 840.7914285714286\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 244.18099360956498\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 4900\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7502193301916122\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007255109104638298\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007779860898153856\n",
+      "        total_loss: 8.407378196716309\n",
+      "        vf_explained_var: 0.9829282760620117\n",
+      "        vf_loss: 8.414457241694132\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.6\n",
+      "    gpu_util_percent0: 0.32500000000000007\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.788461538461538\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1514547133877412\n",
+      "    mean_env_wait_ms: 1.1866431863334181\n",
+      "    mean_inference_ms: 4.575851559812878\n",
+      "    mean_raw_obs_processing_ms: 0.39639999605166304\n",
+      "  time_since_restore: 568.4001824855804\n",
+      "  time_this_iter_s: 21.730363845825195\n",
+      "  time_total_s: 568.4001824855804\n",
+      "  timers:\n",
+      "    learn_throughput: 11010.05\n",
+      "    learn_time_ms: 14694.937\n",
+      "    sample_throughput: 23139.623\n",
+      "    sample_time_ms: 6991.989\n",
+      "    update_time_ms: 24.748\n",
+      "  timestamp: 1602493725\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     26 |            568.4 | 4206592 |  244.181 |              293.596 |              138.293 |            840.791 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3441.1055632003145\n",
+      "    time_step_min: 3143\n",
+      "  date: 2020-10-12_09-09-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.7184750733138\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 244.85938564530935\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 215\n",
+      "  episodes_total: 5115\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7258548388878504\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.005995944142341614\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00881769720823892\n",
+      "        total_loss: 12.80167587598165\n",
+      "        vf_explained_var: 0.9796185493469238\n",
+      "        vf_loss: 12.810020287831625\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.50384615384615\n",
+      "    gpu_util_percent0: 0.3807692307692308\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130938128528826\n",
+      "    mean_env_wait_ms: 1.1870839040728018\n",
+      "    mean_inference_ms: 4.567077973491149\n",
+      "    mean_raw_obs_processing_ms: 0.3959029906777852\n",
+      "  time_since_restore: 589.9252982139587\n",
+      "  time_this_iter_s: 21.525115728378296\n",
+      "  time_total_s: 589.9252982139587\n",
+      "  timers:\n",
+      "    learn_throughput: 11022.287\n",
+      "    learn_time_ms: 14678.624\n",
+      "    sample_throughput: 23164.787\n",
+      "    sample_time_ms: 6984.394\n",
+      "    update_time_ms: 24.259\n",
+      "  timestamp: 1602493747\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | RUNNING  | 172.17.0.4:61288 |     27 |          589.925 | 4368384 |  244.859 |              293.596 |              138.293 |            839.718 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2ff5d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3435.807771728928\n",
+      "    time_step_min: 3143\n",
+      "  date: 2020-10-12_09-09-29\n",
+      "  done: true\n",
+      "  episode_len_mean: 838.581512605042\n",
+      "  episode_reward_max: 293.59595959595947\n",
+      "  episode_reward_mean: 245.61831197125315\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 240\n",
+      "  episodes_total: 5355\n",
+      "  experiment_id: 53eea350ceb84a0185dd431d0f55a03d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7102122207482656\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007275186013430357\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01022022515341329\n",
+      "        total_loss: 8.86198623975118\n",
+      "        vf_explained_var: 0.9859199523925781\n",
+      "        vf_loss: 8.871461629867554\n",
+      "    num_steps_sampled: 4530176\n",
+      "    num_steps_trained: 4530176\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.707692307692305\n",
+      "    gpu_util_percent0: 0.4034615384615385\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761538461538461\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61288\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15116122180138195\n",
+      "    mean_env_wait_ms: 1.1875290665151548\n",
+      "    mean_inference_ms: 4.557807153575949\n",
+      "    mean_raw_obs_processing_ms: 0.3953896112400835\n",
+      "  time_since_restore: 611.5453379154205\n",
+      "  time_this_iter_s: 21.620039701461792\n",
+      "  time_total_s: 611.5453379154205\n",
+      "  timers:\n",
+      "    learn_throughput: 11042.42\n",
+      "    learn_time_ms: 14651.86\n",
+      "    sample_throughput: 23203.388\n",
+      "    sample_time_ms: 6972.775\n",
+      "    update_time_ms: 24.119\n",
+      "  timestamp: 1602493769\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4530176\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 2ff5d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | TERMINATED |       |     28 |          611.545 | 4530176 |  245.618 |              293.596 |              138.293 |            838.582 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2ff5d_00000 | TERMINATED |       |     28 |          611.545 | 4530176 |  245.618 |              293.596 |              138.293 |            838.582 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 61032\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_085902-9p8ohhdo/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_085902-9p8ohhdo/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3143\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 627\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602493769\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4143\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3435.80777\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 293.59596\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.29293\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 245.61831\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5355\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msmart-sweep-7\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/9p8ohhdo\u001b[0m\n",
+      "2020-10-12 09:09:36,758 - wandb.wandb_agent - INFO - Cleaning up finished run: 9p8ohhdo\n",
+      "2020-10-12 09:09:37,090 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 09:09:37,090 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tentropy_coeff: 0.001\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 09:09:37,092 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --entropy_coeff=0.001 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 09:09:42,110 - wandb.wandb_agent - INFO - Running runs: ['sytvyrt5']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-sweep-8\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/sytvyrt5\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_090938-sytvyrt5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 09:09:42,767\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m F1012 09:09:44.974668 11539 11539 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m F1012 09:09:44.974699 11518 11518 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f61268a26ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m F1012 09:09:44.974720 11521 11521 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b9096ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m F1012 09:09:44.974675 11541 11541 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:38247\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23e256ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf39896ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf398a84c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f61268a384c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b90a84c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b9093c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23e2684c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23e253c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf39893c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf39895e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf3940789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f61268a23c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f61268a25e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f6126859789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b9095e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23e255e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23ddc789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf36841ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf36842ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f612659d1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f612659d2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b8c0789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b6041ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b6042ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23b201ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23b202ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23b20491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf3684491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf3686801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f612659d491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f612659f801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f61264ae7a8  ray::gcs::GlobalStateAccessor::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b604491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b606801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23b22801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23aa3ed6  ray::CoreWorker::CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf3607ed6  ray::CoreWorker::CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf360bc14  ray::CoreWorkerProcess::CreateWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f612641fa2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4aa98a  method_vectorcall_NOARGS\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f43ab08  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c56a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c6a20  method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f43bde6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c5baf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c6643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f43bde6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c56a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4c6454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f554bbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f554c64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b5157a8  ray::gcs::GlobalStateAccessor::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20b486a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054c398a  method_vectorcall_NOARGS\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305453b08  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054de6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054dfa20  method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305454de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054debaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054df643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305454de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054de6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23aa7c14  ray::CoreWorkerProcess::CreateWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23aa8e82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf360ce82  ray::CoreWorkerProcess::CoreWorkerProcess()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf360d84b  ray::CoreWorkerProcess::Initialize()\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f586d14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f44f625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f44fa0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f4508cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f589829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x7f6127ba7840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=11518)\u001b[0m     @     0x56500f519b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054df454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x55830556dbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x55830556dc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x55830559fd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305468625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305468a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583054698cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x5583055a2829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e23aa984b  ray::CoreWorkerProcess::Initialize()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e239e7448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf354b448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf354cba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b88f37d  _PyObject_MakeTpCall\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b917d09  _PyEval_EvalFrameDefault\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b8dcbaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b8dd643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b852de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x7fd20cc0e840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=11521)\u001b[0m     @     0x558305532b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e239e8ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc062137d  _PyObject_MakeTpCall\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc06a9d09  _PyEval_EvalFrameDefault\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc066ebaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc066f643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc05e4de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc066e6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc066f454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b8dc6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b8dd454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b96bbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b96bc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b99dd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b866625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b866a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b8678cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b9a0829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc06fdbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc06fdc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc072fd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc05f8625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc05f8a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc05f98cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc0732829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x7f0bf4c8e840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=11539)\u001b[0m     @     0x55e42b930b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x7f4e2512a840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=11541)\u001b[0m     @     0x564bc06c2b33  (unknown)\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1012 09:09:45.152127 11475 11475 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1012 09:09:45.187711 11475 11475 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed\n",
+      "\u001b[2m\u001b[36m(pid=11639)\u001b[0m 2020-10-12 09:09:45,605\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=11607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11634)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11634)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11523)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11523)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11529)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11529)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11602)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11602)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11532)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11538)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11538)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11616)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11616)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11519)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11520)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11594)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11594)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11536)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11536)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11526)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11526)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11537)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11537)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11619)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11619)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11630)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11630)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11544)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11544)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=12931)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=12931)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11522)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11522)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11524)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11524)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11601)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11601)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11528)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11528)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11578)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11578)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=12930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=12930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=12932)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=12932)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=12929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=12929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_09-10-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.182355095942815\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.006899550712356965\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009150916089614233\n",
+      "        total_loss: 507.0743637084961\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.500000000000004\n",
+      "    gpu_util_percent0: 0.27060606060606057\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5757575757575757\n",
+      "    vram_util_percent0: 0.08736346740610434\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1709314554184445\n",
+      "    mean_env_wait_ms: 1.1781879618198061\n",
+      "    mean_inference_ms: 5.888402364106044\n",
+      "    mean_raw_obs_processing_ms: 0.4616009846775942\n",
+      "  time_since_restore: 28.510921239852905\n",
+      "  time_this_iter_s: 28.510921239852905\n",
+      "  time_total_s: 28.510921239852905\n",
+      "  timers:\n",
+      "    learn_throughput: 8407.548\n",
+      "    learn_time_ms: 19243.66\n",
+      "    sample_throughput: 17607.121\n",
+      "    sample_time_ms: 9189.009\n",
+      "    update_time_ms: 44.64\n",
+      "  timestamp: 1602493819\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.9/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      1 |          28.5109 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3608.8263888888887\n",
+      "    time_step_min: 3346\n",
+      "  date: 2020-10-12_09-10-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 892.506329113924\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 218.37156373865213\n",
+      "  episode_reward_min: 143.74747474747463\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.149287035067876\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.007768862143469353\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011663281096844003\n",
+      "        total_loss: 125.33597246805827\n",
+      "        vf_explained_var: 0.8107926249504089\n",
+      "        vf_loss: 125.34722963968913\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.083870967741934\n",
+      "    gpu_util_percent0: 0.2783870967741936\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.767741935483871\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16605058809426132\n",
+      "    mean_env_wait_ms: 1.1724585850409024\n",
+      "    mean_inference_ms: 5.608469227957835\n",
+      "    mean_raw_obs_processing_ms: 0.44818381015639347\n",
+      "  time_since_restore: 55.49300575256348\n",
+      "  time_this_iter_s: 26.98208451271057\n",
+      "  time_total_s: 55.49300575256348\n",
+      "  timers:\n",
+      "    learn_throughput: 8410.298\n",
+      "    learn_time_ms: 19237.369\n",
+      "    sample_throughput: 19205.99\n",
+      "    sample_time_ms: 8424.038\n",
+      "    update_time_ms: 41.79\n",
+      "  timestamp: 1602493846\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      2 |           55.493 | 323584 |  218.372 |              264.354 |              143.747 |            892.506 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3600.177130044843\n",
+      "    time_step_min: 3312\n",
+      "  date: 2020-10-12_09-11-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 888.2679324894515\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 220.42245237181922\n",
+      "  episode_reward_min: 143.74747474747463\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1440819799900055\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.012469007167965174\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013894526307315877\n",
+      "        total_loss: 55.279540061950684\n",
+      "        vf_explained_var: 0.8949055075645447\n",
+      "        vf_loss: 55.29208596547445\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.58709677419355\n",
+      "    gpu_util_percent0: 0.4445161290322581\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.790322580645162\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16301342233903654\n",
+      "    mean_env_wait_ms: 1.1710658606447342\n",
+      "    mean_inference_ms: 5.413075620264339\n",
+      "    mean_raw_obs_processing_ms: 0.43901216608845256\n",
+      "  time_since_restore: 82.09788537025452\n",
+      "  time_this_iter_s: 26.60487961769104\n",
+      "  time_total_s: 82.09788537025452\n",
+      "  timers:\n",
+      "    learn_throughput: 8409.789\n",
+      "    learn_time_ms: 19238.532\n",
+      "    sample_throughput: 20121.751\n",
+      "    sample_time_ms: 8040.652\n",
+      "    update_time_ms: 41.813\n",
+      "  timestamp: 1602493873\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      3 |          82.0979 | 485376 |  220.422 |              264.354 |              143.747 |            888.268 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3592.248344370861\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-12_09-11-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 887.4762658227849\n",
+      "  episode_reward_max: 276.7777777777773\n",
+      "  episode_reward_mean: 221.1168169032091\n",
+      "  episode_reward_min: 143.74747474747463\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1269059876600902\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.0107233178957055\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013501833062036894\n",
+      "        total_loss: 41.97398853302002\n",
+      "        vf_explained_var: 0.9246423840522766\n",
+      "        vf_loss: 41.98647212982178\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.654838709677417\n",
+      "    gpu_util_percent0: 0.3119354838709677\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7967741935483863\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16088157000858677\n",
+      "    mean_env_wait_ms: 1.1702201553059415\n",
+      "    mean_inference_ms: 5.271199229980809\n",
+      "    mean_raw_obs_processing_ms: 0.4321947251479392\n",
+      "  time_since_restore: 108.49108576774597\n",
+      "  time_this_iter_s: 26.393200397491455\n",
+      "  time_total_s: 108.49108576774597\n",
+      "  timers:\n",
+      "    learn_throughput: 8419.173\n",
+      "    learn_time_ms: 19217.089\n",
+      "    sample_throughput: 20743.31\n",
+      "    sample_time_ms: 7799.719\n",
+      "    update_time_ms: 57.526\n",
+      "  timestamp: 1602493899\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      4 |          108.491 | 647168 |  221.117 |              276.778 |              143.747 |            887.476 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3590.7965879265093\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-12_09-12-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 883.4784810126582\n",
+      "  episode_reward_max: 276.7777777777773\n",
+      "  episode_reward_mean: 222.1676895537653\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.099730372428894\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.010723261473079523\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01573065633419901\n",
+      "        total_loss: 36.1703904469808\n",
+      "        vf_explained_var: 0.9362662434577942\n",
+      "        vf_loss: 36.18507480621338\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.289999999999996\n",
+      "    gpu_util_percent0: 0.37566666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15926300672453003\n",
+      "    mean_env_wait_ms: 1.1702455143397732\n",
+      "    mean_inference_ms: 5.164355253128473\n",
+      "    mean_raw_obs_processing_ms: 0.4266825704252954\n",
+      "  time_since_restore: 134.8220145702362\n",
+      "  time_this_iter_s: 26.330928802490234\n",
+      "  time_total_s: 134.8220145702362\n",
+      "  timers:\n",
+      "    learn_throughput: 8424.121\n",
+      "    learn_time_ms: 19205.801\n",
+      "    sample_throughput: 21124.398\n",
+      "    sample_time_ms: 7659.011\n",
+      "    update_time_ms: 51.085\n",
+      "  timestamp: 1602493925\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      5 |          134.822 | 808960 |  222.168 |              276.778 |              123.293 |            883.478 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3577.4291300097752\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-12_09-12-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 876.5889628924833\n",
+      "  episode_reward_max: 276.7777777777773\n",
+      "  episode_reward_mean: 224.38236792280537\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 261\n",
+      "  episodes_total: 1051\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0695344706376393\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.011311198429514965\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013925497497742375\n",
+      "        total_loss: 34.00605169932047\n",
+      "        vf_explained_var: 0.9589201807975769\n",
+      "        vf_loss: 34.018784523010254\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.090322580645154\n",
+      "    gpu_util_percent0: 0.2767741935483871\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1573920417937042\n",
+      "    mean_env_wait_ms: 1.172214831327009\n",
+      "    mean_inference_ms: 5.040071713656986\n",
+      "    mean_raw_obs_processing_ms: 0.4202543153320228\n",
+      "  time_since_restore: 161.29357409477234\n",
+      "  time_this_iter_s: 26.471559524536133\n",
+      "  time_total_s: 161.29357409477234\n",
+      "  timers:\n",
+      "    learn_throughput: 8421.719\n",
+      "    learn_time_ms: 19211.279\n",
+      "    sample_throughput: 21366.692\n",
+      "    sample_time_ms: 7572.16\n",
+      "    update_time_ms: 49.828\n",
+      "  timestamp: 1602493952\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      6 |          161.294 | 970752 |  224.382 |              276.778 |              123.293 |            876.589 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3570.6642394822006\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-12_09-12-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 873.5340189873418\n",
+      "  episode_reward_max: 276.7777777777773\n",
+      "  episode_reward_mean: 225.2434471295229\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 213\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.074757029612859\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009882260967666904\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0106422333434845\n",
+      "        total_loss: 24.986013253529865\n",
+      "        vf_explained_var: 0.9613370895385742\n",
+      "        vf_loss: 24.99575424194336\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.040000000000003\n",
+      "    gpu_util_percent0: 0.33499999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8033333333333337\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15627850769846607\n",
+      "    mean_env_wait_ms: 1.173120070322761\n",
+      "    mean_inference_ms: 4.965893468385096\n",
+      "    mean_raw_obs_processing_ms: 0.4164646233124774\n",
+      "  time_since_restore: 187.7696831226349\n",
+      "  time_this_iter_s: 26.47610902786255\n",
+      "  time_total_s: 187.7696831226349\n",
+      "  timers:\n",
+      "    learn_throughput: 8413.946\n",
+      "    learn_time_ms: 19229.029\n",
+      "    sample_throughput: 21590.852\n",
+      "    sample_time_ms: 7493.544\n",
+      "    update_time_ms: 48.386\n",
+      "  timestamp: 1602493978\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      7 |           187.77 | 1132544 |  225.243 |              276.778 |              123.293 |            873.534 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3562.3916786226687\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-12_09-13-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 870.5189873417721\n",
+      "  episode_reward_max: 280.26262626262564\n",
+      "  episode_reward_mean: 226.60186250692564\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0478589634100597\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.01174442881407837\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014641193168548247\n",
+      "        total_loss: 17.139351685841877\n",
+      "        vf_explained_var: 0.9697672724723816\n",
+      "        vf_loss: 17.152692159016926\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.78064516129032\n",
+      "    gpu_util_percent0: 0.4012903225806452\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7935483870967737\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15561437925844776\n",
+      "    mean_env_wait_ms: 1.1739122541840687\n",
+      "    mean_inference_ms: 4.9212315832210916\n",
+      "    mean_raw_obs_processing_ms: 0.41412802790411113\n",
+      "  time_since_restore: 214.15947604179382\n",
+      "  time_this_iter_s: 26.389792919158936\n",
+      "  time_total_s: 214.15947604179382\n",
+      "  timers:\n",
+      "    learn_throughput: 8413.294\n",
+      "    learn_time_ms: 19230.517\n",
+      "    sample_throughput: 21749.461\n",
+      "    sample_time_ms: 7438.897\n",
+      "    update_time_ms: 47.571\n",
+      "  timestamp: 1602494005\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      8 |          214.159 | 1294336 |  226.602 |              280.263 |              123.293 |            870.519 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3553.064432989691\n",
+      "    time_step_min: 3210\n",
+      "  date: 2020-10-12_09-13-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 866.9943037974683\n",
+      "  episode_reward_max: 280.26262626262564\n",
+      "  episode_reward_mean: 228.16375783147922\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0198639531930287\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.011228926635036865\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013478583695056537\n",
+      "        total_loss: 16.173202673594158\n",
+      "        vf_explained_var: 0.9687080383300781\n",
+      "        vf_loss: 16.185454845428467\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.146666666666665\n",
+      "    gpu_util_percent0: 0.29933333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.796666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1550431438401806\n",
+      "    mean_env_wait_ms: 1.1747210313127066\n",
+      "    mean_inference_ms: 4.882125370722626\n",
+      "    mean_raw_obs_processing_ms: 0.4120349560638267\n",
+      "  time_since_restore: 240.35650873184204\n",
+      "  time_this_iter_s: 26.197032690048218\n",
+      "  time_total_s: 240.35650873184204\n",
+      "  timers:\n",
+      "    learn_throughput: 8413.229\n",
+      "    learn_time_ms: 19230.667\n",
+      "    sample_throughput: 21937.656\n",
+      "    sample_time_ms: 7375.081\n",
+      "    update_time_ms: 46.434\n",
+      "  timestamp: 1602494031\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |      9 |          240.357 | 1456128 |  228.164 |              280.263 |              123.293 |            866.994 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3544.88450377249\n",
+      "    time_step_min: 3210\n",
+      "  date: 2020-10-12_09-14-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.3375214163335\n",
+      "  episode_reward_max: 281.1717171717168\n",
+      "  episode_reward_mean: 229.46619824746594\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 171\n",
+      "  episodes_total: 1751\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9780503561099371\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009758495492860675\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0139435965490217\n",
+      "        total_loss: 17.738577047983807\n",
+      "        vf_explained_var: 0.9718084931373596\n",
+      "        vf_loss: 17.75154670079549\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.190000000000005\n",
+      "    gpu_util_percent0: 0.3986666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.793333333333334\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1545050007526534\n",
+      "    mean_env_wait_ms: 1.1757773298552918\n",
+      "    mean_inference_ms: 4.8451503884978555\n",
+      "    mean_raw_obs_processing_ms: 0.4100415540938448\n",
+      "  time_since_restore: 266.710839509964\n",
+      "  time_this_iter_s: 26.35433077812195\n",
+      "  time_total_s: 266.710839509964\n",
+      "  timers:\n",
+      "    learn_throughput: 8408.138\n",
+      "    learn_time_ms: 19242.311\n",
+      "    sample_throughput: 22075.475\n",
+      "    sample_time_ms: 7329.038\n",
+      "    update_time_ms: 45.726\n",
+      "  timestamp: 1602494058\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     10 |          266.711 | 1617920 |  229.466 |              281.172 |              123.293 |            863.338 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3534.246778989098\n",
+      "    time_step_min: 3210\n",
+      "  date: 2020-10-12_09-14-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 858.5786901270773\n",
+      "  episode_reward_max: 286.77777777777817\n",
+      "  episode_reward_mean: 230.9822121508337\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 295\n",
+      "  episodes_total: 2046\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9707790662844976\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009111629178126654\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01193074702132435\n",
+      "        total_loss: 21.812623182932537\n",
+      "        vf_explained_var: 0.972846269607544\n",
+      "        vf_loss: 21.82370201746623\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.64999999999999\n",
+      "    gpu_util_percent0: 0.261\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15373903338701672\n",
+      "    mean_env_wait_ms: 1.1774911722734291\n",
+      "    mean_inference_ms: 4.792413567775025\n",
+      "    mean_raw_obs_processing_ms: 0.4072536118481191\n",
+      "  time_since_restore: 292.91805124282837\n",
+      "  time_this_iter_s: 26.20721173286438\n",
+      "  time_total_s: 292.91805124282837\n",
+      "  timers:\n",
+      "    learn_throughput: 8409.23\n",
+      "    learn_time_ms: 19239.812\n",
+      "    sample_throughput: 22791.619\n",
+      "    sample_time_ms: 7098.75\n",
+      "    update_time_ms: 45.649\n",
+      "  timestamp: 1602494084\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     11 |          292.918 | 1779712 |  230.982 |              286.778 |              123.293 |            858.579 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3527.223443223443\n",
+      "    time_step_min: 3200\n",
+      "  date: 2020-10-12_09-15-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 856.6713381555154\n",
+      "  episode_reward_max: 286.77777777777817\n",
+      "  episode_reward_mean: 232.1279339507186\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9551966488361359\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009806284758572778\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013617369385125736\n",
+      "        total_loss: 13.879839897155762\n",
+      "        vf_explained_var: 0.9759161472320557\n",
+      "        vf_loss: 13.8924511273702\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.677419354838708\n",
+      "    gpu_util_percent0: 0.36967741935483867\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15338491645842753\n",
+      "    mean_env_wait_ms: 1.1783542788983006\n",
+      "    mean_inference_ms: 4.767533848675805\n",
+      "    mean_raw_obs_processing_ms: 0.40595214319690065\n",
+      "  time_since_restore: 319.4405264854431\n",
+      "  time_this_iter_s: 26.522475242614746\n",
+      "  time_total_s: 319.4405264854431\n",
+      "  timers:\n",
+      "    learn_throughput: 8401.506\n",
+      "    learn_time_ms: 19257.501\n",
+      "    sample_throughput: 22995.188\n",
+      "    sample_time_ms: 7035.907\n",
+      "    update_time_ms: 44.501\n",
+      "  timestamp: 1602494111\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     12 |          319.441 | 1941504 |  232.128 |              286.778 |              123.293 |            856.671 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3521.5333048676343\n",
+      "    time_step_min: 3200\n",
+      "  date: 2020-10-12_09-15-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 854.5388185654008\n",
+      "  episode_reward_max: 286.77777777777817\n",
+      "  episode_reward_mean: 233.08355708988609\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9413289129734039\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008010121838500103\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01172462550069516\n",
+      "        total_loss: 15.081488529841105\n",
+      "        vf_explained_var: 0.972363293170929\n",
+      "        vf_loss: 15.092552741368612\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.846666666666668\n",
+      "    gpu_util_percent0: 0.28733333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8000000000000003\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15307903200662712\n",
+      "    mean_env_wait_ms: 1.179158797690685\n",
+      "    mean_inference_ms: 4.746250296736081\n",
+      "    mean_raw_obs_processing_ms: 0.4048109758123445\n",
+      "  time_since_restore: 345.8816432952881\n",
+      "  time_this_iter_s: 26.44111680984497\n",
+      "  time_total_s: 345.8816432952881\n",
+      "  timers:\n",
+      "    learn_throughput: 8395.135\n",
+      "    learn_time_ms: 19272.114\n",
+      "    sample_throughput: 23094.095\n",
+      "    sample_time_ms: 7005.774\n",
+      "    update_time_ms: 42.498\n",
+      "  timestamp: 1602494137\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     13 |          345.882 | 2103296 |  233.084 |              286.778 |              123.293 |            854.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3515.089207487057\n",
+      "    time_step_min: 3200\n",
+      "  date: 2020-10-12_09-16-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.2583694367861\n",
+      "  episode_reward_max: 286.77777777777817\n",
+      "  episode_reward_mean: 234.0807603407051\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 169\n",
+      "  episodes_total: 2539\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9056168496608734\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009796336991712451\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013294228323502466\n",
+      "        total_loss: 13.875916957855225\n",
+      "        vf_explained_var: 0.9769673347473145\n",
+      "        vf_loss: 13.88815744717916\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.880000000000003\n",
+      "    gpu_util_percent0: 0.31666666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.806666666666666\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15277447557429397\n",
+      "    mean_env_wait_ms: 1.1800135637448719\n",
+      "    mean_inference_ms: 4.72551806953912\n",
+      "    mean_raw_obs_processing_ms: 0.4036840813331012\n",
+      "  time_since_restore: 372.2597620487213\n",
+      "  time_this_iter_s: 26.378118753433228\n",
+      "  time_total_s: 372.2597620487213\n",
+      "  timers:\n",
+      "    learn_throughput: 8391.326\n",
+      "    learn_time_ms: 19280.862\n",
+      "    sample_throughput: 23106.345\n",
+      "    sample_time_ms: 7002.059\n",
+      "    update_time_ms: 35.618\n",
+      "  timestamp: 1602494164\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     14 |           372.26 | 2265088 |  234.081 |              286.778 |              123.293 |            852.258 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3502.648426323319\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-12_09-16-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.600566572238\n",
+      "  episode_reward_max: 287.2323232323233\n",
+      "  episode_reward_mean: 235.92292972215057\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 285\n",
+      "  episodes_total: 2824\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8858138074477514\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008729042252525687\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01212932908674702\n",
+      "        total_loss: 15.029687325159708\n",
+      "        vf_explained_var: 0.9797885417938232\n",
+      "        vf_loss: 15.040957053502401\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.80322580645161\n",
+      "    gpu_util_percent0: 0.3496774193548387\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7806451612903222\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15233331834828823\n",
+      "    mean_env_wait_ms: 1.1814026695620998\n",
+      "    mean_inference_ms: 4.695138773537019\n",
+      "    mean_raw_obs_processing_ms: 0.40202783416969384\n",
+      "  time_since_restore: 398.7684223651886\n",
+      "  time_this_iter_s: 26.508660316467285\n",
+      "  time_total_s: 398.7684223651886\n",
+      "  timers:\n",
+      "    learn_throughput: 8385.521\n",
+      "    learn_time_ms: 19294.21\n",
+      "    sample_throughput: 23098.392\n",
+      "    sample_time_ms: 7004.47\n",
+      "    update_time_ms: 36.796\n",
+      "  timestamp: 1602494190\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     15 |          398.768 | 2426880 |  235.923 |              287.232 |              123.293 |            848.601 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3495.150975117687\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-12_09-16-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 846.7524983344437\n",
+      "  episode_reward_max: 287.2323232323233\n",
+      "  episode_reward_mean: 236.98188413111785\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 178\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.873380055030187\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009605405774588386\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014174769399687648\n",
+      "        total_loss: 8.852904081344604\n",
+      "        vf_explained_var: 0.9842066168785095\n",
+      "        vf_loss: 8.866031328837076\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.716666666666665\n",
+      "    gpu_util_percent0: 0.3466666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8000000000000003\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15209292308422775\n",
+      "    mean_env_wait_ms: 1.1821958954982226\n",
+      "    mean_inference_ms: 4.6787285721858725\n",
+      "    mean_raw_obs_processing_ms: 0.401153686184005\n",
+      "  time_since_restore: 425.24342155456543\n",
+      "  time_this_iter_s: 26.47499918937683\n",
+      "  time_total_s: 425.24342155456543\n",
+      "  timers:\n",
+      "    learn_throughput: 8380.352\n",
+      "    learn_time_ms: 19306.111\n",
+      "    sample_throughput: 23138.248\n",
+      "    sample_time_ms: 6992.405\n",
+      "    update_time_ms: 36.347\n",
+      "  timestamp: 1602494217\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     16 |          425.243 | 2588672 |  236.982 |              287.232 |              123.293 |            846.752 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3489.791826309068\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-12_09-17-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.1911392405063\n",
+      "  episode_reward_max: 287.2323232323233\n",
+      "  episode_reward_mean: 237.82586945403386\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8668454786141714\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008814893662929535\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011805401959766945\n",
+      "        total_loss: 10.369755109151205\n",
+      "        vf_explained_var: 0.980014979839325\n",
+      "        vf_loss: 10.380664348602295\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.633333333333333\n",
+      "    gpu_util_percent0: 0.30433333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8033333333333337\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1518939132452068\n",
+      "    mean_env_wait_ms: 1.1828715767868674\n",
+      "    mean_inference_ms: 4.665102003707222\n",
+      "    mean_raw_obs_processing_ms: 0.4004250767522837\n",
+      "  time_since_restore: 451.46355152130127\n",
+      "  time_this_iter_s: 26.22012996673584\n",
+      "  time_total_s: 451.46355152130127\n",
+      "  timers:\n",
+      "    learn_throughput: 8377.898\n",
+      "    learn_time_ms: 19311.765\n",
+      "    sample_throughput: 23233.435\n",
+      "    sample_time_ms: 6963.757\n",
+      "    update_time_ms: 36.044\n",
+      "  timestamp: 1602494243\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     17 |          451.464 | 2750464 |  237.826 |              287.232 |              123.293 |            845.191 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3482.9842995169083\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-12_09-17-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.6434131736527\n",
+      "  episode_reward_max: 287.2323232323233\n",
+      "  episode_reward_mean: 238.74125990443346\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 180\n",
+      "  episodes_total: 3340\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8216705471277237\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008909148629754782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013433378713671118\n",
+      "        total_loss: 8.975247144699097\n",
+      "        vf_explained_var: 0.9846148490905762\n",
+      "        vf_loss: 8.987720568974813\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.03103448275862\n",
+      "    gpu_util_percent0: 0.2879310344827586\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8034482758620682\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1516824536319952\n",
+      "    mean_env_wait_ms: 1.183662094655912\n",
+      "    mean_inference_ms: 4.650801891684328\n",
+      "    mean_raw_obs_processing_ms: 0.39965731772831625\n",
+      "  time_since_restore: 477.3016357421875\n",
+      "  time_this_iter_s: 25.83808422088623\n",
+      "  time_total_s: 477.3016357421875\n",
+      "  timers:\n",
+      "    learn_throughput: 8387.159\n",
+      "    learn_time_ms: 19290.441\n",
+      "    sample_throughput: 23349.348\n",
+      "    sample_time_ms: 6929.187\n",
+      "    update_time_ms: 35.786\n",
+      "  timestamp: 1602494269\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     18 |          477.302 | 2912256 |  238.741 |              287.232 |              123.293 |            843.643 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3473.5977139671036\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_09-18-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.0929460580913\n",
+      "  episode_reward_max: 288.7474747474747\n",
+      "  episode_reward_mean: 240.02900373024843\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 275\n",
+      "  episodes_total: 3615\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8049357434113821\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008266594493761659\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011415963868785184\n",
+      "        total_loss: 11.906183878580729\n",
+      "        vf_explained_var: 0.9831228852272034\n",
+      "        vf_loss: 11.916751384735107\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.87096774193548\n",
+      "    gpu_util_percent0: 0.38064516129032255\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7838709677419344\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15140022504781708\n",
+      "    mean_env_wait_ms: 1.1847662527935785\n",
+      "    mean_inference_ms: 4.630730531528002\n",
+      "    mean_raw_obs_processing_ms: 0.3985929411459491\n",
+      "  time_since_restore: 503.61667227745056\n",
+      "  time_this_iter_s: 26.31503653526306\n",
+      "  time_total_s: 503.61667227745056\n",
+      "  timers:\n",
+      "    learn_throughput: 8379.397\n",
+      "    learn_time_ms: 19308.31\n",
+      "    sample_throughput: 23394.279\n",
+      "    sample_time_ms: 6915.879\n",
+      "    update_time_ms: 41.848\n",
+      "  timestamp: 1602494296\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     19 |          503.617 | 3074048 |  240.029 |              288.747 |              123.293 |            841.093 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3469.2547821466524\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_09-18-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.415611814346\n",
+      "  episode_reward_max: 288.7474747474747\n",
+      "  episode_reward_mean: 240.75353215701304\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 177\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7987531820933024\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009079231104503075\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01224838827814286\n",
+      "        total_loss: 7.98631485303243\n",
+      "        vf_explained_var: 0.9849869608879089\n",
+      "        vf_loss: 7.997546116511027\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.95862068965517\n",
+      "    gpu_util_percent0: 0.42896551724137927\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1512318108286515\n",
+      "    mean_env_wait_ms: 1.1854403616712963\n",
+      "    mean_inference_ms: 4.619308581693827\n",
+      "    mean_raw_obs_processing_ms: 0.39798201719273574\n",
+      "  time_since_restore: 529.7231526374817\n",
+      "  time_this_iter_s: 26.106480360031128\n",
+      "  time_total_s: 529.7231526374817\n",
+      "  timers:\n",
+      "    learn_throughput: 8384.536\n",
+      "    learn_time_ms: 19296.475\n",
+      "    sample_throughput: 23441.212\n",
+      "    sample_time_ms: 6902.032\n",
+      "    update_time_ms: 41.797\n",
+      "  timestamp: 1602494322\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     20 |          529.723 | 3235840 |  240.754 |              288.747 |              123.293 |            839.416 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3465.1249044098904\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_09-19-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.9002784105289\n",
+      "  episode_reward_max: 288.7474747474747\n",
+      "  episode_reward_mean: 241.3841681814346\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 3951\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7892453173796335\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008678884012624621\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013489016583965471\n",
+      "        total_loss: 8.202074805895487\n",
+      "        vf_explained_var: 0.9837081432342529\n",
+      "        vf_loss: 8.214617093404135\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.576666666666664\n",
+      "    gpu_util_percent0: 0.33299999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.8100000000000005\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510910394398947\n",
+      "    mean_env_wait_ms: 1.1860755375048555\n",
+      "    mean_inference_ms: 4.609591237803295\n",
+      "    mean_raw_obs_processing_ms: 0.39746154916894355\n",
+      "  time_since_restore: 555.8554036617279\n",
+      "  time_this_iter_s: 26.132251024246216\n",
+      "  time_total_s: 555.8554036617279\n",
+      "  timers:\n",
+      "    learn_throughput: 8384.49\n",
+      "    learn_time_ms: 19296.582\n",
+      "    sample_throughput: 23466.212\n",
+      "    sample_time_ms: 6894.679\n",
+      "    update_time_ms: 40.938\n",
+      "  timestamp: 1602494348\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     21 |          555.855 | 3397632 |  241.384 |              288.747 |              123.293 |              837.9 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3459.7059956657836\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_09-19-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 835.4640038268357\n",
+      "  episode_reward_max: 288.7474747474747\n",
+      "  episode_reward_mean: 242.1401312817241\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 230\n",
+      "  episodes_total: 4181\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7601525833209356\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.009010187815874815\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012391658771472672\n",
+      "        total_loss: 10.299412171045939\n",
+      "        vf_explained_var: 0.9842986464500427\n",
+      "        vf_loss: 10.31076200803121\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.053333333333338\n",
+      "    gpu_util_percent0: 0.3506666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.796666666666667\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1509019954239079\n",
+      "    mean_env_wait_ms: 1.1870673081191399\n",
+      "    mean_inference_ms: 4.596511436234388\n",
+      "    mean_raw_obs_processing_ms: 0.3967569355943852\n",
+      "  time_since_restore: 582.0722694396973\n",
+      "  time_this_iter_s: 26.21686577796936\n",
+      "  time_total_s: 582.0722694396973\n",
+      "  timers:\n",
+      "    learn_throughput: 8389.319\n",
+      "    learn_time_ms: 19285.474\n",
+      "    sample_throughput: 23539.335\n",
+      "    sample_time_ms: 6873.261\n",
+      "    update_time_ms: 42.019\n",
+      "  timestamp: 1602494374\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | RUNNING  | 172.17.0.4:11639 |     22 |          582.072 | 3559424 |   242.14 |              288.747 |              123.293 |            835.464 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ab0cc_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4242\n",
+      "    time_step_mean: 3454.6921501706483\n",
+      "    time_step_min: 3150\n",
+      "  date: 2020-10-12_09-20-01\n",
+      "  done: true\n",
+      "  episode_len_mean: 832.845127741352\n",
+      "  episode_reward_max: 288.7474747474747\n",
+      "  episode_reward_mean: 242.9193312277191\n",
+      "  episode_reward_min: 123.29292929292922\n",
+      "  episodes_this_iter: 242\n",
+      "  episodes_total: 4423\n",
+      "  experiment_id: 106c69a97c93469e859f3a7e2b7f731c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7429485023021698\n",
+      "        entropy_coeff: 0.0010000000000000002\n",
+      "        kl: 0.008412127305443088\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013832842392730527\n",
+      "        total_loss: 9.076472520828247\n",
+      "        vf_explained_var: 0.9854559302330017\n",
+      "        vf_loss: 9.08936619758606\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.276666666666667\n",
+      "    gpu_util_percent0: 0.3273333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.803333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 11639\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1507183214765464\n",
+      "    mean_env_wait_ms: 1.1880050261807538\n",
+      "    mean_inference_ms: 4.583941039758726\n",
+      "    mean_raw_obs_processing_ms: 0.39609077607755505\n",
+      "  time_since_restore: 608.0814437866211\n",
+      "  time_this_iter_s: 26.009174346923828\n",
+      "  time_total_s: 608.0814437866211\n",
+      "  timers:\n",
+      "    learn_throughput: 8399.918\n",
+      "    learn_time_ms: 19261.14\n",
+      "    sample_throughput: 23606.525\n",
+      "    sample_time_ms: 6853.698\n",
+      "    update_time_ms: 42.01\n",
+      "  timestamp: 1602494401\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: ab0cc_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | TERMINATED |       |     23 |          608.081 | 3721216 |  242.919 |              288.747 |              123.293 |            832.845 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ab0cc_00000 | TERMINATED |       |     23 |          608.081 | 3721216 |  242.919 |              288.747 |              123.293 |            832.845 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 11384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_090938-sytvyrt5/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_090938-sytvyrt5/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3150\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 623\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602494401\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4242\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3454.69215\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 288.74747\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 123.29293\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 242.91933\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4423\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevout-sweep-8\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/sytvyrt5\u001b[0m\n",
+      "2020-10-12 09:20:08,124 - wandb.wandb_agent - INFO - Cleaning up finished run: sytvyrt5\n",
+      "2020-10-12 09:20:08,475 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 09:20:08,475 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tentropy_coeff: 0.0005\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 09:20:08,477 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --entropy_coeff=0.0005 --num_sgd_iter=20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 09:20:13,495 - wandb.wandb_agent - INFO - Running runs: ['zi1cm2xf']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevout-sweep-9\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zi1cm2xf\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_092010-zi1cm2xf\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 09:20:14,254\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=38914)\u001b[0m 2020-10-12 09:20:16,993\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=38797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38864)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38864)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38927)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38927)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38920)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38920)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38915)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38915)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38796)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38796)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38899)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38899)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38803)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38803)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38874)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38874)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38861)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38861)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=38823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=38823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_09-20-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1827744742234547\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007263169119444986\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00761965052515734\n",
+      "        total_loss: 514.7333196004232\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.823333333333338\n",
+      "    gpu_util_percent0: 0.319\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.550000000000001\n",
+      "    vram_util_percent0: 0.08396742101235381\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1686786140472516\n",
+      "    mean_env_wait_ms: 1.1653963037757602\n",
+      "    mean_inference_ms: 5.951796741020389\n",
+      "    mean_raw_obs_processing_ms: 0.45555506933247036\n",
+      "  time_since_restore: 25.677541971206665\n",
+      "  time_this_iter_s: 25.677541971206665\n",
+      "  time_total_s: 25.677541971206665\n",
+      "  timers:\n",
+      "    learn_throughput: 10161.034\n",
+      "    learn_time_ms: 15922.789\n",
+      "    sample_throughput: 16729.27\n",
+      "    sample_time_ms: 9671.193\n",
+      "    update_time_ms: 49.843\n",
+      "  timestamp: 1602494448\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      1 |          25.6775 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3627.9444444444443\n",
+      "    time_step_min: 3352\n",
+      "  date: 2020-10-12_09-21-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.5791139240506\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.4263201636617\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1514901518821716\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008677494013682008\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007752557110507041\n",
+      "        total_loss: 149.27600733439127\n",
+      "        vf_explained_var: 0.7886922955513\n",
+      "        vf_loss: 149.28260294596353\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.250000000000004\n",
+      "    gpu_util_percent0: 0.28285714285714286\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.75\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16522475825236266\n",
+      "    mean_env_wait_ms: 1.1631367512626534\n",
+      "    mean_inference_ms: 5.757631300482575\n",
+      "    mean_raw_obs_processing_ms: 0.44612020259142066\n",
+      "  time_since_restore: 49.853564500808716\n",
+      "  time_this_iter_s: 24.17602252960205\n",
+      "  time_total_s: 49.853564500808716\n",
+      "  timers:\n",
+      "    learn_throughput: 10225.246\n",
+      "    learn_time_ms: 15822.798\n",
+      "    sample_throughput: 17935.916\n",
+      "    sample_time_ms: 9020.56\n",
+      "    update_time_ms: 41.407\n",
+      "  timestamp: 1602494472\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      2 |          49.8536 | 323584 |  216.426 |              258.596 |              138.293 |            891.579 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3619.372197309417\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-12_09-21-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.7763713080169\n",
+      "  episode_reward_max: 265.111111111111\n",
+      "  episode_reward_mean: 218.3539828666409\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1501519680023193\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00987866218201816\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011303798101531962\n",
+      "        total_loss: 68.9120267232259\n",
+      "        vf_explained_var: 0.8753736019134521\n",
+      "        vf_loss: 68.92193285624187\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.622222222222224\n",
+      "    gpu_util_percent0: 0.3292592592592593\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7666666666666666\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16271943504127687\n",
+      "    mean_env_wait_ms: 1.1637210719889728\n",
+      "    mean_inference_ms: 5.566098416995584\n",
+      "    mean_raw_obs_processing_ms: 0.43808816597207934\n",
+      "  time_since_restore: 72.73792386054993\n",
+      "  time_this_iter_s: 22.88435935974121\n",
+      "  time_total_s: 72.73792386054993\n",
+      "  timers:\n",
+      "    learn_throughput: 10294.333\n",
+      "    learn_time_ms: 15716.608\n",
+      "    sample_throughput: 19205.703\n",
+      "    sample_time_ms: 8424.165\n",
+      "    update_time_ms: 59.316\n",
+      "  timestamp: 1602494495\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      3 |          72.7379 | 485376 |  218.354 |              265.111 |              138.293 |            885.776 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3609.2218543046356\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-12_09-21-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.5458860759494\n",
+      "  episode_reward_max: 271.9292929292925\n",
+      "  episode_reward_mean: 219.63067382687615\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.123563160498937\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.01068496766189734\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00788415075900654\n",
+      "        total_loss: 51.15607770284017\n",
+      "        vf_explained_var: 0.9072044491767883\n",
+      "        vf_loss: 51.162388483683266\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.31923076923077\n",
+      "    gpu_util_percent0: 0.2553846153846154\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16081538205548576\n",
+      "    mean_env_wait_ms: 1.164579723782807\n",
+      "    mean_inference_ms: 5.416884148073274\n",
+      "    mean_raw_obs_processing_ms: 0.43160135943520156\n",
+      "  time_since_restore: 95.40110111236572\n",
+      "  time_this_iter_s: 22.663177251815796\n",
+      "  time_total_s: 95.40110111236572\n",
+      "  timers:\n",
+      "    learn_throughput: 10319.316\n",
+      "    learn_time_ms: 15678.558\n",
+      "    sample_throughput: 20045.004\n",
+      "    sample_time_ms: 8071.437\n",
+      "    update_time_ms: 53.564\n",
+      "  timestamp: 1602494517\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      4 |          95.4011 | 647168 |  219.631 |              271.929 |              138.293 |            881.546 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3597.922572178478\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-12_09-22-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 878.0860759493671\n",
+      "  episode_reward_max: 278.14141414141426\n",
+      "  episode_reward_mean: 220.69051272215813\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0902884205182393\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00903574850720664\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009291995510769388\n",
+      "        total_loss: 44.12793127695719\n",
+      "        vf_explained_var: 0.927177906036377\n",
+      "        vf_loss: 44.13595962524414\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.16153846153846\n",
+      "    gpu_util_percent0: 0.28500000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.757692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15939243547503956\n",
+      "    mean_env_wait_ms: 1.165936563255046\n",
+      "    mean_inference_ms: 5.301039287467012\n",
+      "    mean_raw_obs_processing_ms: 0.4264011198442179\n",
+      "  time_since_restore: 117.91398453712463\n",
+      "  time_this_iter_s: 22.51288342475891\n",
+      "  time_total_s: 117.91398453712463\n",
+      "  timers:\n",
+      "    learn_throughput: 10355.112\n",
+      "    learn_time_ms: 15624.36\n",
+      "    sample_throughput: 20589.687\n",
+      "    sample_time_ms: 7857.915\n",
+      "    update_time_ms: 50.792\n",
+      "  timestamp: 1602494540\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      5 |          117.914 | 808960 |  220.691 |              278.141 |              138.293 |            878.086 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3581.089201877934\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-12_09-22-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 871.1381518755718\n",
+      "  episode_reward_max: 278.14141414141426\n",
+      "  episode_reward_mean: 223.01693051281325\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 303\n",
+      "  episodes_total: 1093\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0726720094680786\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008798854425549507\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011426329845562577\n",
+      "        total_loss: 42.27958615620931\n",
+      "        vf_explained_var: 0.9519073963165283\n",
+      "        vf_loss: 42.28978888193766\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.003703703703703\n",
+      "    gpu_util_percent0: 0.3118518518518518\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.755555555555555\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1575550389084717\n",
+      "    mean_env_wait_ms: 1.1693032611932224\n",
+      "    mean_inference_ms: 5.14701749967029\n",
+      "    mean_raw_obs_processing_ms: 0.419540382097035\n",
+      "  time_since_restore: 140.6349482536316\n",
+      "  time_this_iter_s: 22.720963716506958\n",
+      "  time_total_s: 140.6349482536316\n",
+      "  timers:\n",
+      "    learn_throughput: 10360.276\n",
+      "    learn_time_ms: 15616.572\n",
+      "    sample_throughput: 20948.818\n",
+      "    sample_time_ms: 7723.204\n",
+      "    update_time_ms: 49.392\n",
+      "  timestamp: 1602494563\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      6 |          140.635 | 970752 |  223.017 |              278.141 |              138.293 |            871.138 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3575.8155339805826\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-12_09-23-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.6273734177215\n",
+      "  episode_reward_max: 278.14141414141426\n",
+      "  episode_reward_mean: 224.21580520393792\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 171\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0701393087704976\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00972194162507852\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012504054078211388\n",
+      "        total_loss: 24.834288756052654\n",
+      "        vf_explained_var: 0.9582985043525696\n",
+      "        vf_loss: 24.845383485158283\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.900000000000002\n",
+      "    gpu_util_percent0: 0.2566666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.777777777777778\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15679506772490143\n",
+      "    mean_env_wait_ms: 1.1709221026744456\n",
+      "    mean_inference_ms: 5.0848212374967305\n",
+      "    mean_raw_obs_processing_ms: 0.4167851193139076\n",
+      "  time_since_restore: 163.35206365585327\n",
+      "  time_this_iter_s: 22.71711540222168\n",
+      "  time_total_s: 163.35206365585327\n",
+      "  timers:\n",
+      "    learn_throughput: 10368.087\n",
+      "    learn_time_ms: 15604.807\n",
+      "    sample_throughput: 21210.289\n",
+      "    sample_time_ms: 7627.996\n",
+      "    update_time_ms: 48.447\n",
+      "  timestamp: 1602494586\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      7 |          163.352 | 1132544 |  224.216 |              278.141 |              138.293 |            867.627 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3567.4081779053085\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-12_09-23-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 864.2721518987341\n",
+      "  episode_reward_max: 278.14141414141426\n",
+      "  episode_reward_mean: 225.9137578314792\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.053697516520818\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00854927790351212\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009208010005143782\n",
+      "        total_loss: 20.169148763020832\n",
+      "        vf_explained_var: 0.9635282158851624\n",
+      "        vf_loss: 20.17717440923055\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.153846153846153\n",
+      "    gpu_util_percent0: 0.31384615384615383\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15620341712189031\n",
+      "    mean_env_wait_ms: 1.1722119121456387\n",
+      "    mean_inference_ms: 5.035066153614783\n",
+      "    mean_raw_obs_processing_ms: 0.4145090279785972\n",
+      "  time_since_restore: 186.05805230140686\n",
+      "  time_this_iter_s: 22.70598864555359\n",
+      "  time_total_s: 186.05805230140686\n",
+      "  timers:\n",
+      "    learn_throughput: 10361.75\n",
+      "    learn_time_ms: 15614.35\n",
+      "    sample_throughput: 21451.184\n",
+      "    sample_time_ms: 7542.334\n",
+      "    update_time_ms: 46.387\n",
+      "  timestamp: 1602494609\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      8 |          186.058 | 1294336 |  225.914 |              278.141 |              138.293 |            864.272 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3556.853092783505\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-12_09-23-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 861.1063291139241\n",
+      "  episode_reward_max: 278.14141414141426\n",
+      "  episode_reward_mean: 227.5715062012529\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0249782105286915\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008773986482992768\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011871100180239106\n",
+      "        total_loss: 18.7819766998291\n",
+      "        vf_explained_var: 0.9634544849395752\n",
+      "        vf_loss: 18.792605717976887\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.815384615384612\n",
+      "    gpu_util_percent0: 0.25230769230769234\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1556915728808796\n",
+      "    mean_env_wait_ms: 1.1734060394791885\n",
+      "    mean_inference_ms: 4.991530438550621\n",
+      "    mean_raw_obs_processing_ms: 0.4124572359884706\n",
+      "  time_since_restore: 208.7378134727478\n",
+      "  time_this_iter_s: 22.679761171340942\n",
+      "  time_total_s: 208.7378134727478\n",
+      "  timers:\n",
+      "    learn_throughput: 10364.133\n",
+      "    learn_time_ms: 15610.761\n",
+      "    sample_throughput: 21617.833\n",
+      "    sample_time_ms: 7484.191\n",
+      "    update_time_ms: 44.225\n",
+      "  timestamp: 1602494631\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |      9 |          208.738 | 1456128 |  227.572 |              278.141 |              138.293 |            861.106 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3542.5145413870246\n",
+      "    time_step_min: 3209\n",
+      "  date: 2020-10-12_09-24-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 855.078744493392\n",
+      "  episode_reward_max: 279.8080808080808\n",
+      "  episode_reward_mean: 229.86081075067844\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 236\n",
+      "  episodes_total: 1816\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9820816020170847\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00821732710270832\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010050915479951072\n",
+      "        total_loss: 21.17539644241333\n",
+      "        vf_explained_var: 0.9707738757133484\n",
+      "        vf_loss: 21.1842942237854\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.251851851851853\n",
+      "    gpu_util_percent0: 0.21962962962962962\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15505376808197696\n",
+      "    mean_env_wait_ms: 1.1757058986829956\n",
+      "    mean_inference_ms: 4.936731188829644\n",
+      "    mean_raw_obs_processing_ms: 0.4099086398609132\n",
+      "  time_since_restore: 231.40399146080017\n",
+      "  time_this_iter_s: 22.666177988052368\n",
+      "  time_total_s: 231.40399146080017\n",
+      "  timers:\n",
+      "    learn_throughput: 10372.554\n",
+      "    learn_time_ms: 15598.087\n",
+      "    sample_throughput: 21725.305\n",
+      "    sample_time_ms: 7447.168\n",
+      "    update_time_ms: 41.731\n",
+      "  timestamp: 1602494654\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     10 |          231.404 | 1617920 |  229.861 |              279.808 |              138.293 |            855.079 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3530.031095755183\n",
+      "    time_step_min: 3209\n",
+      "  date: 2020-10-12_09-24-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 849.9323271665044\n",
+      "  episode_reward_max: 279.8080808080808\n",
+      "  episode_reward_mean: 231.8811975647417\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 238\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9930150409539541\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009119869054605564\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008603869452296445\n",
+      "        total_loss: 16.28092400232951\n",
+      "        vf_explained_var: 0.9731142520904541\n",
+      "        vf_loss: 16.28820053736369\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.61111111111111\n",
+      "    gpu_util_percent0: 0.4014814814814815\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15450174672829692\n",
+      "    mean_env_wait_ms: 1.177575019054972\n",
+      "    mean_inference_ms: 4.890645710340337\n",
+      "    mean_raw_obs_processing_ms: 0.4077204848885823\n",
+      "  time_since_restore: 254.3549039363861\n",
+      "  time_this_iter_s: 22.950912475585938\n",
+      "  time_total_s: 254.3549039363861\n",
+      "  timers:\n",
+      "    learn_throughput: 10393.91\n",
+      "    learn_time_ms: 15566.038\n",
+      "    sample_throughput: 22456.294\n",
+      "    sample_time_ms: 7204.751\n",
+      "    update_time_ms: 40.844\n",
+      "  timestamp: 1602494677\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     11 |          254.355 | 1779712 |  231.881 |              279.808 |              138.293 |            849.932 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3522.0476190476193\n",
+      "    time_step_min: 3209\n",
+      "  date: 2020-10-12_09-25-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.0786618444846\n",
+      "  episode_reward_max: 279.8080808080808\n",
+      "  episode_reward_mean: 233.0196266462088\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9703877021869024\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007759922145244976\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010197352380297767\n",
+      "        total_loss: 12.45139765739441\n",
+      "        vf_explained_var: 0.9765066504478455\n",
+      "        vf_loss: 12.460527817408243\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.723076923076924\n",
+      "    gpu_util_percent0: 0.27499999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15418325967439245\n",
+      "    mean_env_wait_ms: 1.178807434003838\n",
+      "    mean_inference_ms: 4.864168533056006\n",
+      "    mean_raw_obs_processing_ms: 0.4064531879388726\n",
+      "  time_since_restore: 277.23624324798584\n",
+      "  time_this_iter_s: 22.88133931159973\n",
+      "  time_total_s: 277.23624324798584\n",
+      "  timers:\n",
+      "    learn_throughput: 10401.052\n",
+      "    learn_time_ms: 15555.349\n",
+      "    sample_throughput: 22837.812\n",
+      "    sample_time_ms: 7084.391\n",
+      "    update_time_ms: 42.04\n",
+      "  timestamp: 1602494700\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     12 |          277.236 | 1941504 |   233.02 |              279.808 |              138.293 |            847.079 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3515.3185311699403\n",
+      "    time_step_min: 3209\n",
+      "  date: 2020-10-12_09-25-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.0949367088608\n",
+      "  episode_reward_max: 279.8080808080808\n",
+      "  episode_reward_mean: 234.05101649405435\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9404816528161367\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007768297684378922\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011234237026656047\n",
+      "        total_loss: 12.331538756688436\n",
+      "        vf_explained_var: 0.9758628010749817\n",
+      "        vf_loss: 12.341690063476562\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.47692307692307\n",
+      "    gpu_util_percent0: 0.4196153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15389385011663606\n",
+      "    mean_env_wait_ms: 1.1799601908857826\n",
+      "    mean_inference_ms: 4.839993427048123\n",
+      "    mean_raw_obs_processing_ms: 0.4052788314029578\n",
+      "  time_since_restore: 299.8108310699463\n",
+      "  time_this_iter_s: 22.57458782196045\n",
+      "  time_total_s: 299.8108310699463\n",
+      "  timers:\n",
+      "    learn_throughput: 10404.547\n",
+      "    learn_time_ms: 15550.125\n",
+      "    sample_throughput: 22903.193\n",
+      "    sample_time_ms: 7064.168\n",
+      "    update_time_ms: 36.264\n",
+      "  timestamp: 1602494723\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     13 |          299.811 | 2103296 |  234.051 |              279.808 |              138.293 |            845.095 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3502.781992337165\n",
+      "    time_step_min: 3195\n",
+      "  date: 2020-10-12_09-25-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.7566338134951\n",
+      "  episode_reward_max: 281.9292929292926\n",
+      "  episode_reward_mean: 235.95897565495736\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 268\n",
+      "  episodes_total: 2638\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8899559080600739\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008799789395804206\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009050529527788361\n",
+      "        total_loss: 14.480824708938599\n",
+      "        vf_explained_var: 0.979515552520752\n",
+      "        vf_loss: 14.48855996131897\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.46666666666667\n",
+      "    gpu_util_percent0: 0.3048148148148148\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.762962962962962\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15346255248838944\n",
+      "    mean_env_wait_ms: 1.1818818859721714\n",
+      "    mean_inference_ms: 4.804153791082136\n",
+      "    mean_raw_obs_processing_ms: 0.40357690475691743\n",
+      "  time_since_restore: 322.49730682373047\n",
+      "  time_this_iter_s: 22.68647575378418\n",
+      "  time_total_s: 322.49730682373047\n",
+      "  timers:\n",
+      "    learn_throughput: 10409.233\n",
+      "    learn_time_ms: 15543.125\n",
+      "    sample_throughput: 22874.618\n",
+      "    sample_time_ms: 7072.992\n",
+      "    update_time_ms: 35.622\n",
+      "  timestamp: 1602494745\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     14 |          322.497 | 2265088 |  235.959 |              281.929 |              138.293 |            841.757 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3494.737215909091\n",
+      "    time_step_min: 3195\n",
+      "  date: 2020-10-12_09-26-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 840.1722925457103\n",
+      "  episode_reward_max: 281.9292929292926\n",
+      "  episode_reward_mean: 237.35901206154358\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 206\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8923394729693731\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00703572128744175\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01187642919830978\n",
+      "        total_loss: 10.077098766962687\n",
+      "        vf_explained_var: 0.982374370098114\n",
+      "        vf_loss: 10.088014205296835\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.415384615384614\n",
+      "    gpu_util_percent0: 0.28692307692307695\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.153176065517477\n",
+      "    mean_env_wait_ms: 1.183078387126366\n",
+      "    mean_inference_ms: 4.779900284195376\n",
+      "    mean_raw_obs_processing_ms: 0.40240913871715844\n",
+      "  time_since_restore: 345.097039937973\n",
+      "  time_this_iter_s: 22.599733114242554\n",
+      "  time_total_s: 345.097039937973\n",
+      "  timers:\n",
+      "    learn_throughput: 10398.645\n",
+      "    learn_time_ms: 15558.951\n",
+      "    sample_throughput: 22890.538\n",
+      "    sample_time_ms: 7068.073\n",
+      "    update_time_ms: 34.473\n",
+      "  timestamp: 1602494768\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     15 |          345.097 | 2426880 |  237.359 |              281.929 |              138.293 |            840.172 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3488.5406859448553\n",
+      "    time_step_min: 3195\n",
+      "  date: 2020-10-12_09-26-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.1568954030646\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 238.24548617420027\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8800846089919409\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008667680822933713\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010779316173435896\n",
+      "        total_loss: 9.988673686981201\n",
+      "        vf_explained_var: 0.9807379841804504\n",
+      "        vf_loss: 9.998159567515055\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.91923076923077\n",
+      "    gpu_util_percent0: 0.26153846153846155\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15297371270614404\n",
+      "    mean_env_wait_ms: 1.1839169380455592\n",
+      "    mean_inference_ms: 4.763045426569329\n",
+      "    mean_raw_obs_processing_ms: 0.4016037863495797\n",
+      "  time_since_restore: 367.7543263435364\n",
+      "  time_this_iter_s: 22.657286405563354\n",
+      "  time_total_s: 367.7543263435364\n",
+      "  timers:\n",
+      "    learn_throughput: 10405.813\n",
+      "    learn_time_ms: 15548.232\n",
+      "    sample_throughput: 22877.624\n",
+      "    sample_time_ms: 7072.063\n",
+      "    update_time_ms: 34.536\n",
+      "  timestamp: 1602494791\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     16 |          367.754 | 2588672 |  238.245 |              291.626 |              138.293 |            839.157 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3482.6005747126437\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-26-54\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.3003164556962\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 239.13158483569867\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8536874353885651\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007795991492457688\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0078069346491247416\n",
+      "        total_loss: 10.167111794153849\n",
+      "        vf_explained_var: 0.9799486994743347\n",
+      "        vf_loss: 10.173785924911499\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.26666666666667\n",
+      "    gpu_util_percent0: 0.42037037037037045\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.77037037037037\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1527843375612678\n",
+      "    mean_env_wait_ms: 1.1846727712863188\n",
+      "    mean_inference_ms: 4.747365968268405\n",
+      "    mean_raw_obs_processing_ms: 0.40084186735936783\n",
+      "  time_since_restore: 390.42669439315796\n",
+      "  time_this_iter_s: 22.672368049621582\n",
+      "  time_total_s: 390.42669439315796\n",
+      "  timers:\n",
+      "    learn_throughput: 10400.664\n",
+      "    learn_time_ms: 15555.93\n",
+      "    sample_throughput: 22906.994\n",
+      "    sample_time_ms: 7062.996\n",
+      "    update_time_ms: 34.073\n",
+      "  timestamp: 1602494814\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     17 |          390.427 | 2750464 |  239.132 |              291.626 |              138.293 |              838.3 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3473.450309643173\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-27-17\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.8543433752559\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 240.43895816899607\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 259\n",
+      "  episodes_total: 3419\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8139620572328568\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007261293552195032\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010260122634160021\n",
+      "        total_loss: 13.31914758682251\n",
+      "        vf_explained_var: 0.9808043837547302\n",
+      "        vf_loss: 13.328362544377645\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.24615384615385\n",
+      "    gpu_util_percent0: 0.2373076923076923\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15250233321054504\n",
+      "    mean_env_wait_ms: 1.185879539178616\n",
+      "    mean_inference_ms: 4.724170317877592\n",
+      "    mean_raw_obs_processing_ms: 0.3997331904205269\n",
+      "  time_since_restore: 413.07285046577454\n",
+      "  time_this_iter_s: 22.646156072616577\n",
+      "  time_total_s: 413.07285046577454\n",
+      "  timers:\n",
+      "    learn_throughput: 10407.574\n",
+      "    learn_time_ms: 15545.601\n",
+      "    sample_throughput: 22901.294\n",
+      "    sample_time_ms: 7064.754\n",
+      "    update_time_ms: 35.488\n",
+      "  timestamp: 1602494837\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     18 |          413.073 | 2912256 |  240.439 |              291.626 |              138.293 |            836.854 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3467.253743760399\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-27-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 835.5393505778757\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 241.34495477615997\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 215\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8341793666283289\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008043301058933139\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009528601134661585\n",
+      "        total_loss: 10.148140748341879\n",
+      "        vf_explained_var: 0.9823832511901855\n",
+      "        vf_loss: 10.156477610270182\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.949999999999996\n",
+      "    gpu_util_percent0: 0.26269230769230767\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.773076923076923\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15229438406005505\n",
+      "    mean_env_wait_ms: 1.1867253963739983\n",
+      "    mean_inference_ms: 4.706751181471518\n",
+      "    mean_raw_obs_processing_ms: 0.39890343696658775\n",
+      "  time_since_restore: 435.53685665130615\n",
+      "  time_this_iter_s: 22.464006185531616\n",
+      "  time_total_s: 435.53685665130615\n",
+      "  timers:\n",
+      "    learn_throughput: 10426.012\n",
+      "    learn_time_ms: 15518.109\n",
+      "    sample_throughput: 22886.786\n",
+      "    sample_time_ms: 7069.232\n",
+      "    update_time_ms: 36.133\n",
+      "  timestamp: 1602494859\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     19 |          435.537 | 3074048 |  241.345 |              291.626 |              138.293 |            835.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3462.7428267800215\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-28-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.5495780590717\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 242.07749168904223\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8270436624685923\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007921267068013549\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008027644410807019\n",
+      "        total_loss: 8.775661627451578\n",
+      "        vf_explained_var: 0.9819247722625732\n",
+      "        vf_loss: 8.78251854578654\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.361538461538462\n",
+      "    gpu_util_percent0: 0.2811538461538462\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7884615384615383\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15215330072412026\n",
+      "    mean_env_wait_ms: 1.1873365349754388\n",
+      "    mean_inference_ms: 4.694970511370541\n",
+      "    mean_raw_obs_processing_ms: 0.39833702433585705\n",
+      "  time_since_restore: 458.296884059906\n",
+      "  time_this_iter_s: 22.760027408599854\n",
+      "  time_total_s: 458.296884059906\n",
+      "  timers:\n",
+      "    learn_throughput: 10416.537\n",
+      "    learn_time_ms: 15532.226\n",
+      "    sample_throughput: 22906.783\n",
+      "    sample_time_ms: 7063.061\n",
+      "    update_time_ms: 36.6\n",
+      "  timestamp: 1602494882\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     20 |          458.297 | 3235840 |  242.077 |              291.626 |              138.293 |             834.55 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3458.382210927573\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-28-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.3790058036841\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 242.7109933552022\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 171\n",
+      "  episodes_total: 3963\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7922637710968653\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00846713703746597\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009647412516642362\n",
+      "        total_loss: 10.379550457000732\n",
+      "        vf_explained_var: 0.9806429743766785\n",
+      "        vf_loss: 10.387900511423746\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.5\n",
+      "    gpu_util_percent0: 0.31037037037037035\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1520079365597308\n",
+      "    mean_env_wait_ms: 1.1879892191210335\n",
+      "    mean_inference_ms: 4.682970435105971\n",
+      "    mean_raw_obs_processing_ms: 0.39775380473998373\n",
+      "  time_since_restore: 480.8740713596344\n",
+      "  time_this_iter_s: 22.577187299728394\n",
+      "  time_total_s: 480.8740713596344\n",
+      "  timers:\n",
+      "    learn_throughput: 10424.895\n",
+      "    learn_time_ms: 15519.772\n",
+      "    sample_throughput: 23010.507\n",
+      "    sample_time_ms: 7031.223\n",
+      "    update_time_ms: 36.505\n",
+      "  timestamp: 1602494905\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     21 |          480.874 | 3397632 |  242.711 |              291.626 |              138.293 |            833.379 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3451.4755344418054\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-28-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.5285512033978\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 243.81068352233987\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 275\n",
+      "  episodes_total: 4238\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7635907779137293\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006186021181444327\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00809120606087769\n",
+      "        total_loss: 12.58633295694987\n",
+      "        vf_explained_var: 0.9819806218147278\n",
+      "        vf_loss: 12.593568722407023\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.292307692307695\n",
+      "    gpu_util_percent0: 0.2896153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761538461538461\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15179261662292176\n",
+      "    mean_env_wait_ms: 1.1889850673180626\n",
+      "    mean_inference_ms: 4.665328442988377\n",
+      "    mean_raw_obs_processing_ms: 0.3969050824181129\n",
+      "  time_since_restore: 503.5492398738861\n",
+      "  time_this_iter_s: 22.67516851425171\n",
+      "  time_total_s: 503.5492398738861\n",
+      "  timers:\n",
+      "    learn_throughput: 10426.544\n",
+      "    learn_time_ms: 15517.318\n",
+      "    sample_throughput: 23073.669\n",
+      "    sample_time_ms: 7011.976\n",
+      "    update_time_ms: 36.777\n",
+      "  timestamp: 1602494928\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     22 |          503.549 | 3559424 |  243.811 |              291.626 |              138.293 |            831.529 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3447.7979981801636\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-29-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.6717902350814\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 244.41100425594084\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 186\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7658579001824061\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006407496286556125\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010411242435414655\n",
+      "        total_loss: 9.48198382059733\n",
+      "        vf_explained_var: 0.9826169013977051\n",
+      "        vf_loss: 9.491496562957764\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.492307692307694\n",
+      "    gpu_util_percent0: 0.2196153846153846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7769230769230764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15166053141927105\n",
+      "    mean_env_wait_ms: 1.1895626757331934\n",
+      "    mean_inference_ms: 4.654318975382179\n",
+      "    mean_raw_obs_processing_ms: 0.396383275691878\n",
+      "  time_since_restore: 526.1185171604156\n",
+      "  time_this_iter_s: 22.56927728652954\n",
+      "  time_total_s: 526.1185171604156\n",
+      "  timers:\n",
+      "    learn_throughput: 10425.191\n",
+      "    learn_time_ms: 15519.331\n",
+      "    sample_throughput: 23088.469\n",
+      "    sample_time_ms: 7007.481\n",
+      "    update_time_ms: 37.323\n",
+      "  timestamp: 1602494950\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     23 |          526.119 | 3721216 |  244.411 |              291.626 |              138.293 |            830.672 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3444.521519543259\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-29-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.0261894369271\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 244.86456004832252\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4582\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7546412895123163\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007149649240697424\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0075514697867523255\n",
+      "        total_loss: 8.021642128626505\n",
+      "        vf_explained_var: 0.9839253425598145\n",
+      "        vf_loss: 8.028141101201376\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.211111111111112\n",
+      "    gpu_util_percent0: 0.3381481481481482\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7777777777777777\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15155384005330969\n",
+      "    mean_env_wait_ms: 1.1900468522916654\n",
+      "    mean_inference_ms: 4.64553421142189\n",
+      "    mean_raw_obs_processing_ms: 0.3959627705576778\n",
+      "  time_since_restore: 548.8968155384064\n",
+      "  time_this_iter_s: 22.778298377990723\n",
+      "  time_total_s: 548.8968155384064\n",
+      "  timers:\n",
+      "    learn_throughput: 10417.224\n",
+      "    learn_time_ms: 15531.201\n",
+      "    sample_throughput: 23102.832\n",
+      "    sample_time_ms: 7003.124\n",
+      "    update_time_ms: 38.812\n",
+      "  timestamp: 1602494973\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     24 |          548.897 | 3883008 |  244.865 |              291.626 |              138.293 |            830.026 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3440.8998312948124\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-29-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.0721174004193\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 245.37192681532292\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 188\n",
+      "  episodes_total: 4770\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.712892139951388\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007282022580814858\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010588849492099447\n",
+      "        total_loss: 9.326696952184042\n",
+      "        vf_explained_var: 0.984372079372406\n",
+      "        vf_loss: 9.336185693740845\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.865384615384617\n",
+      "    gpu_util_percent0: 0.3211538461538461\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7653846153846158\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15143126271022408\n",
+      "    mean_env_wait_ms: 1.1906497688401347\n",
+      "    mean_inference_ms: 4.635565144109004\n",
+      "    mean_raw_obs_processing_ms: 0.3954749750444413\n",
+      "  time_since_restore: 571.5366971492767\n",
+      "  time_this_iter_s: 22.63988161087036\n",
+      "  time_total_s: 571.5366971492767\n",
+      "  timers:\n",
+      "    learn_throughput: 10428.547\n",
+      "    learn_time_ms: 15514.338\n",
+      "    sample_throughput: 23036.553\n",
+      "    sample_time_ms: 7023.273\n",
+      "    update_time_ms: 38.29\n",
+      "  timestamp: 1602494996\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     25 |          571.537 | 4044800 |  245.372 |              291.626 |              138.293 |            829.072 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3436.1666334065058\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-30-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 828.2643381623338\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 246.06244825712966\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 269\n",
+      "  episodes_total: 5039\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6960836946964264\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0067783767978350324\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009497678205661941\n",
+      "        total_loss: 9.854984839757284\n",
+      "        vf_explained_var: 0.9858968257904053\n",
+      "        vf_loss: 9.86347476641337\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.766666666666666\n",
+      "    gpu_util_percent0: 0.26814814814814814\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1512703561173303\n",
+      "    mean_env_wait_ms: 1.1913865426440073\n",
+      "    mean_inference_ms: 4.622600936815719\n",
+      "    mean_raw_obs_processing_ms: 0.39486517336879373\n",
+      "  time_since_restore: 594.444696187973\n",
+      "  time_this_iter_s: 22.90799903869629\n",
+      "  time_total_s: 594.444696187973\n",
+      "  timers:\n",
+      "    learn_throughput: 10410.872\n",
+      "    learn_time_ms: 15540.677\n",
+      "    sample_throughput: 23045.044\n",
+      "    sample_time_ms: 7020.685\n",
+      "    update_time_ms: 38.302\n",
+      "  timestamp: 1602495019\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | RUNNING  | 172.17.0.4:38914 |     26 |          594.445 | 4206592 |  246.062 |              291.626 |              138.293 |            828.264 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_2368d_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3433.269571924412\n",
+      "    time_step_min: 3156\n",
+      "  date: 2020-10-12_09-30-42\n",
+      "  done: true\n",
+      "  episode_len_mean: 827.7301495972382\n",
+      "  episode_reward_max: 291.6262626262624\n",
+      "  episode_reward_mean: 246.5109262940102\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 175\n",
+      "  episodes_total: 5214\n",
+      "  experiment_id: b35504ea99e6454b9b23eaebff6c8ae6\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7203244020541509\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006474755665597816\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008001692759838383\n",
+      "        total_loss: 8.758366187413534\n",
+      "        vf_explained_var: 0.9835500717163086\n",
+      "        vf_loss: 8.765433549880981\n",
+      "    num_steps_sampled: 4368384\n",
+      "    num_steps_trained: 4368384\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.35185185185185\n",
+      "    gpu_util_percent0: 0.2525925925925926\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.777777777777778\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 38914\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1511747547181723\n",
+      "    mean_env_wait_ms: 1.1918082964819434\n",
+      "    mean_inference_ms: 4.6145812163910245\n",
+      "    mean_raw_obs_processing_ms: 0.3944869495641862\n",
+      "  time_since_restore: 617.2291052341461\n",
+      "  time_this_iter_s: 22.784409046173096\n",
+      "  time_total_s: 617.2291052341461\n",
+      "  timers:\n",
+      "    learn_throughput: 10412.647\n",
+      "    learn_time_ms: 15538.028\n",
+      "    sample_throughput: 23025.938\n",
+      "    sample_time_ms: 7026.511\n",
+      "    update_time_ms: 38.592\n",
+      "  timestamp: 1602495042\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4368384\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 2368d_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | TERMINATED |       |     27 |          617.229 | 4368384 |  246.511 |              291.626 |              138.293 |             827.73 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "2020-10-12 09:30:42,885\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff61dc472601000000.\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m 2020-10-12 09:30:42,808\tERROR worker.py:372 -- SystemExit was raised from the worker\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py\", line 553, in actor_method_executor\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     return method(actor, *args, **kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 929, in __ray_terminate__\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     ray.actor.exit_actor()\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 996, in exit_actor\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     raise exit\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m SystemExit: 0\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m During handling of the above exception, another exception occurred:\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 553, in ray._raylet.task_execution_handler\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/_raylet.pyx\", line 440, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 167, in format_exc\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 120, in format_exception\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     return list(TracebackException(\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 509, in __init__\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     self.stack = StackSummary.extract(\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 359, in extract\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     result.append(FrameSummary(\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 243, in __init__\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     def __init__(self, filename, lineno, name, *, lookup_line=True,\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 369, in sigterm_handler\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m     sys.exit(1)\n",
+      "\u001b[2m\u001b[36m(pid=38870)\u001b[0m SystemExit: 1\n",
+      "\u001b[2m\u001b[33m(pid=raylet)\u001b[0m E1012 09:30:42.886673 38754 38754 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_2368d_00000 | TERMINATED |       |     27 |          617.229 | 4368384 |  246.511 |              291.626 |              138.293 |             827.73 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 38661\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_092010-zi1cm2xf/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_092010-zi1cm2xf/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3156\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602495042\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4143\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3433.26957\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.62626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.29293\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 246.51093\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 5214\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 27\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdevout-sweep-9\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zi1cm2xf\u001b[0m\n",
+      "2020-10-12 09:30:54,590 - wandb.wandb_agent - INFO - Cleaning up finished run: zi1cm2xf\n",
+      "2020-10-12 09:30:54,950 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 09:30:54,951 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tentropy_coeff: 0.0005\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 09:30:54,953 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --entropy_coeff=0.0005 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 09:30:59,971 - wandb.wandb_agent - INFO - Running runs: ['d8bggh8m']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwild-sweep-10\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/d8bggh8m\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_093056-d8bggh8m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 09:31:00,668\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=69901)\u001b[0m 2020-10-12 09:31:03,338\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=69783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69864)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69864)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69786)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69786)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69782)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69782)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69873)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69873)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69851)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69851)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69801)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69801)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69861)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69861)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69804)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69804)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69790)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69790)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69787)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69787)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69789)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69789)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69785)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69785)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69784)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69784)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=69875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=69875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_09-31-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1823383669058483\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.006917016425480445\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009157503198366612\n",
+      "        total_loss: 507.07493591308594\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.741176470588236\n",
+      "    gpu_util_percent0: 0.27999999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5676470588235296\n",
+      "    vram_util_percent0: 0.08659541218914593\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1706032312810697\n",
+      "    mean_env_wait_ms: 1.1820741125226353\n",
+      "    mean_inference_ms: 5.6304426390508615\n",
+      "    mean_raw_obs_processing_ms: 0.4503037628475329\n",
+      "  time_since_restore: 28.269787549972534\n",
+      "  time_this_iter_s: 28.269787549972534\n",
+      "  time_total_s: 28.269787549972534\n",
+      "  timers:\n",
+      "    learn_throughput: 8296.701\n",
+      "    learn_time_ms: 19500.762\n",
+      "    sample_throughput: 18600.765\n",
+      "    sample_time_ms: 8698.137\n",
+      "    update_time_ms: 41.837\n",
+      "  timestamp: 1602495097\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      1 |          28.2698 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3614.2256944444443\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_09-32-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 892.4873417721519\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 217.54734049354283\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.149937113126119\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007523950111741821\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00998671705989788\n",
+      "        total_loss: 126.33550771077473\n",
+      "        vf_explained_var: 0.8110877871513367\n",
+      "        vf_loss: 126.34455998738606\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.690624999999997\n",
+      "    gpu_util_percent0: 0.33218749999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.753125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16582102436586446\n",
+      "    mean_env_wait_ms: 1.1757634400756574\n",
+      "    mean_inference_ms: 5.40283045650808\n",
+      "    mean_raw_obs_processing_ms: 0.438719071797137\n",
+      "  time_since_restore: 54.7525577545166\n",
+      "  time_this_iter_s: 26.482770204544067\n",
+      "  time_total_s: 54.7525577545166\n",
+      "  timers:\n",
+      "    learn_throughput: 8414.328\n",
+      "    learn_time_ms: 19228.155\n",
+      "    sample_throughput: 20028.496\n",
+      "    sample_time_ms: 8078.09\n",
+      "    update_time_ms: 32.139\n",
+      "  timestamp: 1602495123\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      2 |          54.7526 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3605.479820627803\n",
+      "    time_step_min: 3310\n",
+      "  date: 2020-10-12_09-32-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 888.5801687763714\n",
+      "  episode_reward_max: 264.50505050505006\n",
+      "  episode_reward_mean: 219.20585602864062\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1411352157592773\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010440803055341044\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013970387983135879\n",
+      "        total_loss: 54.93683338165283\n",
+      "        vf_explained_var: 0.8966913819313049\n",
+      "        vf_loss: 54.94928582509359\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.384375\n",
+      "    gpu_util_percent0: 0.2896875\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7750000000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16280803946873557\n",
+      "    mean_env_wait_ms: 1.1738148708567302\n",
+      "    mean_inference_ms: 5.235817334700198\n",
+      "    mean_raw_obs_processing_ms: 0.4307773715856723\n",
+      "  time_since_restore: 81.17681360244751\n",
+      "  time_this_iter_s: 26.424255847930908\n",
+      "  time_total_s: 81.17681360244751\n",
+      "  timers:\n",
+      "    learn_throughput: 8410.61\n",
+      "    learn_time_ms: 19236.655\n",
+      "    sample_throughput: 20871.622\n",
+      "    sample_time_ms: 7751.769\n",
+      "    update_time_ms: 28.37\n",
+      "  timestamp: 1602495150\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      3 |          81.1768 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3591.1639072847684\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_09-32-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.4873417721519\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 221.420326684567\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1191200812657673\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011468215147033334\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013862663588952273\n",
+      "        total_loss: 39.326786041259766\n",
+      "        vf_explained_var: 0.9241357445716858\n",
+      "        vf_loss: 39.33891359965006\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.103125\n",
+      "    gpu_util_percent0: 0.3578125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16076016041517052\n",
+      "    mean_env_wait_ms: 1.1730123640074046\n",
+      "    mean_inference_ms: 5.115626480000997\n",
+      "    mean_raw_obs_processing_ms: 0.4246610408231483\n",
+      "  time_since_restore: 107.39726638793945\n",
+      "  time_this_iter_s: 26.220452785491943\n",
+      "  time_total_s: 107.39726638793945\n",
+      "  timers:\n",
+      "    learn_throughput: 8444.124\n",
+      "    learn_time_ms: 19160.307\n",
+      "    sample_throughput: 21289.165\n",
+      "    sample_time_ms: 7599.735\n",
+      "    update_time_ms: 30.529\n",
+      "  timestamp: 1602495176\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      4 |          107.397 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3577.469816272966\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_09-33-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 882.6164556962025\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 223.37348165196246\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0904998779296875\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010465693194419146\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013936646308138734\n",
+      "        total_loss: 29.070746898651123\n",
+      "        vf_explained_var: 0.9454066157341003\n",
+      "        vf_loss: 29.0831356048584\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.73225806451613\n",
+      "    gpu_util_percent0: 0.31580645161290327\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15921377221334443\n",
+      "    mean_env_wait_ms: 1.1729646717527076\n",
+      "    mean_inference_ms: 5.0246544027543685\n",
+      "    mean_raw_obs_processing_ms: 0.4197779138191918\n",
+      "  time_since_restore: 133.44354581832886\n",
+      "  time_this_iter_s: 26.046279430389404\n",
+      "  time_total_s: 133.44354581832886\n",
+      "  timers:\n",
+      "    learn_throughput: 8460.765\n",
+      "    learn_time_ms: 19122.62\n",
+      "    sample_throughput: 21637.895\n",
+      "    sample_time_ms: 7477.252\n",
+      "    update_time_ms: 32.096\n",
+      "  timestamp: 1602495202\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      5 |          133.444 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3562.2380487804876\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_09-33-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 875.4055080721747\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 225.90998302109395\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 263\n",
+      "  episodes_total: 1053\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0669801433881123\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010119187956055006\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014624884177464992\n",
+      "        total_loss: 30.67037757237752\n",
+      "        vf_explained_var: 0.9617660641670227\n",
+      "        vf_loss: 30.683512210845947\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.19375\n",
+      "    gpu_util_percent0: 0.43093750000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15738681973338306\n",
+      "    mean_env_wait_ms: 1.17444902530319\n",
+      "    mean_inference_ms: 4.917084374849647\n",
+      "    mean_raw_obs_processing_ms: 0.4140822595710767\n",
+      "  time_since_restore: 159.70570516586304\n",
+      "  time_this_iter_s: 26.26215934753418\n",
+      "  time_total_s: 159.70570516586304\n",
+      "  timers:\n",
+      "    learn_throughput: 8454.515\n",
+      "    learn_time_ms: 19136.758\n",
+      "    sample_throughput: 21915.619\n",
+      "    sample_time_ms: 7382.498\n",
+      "    update_time_ms: 42.043\n",
+      "  timestamp: 1602495228\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      6 |          159.706 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3547.7540453074434\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_09-34-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 868.5514240506329\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 228.15807601329732\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 211\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0668786863485973\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.012256689059237639\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01610318278350557\n",
+      "        total_loss: 20.370780150095623\n",
+      "        vf_explained_var: 0.963979959487915\n",
+      "        vf_loss: 20.384966214497883\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.951612903225808\n",
+      "    gpu_util_percent0: 0.39806451612903226\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15631439565107336\n",
+      "    mean_env_wait_ms: 1.175829711355721\n",
+      "    mean_inference_ms: 4.855880701336491\n",
+      "    mean_raw_obs_processing_ms: 0.410889061224067\n",
+      "  time_since_restore: 186.14849662780762\n",
+      "  time_this_iter_s: 26.44279146194458\n",
+      "  time_total_s: 186.14849662780762\n",
+      "  timers:\n",
+      "    learn_throughput: 8449.54\n",
+      "    learn_time_ms: 19148.025\n",
+      "    sample_throughput: 22019.601\n",
+      "    sample_time_ms: 7347.635\n",
+      "    update_time_ms: 41.121\n",
+      "  timestamp: 1602495255\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      7 |          186.148 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3536.647776183644\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_09-34-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 862.704641350211\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 229.98016025231198\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0334690809249878\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010793289790550867\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015747709141578525\n",
+      "        total_loss: 15.715624650319418\n",
+      "        vf_explained_var: 0.969296395778656\n",
+      "        vf_loss: 15.729730685551962\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.361290322580643\n",
+      "    gpu_util_percent0: 0.3574193548387097\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.780645161290322\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15567327988933125\n",
+      "    mean_env_wait_ms: 1.1770876489003141\n",
+      "    mean_inference_ms: 4.8179954108961445\n",
+      "    mean_raw_obs_processing_ms: 0.4088420134598298\n",
+      "  time_since_restore: 211.94712591171265\n",
+      "  time_this_iter_s: 25.79862928390503\n",
+      "  time_total_s: 211.94712591171265\n",
+      "  timers:\n",
+      "    learn_throughput: 8468.927\n",
+      "    learn_time_ms: 19104.192\n",
+      "    sample_throughput: 22175.584\n",
+      "    sample_time_ms: 7295.952\n",
+      "    update_time_ms: 38.011\n",
+      "  timestamp: 1602495281\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      8 |          211.947 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3525.568943298969\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_09-35-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 857.1208860759493\n",
+      "  episode_reward_max: 279.3535353535359\n",
+      "  episode_reward_mean: 231.70662319396482\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0033017992973328\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010770521514738599\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015525121105990062\n",
+      "        total_loss: 16.273523728052776\n",
+      "        vf_explained_var: 0.9674468040466309\n",
+      "        vf_loss: 16.28739635149638\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.090625000000003\n",
+      "    gpu_util_percent0: 0.3553125\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.771875\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.155116540595777\n",
+      "    mean_env_wait_ms: 1.1784839514372694\n",
+      "    mean_inference_ms: 4.784972930701284\n",
+      "    mean_raw_obs_processing_ms: 0.4069818494819767\n",
+      "  time_since_restore: 237.8651885986328\n",
+      "  time_this_iter_s: 25.918062686920166\n",
+      "  time_total_s: 237.8651885986328\n",
+      "  timers:\n",
+      "    learn_throughput: 8479.955\n",
+      "    learn_time_ms: 19079.347\n",
+      "    sample_throughput: 22292.428\n",
+      "    sample_time_ms: 7257.711\n",
+      "    update_time_ms: 36.017\n",
+      "  timestamp: 1602495307\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      9 |          237.865 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3504.7218934911243\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_09-35-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.3826179120297\n",
+      "  episode_reward_max: 284.0505050505049\n",
+      "  episode_reward_mean: 234.9192882722293\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9698180854320526\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008762541770314177\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011754670903125467\n",
+      "        total_loss: 22.15676514307658\n",
+      "        vf_explained_var: 0.9699413776397705\n",
+      "        vf_loss: 22.167253017425537\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.82258064516129\n",
+      "    gpu_util_percent0: 0.3303225806451613\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7645161290322577\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1542483860669258\n",
+      "    mean_env_wait_ms: 1.181754387642914\n",
+      "    mean_inference_ms: 4.73275266033599\n",
+      "    mean_raw_obs_processing_ms: 0.4041681313374543\n",
+      "  time_since_restore: 263.87894344329834\n",
+      "  time_this_iter_s: 26.013754844665527\n",
+      "  time_total_s: 263.87894344329834\n",
+      "  timers:\n",
+      "    learn_throughput: 8483.789\n",
+      "    learn_time_ms: 19070.725\n",
+      "    sample_throughput: 22393.486\n",
+      "    sample_time_ms: 7224.958\n",
+      "    update_time_ms: 35.818\n",
+      "  timestamp: 1602495333\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     10 |          263.879 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3494.990128331688\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_09-35-59\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.626582278481\n",
+      "  episode_reward_max: 287.38383838383817\n",
+      "  episode_reward_mean: 236.53693212553955\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.959399938583374\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009050344349816442\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014448691198291877\n",
+      "        total_loss: 14.143741130828857\n",
+      "        vf_explained_var: 0.9704552292823792\n",
+      "        vf_loss: 14.156859795252482\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.72258064516129\n",
+      "    gpu_util_percent0: 0.3361290322580645\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7774193548387096\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15385116156127512\n",
+      "    mean_env_wait_ms: 1.1834246683300518\n",
+      "    mean_inference_ms: 4.709276635922973\n",
+      "    mean_raw_obs_processing_ms: 0.40286794856730274\n",
+      "  time_since_restore: 289.79921793937683\n",
+      "  time_this_iter_s: 25.92027449607849\n",
+      "  time_total_s: 289.79921793937683\n",
+      "  timers:\n",
+      "    learn_throughput: 8509.034\n",
+      "    learn_time_ms: 19014.145\n",
+      "    sample_throughput: 22962.238\n",
+      "    sample_time_ms: 7046.003\n",
+      "    update_time_ms: 33.835\n",
+      "  timestamp: 1602495359\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     11 |          289.799 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3486.236721611722\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-36-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.50226039783\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 237.80845069136197\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9463174144426981\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009074758971109986\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014368217787705362\n",
+      "        total_loss: 10.841783205668131\n",
+      "        vf_explained_var: 0.9763579368591309\n",
+      "        vf_loss: 10.854809761047363\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.564516129032253\n",
+      "    gpu_util_percent0: 0.30129032258064514\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7806451612903227\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15352615558692534\n",
+      "    mean_env_wait_ms: 1.18493950428817\n",
+      "    mean_inference_ms: 4.689246037556198\n",
+      "    mean_raw_obs_processing_ms: 0.40173597296905394\n",
+      "  time_since_restore: 315.95725440979004\n",
+      "  time_this_iter_s: 26.158036470413208\n",
+      "  time_total_s: 315.95725440979004\n",
+      "  timers:\n",
+      "    learn_throughput: 8496.29\n",
+      "    learn_time_ms: 19042.665\n",
+      "    sample_throughput: 23169.192\n",
+      "    sample_time_ms: 6983.066\n",
+      "    update_time_ms: 35.087\n",
+      "  timestamp: 1602495385\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     12 |          315.957 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3477.1867900715188\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-36-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.276923076923\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 239.12358512358495\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 193\n",
+      "  episodes_total: 2405\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9069925745328268\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009530291194096208\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014515867456793785\n",
+      "        total_loss: 15.319237470626831\n",
+      "        vf_explained_var: 0.9747470021247864\n",
+      "        vf_loss: 15.332300901412964\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.335483870967746\n",
+      "    gpu_util_percent0: 0.3419354838709677\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15318451301500233\n",
+      "    mean_env_wait_ms: 1.1868007730600614\n",
+      "    mean_inference_ms: 4.667199300470967\n",
+      "    mean_raw_obs_processing_ms: 0.4004844786802626\n",
+      "  time_since_restore: 341.68492245674133\n",
+      "  time_this_iter_s: 25.727668046951294\n",
+      "  time_total_s: 341.68492245674133\n",
+      "  timers:\n",
+      "    learn_throughput: 8515.012\n",
+      "    learn_time_ms: 19000.796\n",
+      "    sample_throughput: 23264.32\n",
+      "    sample_time_ms: 6954.512\n",
+      "    update_time_ms: 35.027\n",
+      "  timestamp: 1602495411\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     13 |          341.685 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3465.9672686230247\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-37-17\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.3082650781831\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 240.80178553968565\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 281\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9011691262324651\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010886709050585827\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01605825025762897\n",
+      "        total_loss: 13.799258867899576\n",
+      "        vf_explained_var: 0.9779562950134277\n",
+      "        vf_loss: 13.813590288162231\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.28064516129032\n",
+      "    gpu_util_percent0: 0.3680645161290322\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7677419354838704\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15272069323343457\n",
+      "    mean_env_wait_ms: 1.1891189732666108\n",
+      "    mean_inference_ms: 4.639373399553593\n",
+      "    mean_raw_obs_processing_ms: 0.39890077522278816\n",
+      "  time_since_restore: 367.5613408088684\n",
+      "  time_this_iter_s: 25.876418352127075\n",
+      "  time_total_s: 367.5613408088684\n",
+      "  timers:\n",
+      "    learn_throughput: 8511.704\n",
+      "    learn_time_ms: 19008.179\n",
+      "    sample_throughput: 23386.097\n",
+      "    sample_time_ms: 6918.298\n",
+      "    update_time_ms: 34.621\n",
+      "  timestamp: 1602495437\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     14 |          367.561 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3459.754971590909\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-37-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.3291139240506\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 241.694508374888\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8705271085103353\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010132285223032037\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01209646585630253\n",
+      "        total_loss: 9.354986588160196\n",
+      "        vf_explained_var: 0.9806396961212158\n",
+      "        vf_loss: 9.36549154917399\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.243333333333336\n",
+      "    gpu_util_percent0: 0.378\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7833333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15249740481549917\n",
+      "    mean_env_wait_ms: 1.1903172938011715\n",
+      "    mean_inference_ms: 4.62561428432916\n",
+      "    mean_raw_obs_processing_ms: 0.3981163619264575\n",
+      "  time_since_restore: 393.3409516811371\n",
+      "  time_this_iter_s: 25.779610872268677\n",
+      "  time_total_s: 393.3409516811371\n",
+      "  timers:\n",
+      "    learn_throughput: 8515.515\n",
+      "    learn_time_ms: 18999.673\n",
+      "    sample_throughput: 23451.528\n",
+      "    sample_time_ms: 6898.996\n",
+      "    update_time_ms: 35.102\n",
+      "  timestamp: 1602495463\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     15 |          393.341 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3454.032279757902\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-38-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 828.5073284477015\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 242.50461645098542\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8471738596757253\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009305963292717934\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01094130908313673\n",
+      "        total_loss: 10.646601835886637\n",
+      "        vf_explained_var: 0.9784726500511169\n",
+      "        vf_loss: 10.656105756759644\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.225\n",
+      "    gpu_util_percent0: 0.38656250000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.775\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15228918826336724\n",
+      "    mean_env_wait_ms: 1.1914508541726399\n",
+      "    mean_inference_ms: 4.612918529018248\n",
+      "    mean_raw_obs_processing_ms: 0.39737396786903656\n",
+      "  time_since_restore: 419.60946822166443\n",
+      "  time_this_iter_s: 26.268516540527344\n",
+      "  time_total_s: 419.60946822166443\n",
+      "  timers:\n",
+      "    learn_throughput: 8514.727\n",
+      "    learn_time_ms: 19001.431\n",
+      "    sample_throughput: 23437.658\n",
+      "    sample_time_ms: 6903.079\n",
+      "    update_time_ms: 29.57\n",
+      "  timestamp: 1602495489\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     16 |          419.609 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3446.2361408882084\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_09-38-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.9881566960219\n",
+      "  episode_reward_max: 289.9595959595964\n",
+      "  episode_reward_mean: 243.72948433622582\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 291\n",
+      "  episodes_total: 3293\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8250234176715215\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008491925351942578\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014777651784243062\n",
+      "        total_loss: 15.209494908650717\n",
+      "        vf_explained_var: 0.9786728024482727\n",
+      "        vf_loss: 15.222986777623495\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.845161290322586\n",
+      "    gpu_util_percent0: 0.30064516129032254\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.770967741935483\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15194983700517062\n",
+      "    mean_env_wait_ms: 1.193424276440354\n",
+      "    mean_inference_ms: 4.592054535507143\n",
+      "    mean_raw_obs_processing_ms: 0.3961640095375659\n",
+      "  time_since_restore: 445.8301305770874\n",
+      "  time_this_iter_s: 26.220662355422974\n",
+      "  time_total_s: 445.8301305770874\n",
+      "  timers:\n",
+      "    learn_throughput: 8516.051\n",
+      "    learn_time_ms: 18998.478\n",
+      "    sample_throughput: 23505.365\n",
+      "    sample_time_ms: 6883.194\n",
+      "    update_time_ms: 29.602\n",
+      "  timestamp: 1602495516\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     17 |           445.83 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3440.9040023201856\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-39-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.563003452244\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 244.5732671943833\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 183\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8241499215364456\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007864817045629025\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01140341673938868\n",
+      "        total_loss: 8.79675587018331\n",
+      "        vf_explained_var: 0.9828992486000061\n",
+      "        vf_loss: 8.806998491287231\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.18387096774193\n",
+      "    gpu_util_percent0: 0.3493548387096774\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.787096774193548\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15175248665701024\n",
+      "    mean_env_wait_ms: 1.1945114475347647\n",
+      "    mean_inference_ms: 4.580413585929778\n",
+      "    mean_raw_obs_processing_ms: 0.3954965651313218\n",
+      "  time_since_restore: 471.92249512672424\n",
+      "  time_this_iter_s: 26.09236454963684\n",
+      "  time_total_s: 471.92249512672424\n",
+      "  timers:\n",
+      "    learn_throughput: 8507.172\n",
+      "    learn_time_ms: 19018.307\n",
+      "    sample_throughput: 23482.92\n",
+      "    sample_time_ms: 6889.773\n",
+      "    update_time_ms: 31.753\n",
+      "  timestamp: 1602495542\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     18 |          471.922 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3436.840266222962\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-39-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.8428728673638\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.09397497262097\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8113949745893478\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008743428780386845\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012751462903300611\n",
+      "        total_loss: 8.8964794476827\n",
+      "        vf_explained_var: 0.9816879630088806\n",
+      "        vf_loss: 8.907887935638428\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.784375\n",
+      "    gpu_util_percent0: 0.38625\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.151597397235719\n",
+      "    mean_env_wait_ms: 1.1953715585590745\n",
+      "    mean_inference_ms: 4.57108739623239\n",
+      "    mean_raw_obs_processing_ms: 0.39495320036159126\n",
+      "  time_since_restore: 498.16626834869385\n",
+      "  time_this_iter_s: 26.243773221969604\n",
+      "  time_total_s: 498.16626834869385\n",
+      "  timers:\n",
+      "    learn_throughput: 8488.395\n",
+      "    learn_time_ms: 19060.376\n",
+      "    sample_throughput: 23518.539\n",
+      "    sample_time_ms: 6879.339\n",
+      "    update_time_ms: 32.878\n",
+      "  timestamp: 1602495568\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     19 |          498.166 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3432.525217850541\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-39-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.0579292267365\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.79004990931585\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 181\n",
+      "  episodes_total: 3815\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7609985868136088\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00916624628007412\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012107667707217237\n",
+      "        total_loss: 10.657151778539022\n",
+      "        vf_explained_var: 0.9814252257347107\n",
+      "        vf_loss: 10.66780686378479\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.46129032258065\n",
+      "    gpu_util_percent0: 0.29387096774193544\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7806451612903227\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15143379689100692\n",
+      "    mean_env_wait_ms: 1.1962897590929857\n",
+      "    mean_inference_ms: 4.561024131285795\n",
+      "    mean_raw_obs_processing_ms: 0.39436647599235486\n",
+      "  time_since_restore: 524.3989090919495\n",
+      "  time_this_iter_s: 26.232640743255615\n",
+      "  time_total_s: 524.3989090919495\n",
+      "  timers:\n",
+      "    learn_throughput: 8479.166\n",
+      "    learn_time_ms: 19081.122\n",
+      "    sample_throughput: 23518.349\n",
+      "    sample_time_ms: 6879.394\n",
+      "    update_time_ms: 33.453\n",
+      "  timestamp: 1602495595\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     20 |          524.399 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3425.473593711619\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-40-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.8972920224445\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 246.80025184758034\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4099\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7578712403774261\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0086368964985013\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011422600480727851\n",
+      "        total_loss: 10.725571791330973\n",
+      "        vf_explained_var: 0.9839944839477539\n",
+      "        vf_loss: 10.735645691553751\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.603225806451615\n",
+      "    gpu_util_percent0: 0.35129032258064513\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7645161290322577\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15119852929530592\n",
+      "    mean_env_wait_ms: 1.1975670107903695\n",
+      "    mean_inference_ms: 4.5469503490892755\n",
+      "    mean_raw_obs_processing_ms: 0.3935541127176128\n",
+      "  time_since_restore: 550.3081252574921\n",
+      "  time_this_iter_s: 25.909216165542603\n",
+      "  time_total_s: 550.3081252574921\n",
+      "  timers:\n",
+      "    learn_throughput: 8480.142\n",
+      "    learn_time_ms: 19078.926\n",
+      "    sample_throughput: 23518.656\n",
+      "    sample_time_ms: 6879.305\n",
+      "    update_time_ms: 33.779\n",
+      "  timestamp: 1602495621\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     21 |          550.308 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3421.670599339311\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-40-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.5065635255509\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.35105627299706\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7521579414606094\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007824398732433716\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01322558480508936\n",
+      "        total_loss: 7.959930698076884\n",
+      "        vf_explained_var: 0.9843184947967529\n",
+      "        vf_loss: 7.971967538197835\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.20322580645162\n",
+      "    gpu_util_percent0: 0.4109677419354838\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.777419354838709\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1510679868990353\n",
+      "    mean_env_wait_ms: 1.1982443737022626\n",
+      "    mean_inference_ms: 4.539386141207358\n",
+      "    mean_raw_obs_processing_ms: 0.3931198875982084\n",
+      "  time_since_restore: 576.5084743499756\n",
+      "  time_this_iter_s: 26.20034909248352\n",
+      "  time_total_s: 576.5084743499756\n",
+      "  timers:\n",
+      "    learn_throughput: 8483.554\n",
+      "    learn_time_ms: 19071.253\n",
+      "    sample_throughput: 23483.086\n",
+      "    sample_time_ms: 6889.725\n",
+      "    update_time_ms: 34.36\n",
+      "  timestamp: 1602495647\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     22 |          576.508 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a4b10_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3418.63762511374\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-41-13\n",
+      "  done: true\n",
+      "  episode_len_mean: 821.0913200723327\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.84626098233684\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: 3c8f436c080648ceb1e1d86467b9e445\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.739922359585762\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008788479414458076\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013709326779159406\n",
+      "        total_loss: 7.252472162246704\n",
+      "        vf_explained_var: 0.9847645163536072\n",
+      "        vf_loss: 7.264793713887532\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.375\n",
+      "    gpu_util_percent0: 0.43624999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.78125\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 69901\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15095415633269516\n",
+      "    mean_env_wait_ms: 1.1988304948090098\n",
+      "    mean_inference_ms: 4.53258037682116\n",
+      "    mean_raw_obs_processing_ms: 0.3927268538387242\n",
+      "  time_since_restore: 602.7547671794891\n",
+      "  time_this_iter_s: 26.24629282951355\n",
+      "  time_total_s: 602.7547671794891\n",
+      "  timers:\n",
+      "    learn_throughput: 8459.796\n",
+      "    learn_time_ms: 19124.81\n",
+      "    sample_throughput: 23498.028\n",
+      "    sample_time_ms: 6885.344\n",
+      "    update_time_ms: 36.405\n",
+      "  timestamp: 1602495673\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: a4b10_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | TERMINATED |       |     23 |          602.755 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a4b10_00000 | TERMINATED |       |     23 |          602.755 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 69634\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_093056-d8bggh8m/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_093056-d8bggh8m/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3098\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 618\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602495674\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4172\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3418.63763\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 296.62626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 133.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.84626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mwild-sweep-10\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/d8bggh8m\u001b[0m\n",
+      "2020-10-12 09:41:25,529 - wandb.wandb_agent - INFO - Cleaning up finished run: d8bggh8m\n",
+      "2020-10-12 09:41:25,920 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 09:41:25,920 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tentropy_coeff: 0.0001\n",
+      "\tnum_sgd_iter: 20\n",
+      "2020-10-12 09:41:25,922 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --entropy_coeff=0.0001 --num_sgd_iter=20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 09:41:30,938 - wandb.wandb_agent - INFO - Running runs: ['bp1vs2s3']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mamber-sweep-11\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/q78e25ms\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/bp1vs2s3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_094127-bp1vs2s3\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-12 09:41:31,654\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=15409)\u001b[0m 2020-10-12 09:41:34,369\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=15387)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15387)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15408)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15408)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15397)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15397)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15427)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15427)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15413)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15413)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15380)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15380)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15394)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15394)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15392)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15392)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15418)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15418)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15402)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15402)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15389)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15389)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15422)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15422)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15294)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15294)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15293)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15293)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15303)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15303)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15404)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15404)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15399)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15399)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15291)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15291)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15405)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15405)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15296)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15296)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15302)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15302)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15307)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15307)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15396)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15396)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15367)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15367)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15374)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15374)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15416)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15416)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15390)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15390)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=15287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=15287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_09-42-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1827652951081593\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007272620219737291\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007613244587749553\n",
+      "        total_loss: 514.7338180541992\n",
+      "        vf_explained_var: 0.4917435944080353\n",
+      "        vf_loss: 514.7400767008463\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.096551724137928\n",
+      "    gpu_util_percent0: 0.28034482758620693\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5482758620689663\n",
+      "    vram_util_percent0: 0.08518055665509329\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16719988298548635\n",
+      "    mean_env_wait_ms: 1.1723686552739652\n",
+      "    mean_inference_ms: 5.654562095978923\n",
+      "    mean_raw_obs_processing_ms: 0.44828229128633545\n",
+      "  time_since_restore: 24.73012089729309\n",
+      "  time_this_iter_s: 24.73012089729309\n",
+      "  time_total_s: 24.73012089729309\n",
+      "  timers:\n",
+      "    learn_throughput: 10320.222\n",
+      "    learn_time_ms: 15677.182\n",
+      "    sample_throughput: 18007.396\n",
+      "    sample_time_ms: 8984.753\n",
+      "    update_time_ms: 29.302\n",
+      "  timestamp: 1602495724\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      1 |          24.7301 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3628.777777777778\n",
+      "    time_step_min: 3352\n",
+      "  date: 2020-10-12_09-42-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1075949367089\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.1851425648892\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1526374816894531\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00941026327200234\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006966680482340355\n",
+      "        total_loss: 150.38987477620444\n",
+      "        vf_explained_var: 0.788153886795044\n",
+      "        vf_loss: 150.39507675170898\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.85555555555556\n",
+      "    gpu_util_percent0: 0.2437037037037037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7518518518518515\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16348414029564448\n",
+      "    mean_env_wait_ms: 1.167435498228299\n",
+      "    mean_inference_ms: 5.453774285819036\n",
+      "    mean_raw_obs_processing_ms: 0.4380923883127803\n",
+      "  time_since_restore: 48.18699240684509\n",
+      "  time_this_iter_s: 23.456871509552002\n",
+      "  time_total_s: 48.18699240684509\n",
+      "  timers:\n",
+      "    learn_throughput: 10361.762\n",
+      "    learn_time_ms: 15614.332\n",
+      "    sample_throughput: 19268.285\n",
+      "    sample_time_ms: 8396.803\n",
+      "    update_time_ms: 37.785\n",
+      "  timestamp: 1602495747\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      2 |           48.187 | 323584 |  216.185 |              258.596 |              138.293 |            891.108 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3620.919282511211\n",
+      "    time_step_min: 3352\n",
+      "  date: 2020-10-12_09-42-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 886.5253164556962\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 217.62197928653603\n",
+      "  episode_reward_min: 138.29292929292922\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1465057929356892\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007596938055939972\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00962961143522989\n",
+      "        total_loss: 67.56635856628418\n",
+      "        vf_explained_var: 0.8835484385490417\n",
+      "        vf_loss: 67.57458432515462\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.669230769230772\n",
+      "    gpu_util_percent0: 0.22730769230769232\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1609748364818216\n",
+      "    mean_env_wait_ms: 1.1668825514250778\n",
+      "    mean_inference_ms: 5.285935702802652\n",
+      "    mean_raw_obs_processing_ms: 0.4299000724180522\n",
+      "  time_since_restore: 70.7890784740448\n",
+      "  time_this_iter_s: 22.602086067199707\n",
+      "  time_total_s: 70.7890784740448\n",
+      "  timers:\n",
+      "    learn_throughput: 10389.349\n",
+      "    learn_time_ms: 15572.872\n",
+      "    sample_throughput: 20365.656\n",
+      "    sample_time_ms: 7944.355\n",
+      "    update_time_ms: 33.242\n",
+      "  timestamp: 1602495770\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      3 |          70.7891 | 485376 |  217.622 |              258.596 |              138.293 |            886.525 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3612.041390728477\n",
+      "    time_step_min: 3305\n",
+      "  date: 2020-10-12_09-43-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 883.496835443038\n",
+      "  episode_reward_max: 265.26262626262604\n",
+      "  episode_reward_mean: 218.3276914716786\n",
+      "  episode_reward_min: 132.98989898989885\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1241056124369304\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.011608533406009277\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00946155054649959\n",
+      "        total_loss: 60.05288569132487\n",
+      "        vf_explained_var: 0.8973535895347595\n",
+      "        vf_loss: 60.060139656066895\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.76923076923077\n",
+      "    gpu_util_percent0: 0.25730769230769224\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.757692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15918644024100886\n",
+      "    mean_env_wait_ms: 1.1671787041913788\n",
+      "    mean_inference_ms: 5.161566920499106\n",
+      "    mean_raw_obs_processing_ms: 0.42358548790394485\n",
+      "  time_since_restore: 93.4354133605957\n",
+      "  time_this_iter_s: 22.646334886550903\n",
+      "  time_total_s: 93.4354133605957\n",
+      "  timers:\n",
+      "    learn_throughput: 10400.027\n",
+      "    learn_time_ms: 15556.883\n",
+      "    sample_throughput: 20944.531\n",
+      "    sample_time_ms: 7724.785\n",
+      "    update_time_ms: 30.506\n",
+      "  timestamp: 1602495793\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      4 |          93.4354 | 647168 |  218.328 |              265.263 |               132.99 |            883.497 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3606.551181102362\n",
+      "    time_step_min: 3305\n",
+      "  date: 2020-10-12_09-43-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 881.6873417721519\n",
+      "  episode_reward_max: 265.26262626262604\n",
+      "  episode_reward_mean: 219.2177470911646\n",
+      "  episode_reward_min: 132.98989898989885\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.096491704384486\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008717880196248492\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010342208658888316\n",
+      "        total_loss: 41.938445409139\n",
+      "        vf_explained_var: 0.9299905896186829\n",
+      "        vf_loss: 41.94715404510498\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.08846153846154\n",
+      "    gpu_util_percent0: 0.22923076923076927\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761538461538461\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15783860786460846\n",
+      "    mean_env_wait_ms: 1.1679732276895893\n",
+      "    mean_inference_ms: 5.06718229484942\n",
+      "    mean_raw_obs_processing_ms: 0.4187261494125702\n",
+      "  time_since_restore: 116.06715679168701\n",
+      "  time_this_iter_s: 22.63174343109131\n",
+      "  time_total_s: 116.06715679168701\n",
+      "  timers:\n",
+      "    learn_throughput: 10387.849\n",
+      "    learn_time_ms: 15575.121\n",
+      "    sample_throughput: 21399.851\n",
+      "    sample_time_ms: 7560.427\n",
+      "    update_time_ms: 29.432\n",
+      "  timestamp: 1602495816\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      5 |          116.067 | 808960 |  219.218 |              265.263 |               132.99 |            881.687 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3598.375851996105\n",
+      "    time_step_min: 3232\n",
+      "  date: 2020-10-12_09-43-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 875.7440758293839\n",
+      "  episode_reward_max: 276.32323232323233\n",
+      "  episode_reward_mean: 220.861649672076\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 265\n",
+      "  episodes_total: 1055\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0718888938426971\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00855911266990006\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008412331051658839\n",
+      "        total_loss: 43.087538401285805\n",
+      "        vf_explained_var: 0.950161874294281\n",
+      "        vf_loss: 43.09434572855631\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.08148148148148\n",
+      "    gpu_util_percent0: 0.25222222222222224\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15625250824378256\n",
+      "    mean_env_wait_ms: 1.1707091032801356\n",
+      "    mean_inference_ms: 4.955649532650974\n",
+      "    mean_raw_obs_processing_ms: 0.412994775757945\n",
+      "  time_since_restore: 138.94322419166565\n",
+      "  time_this_iter_s: 22.876067399978638\n",
+      "  time_total_s: 138.94322419166565\n",
+      "  timers:\n",
+      "    learn_throughput: 10357.435\n",
+      "    learn_time_ms: 15620.856\n",
+      "    sample_throughput: 21690.516\n",
+      "    sample_time_ms: 7459.112\n",
+      "    update_time_ms: 28.271\n",
+      "  timestamp: 1602495838\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      6 |          138.943 | 970752 |  220.862 |              276.323 |               127.99 |            875.744 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3588.668284789644\n",
+      "    time_step_min: 3232\n",
+      "  date: 2020-10-12_09-44-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 871.2341772151899\n",
+      "  episode_reward_max: 276.32323232323233\n",
+      "  episode_reward_mean: 222.59301080424478\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 209\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0818674564361572\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00971197453327477\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010616305696506364\n",
+      "        total_loss: 23.823532422383625\n",
+      "        vf_explained_var: 0.9594845771789551\n",
+      "        vf_loss: 23.83231512705485\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.46923076923077\n",
+      "    gpu_util_percent0: 0.22192307692307695\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15537245096946856\n",
+      "    mean_env_wait_ms: 1.1723962844204818\n",
+      "    mean_inference_ms: 4.892394952236287\n",
+      "    mean_raw_obs_processing_ms: 0.40986308281523554\n",
+      "  time_since_restore: 161.52490735054016\n",
+      "  time_this_iter_s: 22.58168315887451\n",
+      "  time_total_s: 161.52490735054016\n",
+      "  timers:\n",
+      "    learn_throughput: 10365.723\n",
+      "    learn_time_ms: 15608.367\n",
+      "    sample_throughput: 21891.193\n",
+      "    sample_time_ms: 7390.735\n",
+      "    update_time_ms: 26.819\n",
+      "  timestamp: 1602495861\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      7 |          161.525 | 1132544 |  222.593 |              276.323 |               127.99 |            871.234 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3577.01649928264\n",
+      "    time_step_min: 3214\n",
+      "  date: 2020-10-12_09-44-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.4001406469761\n",
+      "  episode_reward_max: 279.05050505050457\n",
+      "  episode_reward_mean: 224.2522056003067\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0567615330219269\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00996107313161095\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011470459081465378\n",
+      "        total_loss: 18.90604877471924\n",
+      "        vf_explained_var: 0.9650539755821228\n",
+      "        vf_loss: 18.915632883707683\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.846153846153843\n",
+      "    gpu_util_percent0: 0.3761538461538461\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7769230769230764\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15482257370550753\n",
+      "    mean_env_wait_ms: 1.1737521015533703\n",
+      "    mean_inference_ms: 4.853095587210327\n",
+      "    mean_raw_obs_processing_ms: 0.40788148532503454\n",
+      "  time_since_restore: 184.23433375358582\n",
+      "  time_this_iter_s: 22.709426403045654\n",
+      "  time_total_s: 184.23433375358582\n",
+      "  timers:\n",
+      "    learn_throughput: 10360.714\n",
+      "    learn_time_ms: 15615.912\n",
+      "    sample_throughput: 22056.978\n",
+      "    sample_time_ms: 7335.184\n",
+      "    update_time_ms: 28.436\n",
+      "  timestamp: 1602495884\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      8 |          184.234 | 1294336 |  224.252 |              279.051 |               127.99 |              867.4 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3568.581829896907\n",
+      "    time_step_min: 3214\n",
+      "  date: 2020-10-12_09-45-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 864.1550632911392\n",
+      "  episode_reward_max: 279.05050505050457\n",
+      "  episode_reward_mean: 225.24555683416426\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0333571831385295\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.009536566135163108\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01221390765082712\n",
+      "        total_loss: 19.71573845545451\n",
+      "        vf_explained_var: 0.9644169211387634\n",
+      "        vf_loss: 19.726147810618084\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.365384615384617\n",
+      "    gpu_util_percent0: 0.2776923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7730769230769234\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15434498849927897\n",
+      "    mean_env_wait_ms: 1.1750500902693974\n",
+      "    mean_inference_ms: 4.818796335363184\n",
+      "    mean_raw_obs_processing_ms: 0.40609763167483137\n",
+      "  time_since_restore: 207.12374019622803\n",
+      "  time_this_iter_s: 22.889406442642212\n",
+      "  time_total_s: 207.12374019622803\n",
+      "  timers:\n",
+      "    learn_throughput: 10337.867\n",
+      "    learn_time_ms: 15650.424\n",
+      "    sample_throughput: 22213.334\n",
+      "    sample_time_ms: 7283.553\n",
+      "    update_time_ms: 27.78\n",
+      "  timestamp: 1602495907\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |      9 |          207.124 | 1456128 |  225.246 |              279.051 |               127.99 |            864.155 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3555.7805714285714\n",
+      "    time_step_min: 3191\n",
+      "  date: 2020-10-12_09-45-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 858.9904386951631\n",
+      "  episode_reward_max: 282.5353535353537\n",
+      "  episode_reward_mean: 227.2556725863811\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 198\n",
+      "  episodes_total: 1778\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9826192061106364\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008173057382615903\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010862024593128202\n",
+      "        total_loss: 19.867599328358967\n",
+      "        vf_explained_var: 0.9715912342071533\n",
+      "        vf_loss: 19.876925468444824\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.685185185185187\n",
+      "    gpu_util_percent0: 0.3214814814814815\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.766666666666666\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15384385545962956\n",
+      "    mean_env_wait_ms: 1.1770206810921942\n",
+      "    mean_inference_ms: 4.782075729559632\n",
+      "    mean_raw_obs_processing_ms: 0.40416715160041744\n",
+      "  time_since_restore: 230.0156054496765\n",
+      "  time_this_iter_s: 22.891865253448486\n",
+      "  time_total_s: 230.0156054496765\n",
+      "  timers:\n",
+      "    learn_throughput: 10329.164\n",
+      "    learn_time_ms: 15663.61\n",
+      "    sample_throughput: 22295.036\n",
+      "    sample_time_ms: 7256.862\n",
+      "    update_time_ms: 28.799\n",
+      "  timestamp: 1602495930\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     10 |          230.016 | 1617920 |  227.256 |              282.535 |               127.99 |             858.99 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3537.7013820335637\n",
+      "    time_step_min: 3178\n",
+      "  date: 2020-10-12_09-45-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.246835443038\n",
+      "  episode_reward_max: 284.959595959596\n",
+      "  episode_reward_mean: 229.88133034335556\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 276\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.980069100856781\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008664651308208704\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010285136828315444\n",
+      "        total_loss: 15.883270581563314\n",
+      "        vf_explained_var: 0.974926233291626\n",
+      "        vf_loss: 15.891921043395996\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.892307692307693\n",
+      "    gpu_util_percent0: 0.19692307692307692\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7615384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15324781903347287\n",
+      "    mean_env_wait_ms: 1.179404216594314\n",
+      "    mean_inference_ms: 4.739375283582631\n",
+      "    mean_raw_obs_processing_ms: 0.40196203413522014\n",
+      "  time_since_restore: 252.85740852355957\n",
+      "  time_this_iter_s: 22.841803073883057\n",
+      "  time_total_s: 252.85740852355957\n",
+      "  timers:\n",
+      "    learn_throughput: 10319.178\n",
+      "    learn_time_ms: 15678.768\n",
+      "    sample_throughput: 22948.39\n",
+      "    sample_time_ms: 7050.255\n",
+      "    update_time_ms: 30.064\n",
+      "  timestamp: 1602495953\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     11 |          252.857 | 1779712 |  229.881 |               284.96 |               127.99 |            852.247 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3528.0755494505493\n",
+      "    time_step_min: 3178\n",
+      "  date: 2020-10-12_09-46-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.6116636528029\n",
+      "  episode_reward_max: 284.959595959596\n",
+      "  episode_reward_mean: 231.47762434471284\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9662584463755289\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008741923840716481\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011554634586597482\n",
+      "        total_loss: 12.84577759106954\n",
+      "        vf_explained_var: 0.9738784432411194\n",
+      "        vf_loss: 12.855680465698242\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.318518518518523\n",
+      "    gpu_util_percent0: 0.36111111111111116\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7740740740740737\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15296314168382433\n",
+      "    mean_env_wait_ms: 1.1806899230590775\n",
+      "    mean_inference_ms: 4.7187640040286425\n",
+      "    mean_raw_obs_processing_ms: 0.40088628297665907\n",
+      "  time_since_restore: 275.5384020805359\n",
+      "  time_this_iter_s: 22.68099355697632\n",
+      "  time_total_s: 275.5384020805359\n",
+      "  timers:\n",
+      "    learn_throughput: 10326.886\n",
+      "    learn_time_ms: 15667.066\n",
+      "    sample_throughput: 23205.705\n",
+      "    sample_time_ms: 6972.079\n",
+      "    update_time_ms: 27.402\n",
+      "  timestamp: 1602495976\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     12 |          275.538 | 1941504 |  231.478 |               284.96 |               127.99 |            848.612 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3518.4350982066608\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-12_09-46-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.4839662447257\n",
+      "  episode_reward_max: 285.111111111111\n",
+      "  episode_reward_mean: 233.07224140135523\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9387023200591406\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008621097154294452\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00967277765206139\n",
+      "        total_loss: 12.80953542391459\n",
+      "        vf_explained_var: 0.9729047417640686\n",
+      "        vf_loss: 12.817577521006266\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.83846153846154\n",
+      "    gpu_util_percent0: 0.3273076923076923\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.780769230769231\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15270777695146592\n",
+      "    mean_env_wait_ms: 1.181911912016204\n",
+      "    mean_inference_ms: 4.6999831064919215\n",
+      "    mean_raw_obs_processing_ms: 0.3998856494641744\n",
+      "  time_since_restore: 298.22470450401306\n",
+      "  time_this_iter_s: 22.686302423477173\n",
+      "  time_total_s: 298.22470450401306\n",
+      "  timers:\n",
+      "    learn_throughput: 10318.743\n",
+      "    learn_time_ms: 15679.429\n",
+      "    sample_throughput: 23225.474\n",
+      "    sample_time_ms: 6966.144\n",
+      "    update_time_ms: 28.708\n",
+      "  timestamp: 1602495998\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     13 |          298.225 | 2103296 |  233.072 |              285.111 |               127.99 |            845.484 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3502.25966641395\n",
+      "    time_step_min: 3174\n",
+      "  date: 2020-10-12_09-47-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.7460615153789\n",
+      "  episode_reward_max: 289.20202020202015\n",
+      "  episode_reward_mean: 235.52689687573402\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 296\n",
+      "  episodes_total: 2666\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9018679658571879\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007377620747623344\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008896974109423658\n",
+      "        total_loss: 17.63732163111369\n",
+      "        vf_explained_var: 0.9755610823631287\n",
+      "        vf_loss: 17.644832770029705\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.02307692307692\n",
+      "    gpu_util_percent0: 0.34461538461538466\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.753846153846154\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15229449529375025\n",
+      "    mean_env_wait_ms: 1.1842967672709355\n",
+      "    mean_inference_ms: 4.669254228442918\n",
+      "    mean_raw_obs_processing_ms: 0.39828135014453186\n",
+      "  time_since_restore: 320.7379891872406\n",
+      "  time_this_iter_s: 22.51328468322754\n",
+      "  time_total_s: 320.7379891872406\n",
+      "  timers:\n",
+      "    learn_throughput: 10319.958\n",
+      "    learn_time_ms: 15677.584\n",
+      "    sample_throughput: 23270.505\n",
+      "    sample_time_ms: 6952.664\n",
+      "    update_time_ms: 29.962\n",
+      "  timestamp: 1602496021\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     14 |          320.738 | 2265088 |  235.527 |              289.202 |               127.99 |            839.746 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3493.146661931818\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-47-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.4669479606189\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 236.9221540297489\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 178\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8971291532119116\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007792771017799775\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01206710331219559\n",
+      "        total_loss: 11.028913895289103\n",
+      "        vf_explained_var: 0.97767573595047\n",
+      "        vf_loss: 11.039512236913046\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.25925925925926\n",
+      "    gpu_util_percent0: 0.29851851851851846\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.781481481481481\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1520777230668347\n",
+      "    mean_env_wait_ms: 1.1856136436879912\n",
+      "    mean_inference_ms: 4.653484916351531\n",
+      "    mean_raw_obs_processing_ms: 0.39745939006799236\n",
+      "  time_since_restore: 343.63194274902344\n",
+      "  time_this_iter_s: 22.893953561782837\n",
+      "  time_total_s: 343.63194274902344\n",
+      "  timers:\n",
+      "    learn_throughput: 10323.846\n",
+      "    learn_time_ms: 15671.679\n",
+      "    sample_throughput: 23177.696\n",
+      "    sample_time_ms: 6980.504\n",
+      "    update_time_ms: 31.229\n",
+      "  timestamp: 1602496044\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     15 |          343.632 | 2426880 |  236.922 |              294.657 |               127.99 |            836.467 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3485.8947545393407\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-47-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.9077281812125\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 238.04062274981655\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8899312863747278\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008488959011932215\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010237862666447958\n",
+      "        total_loss: 10.270389080047607\n",
+      "        vf_explained_var: 0.9769566655158997\n",
+      "        vf_loss: 10.27901848157247\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.696153846153848\n",
+      "    gpu_util_percent0: 0.28807692307692306\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769230769230769\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15189931799754364\n",
+      "    mean_env_wait_ms: 1.1867475833569647\n",
+      "    mean_inference_ms: 4.6404368159209435\n",
+      "    mean_raw_obs_processing_ms: 0.39677152911987984\n",
+      "  time_since_restore: 366.3158349990845\n",
+      "  time_this_iter_s: 22.683892250061035\n",
+      "  time_total_s: 366.3158349990845\n",
+      "  timers:\n",
+      "    learn_throughput: 10344.118\n",
+      "    learn_time_ms: 15640.966\n",
+      "    sample_throughput: 23143.103\n",
+      "    sample_time_ms: 6990.938\n",
+      "    update_time_ms: 31.546\n",
+      "  timestamp: 1602496067\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     16 |          366.316 | 2588672 |  238.041 |              294.657 |               127.99 |            833.908 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3475.301276065982\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-48-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.9645171243443\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 239.72439919092182\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 239\n",
+      "  episodes_total: 3241\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8366131633520126\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00847634948634853\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011216631411419561\n",
+      "        total_loss: 12.429183880488077\n",
+      "        vf_explained_var: 0.9796220660209656\n",
+      "        vf_loss: 12.438788970311483\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.007407407407406\n",
+      "    gpu_util_percent0: 0.32185185185185183\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7592592592592586\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15165047693134606\n",
+      "    mean_env_wait_ms: 1.188484666843735\n",
+      "    mean_inference_ms: 4.622587604140873\n",
+      "    mean_raw_obs_processing_ms: 0.3958343784656538\n",
+      "  time_since_restore: 389.0548298358917\n",
+      "  time_this_iter_s: 22.73899483680725\n",
+      "  time_total_s: 389.0548298358917\n",
+      "  timers:\n",
+      "    learn_throughput: 10335.169\n",
+      "    learn_time_ms: 15654.509\n",
+      "    sample_throughput: 23147.303\n",
+      "    sample_time_ms: 6989.67\n",
+      "    update_time_ms: 33.686\n",
+      "  timestamp: 1602496090\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     17 |          389.055 | 2750464 |  239.724 |              294.657 |               127.99 |            829.965 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3465.885150812065\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-48-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.8173187571922\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 241.0610884448628\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 235\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8381501287221909\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007169540428246061\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010084045759867877\n",
+      "        total_loss: 10.701085885365805\n",
+      "        vf_explained_var: 0.981029748916626\n",
+      "        vf_loss: 10.709820111592611\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.207407407407405\n",
+      "    gpu_util_percent0: 0.2914814814814814\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7518518518518515\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1514377008951951\n",
+      "    mean_env_wait_ms: 1.1900698919360744\n",
+      "    mean_inference_ms: 4.606857549778642\n",
+      "    mean_raw_obs_processing_ms: 0.39502227879043644\n",
+      "  time_since_restore: 411.75859451293945\n",
+      "  time_this_iter_s: 22.70376467704773\n",
+      "  time_total_s: 411.75859451293945\n",
+      "  timers:\n",
+      "    learn_throughput: 10343.501\n",
+      "    learn_time_ms: 15641.899\n",
+      "    sample_throughput: 23136.695\n",
+      "    sample_time_ms: 6992.874\n",
+      "    update_time_ms: 33.346\n",
+      "  timestamp: 1602496113\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     18 |          411.759 | 2912256 |  241.061 |              294.657 |               127.99 |            826.817 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3459.446755407654\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-48-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.8090258668134\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 242.09656832496674\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8284766972064972\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008137651098271212\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013230978317248324\n",
+      "        total_loss: 7.7549606164296465\n",
+      "        vf_explained_var: 0.9815869927406311\n",
+      "        vf_loss: 7.766646901766459\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.088461538461537\n",
+      "    gpu_util_percent0: 0.38923076923076927\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130529253096925\n",
+      "    mean_env_wait_ms: 1.1910543649427872\n",
+      "    mean_inference_ms: 4.597200023030387\n",
+      "    mean_raw_obs_processing_ms: 0.3945180585983885\n",
+      "  time_since_restore: 434.47132658958435\n",
+      "  time_this_iter_s: 22.712732076644897\n",
+      "  time_total_s: 434.47132658958435\n",
+      "  timers:\n",
+      "    learn_throughput: 10371.676\n",
+      "    learn_time_ms: 15599.408\n",
+      "    sample_throughput: 23056.514\n",
+      "    sample_time_ms: 7017.193\n",
+      "    update_time_ms: 34.782\n",
+      "  timestamp: 1602496136\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     19 |          434.471 | 3074048 |  242.097 |              294.657 |               127.99 |            824.809 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3451.6334472784642\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-12_09-49-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 822.4053771861132\n",
+      "  episode_reward_max: 294.6565656565655\n",
+      "  episode_reward_mean: 243.31756879681694\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 197\n",
+      "  episodes_total: 3831\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7869208405415217\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007604961205894749\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010133413588240122\n",
+      "        total_loss: 9.840572754542032\n",
+      "        vf_explained_var: 0.981395423412323\n",
+      "        vf_loss: 9.8492640654246\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.67777777777778\n",
+      "    gpu_util_percent0: 0.2885185185185185\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15114941311387214\n",
+      "    mean_env_wait_ms: 1.1922685341408457\n",
+      "    mean_inference_ms: 4.586011574112173\n",
+      "    mean_raw_obs_processing_ms: 0.3939255104230208\n",
+      "  time_since_restore: 457.08566451072693\n",
+      "  time_this_iter_s: 22.614337921142578\n",
+      "  time_total_s: 457.08566451072693\n",
+      "  timers:\n",
+      "    learn_throughput: 10385.875\n",
+      "    learn_time_ms: 15578.081\n",
+      "    sample_throughput: 23103.616\n",
+      "    sample_time_ms: 7002.886\n",
+      "    update_time_ms: 41.171\n",
+      "  timestamp: 1602496158\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     20 |          457.086 | 3235840 |  243.318 |              294.657 |               127.99 |            822.405 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3440.7480392156863\n",
+      "    time_step_min: 3104\n",
+      "  date: 2020-10-12_09-49-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.3386075949367\n",
+      "  episode_reward_max: 295.7171717171717\n",
+      "  episode_reward_mean: 244.9092876181483\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 277\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7745808561642965\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0073812031575168175\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009667965777528783\n",
+      "        total_loss: 11.363312005996704\n",
+      "        vf_explained_var: 0.9802958369255066\n",
+      "        vf_loss: 11.371581236521402\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.17777777777778\n",
+      "    gpu_util_percent0: 0.38370370370370377\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7629629629629626\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15095964670663803\n",
+      "    mean_env_wait_ms: 1.1939108660744921\n",
+      "    mean_inference_ms: 4.571771883008823\n",
+      "    mean_raw_obs_processing_ms: 0.3931828897760445\n",
+      "  time_since_restore: 480.1051948070526\n",
+      "  time_this_iter_s: 23.019530296325684\n",
+      "  time_total_s: 480.1051948070526\n",
+      "  timers:\n",
+      "    learn_throughput: 10396.548\n",
+      "    learn_time_ms: 15562.088\n",
+      "    sample_throughput: 22995.32\n",
+      "    sample_time_ms: 7035.867\n",
+      "    update_time_ms: 40.243\n",
+      "  timestamp: 1602496181\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     21 |          480.105 | 3397632 |  244.909 |              295.717 |               127.99 |            819.339 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3435.5653610193485\n",
+      "    time_step_min: 3104\n",
+      "  date: 2020-10-12_09-50-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.9139709329583\n",
+      "  episode_reward_max: 295.7171717171717\n",
+      "  episode_reward_mean: 245.59034082029856\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7785022258758545\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006874656615157922\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008841376831696834\n",
+      "        total_loss: 9.293458461761475\n",
+      "        vf_explained_var: 0.979640781879425\n",
+      "        vf_loss: 9.301002740859985\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.51538461538462\n",
+      "    gpu_util_percent0: 0.2784615384615384\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7807692307692307\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1508585653708034\n",
+      "    mean_env_wait_ms: 1.1947677392219636\n",
+      "    mean_inference_ms: 4.56432513516632\n",
+      "    mean_raw_obs_processing_ms: 0.392795038315332\n",
+      "  time_since_restore: 502.90625405311584\n",
+      "  time_this_iter_s: 22.801059246063232\n",
+      "  time_total_s: 502.90625405311584\n",
+      "  timers:\n",
+      "    learn_throughput: 10376.632\n",
+      "    learn_time_ms: 15591.957\n",
+      "    sample_throughput: 23016.648\n",
+      "    sample_time_ms: 7029.347\n",
+      "    update_time_ms: 42.418\n",
+      "  timestamp: 1602496204\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     22 |          502.906 | 3559424 |   245.59 |              295.717 |               127.99 |            817.914 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3430.725170068027\n",
+      "    time_step_min: 3104\n",
+      "  date: 2020-10-12_09-50-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.4898602974313\n",
+      "  episode_reward_max: 296.3232323232323\n",
+      "  episode_reward_mean: 246.36010396893676\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 172\n",
+      "  episodes_total: 4438\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7434713492790858\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00805954351865997\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010885087378179984\n",
+      "        total_loss: 9.99376400311788\n",
+      "        vf_explained_var: 0.9799308776855469\n",
+      "        vf_loss: 10.003111282984415\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.17037037037037\n",
+      "    gpu_util_percent0: 0.4003703703703703\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7666666666666666\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15074949517692104\n",
+      "    mean_env_wait_ms: 1.1956699611848014\n",
+      "    mean_inference_ms: 4.556674012505479\n",
+      "    mean_raw_obs_processing_ms: 0.39239146014138515\n",
+      "  time_since_restore: 525.576878786087\n",
+      "  time_this_iter_s: 22.67062473297119\n",
+      "  time_total_s: 525.576878786087\n",
+      "  timers:\n",
+      "    learn_throughput: 10379.495\n",
+      "    learn_time_ms: 15587.656\n",
+      "    sample_throughput: 23008.521\n",
+      "    sample_time_ms: 7031.83\n",
+      "    update_time_ms: 41.74\n",
+      "  timestamp: 1602496227\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     23 |          525.577 | 3721216 |   246.36 |              296.323 |               127.99 |             816.49 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3422.3333333333335\n",
+      "    time_step_min: 3104\n",
+      "  date: 2020-10-12_09-50-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.1986070071761\n",
+      "  episode_reward_max: 296.3232323232323\n",
+      "  episode_reward_mean: 247.63816510397345\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 300\n",
+      "  episodes_total: 4738\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7324710537989935\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006941189252150555\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009583616231490547\n",
+      "        total_loss: 11.07440447807312\n",
+      "        vf_explained_var: 0.9827136397361755\n",
+      "        vf_loss: 11.082672993342081\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 28.58846153846154\n",
+      "    gpu_util_percent0: 0.3426923076923077\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.765384615384615\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15058465836623514\n",
+      "    mean_env_wait_ms: 1.197189451212345\n",
+      "    mean_inference_ms: 4.544309060807315\n",
+      "    mean_raw_obs_processing_ms: 0.3917546261686602\n",
+      "  time_since_restore: 548.3126289844513\n",
+      "  time_this_iter_s: 22.735750198364258\n",
+      "  time_total_s: 548.3126289844513\n",
+      "  timers:\n",
+      "    learn_throughput: 10372.901\n",
+      "    learn_time_ms: 15597.566\n",
+      "    sample_throughput: 22967.39\n",
+      "    sample_time_ms: 7044.423\n",
+      "    update_time_ms: 40.949\n",
+      "  timestamp: 1602496250\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     24 |          548.313 | 3883008 |  247.638 |              296.323 |               127.99 |            814.199 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1cd33_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4143\n",
+      "    time_step_mean: 3418.177823408624\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_09-51-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.9987750102082\n",
+      "  episode_reward_max: 296.6262626262622\n",
+      "  episode_reward_mean: 248.23236035322594\n",
+      "  episode_reward_min: 127.9898989898988\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 4898\n",
+      "  experiment_id: 9a18e29456c8418ea74db1acd1907ed2\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7477995902299881\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006272289475115637\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00882955159371098\n",
+      "        total_loss: 8.031121015548706\n",
+      "        vf_explained_var: 0.9821956157684326\n",
+      "        vf_loss: 8.038770953814188\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 27.055555555555557\n",
+      "    gpu_util_percent0: 0.2803703703703704\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7777777777777777\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 15409\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1505027184591084\n",
+      "    mean_env_wait_ms: 1.197937655418847\n",
+      "    mean_inference_ms: 4.538297250322579\n",
+      "    mean_raw_obs_processing_ms: 0.3914461154179944\n",
+      "  time_since_restore: 571.0859563350677\n",
+      "  time_this_iter_s: 22.773327350616455\n",
+      "  time_total_s: 571.0859563350677\n",
+      "  timers:\n",
+      "    learn_throughput: 10375.664\n",
+      "    learn_time_ms: 15593.412\n",
+      "    sample_throughput: 23009.262\n",
+      "    sample_time_ms: 7031.603\n",
+      "    update_time_ms: 47.508\n",
+      "  timestamp: 1602496273\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 1cd33_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1cd33_00000 | RUNNING  | 172.17.0.4:15409 |     25 |          571.086 | 4044800 |  248.232 |              296.626 |               127.99 |            812.999 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent q78e25ms"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index ac81b03..0ea65b2 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 8ee10cb..074683e 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug-internal.log
\ No newline at end of file
+run-20201012_095209-tv2toqz9/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4f3bf3b..99ad07a 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug.log
\ No newline at end of file
+run-20201012_095209-tv2toqz9/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 8be457f..19f7d1e 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201012_023117-p62mhra8
\ No newline at end of file
+run-20201012_095209-tv2toqz9
\ No newline at end of file
