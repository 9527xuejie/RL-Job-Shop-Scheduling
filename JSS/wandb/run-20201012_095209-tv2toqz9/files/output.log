2020-10-12 09:52:13,187	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_9b2f6_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=46313)[0m 2020-10-12 09:52:15,881	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=46250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46254)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46254)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46235)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46235)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46242)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46242)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=46270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=46270)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_09-52-49
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823419034481049
        entropy_coeff: 0.0001
        kl: 0.006913263505945603
        model: {}
        policy_loss: -0.009153704750739658
        total_loss: 507.07541910807294
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.341176470588234
    gpu_util_percent0: 0.336764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5558823529411767
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17198858234609263
    mean_env_wait_ms: 1.1879546732842168
    mean_inference_ms: 5.824168226754971
    mean_raw_obs_processing_ms: 0.4614883663110359
  time_since_restore: 27.865785598754883
  time_this_iter_s: 27.865785598754883
  time_total_s: 27.865785598754883
  timers:
    learn_throughput: 8642.686
    learn_time_ms: 18720.106
    sample_throughput: 17808.211
    sample_time_ms: 9085.247
    update_time_ms: 27.356
  timestamp: 1602496369
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      1 |          27.8658 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3617.4756944444443
    time_step_min: 3379
  date: 2020-10-12_09-53-15
  done: false
  episode_len_mean: 892.6835443037975
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.43370412990643
  episode_reward_min: 143.74747474747463
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1495513916015625
        entropy_coeff: 0.0001
        kl: 0.008068564774778983
        model: {}
        policy_loss: -0.011281727226257013
        total_loss: 126.03075726826985
        vf_explained_var: 0.8121792674064636
        vf_loss: 126.04054133097331
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.428125
    gpu_util_percent0: 0.32375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7531250000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16813805433398402
    mean_env_wait_ms: 1.1814601083872347
    mean_inference_ms: 5.643161706556685
    mean_raw_obs_processing_ms: 0.45287909336398025
  time_since_restore: 54.326616048812866
  time_this_iter_s: 26.460830450057983
  time_total_s: 54.326616048812866
  timers:
    learn_throughput: 8708.636
    learn_time_ms: 18578.34
    sample_throughput: 18997.266
    sample_time_ms: 8516.594
    update_time_ms: 28.536
  timestamp: 1602496395
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      2 |          54.3266 | 323584 |  217.434 |              264.354 |              143.747 |            892.684 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4090
    time_step_mean: 3611.885650224215
    time_step_min: 3304
  date: 2020-10-12_09-53-41
  done: false
  episode_len_mean: 888.92194092827
  episode_reward_max: 265.41414141414145
  episode_reward_mean: 219.27138473340983
  episode_reward_min: 136.47474747474763
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1405511895815532
        entropy_coeff: 0.0001
        kl: 0.010281015497942766
        model: {}
        policy_loss: -0.012611954092183927
        total_loss: 57.214155197143555
        vf_explained_var: 0.8955041766166687
        vf_loss: 57.22482458750407
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.029032258064515
    gpu_util_percent0: 0.3461290322580646
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16548555948700364
    mean_env_wait_ms: 1.179330338166906
    mean_inference_ms: 5.478955871312491
    mean_raw_obs_processing_ms: 0.4452321938918592
  time_since_restore: 80.10341024398804
  time_this_iter_s: 25.77679419517517
  time_total_s: 80.10341024398804
  timers:
    learn_throughput: 8738.503
    learn_time_ms: 18514.842
    sample_throughput: 19931.397
    sample_time_ms: 8117.444
    update_time_ms: 25.67
  timestamp: 1602496421
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      3 |          80.1034 | 485376 |  219.271 |              265.414 |              136.475 |            888.922 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3604.7847682119204
    time_step_min: 3278
  date: 2020-10-12_09-54-07
  done: false
  episode_len_mean: 887.0933544303797
  episode_reward_max: 269.35353535353477
  episode_reward_mean: 220.7296381536886
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.125044176975886
        entropy_coeff: 0.0001
        kl: 0.008713830960914493
        model: {}
        policy_loss: -0.01281238537436972
        total_loss: 42.594160079956055
        vf_explained_var: 0.921076238155365
        vf_loss: 42.605342864990234
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.22903225806452
    gpu_util_percent0: 0.3616129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16346509097822773
    mean_env_wait_ms: 1.1780513302277682
    mean_inference_ms: 5.3501499397249015
    mean_raw_obs_processing_ms: 0.43872757777938814
  time_since_restore: 105.72487092018127
  time_this_iter_s: 25.621460676193237
  time_total_s: 105.72487092018127
  timers:
    learn_throughput: 8754.622
    learn_time_ms: 18480.753
    sample_throughput: 20528.206
    sample_time_ms: 7881.449
    update_time_ms: 25.03
  timestamp: 1602496447
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      4 |          105.725 | 647168 |   220.73 |              269.354 |              129.808 |            887.093 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3599.3018372703414
    time_step_min: 3278
  date: 2020-10-12_09-54-33
  done: false
  episode_len_mean: 882.8556962025316
  episode_reward_max: 269.95959595959573
  episode_reward_mean: 221.7850658483568
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0891432861487071
        entropy_coeff: 0.0001
        kl: 0.012039707663158575
        model: {}
        policy_loss: -0.014468279647796104
        total_loss: 34.90501435597738
        vf_explained_var: 0.9392260909080505
        vf_loss: 34.91718260447184
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.193548387096776
    gpu_util_percent0: 0.32483870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16188470356889226
    mean_env_wait_ms: 1.1777334345245236
    mean_inference_ms: 5.2480015616501845
    mean_raw_obs_processing_ms: 0.43333952123819164
  time_since_restore: 131.6790692806244
  time_this_iter_s: 25.954198360443115
  time_total_s: 131.6790692806244
  timers:
    learn_throughput: 8739.188
    learn_time_ms: 18513.391
    sample_throughput: 20882.145
    sample_time_ms: 7747.863
    update_time_ms: 27.169
  timestamp: 1602496473
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      5 |          131.679 | 808960 |  221.785 |               269.96 |              129.808 |            882.856 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3576.6360153256705
    time_step_min: 3249
  date: 2020-10-12_09-54-58
  done: false
  episode_len_mean: 874.0354477611941
  episode_reward_max: 276.7777777777778
  episode_reward_mean: 224.91535692748363
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 282
  episodes_total: 1072
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0584310293197632
        entropy_coeff: 0.0001
        kl: 0.00993667837853233
        model: {}
        policy_loss: -0.012500340701080859
        total_loss: 36.99903710683187
        vf_explained_var: 0.9552376866340637
        vf_loss: 37.00965595245361
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.990322580645163
    gpu_util_percent0: 0.32483870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15983863524712988
    mean_env_wait_ms: 1.179085289301007
    mean_inference_ms: 5.1155669725150235
    mean_raw_obs_processing_ms: 0.42647978968953176
  time_since_restore: 157.1241717338562
  time_this_iter_s: 25.44510245323181
  time_total_s: 157.1241717338562
  timers:
    learn_throughput: 8748.35
    learn_time_ms: 18494.001
    sample_throughput: 21236.517
    sample_time_ms: 7618.575
    update_time_ms: 26.947
  timestamp: 1602496498
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      6 |          157.124 | 970752 |  224.915 |              276.778 |              129.808 |            874.035 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3563.234627831715
    time_step_min: 3249
  date: 2020-10-12_09-55-24
  done: false
  episode_len_mean: 868.820411392405
  episode_reward_max: 276.7777777777778
  episode_reward_mean: 226.81002269530734
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 192
  episodes_total: 1264
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0695739388465881
        entropy_coeff: 0.0001
        kl: 0.01017006098603209
        model: {}
        policy_loss: -0.015108836193879446
        total_loss: 25.033511479695637
        vf_explained_var: 0.9567611813545227
        vf_loss: 25.046693483988445
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.009677419354844
    gpu_util_percent0: 0.36870967741935495
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15884471287761417
    mean_env_wait_ms: 1.1801285353441675
    mean_inference_ms: 5.050565007508557
    mean_raw_obs_processing_ms: 0.42306341022551897
  time_since_restore: 182.6659381389618
  time_this_iter_s: 25.54176640510559
  time_total_s: 182.6659381389618
  timers:
    learn_throughput: 8751.149
    learn_time_ms: 18488.088
    sample_throughput: 21481.104
    sample_time_ms: 7531.829
    update_time_ms: 26.583
  timestamp: 1602496524
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      7 |          182.666 | 1132544 |   226.81 |              276.778 |              129.808 |             868.82 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3551.6083213773313
    time_step_min: 3241
  date: 2020-10-12_09-55-50
  done: false
  episode_len_mean: 864.3305203938115
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 228.58967310233115
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.049300491809845
        entropy_coeff: 0.0001
        kl: 0.00948797888122499
        model: {}
        policy_loss: -0.012509522377513349
        total_loss: 18.031604131062824
        vf_explained_var: 0.965584933757782
        vf_loss: 18.042320410410564
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.548387096774192
    gpu_util_percent0: 0.34096774193548385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581576577053464
    mean_env_wait_ms: 1.1811510776136653
    mean_inference_ms: 5.004558935330623
    mean_raw_obs_processing_ms: 0.42060463833199985
  time_since_restore: 208.32749938964844
  time_this_iter_s: 25.661561250686646
  time_total_s: 208.32749938964844
  timers:
    learn_throughput: 8748.293
    learn_time_ms: 18494.122
    sample_throughput: 21675.597
    sample_time_ms: 7464.246
    update_time_ms: 25.724
  timestamp: 1602496550
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      8 |          208.327 | 1294336 |   228.59 |              278.444 |              129.808 |            864.331 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3540.101804123711
    time_step_min: 3203
  date: 2020-10-12_09-56-15
  done: false
  episode_len_mean: 859.4512658227848
  episode_reward_max: 280.71717171717177
  episode_reward_mean: 230.29571026722905
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0134407381216686
        entropy_coeff: 0.0001
        kl: 0.009283836542939147
        model: {}
        policy_loss: -0.012368955969577655
        total_loss: 17.686386903127033
        vf_explained_var: 0.9648472666740417
        vf_loss: 17.69700034459432
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.25
    gpu_util_percent0: 0.2733333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15754462663462182
    mean_env_wait_ms: 1.1822888408981462
    mean_inference_ms: 4.963565623558671
    mean_raw_obs_processing_ms: 0.4183437067664652
  time_since_restore: 233.72148966789246
  time_this_iter_s: 25.39399027824402
  time_total_s: 233.72148966789246
  timers:
    learn_throughput: 8754.554
    learn_time_ms: 18480.896
    sample_throughput: 21845.518
    sample_time_ms: 7406.187
    update_time_ms: 25.351
  timestamp: 1602496575
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |      9 |          233.721 | 1456128 |  230.296 |              280.717 |              129.808 |            859.451 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3520.4086956521737
    time_step_min: 3187
  date: 2020-10-12_09-56-41
  done: false
  episode_len_mean: 850.8297644539615
  episode_reward_max: 283.14141414141403
  episode_reward_mean: 233.21481950122194
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 288
  episodes_total: 1868
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9686284810304642
        entropy_coeff: 0.0001
        kl: 0.009191953033829728
        model: {}
        policy_loss: -0.013561500377060534
        total_loss: 21.392618497212727
        vf_explained_var: 0.9707826972007751
        vf_loss: 21.404438972473145
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.103333333333335
    gpu_util_percent0: 0.3733333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566063034645863
    mean_env_wait_ms: 1.1848316104310859
    mean_inference_ms: 4.901210150425738
    mean_raw_obs_processing_ms: 0.41495146897880913
  time_since_restore: 259.0294487476349
  time_this_iter_s: 25.30795907974243
  time_total_s: 259.0294487476349
  timers:
    learn_throughput: 8762.84
    learn_time_ms: 18463.42
    sample_throughput: 21989.017
    sample_time_ms: 7357.855
    update_time_ms: 25.311
  timestamp: 1602496601
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     10 |          259.029 | 1617920 |  233.215 |              283.141 |              129.808 |             850.83 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3507.2546890424483
    time_step_min: 3134
  date: 2020-10-12_09-57-06
  done: false
  episode_len_mean: 846.0447906523856
  episode_reward_max: 291.17171717171703
  episode_reward_mean: 235.21408830269573
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 186
  episodes_total: 2054
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9666833182175955
        entropy_coeff: 0.0001
        kl: 0.009547891871382793
        model: {}
        policy_loss: -0.013738454226465061
        total_loss: 12.241443475087484
        vf_explained_var: 0.9760217666625977
        vf_loss: 12.253368775049845
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.73225806451613
    gpu_util_percent0: 0.37129032258064515
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419344
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15612672147778628
    mean_env_wait_ms: 1.1863963734445986
    mean_inference_ms: 4.868479038213553
    mean_raw_obs_processing_ms: 0.4131405922872756
  time_since_restore: 284.6463975906372
  time_this_iter_s: 25.61694884300232
  time_total_s: 284.6463975906372
  timers:
    learn_throughput: 8776.0
    learn_time_ms: 18435.734
    sample_throughput: 22600.779
    sample_time_ms: 7158.691
    update_time_ms: 24.894
  timestamp: 1602496626
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     11 |          284.646 | 1779712 |  235.214 |              291.172 |              129.808 |            846.045 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3497.9578754578756
    time_step_min: 3134
  date: 2020-10-12_09-57-32
  done: false
  episode_len_mean: 842.4163652802894
  episode_reward_max: 291.17171717171703
  episode_reward_mean: 236.73661113850974
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9434071083863577
        entropy_coeff: 0.0001
        kl: 0.008886806822071472
        model: {}
        policy_loss: -0.013857747412354607
        total_loss: 11.377227465311686
        vf_explained_var: 0.9759158492088318
        vf_loss: 11.389402151107788
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.306451612903224
    gpu_util_percent0: 0.3703225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15574509432431266
    mean_env_wait_ms: 1.1876124112293853
    mean_inference_ms: 4.843109071155534
    mean_raw_obs_processing_ms: 0.4117048130730699
  time_since_restore: 310.26896119117737
  time_this_iter_s: 25.62256360054016
  time_total_s: 310.26896119117737
  timers:
    learn_throughput: 8767.755
    learn_time_ms: 18453.07
    sample_throughput: 22924.701
    sample_time_ms: 7057.54
    update_time_ms: 23.988
  timestamp: 1602496652
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     12 |          310.269 | 1941504 |  236.737 |              291.172 |              129.808 |            842.416 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3486.6059196617334
    time_step_min: 3124
  date: 2020-10-12_09-57-58
  done: false
  episode_len_mean: 838.6017551190973
  episode_reward_max: 292.6868686868691
  episode_reward_mean: 238.48256066726591
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 181
  episodes_total: 2393
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8922233482201894
        entropy_coeff: 0.0001
        kl: 0.009549010079354048
        model: {}
        policy_loss: -0.01278734568040818
        total_loss: 13.555466810862223
        vf_explained_var: 0.9759069085121155
        vf_loss: 13.566433668136597
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.638709677419353
    gpu_util_percent0: 0.3909677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15534871599212013
    mean_env_wait_ms: 1.1890876700871462
    mean_inference_ms: 4.816985620989027
    mean_raw_obs_processing_ms: 0.41020097641184006
  time_since_restore: 335.8497335910797
  time_this_iter_s: 25.580772399902344
  time_total_s: 335.8497335910797
  timers:
    learn_throughput: 8765.745
    learn_time_ms: 18457.301
    sample_throughput: 23025.968
    sample_time_ms: 7026.501
    update_time_ms: 24.001
  timestamp: 1602496678
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     13 |           335.85 | 2103296 |  238.483 |              292.687 |              129.808 |            838.602 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3469.7535741158767
    time_step_min: 3113
  date: 2020-10-12_09-58-23
  done: false
  episode_len_mean: 833.5454206999256
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 240.81842625811342
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 293
  episodes_total: 2686
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8776892324288686
        entropy_coeff: 0.0001
        kl: 0.007773946427429716
        model: {}
        policy_loss: -0.010698449972551316
        total_loss: 15.110443512598673
        vf_explained_var: 0.9769299030303955
        vf_loss: 15.119674841562906
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.886666666666663
    gpu_util_percent0: 0.3466666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154792860512786
    mean_env_wait_ms: 1.1912418882872648
    mean_inference_ms: 4.779653799092645
    mean_raw_obs_processing_ms: 0.40808969465063455
  time_since_restore: 361.2861702442169
  time_this_iter_s: 25.436436653137207
  time_total_s: 361.2861702442169
  timers:
    learn_throughput: 8759.95
    learn_time_ms: 18469.512
    sample_throughput: 23134.18
    sample_time_ms: 6993.634
    update_time_ms: 24.974
  timestamp: 1602496703
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     14 |          361.286 | 2265088 |  240.818 |              294.354 |              129.808 |            833.545 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3462.2837357954545
    time_step_min: 3113
  date: 2020-10-12_09-58-49
  done: false
  episode_len_mean: 830.8618143459915
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 241.84911349784755
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.863788440823555
        entropy_coeff: 0.0001
        kl: 0.007791075816688438
        model: {}
        policy_loss: -0.012327776794942716
        total_loss: 10.273081302642822
        vf_explained_var: 0.9786503911018372
        vf_loss: 10.283936818440756
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.829032258064515
    gpu_util_percent0: 0.35935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545288520649961
    mean_env_wait_ms: 1.1923264992783478
    mean_inference_ms: 4.7620573955222865
    mean_raw_obs_processing_ms: 0.4070881514403496
  time_since_restore: 386.6682999134064
  time_this_iter_s: 25.382129669189453
  time_total_s: 386.6682999134064
  timers:
    learn_throughput: 8768.425
    learn_time_ms: 18451.66
    sample_throughput: 23261.908
    sample_time_ms: 6955.233
    update_time_ms: 24.093
  timestamp: 1602496729
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     15 |          386.668 | 2426880 |  241.849 |              294.354 |              129.808 |            830.862 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3455.942876344086
    time_step_min: 3113
  date: 2020-10-12_09-59-14
  done: false
  episode_len_mean: 828.2247003994673
  episode_reward_max: 294.35353535353534
  episode_reward_mean: 242.81659470873842
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.83723417421182
        entropy_coeff: 0.0001
        kl: 0.007628274809879561
        model: {}
        policy_loss: -0.012279657608208558
        total_loss: 12.01127060254415
        vf_explained_var: 0.9756709933280945
        vf_loss: 12.02210815747579
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.470000000000002
    gpu_util_percent0: 0.349
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15427800068784164
    mean_env_wait_ms: 1.193411831131105
    mean_inference_ms: 4.7454461372937695
    mean_raw_obs_processing_ms: 0.4061336934289762
  time_since_restore: 412.1212205886841
  time_this_iter_s: 25.45292067527771
  time_total_s: 412.1212205886841
  timers:
    learn_throughput: 8766.957
    learn_time_ms: 18454.75
    sample_throughput: 23273.875
    sample_time_ms: 6951.657
    update_time_ms: 24.219
  timestamp: 1602496754
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     16 |          412.121 | 2588672 |  242.817 |              294.354 |              129.808 |            828.225 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3444.122673176686
    time_step_min: 3094
  date: 2020-10-12_09-59-40
  done: false
  episode_len_mean: 823.5167927382753
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 244.61548923424857
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 301
  episodes_total: 3305
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113860189914703
        entropy_coeff: 0.0001
        kl: 0.007556577174303432
        model: {}
        policy_loss: -0.013141293660737574
        total_loss: 15.380037069320679
        vf_explained_var: 0.977569580078125
        vf_loss: 15.391748189926147
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.95161290322581
    gpu_util_percent0: 0.30741935483870964
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538597460723591
    mean_env_wait_ms: 1.1954877267131039
    mean_inference_ms: 4.717756489156589
    mean_raw_obs_processing_ms: 0.4045514578042388
  time_since_restore: 437.8751037120819
  time_this_iter_s: 25.753883123397827
  time_total_s: 437.8751037120819
  timers:
    learn_throughput: 8758.737
    learn_time_ms: 18472.071
    sample_throughput: 23262.874
    sample_time_ms: 6954.945
    update_time_ms: 23.779
  timestamp: 1602496780
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     17 |          437.875 | 2750464 |  244.615 |              297.232 |              129.808 |            823.517 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3438.5295823665892
    time_step_min: 3094
  date: 2020-10-12_10-00-06
  done: false
  episode_len_mean: 821.4971231300345
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 245.47900175518117
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 171
  episodes_total: 3476
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8175450464089712
        entropy_coeff: 0.0001
        kl: 0.008889387284095088
        model: {}
        policy_loss: -0.012165131881677857
        total_loss: 9.633394241333008
        vf_explained_var: 0.979500949382782
        vf_loss: 9.643863201141357
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.900000000000006
    gpu_util_percent0: 0.27999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15364497985829317
    mean_env_wait_ms: 1.1965303070364095
    mean_inference_ms: 4.70373287119597
    mean_raw_obs_processing_ms: 0.4037546513656012
  time_since_restore: 463.27351689338684
  time_this_iter_s: 25.39841318130493
  time_total_s: 463.27351689338684
  timers:
    learn_throughput: 8766.562
    learn_time_ms: 18455.582
    sample_throughput: 23281.049
    sample_time_ms: 6949.515
    update_time_ms: 24.535
  timestamp: 1602496806
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     18 |          463.274 | 2912256 |  245.479 |              297.232 |              129.808 |            821.497 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3433.6869975048517
    time_step_min: 3094
  date: 2020-10-12_10-00-32
  done: false
  episode_len_mean: 819.7515818431912
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 246.22265293929658
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8071245352427164
        entropy_coeff: 0.0001
        kl: 0.008481618443814417
        model: {}
        policy_loss: -0.012896277631322542
        total_loss: 10.852858781814575
        vf_explained_var: 0.9760850071907043
        vf_loss: 10.864139159520468
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.941935483870967
    gpu_util_percent0: 0.31483870967741934
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15346036680491582
    mean_env_wait_ms: 1.1974804674349901
    mean_inference_ms: 4.691491113881815
    mean_raw_obs_processing_ms: 0.40305586848146685
  time_since_restore: 489.002060174942
  time_this_iter_s: 25.728543281555176
  time_total_s: 489.002060174942
  timers:
    learn_throughput: 8753.051
    learn_time_ms: 18484.069
    sample_throughput: 23269.483
    sample_time_ms: 6952.969
    update_time_ms: 24.988
  timestamp: 1602496832
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     19 |          489.002 | 3074048 |  246.223 |              297.232 |              129.808 |            819.752 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3426.42053915276
    time_step_min: 3094
  date: 2020-10-12_10-00-57
  done: false
  episode_len_mean: 816.5918939587051
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 247.43319764043696
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 288
  episodes_total: 3923
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7764832923809687
        entropy_coeff: 0.0001
        kl: 0.006902001642932494
        model: {}
        policy_loss: -0.013880621010988156
        total_loss: 13.025757471720377
        vf_explained_var: 0.9806082844734192
        vf_loss: 13.03833532333374
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.590322580645164
    gpu_util_percent0: 0.39612903225806456
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15315309904296956
    mean_env_wait_ms: 1.199214871338701
    mean_inference_ms: 4.671239627167318
    mean_raw_obs_processing_ms: 0.401908938780428
  time_since_restore: 514.511857509613
  time_this_iter_s: 25.50979733467102
  time_total_s: 514.511857509613
  timers:
    learn_throughput: 8745.421
    learn_time_ms: 18500.195
    sample_throughput: 23257.111
    sample_time_ms: 6956.668
    update_time_ms: 24.961
  timestamp: 1602496857
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     20 |          514.512 | 3235840 |  247.433 |              297.232 |              129.808 |            816.592 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3421.3232843137257
    time_step_min: 3094
  date: 2020-10-12_10-01-23
  done: false
  episode_len_mean: 814.9396299902629
  episode_reward_max: 297.23232323232276
  episode_reward_mean: 248.11603867300065
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 185
  episodes_total: 4108
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7784419159094492
        entropy_coeff: 0.0001
        kl: 0.00804499420337379
        model: {}
        policy_loss: -0.014405049829899022
        total_loss: 8.84128741423289
        vf_explained_var: 0.9825008511543274
        vf_loss: 8.854161024093628
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.909677419354836
    gpu_util_percent0: 0.3693548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290322
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15297543519878085
    mean_env_wait_ms: 1.2002093241878489
    mean_inference_ms: 4.659513472391465
    mean_raw_obs_processing_ms: 0.4012336127405691
  time_since_restore: 540.1096513271332
  time_this_iter_s: 25.59779381752014
  time_total_s: 540.1096513271332
  timers:
    learn_throughput: 8742.215
    learn_time_ms: 18506.981
    sample_throughput: 23315.111
    sample_time_ms: 6939.362
    update_time_ms: 29.834
  timestamp: 1602496883
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     21 |           540.11 | 3397632 |  248.116 |              297.232 |              129.808 |             814.94 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3417.2550129747583
    time_step_min: 3090
  date: 2020-10-12_10-01-48
  done: false
  episode_len_mean: 813.5680806187016
  episode_reward_max: 297.8383838383839
  episode_reward_mean: 248.68299114889217
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 159
  episodes_total: 4267
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7700633853673935
        entropy_coeff: 0.0001
        kl: 0.007813045522198081
        model: {}
        policy_loss: -0.012473011311764518
        total_loss: 8.323536992073059
        vf_explained_var: 0.9814441204071045
        vf_loss: 8.334524432818094
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.716666666666665
    gpu_util_percent0: 0.344
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7899999999999996
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152830936628649
    mean_env_wait_ms: 1.201035397656881
    mean_inference_ms: 4.64995730266908
    mean_raw_obs_processing_ms: 0.40068776446312954
  time_since_restore: 565.5083453655243
  time_this_iter_s: 25.398694038391113
  time_total_s: 565.5083453655243
  timers:
    learn_throughput: 8748.845
    learn_time_ms: 18492.955
    sample_throughput: 23353.357
    sample_time_ms: 6927.998
    update_time_ms: 32.11
  timestamp: 1602496908
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     22 |          565.508 | 3559424 |  248.683 |              297.838 |              129.808 |            813.568 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3411.738772787906
    time_step_min: 3090
  date: 2020-10-12_10-02-14
  done: false
  episode_len_mean: 811.4891736632788
  episode_reward_max: 297.8383838383839
  episode_reward_mean: 249.50558613086224
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 259
  episodes_total: 4526
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7288455019394556
        entropy_coeff: 0.0001
        kl: 0.007099877965326111
        model: {}
        policy_loss: -0.013382211055917045
        total_loss: 12.866562684377035
        vf_explained_var: 0.9804218411445618
        vf_loss: 12.878597736358643
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.80666666666667
    gpu_util_percent0: 0.38866666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15261251771401957
    mean_env_wait_ms: 1.2023947388471052
    mean_inference_ms: 4.635446942182516
    mean_raw_obs_processing_ms: 0.3998721125282131
  time_since_restore: 590.9519050121307
  time_this_iter_s: 25.443559646606445
  time_total_s: 590.9519050121307
  timers:
    learn_throughput: 8751.096
    learn_time_ms: 18488.199
    sample_throughput: 23365.172
    sample_time_ms: 6924.494
    update_time_ms: 32.258
  timestamp: 1602496934
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | RUNNING  | 172.17.0.4:46313 |     23 |          590.952 | 3721216 |  249.506 |              297.838 |              129.808 |            811.489 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_9b2f6_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3408.1869694397283
    time_step_min: 3090
  date: 2020-10-12_10-02-39
  done: true
  episode_len_mean: 809.9776371308017
  episode_reward_max: 297.8383838383839
  episode_reward_mean: 250.02007415931465
  episode_reward_min: 129.8080808080803
  episodes_this_iter: 214
  episodes_total: 4740
  experiment_id: 3642d37c8d0e4f7d825945f40ae3e7be
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7325403789679209
        entropy_coeff: 0.0001
        kl: 0.008065837513034543
        model: {}
        policy_loss: -0.010478002213252088
        total_loss: 8.930273612340292
        vf_explained_var: 0.9836755394935608
        vf_loss: 8.93921160697937
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.796666666666667
    gpu_util_percent0: 0.3436666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 46313
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15244229203225002
    mean_env_wait_ms: 1.2034017956588214
    mean_inference_ms: 4.624382951847742
    mean_raw_obs_processing_ms: 0.39923817792461563
  time_since_restore: 615.9667706489563
  time_this_iter_s: 25.01486563682556
  time_total_s: 615.9667706489563
  timers:
    learn_throughput: 8767.167
    learn_time_ms: 18454.308
    sample_throughput: 23392.354
    sample_time_ms: 6916.448
    update_time_ms: 31.101
  timestamp: 1602496959
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 9b2f6_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | TERMINATED |       |     24 |          615.967 | 3883008 |   250.02 |              297.838 |              129.808 |            809.978 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_9b2f6_00000 | TERMINATED |       |     24 |          615.967 | 3883008 |   250.02 |              297.838 |              129.808 |            809.978 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


