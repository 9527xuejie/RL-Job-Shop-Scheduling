2020-10-12 08:37:49,154	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_36689_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=2100)[0m 2020-10-12 08:37:51,901	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=2007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2090)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2090)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2074)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2074)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2084)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2084)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2079)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2079)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2038)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2038)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2030)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_08-38-22
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1858499546845753
        entropy_coeff: 0.0001
        kl: 0.004094068659469485
        model: {}
        policy_loss: -0.006398881853177348
        total_loss: 514.7343877156576
        vf_explained_var: 0.4917435944080353
        vf_loss: 514.7400767008463
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.83225806451613
    gpu_util_percent0: 0.31935483870967746
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.529032258064517
    vram_util_percent0: 0.08267914387583453
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17258576383999963
    mean_env_wait_ms: 1.1829761753629924
    mean_inference_ms: 6.494177267410828
    mean_raw_obs_processing_ms: 0.46709867714731446
  time_since_restore: 25.266931295394897
  time_this_iter_s: 25.266931295394897
  time_total_s: 25.266931295394897
  timers:
    learn_throughput: 10740.473
    learn_time_ms: 15063.769
    sample_throughput: 16038.612
    sample_time_ms: 10087.656
    update_time_ms: 82.904
  timestamp: 1602491902
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      1 |          25.2669 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3621.3333333333335
    time_step_min: 3354
  date: 2020-10-12_08-38-45
  done: false
  episode_len_mean: 889.8607594936709
  episode_reward_max: 265.2626262626262
  episode_reward_mean: 216.678046285641
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1562648216883342
        entropy_coeff: 0.0001
        kl: 0.007113986609814067
        model: {}
        policy_loss: -0.006645135644551677
        total_loss: 154.0817502339681
        vf_explained_var: 0.7768774628639221
        vf_loss: 154.08780415852866
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.881481481481483
    gpu_util_percent0: 0.3425925925925926
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.744444444444444
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16694925418086923
    mean_env_wait_ms: 1.1769385115639088
    mean_inference_ms: 6.042500853772362
    mean_raw_obs_processing_ms: 0.4504103289487157
  time_since_restore: 47.70790386199951
  time_this_iter_s: 22.440972566604614
  time_total_s: 47.70790386199951
  timers:
    learn_throughput: 10829.452
    learn_time_ms: 14939.999
    sample_throughput: 18339.568
    sample_time_ms: 8822.018
    update_time_ms: 50.596
  timestamp: 1602491925
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      2 |          47.7079 | 323584 |  216.678 |              265.263 |              135.869 |            889.861 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.932735426009
    time_step_min: 3329
  date: 2020-10-12_08-39-07
  done: false
  episode_len_mean: 885.704641350211
  episode_reward_max: 265.2626262626262
  episode_reward_mean: 218.28014320419362
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1506426135698955
        entropy_coeff: 0.0001
        kl: 0.007656096131540835
        model: {}
        policy_loss: -0.009037703911114173
        total_loss: 65.57463296254475
        vf_explained_var: 0.8824062943458557
        vf_loss: 65.58302148183186
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.276923076923076
    gpu_util_percent0: 0.36076923076923073
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7653846153846158
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16357548870072489
    mean_env_wait_ms: 1.1747272183472945
    mean_inference_ms: 5.754892740266521
    mean_raw_obs_processing_ms: 0.4394634701846822
  time_since_restore: 69.77683162689209
  time_this_iter_s: 22.068927764892578
  time_total_s: 69.77683162689209
  timers:
    learn_throughput: 10855.848
    learn_time_ms: 14903.672
    sample_throughput: 19581.576
    sample_time_ms: 8262.46
    update_time_ms: 48.208
  timestamp: 1602491947
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      3 |          69.7768 | 485376 |   218.28 |              265.263 |              135.869 |            885.705 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3601.2201986754967
    time_step_min: 3262
  date: 2020-10-12_08-39-29
  done: false
  episode_len_mean: 881.7737341772151
  episode_reward_max: 271.77777777777743
  episode_reward_mean: 219.97278161360424
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1313580671946208
        entropy_coeff: 0.0001
        kl: 0.007723398506641388
        model: {}
        policy_loss: -0.009239614970283583
        total_loss: 54.47336991628011
        vf_explained_var: 0.9014496803283691
        vf_loss: 54.481950441996254
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.20740740740741
    gpu_util_percent0: 0.2759259259259259
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16126493124675817
    mean_env_wait_ms: 1.174200588219917
    mean_inference_ms: 5.557115527329504
    mean_raw_obs_processing_ms: 0.4317369350133932
  time_since_restore: 92.07130265235901
  time_this_iter_s: 22.29447102546692
  time_total_s: 92.07130265235901
  timers:
    learn_throughput: 10833.262
    learn_time_ms: 14934.744
    sample_throughput: 20246.906
    sample_time_ms: 7990.949
    update_time_ms: 46.722
  timestamp: 1602491969
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      4 |          92.0713 | 647168 |  219.973 |              271.778 |              135.869 |            881.774 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3593.6023622047246
    time_step_min: 3262
  date: 2020-10-12_08-39-51
  done: false
  episode_len_mean: 877.7898734177215
  episode_reward_max: 271.77777777777743
  episode_reward_mean: 221.32649277585966
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0989502271016438
        entropy_coeff: 0.0001
        kl: 0.00747458190501978
        model: {}
        policy_loss: -0.010204876113372544
        total_loss: 44.15726852416992
        vf_explained_var: 0.9253225922584534
        vf_loss: 44.16683801015218
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.38461538461538
    gpu_util_percent0: 0.41961538461538467
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753846153846154
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.159577124214222
    mean_env_wait_ms: 1.174681950498461
    mean_inference_ms: 5.411141375472065
    mean_raw_obs_processing_ms: 0.4257335030475409
  time_since_restore: 114.01365947723389
  time_this_iter_s: 21.942356824874878
  time_total_s: 114.01365947723389
  timers:
    learn_throughput: 10837.772
    learn_time_ms: 14928.529
    sample_throughput: 20781.532
    sample_time_ms: 7785.374
    update_time_ms: 43.138
  timestamp: 1602491991
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      5 |          114.014 | 808960 |  221.326 |              271.778 |              135.869 |             877.79 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3582.591970121382
    time_step_min: 3235
  date: 2020-10-12_08-40-13
  done: false
  episode_len_mean: 869.0391264786169
  episode_reward_max: 275.8686868686869
  episode_reward_mean: 223.00575362358785
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 309
  episodes_total: 1099
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0868350267410278
        entropy_coeff: 0.0001
        kl: 0.006786216011581321
        model: {}
        policy_loss: -0.0066523752466309816
        total_loss: 41.79396152496338
        vf_explained_var: 0.9526734948158264
        vf_loss: 41.800042152404785
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.6
    gpu_util_percent0: 0.34481481481481485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.755555555555555
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573612134680123
    mean_env_wait_ms: 1.177695927887752
    mean_inference_ms: 5.220261052750207
    mean_raw_obs_processing_ms: 0.4181297602212586
  time_since_restore: 135.98845148086548
  time_this_iter_s: 21.974792003631592
  time_total_s: 135.98845148086548
  timers:
    learn_throughput: 10831.663
    learn_time_ms: 14936.949
    sample_throughput: 21183.269
    sample_time_ms: 7637.726
    update_time_ms: 43.33
  timestamp: 1602492013
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      6 |          135.988 | 970752 |  223.006 |              275.869 |              135.869 |            869.039 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3574.207928802589
    time_step_min: 3235
  date: 2020-10-12_08-40-35
  done: false
  episode_len_mean: 864.2927215189874
  episode_reward_max: 275.8686868686869
  episode_reward_mean: 224.54304916251107
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 165
  episodes_total: 1264
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.081433097521464
        entropy_coeff: 0.0001
        kl: 0.006580238269331555
        model: {}
        policy_loss: -0.009145769756287336
        total_loss: 22.552169640858967
        vf_explained_var: 0.9606910347938538
        vf_loss: 22.560765743255615
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.06153846153846
    gpu_util_percent0: 0.34423076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7807692307692307
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1565262924197625
    mean_env_wait_ms: 1.1790704629787336
    mean_inference_ms: 5.147878899875807
    mean_raw_obs_processing_ms: 0.4152048278172211
  time_since_restore: 157.7657482624054
  time_this_iter_s: 21.777296781539917
  time_total_s: 157.7657482624054
  timers:
    learn_throughput: 10850.365
    learn_time_ms: 14911.203
    sample_throughput: 21469.757
    sample_time_ms: 7535.81
    update_time_ms: 42.99
  timestamp: 1602492035
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      7 |          157.766 | 1132544 |  224.543 |              275.869 |              135.869 |            864.293 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3562.984218077475
    time_step_min: 3234
  date: 2020-10-12_08-40-57
  done: false
  episode_len_mean: 859.6540084388186
  episode_reward_max: 276.02020202020185
  episode_reward_mean: 225.97406555001476
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0650863250096638
        entropy_coeff: 0.0001
        kl: 0.006993361671144764
        model: {}
        policy_loss: -0.01039950551542764
        total_loss: 20.5628080368042
        vf_explained_var: 0.9627399444580078
        vf_loss: 20.572614828745525
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.646153846153844
    gpu_util_percent0: 0.3553846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769230769230769
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15586201918474507
    mean_env_wait_ms: 1.180437252767014
    mean_inference_ms: 5.088810304506143
    mean_raw_obs_processing_ms: 0.4127548922147928
  time_since_restore: 179.6518850326538
  time_this_iter_s: 21.886136770248413
  time_total_s: 179.6518850326538
  timers:
    learn_throughput: 10866.77
    learn_time_ms: 14888.692
    sample_throughput: 21637.501
    sample_time_ms: 7477.389
    update_time_ms: 42.395
  timestamp: 1602492057
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      8 |          179.652 | 1294336 |  225.974 |               276.02 |              135.869 |            859.654 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3554.34793814433
    time_step_min: 3234
  date: 2020-10-12_08-41-19
  done: false
  episode_len_mean: 855.3632911392405
  episode_reward_max: 276.02020202020185
  episode_reward_mean: 227.47302135276803
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0342613955338795
        entropy_coeff: 0.0001
        kl: 0.007145024758453171
        model: {}
        policy_loss: -0.012359135745403668
        total_loss: 16.66917912165324
        vf_explained_var: 0.969153881072998
        vf_loss: 16.68092672030131
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.53461538461539
    gpu_util_percent0: 0.3642307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7692307692307696
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15528183181065922
    mean_env_wait_ms: 1.1818439220502401
    mean_inference_ms: 5.0377427518753315
    mean_raw_obs_processing_ms: 0.4105749751688051
  time_since_restore: 201.43642330169678
  time_this_iter_s: 21.78453826904297
  time_total_s: 201.43642330169678
  timers:
    learn_throughput: 10877.626
    learn_time_ms: 14873.834
    sample_throughput: 21813.171
    sample_time_ms: 7417.17
    update_time_ms: 41.963
  timestamp: 1602492079
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |      9 |          201.436 | 1456128 |  227.473 |               276.02 |              135.869 |            855.363 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3538.1871628910462
    time_step_min: 3230
  date: 2020-10-12_08-41-41
  done: false
  episode_len_mean: 848.0605738575983
  episode_reward_max: 279.9595959595959
  episode_reward_mean: 229.94768084672427
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 302
  episodes_total: 1882
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9991929431756338
        entropy_coeff: 0.0001
        kl: 0.006702322629280388
        model: {}
        policy_loss: -0.009044580952225564
        total_loss: 23.912927468617756
        vf_explained_var: 0.9700927734375
        vf_loss: 23.921401182810467
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.314814814814813
    gpu_util_percent0: 0.367037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.755555555555555
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15439027266039412
    mean_env_wait_ms: 1.1847406453962492
    mean_inference_ms: 4.959192362221115
    mean_raw_obs_processing_ms: 0.4073170198745893
  time_since_restore: 223.26062870025635
  time_this_iter_s: 21.82420539855957
  time_total_s: 223.26062870025635
  timers:
    learn_throughput: 10885.919
    learn_time_ms: 14862.503
    sample_throughput: 21962.384
    sample_time_ms: 7366.778
    update_time_ms: 41.253
  timestamp: 1602492101
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     10 |          223.261 | 1617920 |  229.948 |               279.96 |              135.869 |            848.061 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3528.677690029615
    time_step_min: 3230
  date: 2020-10-12_08-42-03
  done: false
  episode_len_mean: 845.0929892891918
  episode_reward_max: 284.9595959595956
  episode_reward_mean: 231.38342529481758
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 172
  episodes_total: 2054
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9863324115673701
        entropy_coeff: 0.0001
        kl: 0.007253075134940445
        model: {}
        policy_loss: -0.010080095797699565
        total_loss: 12.745516856511435
        vf_explained_var: 0.975978672504425
        vf_loss: 12.754970153172811
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.073076923076922
    gpu_util_percent0: 0.33884615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15395971112154033
    mean_env_wait_ms: 1.1861700352928464
    mean_inference_ms: 4.922337023279303
    mean_raw_obs_processing_ms: 0.405765973621554
  time_since_restore: 245.08239674568176
  time_this_iter_s: 21.821768045425415
  time_total_s: 245.08239674568176
  timers:
    learn_throughput: 10912.485
    learn_time_ms: 14826.321
    sample_throughput: 22908.63
    sample_time_ms: 7062.491
    update_time_ms: 35.215
  timestamp: 1602492123
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     11 |          245.082 | 1779712 |  231.383 |               284.96 |              135.869 |            845.093 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3521.334706959707
    time_step_min: 3230
  date: 2020-10-12_08-42-25
  done: false
  episode_len_mean: 843.3512658227849
  episode_reward_max: 284.9595959595956
  episode_reward_mean: 232.42007324602253
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9833590139945348
        entropy_coeff: 0.0001
        kl: 0.006227322039194405
        model: {}
        policy_loss: -0.00852358304352189
        total_loss: 14.60979151725769
        vf_explained_var: 0.971681535243988
        vf_loss: 14.617790699005127
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.46153846153846
    gpu_util_percent0: 0.41346153846153844
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773076923076923
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15361216385441095
    mean_env_wait_ms: 1.1873319753360294
    mean_inference_ms: 4.892219410835038
    mean_raw_obs_processing_ms: 0.40448378793887574
  time_since_restore: 267.23646235466003
  time_this_iter_s: 22.15406560897827
  time_total_s: 267.23646235466003
  timers:
    learn_throughput: 10902.615
    learn_time_ms: 14839.743
    sample_throughput: 23052.506
    sample_time_ms: 7018.413
    update_time_ms: 36.93
  timestamp: 1602492145
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     12 |          267.236 | 1941504 |   232.42 |               284.96 |              135.869 |            843.351 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3515.048249359522
    time_step_min: 3230
  date: 2020-10-12_08-42-47
  done: false
  episode_len_mean: 841.8481012658228
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 233.48216340621394
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9474922468264898
        entropy_coeff: 0.0001
        kl: 0.006475092299903433
        model: {}
        policy_loss: -0.009250502989743836
        total_loss: 14.260765393575033
        vf_explained_var: 0.9733137488365173
        vf_loss: 14.269463221232096
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.09629629629629
    gpu_util_percent0: 0.3014814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77037037037037
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532982326821362
    mean_env_wait_ms: 1.1883857196509395
    mean_inference_ms: 4.865022739372882
    mean_raw_obs_processing_ms: 0.40331712226024746
  time_since_restore: 289.2048056125641
  time_this_iter_s: 21.968343257904053
  time_total_s: 289.2048056125641
  timers:
    learn_throughput: 10891.191
    learn_time_ms: 14855.308
    sample_throughput: 23142.952
    sample_time_ms: 6990.984
    update_time_ms: 37.068
  timestamp: 1602492167
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     13 |          289.205 | 2103296 |  233.482 |              286.626 |              135.869 |            841.848 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3501.123633622314
    time_step_min: 3173
  date: 2020-10-12_08-43-09
  done: false
  episode_len_mean: 838.1547929876912
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 235.55068024519713
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 311
  episodes_total: 2681
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9234441419442495
        entropy_coeff: 0.0001
        kl: 0.006116377733026941
        model: {}
        policy_loss: -0.008196644863346592
        total_loss: 19.14843002955119
        vf_explained_var: 0.974140465259552
        vf_loss: 19.15610710779826
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.373076923076926
    gpu_util_percent0: 0.36115384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7576923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15276546501530014
    mean_env_wait_ms: 1.1904107868575922
    mean_inference_ms: 4.8189728498329485
    mean_raw_obs_processing_ms: 0.4014017127349726
  time_since_restore: 310.99618577957153
  time_this_iter_s: 21.791380167007446
  time_total_s: 310.99618577957153
  timers:
    learn_throughput: 10904.933
    learn_time_ms: 14836.589
    sample_throughput: 23245.705
    sample_time_ms: 6960.082
    update_time_ms: 35.505
  timestamp: 1602492189
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     14 |          310.996 | 2265088 |  235.551 |              286.626 |              135.869 |            838.155 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3495.3238636363635
    time_step_min: 3173
  date: 2020-10-12_08-43-31
  done: false
  episode_len_mean: 836.3660337552743
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 236.4045838128116
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 163
  episodes_total: 2844
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.915911003947258
        entropy_coeff: 0.0001
        kl: 0.0061395803932100534
        model: {}
        policy_loss: -0.010156944151579713
        total_loss: 11.34574580192566
        vf_explained_var: 0.9787011742591858
        vf_loss: 11.355380455652872
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.007692307692306
    gpu_util_percent0: 0.33192307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525226137968328
    mean_env_wait_ms: 1.191373284138838
    mean_inference_ms: 4.798271945270741
    mean_raw_obs_processing_ms: 0.40052132412082564
  time_since_restore: 332.7011032104492
  time_this_iter_s: 21.704917430877686
  time_total_s: 332.7011032104492
  timers:
    learn_throughput: 10917.13
    learn_time_ms: 14820.012
    sample_throughput: 23276.711
    sample_time_ms: 6950.81
    update_time_ms: 36.581
  timestamp: 1602492211
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     15 |          332.701 | 2426880 |  236.405 |              286.626 |              135.869 |            836.366 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3489.8749159381305
    time_step_min: 3173
  date: 2020-10-12_08-43-53
  done: false
  episode_len_mean: 834.4490339773484
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 237.28117955033338
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9094983438650767
        entropy_coeff: 0.0001
        kl: 0.006247825222089887
        model: {}
        policy_loss: -0.0099478800984798
        total_loss: 12.494431257247925
        vf_explained_var: 0.9735568165779114
        vf_loss: 12.503845612208048
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.770370370370372
    gpu_util_percent0: 0.3325925925925926
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666666
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15230749442700836
    mean_env_wait_ms: 1.1922618136568186
    mean_inference_ms: 4.779647564940922
    mean_raw_obs_processing_ms: 0.39972468508854025
  time_since_restore: 354.660724401474
  time_this_iter_s: 21.95962119102478
  time_total_s: 354.660724401474
  timers:
    learn_throughput: 10932.893
    learn_time_ms: 14798.644
    sample_throughput: 23231.51
    sample_time_ms: 6964.334
    update_time_ms: 35.858
  timestamp: 1602492233
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     16 |          354.661 | 2588672 |  237.281 |              286.626 |              135.869 |            834.449 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3484.2136968928344
    time_step_min: 3173
  date: 2020-10-12_08-44-15
  done: false
  episode_len_mean: 832.9575738529227
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 238.11965348011853
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 180
  episodes_total: 3182
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8757123003403345
        entropy_coeff: 0.0001
        kl: 0.006264201404216389
        model: {}
        policy_loss: -0.009777444618521258
        total_loss: 13.901710192362467
        vf_explained_var: 0.9767399430274963
        vf_loss: 13.910948832829794
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.515384615384615
    gpu_util_percent0: 0.30576923076923074
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7653846153846158
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520823720998534
    mean_env_wait_ms: 1.1932319551868942
    mean_inference_ms: 4.760040912603402
    mean_raw_obs_processing_ms: 0.39888700003710004
  time_since_restore: 376.5495798587799
  time_this_iter_s: 21.888855457305908
  time_total_s: 376.5495798587799
  timers:
    learn_throughput: 10926.535
    learn_time_ms: 14807.255
    sample_throughput: 23218.041
    sample_time_ms: 6968.374
    update_time_ms: 34.069
  timestamp: 1602492255
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     17 |           376.55 | 2750464 |   238.12 |              286.626 |              135.869 |            832.958 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3476.53671988389
    time_step_min: 3173
  date: 2020-10-12_08-44-37
  done: false
  episode_len_mean: 831.0423265188598
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 239.41880073409004
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 291
  episodes_total: 3473
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.862436776359876
        entropy_coeff: 0.0001
        kl: 0.00582402265475442
        model: {}
        policy_loss: -0.0065109556599054486
        total_loss: 16.89293646812439
        vf_explained_var: 0.9754787087440491
        vf_loss: 16.898951292037964
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.926923076923078
    gpu_util_percent0: 0.34500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7615384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517612004517305
    mean_env_wait_ms: 1.1946496078443667
    mean_inference_ms: 4.731862828478537
    mean_raw_obs_processing_ms: 0.39770574920140944
  time_since_restore: 398.4416320323944
  time_this_iter_s: 21.892052173614502
  time_total_s: 398.4416320323944
  timers:
    learn_throughput: 10918.614
    learn_time_ms: 14817.997
    sample_throughput: 23251.091
    sample_time_ms: 6958.469
    update_time_ms: 32.599
  timestamp: 1602492277
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     18 |          398.442 | 2912256 |  239.419 |              286.626 |              135.869 |            831.042 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3472.1566833056017
    time_step_min: 3173
  date: 2020-10-12_08-44-59
  done: false
  episode_len_mean: 830.3706659328564
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 240.11061078589967
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 161
  episodes_total: 3634
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8508865286906561
        entropy_coeff: 0.0001
        kl: 0.005722010508179665
        model: {}
        policy_loss: -0.010631043463945389
        total_loss: 9.665903091430664
        vf_explained_var: 0.9808840155601501
        vf_loss: 9.676047007242838
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.12962962962963
    gpu_util_percent0: 0.3181481481481481
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7814814814814808
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15160220027619284
    mean_env_wait_ms: 1.1953684893976586
    mean_inference_ms: 4.717913496142562
    mean_raw_obs_processing_ms: 0.3971194057832533
  time_since_restore: 420.2288022041321
  time_this_iter_s: 21.78717017173767
  time_total_s: 420.2288022041321
  timers:
    learn_throughput: 10920.147
    learn_time_ms: 14815.918
    sample_throughput: 23242.947
    sample_time_ms: 6960.907
    update_time_ms: 32.142
  timestamp: 1602492299
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     19 |          420.229 | 3074048 |  240.111 |              286.626 |              135.869 |            830.371 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3467.42348565356
    time_step_min: 3173
  date: 2020-10-12_08-45-21
  done: false
  episode_len_mean: 829.4894514767932
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 240.77151259429735
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8476235717535019
        entropy_coeff: 0.0001
        kl: 0.005998994805850089
        model: {}
        policy_loss: -0.009499937470536679
        total_loss: 10.576106945673624
        vf_explained_var: 0.97751784324646
        vf_loss: 10.585091590881348
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.78461538461539
    gpu_util_percent0: 0.34807692307692306
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784615384615385
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15145770518598975
    mean_env_wait_ms: 1.1960228017989614
    mean_inference_ms: 4.705052577742813
    mean_raw_obs_processing_ms: 0.39657759839835627
  time_since_restore: 442.2300491333008
  time_this_iter_s: 22.0012469291687
  time_total_s: 442.2300491333008
  timers:
    learn_throughput: 10912.126
    learn_time_ms: 14826.808
    sample_throughput: 23197.629
    sample_time_ms: 6974.506
    update_time_ms: 31.2
  timestamp: 1602492321
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     20 |           442.23 | 3235840 |  240.772 |              286.626 |              135.869 |            829.489 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3461.8119808708784
    time_step_min: 3173
  date: 2020-10-12_08-45-43
  done: false
  episode_len_mean: 828.7065733566608
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 241.63679029737514
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 209
  episodes_total: 4001
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8073496967554092
        entropy_coeff: 0.0001
        kl: 0.0053013469247768326
        model: {}
        policy_loss: -0.007447434841499974
        total_loss: 13.215350230534872
        vf_explained_var: 0.9791877269744873
        vf_loss: 13.222347656885782
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.248148148148147
    gpu_util_percent0: 0.3062962962962963
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7629629629629626
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15128604750252658
    mean_env_wait_ms: 1.196811102954551
    mean_inference_ms: 4.689196081330257
    mean_raw_obs_processing_ms: 0.3959243949246973
  time_since_restore: 464.0425639152527
  time_this_iter_s: 21.812514781951904
  time_total_s: 464.0425639152527
  timers:
    learn_throughput: 10907.966
    learn_time_ms: 14832.462
    sample_throughput: 23243.462
    sample_time_ms: 6960.753
    update_time_ms: 30.816
  timestamp: 1602492343
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     21 |          464.043 | 3397632 |  241.637 |              286.626 |              135.869 |            828.707 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3454.145184135977
    time_step_min: 3173
  date: 2020-10-12_08-46-05
  done: false
  episode_len_mean: 827.9786585365854
  episode_reward_max: 286.62626262626225
  episode_reward_mean: 242.722224591127
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 263
  episodes_total: 4264
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7928875287373861
        entropy_coeff: 0.0001
        kl: 0.005559906829148531
        model: {}
        policy_loss: -0.009087247861316428
        total_loss: 10.697956959406534
        vf_explained_var: 0.9829474091529846
        vf_loss: 10.706567605336508
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.349999999999998
    gpu_util_percent0: 0.2907692307692308
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765384615384615
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510860289808531
    mean_env_wait_ms: 1.197690271183912
    mean_inference_ms: 4.671202928544622
    mean_raw_obs_processing_ms: 0.39516008240817785
  time_since_restore: 485.9816827774048
  time_this_iter_s: 21.9391188621521
  time_total_s: 485.9816827774048
  timers:
    learn_throughput: 10915.786
    learn_time_ms: 14821.837
    sample_throughput: 23285.007
    sample_time_ms: 6948.334
    update_time_ms: 31.259
  timestamp: 1602492365
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     22 |          485.982 | 3559424 |  242.722 |              286.626 |              135.869 |            827.979 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3450.070973612375
    time_step_min: 3130
  date: 2020-10-12_08-46-27
  done: false
  episode_len_mean: 827.4380650994575
  episode_reward_max: 291.777777777778
  episode_reward_mean: 243.26666073026828
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 160
  episodes_total: 4424
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7965629249811172
        entropy_coeff: 0.0001
        kl: 0.004790663408736388
        model: {}
        policy_loss: -0.008145113398010531
        total_loss: 10.19397759437561
        vf_explained_var: 0.979886531829834
        vf_loss: 10.201723416646322
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.873076923076926
    gpu_util_percent0: 0.3742307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7769230769230764
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097523831193937
    mean_env_wait_ms: 1.198180034212628
    mean_inference_ms: 4.661100264257637
    mean_raw_obs_processing_ms: 0.3947356773964307
  time_since_restore: 507.8446464538574
  time_this_iter_s: 21.862963676452637
  time_total_s: 507.8446464538574
  timers:
    learn_throughput: 10921.942
    learn_time_ms: 14813.483
    sample_throughput: 23283.338
    sample_time_ms: 6948.832
    update_time_ms: 28.976
  timestamp: 1602492387
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     23 |          507.845 | 3721216 |  243.267 |              291.778 |              135.869 |            827.438 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3446.520421607378
    time_step_min: 3130
  date: 2020-10-12_08-46-49
  done: false
  episode_len_mean: 826.8005237887386
  episode_reward_max: 291.777777777778
  episode_reward_mean: 243.8116917758995
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7860831270615259
        entropy_coeff: 0.0001
        kl: 0.006281677827549477
        model: {}
        policy_loss: -0.008127124708456298
        total_loss: 9.384316762288412
        vf_explained_var: 0.9807237982749939
        vf_loss: 9.392208496729532
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.051851851851854
    gpu_util_percent0: 0.2914814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7851851851851848
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150872520219993
    mean_env_wait_ms: 1.198637669472401
    mean_inference_ms: 4.651638105431035
    mean_raw_obs_processing_ms: 0.3943363563376779
  time_since_restore: 529.604768037796
  time_this_iter_s: 21.7601215839386
  time_total_s: 529.604768037796
  timers:
    learn_throughput: 10924.108
    learn_time_ms: 14810.546
    sample_throughput: 23288.432
    sample_time_ms: 6947.312
    update_time_ms: 29.667
  timestamp: 1602492409
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     24 |          529.605 | 3883008 |  243.812 |              291.778 |              135.869 |            826.801 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3440.437057107128
    time_step_min: 3130
  date: 2020-10-12_08-47-11
  done: false
  episode_len_mean: 825.8632407791131
  episode_reward_max: 291.777777777778
  episode_reward_mean: 244.76139555522067
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 244
  episodes_total: 4826
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.754992201924324
        entropy_coeff: 0.0001
        kl: 0.005963448085822165
        model: {}
        policy_loss: -0.008779487393136757
        total_loss: 9.597943862279257
        vf_explained_var: 0.9848809242248535
        vf_loss: 9.606500705083212
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.923076923076923
    gpu_util_percent0: 0.3515384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15072576914319252
    mean_env_wait_ms: 1.1993330760083902
    mean_inference_ms: 4.638071597147566
    mean_raw_obs_processing_ms: 0.3937742830795006
  time_since_restore: 551.7138071060181
  time_this_iter_s: 22.109039068222046
  time_total_s: 551.7138071060181
  timers:
    learn_throughput: 10926.872
    learn_time_ms: 14806.8
    sample_throughput: 23136.794
    sample_time_ms: 6992.844
    update_time_ms: 27.45
  timestamp: 1602492431
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     25 |          551.714 | 4044800 |  244.761 |              291.778 |              135.869 |            825.863 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3435.615552903739
    time_step_min: 3130
  date: 2020-10-12_08-47-33
  done: false
  episode_len_mean: 825.2846123417721
  episode_reward_max: 291.777777777778
  episode_reward_mean: 245.55597709691855
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 230
  episodes_total: 5056
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7510520567496618
        entropy_coeff: 0.0001
        kl: 0.006108862425511082
        model: {}
        policy_loss: -0.009180293748310456
        total_loss: 9.422614336013794
        vf_explained_var: 0.9839019179344177
        vf_loss: 9.431564490000406
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.46666666666667
    gpu_util_percent0: 0.32555555555555554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7629629629629626
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15059448528084024
    mean_env_wait_ms: 1.19986428552713
    mean_inference_ms: 4.626139098768838
    mean_raw_obs_processing_ms: 0.39326811905687803
  time_since_restore: 573.6764891147614
  time_this_iter_s: 21.962682008743286
  time_total_s: 573.6764891147614
  timers:
    learn_throughput: 10916.067
    learn_time_ms: 14821.456
    sample_throughput: 23159.204
    sample_time_ms: 6986.078
    update_time_ms: 25.423
  timestamp: 1602492453
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     26 |          573.676 | 4206592 |  245.556 |              291.778 |              135.869 |            825.285 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3432.570381797146
    time_step_min: 3130
  date: 2020-10-12_08-47-56
  done: false
  episode_len_mean: 824.927694668201
  episode_reward_max: 291.777777777778
  episode_reward_mean: 246.02223617068262
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 158
  episodes_total: 5214
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7519985487063726
        entropy_coeff: 0.0001
        kl: 0.00578857046396782
        model: {}
        policy_loss: -0.007587263817792215
        total_loss: 8.542066733042398
        vf_explained_var: 0.9829537272453308
        vf_loss: 8.549439509709677
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.85769230769231
    gpu_util_percent0: 0.33807692307692305
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776923076923077
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15051100010946178
    mean_env_wait_ms: 1.2002167686108423
    mean_inference_ms: 4.61849677217929
    mean_raw_obs_processing_ms: 0.3929485309367278
  time_since_restore: 595.6711790561676
  time_this_iter_s: 21.99468994140625
  time_total_s: 595.6711790561676
  timers:
    learn_throughput: 10927.326
    learn_time_ms: 14806.184
    sample_throughput: 23074.942
    sample_time_ms: 7011.589
    update_time_ms: 25.225
  timestamp: 1602492476
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | RUNNING  | 172.17.0.4:2100 |     27 |          595.671 | 4368384 |  246.022 |              291.778 |              135.869 |            824.928 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_36689_00000:
  custom_metrics:
    time_step_max: 4135
    time_step_mean: 3429.3792974588937
    time_step_min: 3130
  date: 2020-10-12_08-48-18
  done: true
  episode_len_mean: 824.468029739777
  episode_reward_max: 291.777777777778
  episode_reward_mean: 246.4583286395554
  episode_reward_min: 135.86868686868658
  episodes_this_iter: 166
  episodes_total: 5380
  experiment_id: dc93f86da89d474f81761675826ff91a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.0e-05
        entropy: 0.7269033441940943
        entropy_coeff: 0.0001
        kl: 0.006252984749153256
        model: {}
        policy_loss: -0.007048466320460041
        total_loss: 9.722230116526285
        vf_explained_var: 0.9817023277282715
        vf_loss: 9.729038715362549
    num_steps_sampled: 4530176
    num_steps_trained: 4530176
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.3037037037037
    gpu_util_percent0: 0.337037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7851851851851848
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2100
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15042886996746352
    mean_env_wait_ms: 1.2005724653972405
    mean_inference_ms: 4.610864653434181
    mean_raw_obs_processing_ms: 0.3926279850182893
  time_since_restore: 617.6555559635162
  time_this_iter_s: 21.984376907348633
  time_total_s: 617.6555559635162
  timers:
    learn_throughput: 10928.071
    learn_time_ms: 14805.175
    sample_throughput: 23043.461
    sample_time_ms: 7021.167
    update_time_ms: 24.873
  timestamp: 1602492498
  timesteps_since_restore: 0
  timesteps_total: 4530176
  training_iteration: 28
  trial_id: '36689_00000'
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | TERMINATED |       |     28 |          617.656 | 4530176 |  246.458 |              291.778 |              135.869 |            824.468 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.81 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_36689_00000 | TERMINATED |       |     28 |          617.656 | 4530176 |  246.458 |              291.778 |              135.869 |            824.468 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


