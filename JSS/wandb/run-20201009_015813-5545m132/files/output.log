2020-10-09 01:58:15,499	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_e5dd2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=73809)[0m 2020-10-09 01:58:18,510	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=73754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73673)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73673)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73671)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73671)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73680)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73680)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73679)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73679)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73665)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73665)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73674)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73674)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73667)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73667)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73682)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73682)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73660)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3225.0
  date: 2020-10-09_01-59-25
  done: false
  episode_len_mean: 875.496835443038
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 227.93504666922368
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 1.0e-05
        entropy: 1.1658145666122437
        entropy_coeff: 0.0
        kl: 0.003689856524579227
        model: {}
        policy_loss: -0.0033752704272046684
        total_loss: 26.510688400268556
        vf_explained_var: 0.18367254734039307
        vf_loss: 26.513325691223145
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.00845070422535
    gpu_util_percent0: 0.31352112676056343
    gpu_util_percent1: 0.00014084507042253522
    gpu_util_percent2: 0.00014084507042253522
    ram_util_percent: 9.840845070422533
    vram_util_percent0: 0.3254253299396247
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.24921989028709246
    mean_env_wait_ms: 3.2760606484856276
    mean_inference_ms: 9.385597806684983
    mean_raw_obs_processing_ms: 0.8702416374345516
  time_since_restore: 60.99007296562195
  time_this_iter_s: 60.99007296562195
  time_total_s: 60.99007296562195
  timers:
    learn_throughput: 7235.251
    learn_time_ms: 44723.257
    sample_throughput: 20001.679
    sample_time_ms: 16177.842
    update_time_ms: 48.401
  timestamp: 1602208765
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 75.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      1 |          60.9901 | 323584 |  227.935 |              284.798 |              147.061 |            875.497 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3220.0
  date: 2020-10-09_02-00-24
  done: false
  episode_len_mean: 867.5712025316456
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.34945978775076
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.1402915358543395
        entropy_coeff: 0.0
        kl: 0.0061815905850380656
        model: {}
        policy_loss: -0.004027105495333671
        total_loss: 15.702640151977539
        vf_explained_var: 0.5521119236946106
        vf_loss: 15.706049251556397
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.360294117647054
    gpu_util_percent0: 0.34191176470588236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.176470588235293
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2425325415968734
    mean_env_wait_ms: 3.270187064595162
    mean_inference_ms: 8.937557195915137
    mean_raw_obs_processing_ms: 0.8510594086183576
  time_since_restore: 120.17724013328552
  time_this_iter_s: 59.187167167663574
  time_total_s: 120.17724013328552
  timers:
    learn_throughput: 7229.875
    learn_time_ms: 44756.516
    sample_throughput: 21248.331
    sample_time_ms: 15228.679
    update_time_ms: 43.217
  timestamp: 1602208824
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      2 |          120.177 | 647168 |  229.349 |              284.798 |              147.061 |            867.571 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-01-23
  done: false
  episode_len_mean: 860.1561181434599
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 229.97831692451933
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.1210898756980896
        entropy_coeff: 0.0
        kl: 0.008123426977545024
        model: {}
        policy_loss: -0.004418270767200738
        total_loss: 13.895159149169922
        vf_explained_var: 0.7605623006820679
        vf_loss: 13.898765087127686
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.858208955223883
    gpu_util_percent0: 0.42149253731343284
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.198507462686567
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2386042745489012
    mean_env_wait_ms: 3.272622460167931
    mean_inference_ms: 8.65059331669967
    mean_raw_obs_processing_ms: 0.8384124019567656
  time_since_restore: 178.92884826660156
  time_this_iter_s: 58.75160813331604
  time_total_s: 178.92884826660156
  timers:
    learn_throughput: 7228.225
    learn_time_ms: 44766.728
    sample_throughput: 21907.031
    sample_time_ms: 14770.783
    update_time_ms: 36.12
  timestamp: 1602208883
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      3 |          178.929 | 970752 |  229.978 |              284.798 |              147.061 |            860.156 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-02-22
  done: false
  episode_len_mean: 852.1400316455696
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.94232674849752
  episode_reward_min: 147.0606060606061
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.0867977023124695
        entropy_coeff: 0.0
        kl: 0.0066032628528773785
        model: {}
        policy_loss: -0.003924187913071364
        total_loss: 14.169937801361083
        vf_explained_var: 0.846515953540802
        vf_loss: 14.173201370239259
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.866176470588236
    gpu_util_percent0: 0.3763235294117647
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.183823529411766
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2360927389801917
    mean_env_wait_ms: 3.281027369924338
    mean_inference_ms: 8.451503417224291
    mean_raw_obs_processing_ms: 0.8294514283938429
  time_since_restore: 237.6311583518982
  time_this_iter_s: 58.70231008529663
  time_total_s: 237.6311583518982
  timers:
    learn_throughput: 7227.252
    learn_time_ms: 44772.754
    sample_throughput: 22272.171
    sample_time_ms: 14528.624
    update_time_ms: 32.551
  timestamp: 1602208942
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      4 |          237.631 | 1294336 |  230.942 |              284.798 |              147.061 |             852.14 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-03-21
  done: false
  episode_len_mean: 837.092299578059
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 230.84534692920758
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 632
  episodes_total: 1896
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.064141583442688
        entropy_coeff: 0.0
        kl: 0.005117633752524853
        model: {}
        policy_loss: -0.0034836243838071825
        total_loss: 20.375638961791992
        vf_explained_var: 0.9164049029350281
        vf_loss: 20.378611373901368
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.301470588235293
    gpu_util_percent0: 0.3651470588235294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.176470588235297
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23316448522270125
    mean_env_wait_ms: 3.3021618620282807
    mean_inference_ms: 8.211928298399048
    mean_raw_obs_processing_ms: 0.819102465453104
  time_since_restore: 296.40994453430176
  time_this_iter_s: 58.778786182403564
  time_total_s: 296.40994453430176
  timers:
    learn_throughput: 7237.162
    learn_time_ms: 44711.452
    sample_throughput: 22401.118
    sample_time_ms: 14444.993
    update_time_ms: 33.278
  timestamp: 1602209001
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      5 |           296.41 | 1617920 |  230.845 |              284.798 |               143.97 |            837.092 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-04-20
  done: false
  episode_len_mean: 830.878390596745
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.56457431457423
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 316
  episodes_total: 2212
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.0478770732879639
        entropy_coeff: 0.0
        kl: 0.00407116450369358
        model: {}
        policy_loss: -0.0036003258428536355
        total_loss: 15.362028121948242
        vf_explained_var: 0.9244366884231567
        vf_loss: 15.365221500396729
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.943283582089553
    gpu_util_percent0: 0.4216417910447761
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.211940298507463
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23222839920839689
    mean_env_wait_ms: 3.3109024682962644
    mean_inference_ms: 8.131779793500565
    mean_raw_obs_processing_ms: 0.8155448201229852
  time_since_restore: 355.26661014556885
  time_this_iter_s: 58.85666561126709
  time_total_s: 355.26661014556885
  timers:
    learn_throughput: 7239.119
    learn_time_ms: 44699.36
    sample_throughput: 22489.616
    sample_time_ms: 14388.151
    update_time_ms: 31.115
  timestamp: 1602209060
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      6 |          355.267 | 1941504 |  231.565 |              284.798 |               143.97 |            830.878 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-05-19
  done: false
  episode_len_mean: 825.8916139240506
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.66313850530616
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 316
  episodes_total: 2528
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.0206212043762206
        entropy_coeff: 0.0
        kl: 0.004263193905353546
        model: {}
        policy_loss: -0.0033799497061409054
        total_loss: 15.32041826248169
        vf_explained_var: 0.9417697787284851
        vf_loss: 15.323585319519044
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.761764705882356
    gpu_util_percent0: 0.38294117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.200000000000001
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.23143279464087024
    mean_env_wait_ms: 3.3190383516566166
    mean_inference_ms: 8.063131859455337
    mean_raw_obs_processing_ms: 0.812375894406717
  time_since_restore: 414.30839920043945
  time_this_iter_s: 59.041789054870605
  time_total_s: 414.30839920043945
  timers:
    learn_throughput: 7231.934
    learn_time_ms: 44743.773
    sample_throughput: 22595.163
    sample_time_ms: 14320.941
    update_time_ms: 29.773
  timestamp: 1602209119
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      7 |          414.308 | 2265088 |  231.663 |              284.798 |               143.97 |            825.892 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-06-19
  done: false
  episode_len_mean: 818.9200913242009
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.77691790705484
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 538
  episodes_total: 3066
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 1.0e-05
        entropy: 0.9625406742095948
        entropy_coeff: 0.0
        kl: 0.004602713184431196
        model: {}
        policy_loss: -0.0031631637131795285
        total_loss: 17.743195724487304
        vf_explained_var: 0.9637018442153931
        vf_loss: 17.74624366760254
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.20869565217392
    gpu_util_percent0: 0.3610144927536232
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.218840579710147
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2303567877137798
    mean_env_wait_ms: 3.3327588159101733
    mean_inference_ms: 7.967507683463993
    mean_raw_obs_processing_ms: 0.8076797266951058
  time_since_restore: 473.7904372215271
  time_this_iter_s: 59.48203802108765
  time_total_s: 473.7904372215271
  timers:
    learn_throughput: 7230.321
    learn_time_ms: 44753.754
    sample_throughput: 22567.674
    sample_time_ms: 14338.385
    update_time_ms: 38.915
  timestamp: 1602209179
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      8 |           473.79 | 2588672 |  231.777 |              284.798 |               143.97 |             818.92 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-07-18
  done: false
  episode_len_mean: 814.617088607595
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 231.7840429612581
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 410
  episodes_total: 3476
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 0.9388803482055664
        entropy_coeff: 0.0
        kl: 0.004396444978192448
        model: {}
        policy_loss: -0.0035341545823030173
        total_loss: 13.051942920684814
        vf_explained_var: 0.9669912457466125
        vf_loss: 13.055422115325928
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.123529411764707
    gpu_util_percent0: 0.40176470588235297
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.19264705882353
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22975752357919899
    mean_env_wait_ms: 3.3422487153590366
    mean_inference_ms: 7.91040288659759
    mean_raw_obs_processing_ms: 0.8053450494810214
  time_since_restore: 533.2098636627197
  time_this_iter_s: 59.41942644119263
  time_total_s: 533.2098636627197
  timers:
    learn_throughput: 7226.327
    learn_time_ms: 44778.49
    sample_throughput: 22573.093
    sample_time_ms: 14334.943
    update_time_ms: 39.11
  timestamp: 1602209238
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |      9 |           533.21 | 2912256 |  231.784 |              284.798 |               143.97 |            814.617 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-08-18
  done: false
  episode_len_mean: 811.6542721518987
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 232.0653076119848
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 316
  episodes_total: 3792
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 1.0e-05
        entropy: 0.9036332726478576
        entropy_coeff: 0.0
        kl: 0.0040697598364204165
        model: {}
        policy_loss: -0.0032764585223048924
        total_loss: 10.02047004699707
        vf_explained_var: 0.9763003587722778
        vf_loss: 10.023721027374268
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.950000000000003
    gpu_util_percent0: 0.38382352941176473
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.20588235294118
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22932470753582124
    mean_env_wait_ms: 3.349006830861882
    mean_inference_ms: 7.871381988660179
    mean_raw_obs_processing_ms: 0.8036301466135422
  time_since_restore: 592.7080955505371
  time_this_iter_s: 59.49823188781738
  time_total_s: 592.7080955505371
  timers:
    learn_throughput: 7223.377
    learn_time_ms: 44796.774
    sample_throughput: 22561.502
    sample_time_ms: 14342.308
    update_time_ms: 38.795
  timestamp: 1602209298
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | RUNNING  | 172.17.0.4:73809 |     10 |          592.708 | 3235840 |  232.065 |              284.798 |               143.97 |            811.654 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_e5dd2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3187.0
  date: 2020-10-09_02-09-17
  done: true
  episode_len_mean: 808.6022152660727
  episode_reward_max: 284.79797979797996
  episode_reward_mean: 232.34176340822137
  episode_reward_min: 143.96969696969705
  episodes_this_iter: 361
  episodes_total: 4153
  experiment_id: f5321a75f70a4cf4966fdeca458cd116
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 1.0e-05
        entropy: 0.8569606184959412
        entropy_coeff: 0.0
        kl: 0.004031547019258142
        model: {}
        policy_loss: -0.0030213016318157314
        total_loss: 9.32835578918457
        vf_explained_var: 0.9846111536026001
        vf_loss: 9.331364631652832
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.25588235294118
    gpu_util_percent0: 0.43220588235294116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 10.194117647058825
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73809
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22893327193781315
    mean_env_wait_ms: 3.3572341287494907
    mean_inference_ms: 7.831757867538433
    mean_raw_obs_processing_ms: 0.8018511602525116
  time_since_restore: 651.4390113353729
  time_this_iter_s: 58.730915784835815
  time_total_s: 651.4390113353729
  timers:
    learn_throughput: 7223.827
    learn_time_ms: 44793.988
    sample_throughput: 22926.707
    sample_time_ms: 14113.846
    update_time_ms: 38.189
  timestamp: 1602209357
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: e5dd2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 76.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | TERMINATED |       |     11 |          651.439 | 3559424 |  232.342 |              284.798 |               143.97 |            808.602 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 76.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_e5dd2_00000 | TERMINATED |       |     11 |          651.439 | 3559424 |  232.342 |              284.798 |               143.97 |            808.602 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


