2020-10-11 02:33:04,128	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_178a0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=18606)[0m 2020-10-11 02:33:06,998	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=18472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18471)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18471)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18540)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18540)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18576)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18576)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18473)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18473)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18537)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18537)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18613)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_02-33-44
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1822375399725777
        entropy_coeff: 0.0
        kl: 0.007213647311021175
        model: {}
        policy_loss: -0.013822373850936336
        total_loss: 499.54760306222096
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.31282051282052
    gpu_util_percent0: 0.3515384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.284615384615386
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17359067275591122
    mean_env_wait_ms: 1.2013391286880009
    mean_inference_ms: 5.616361032705611
    mean_raw_obs_processing_ms: 0.4616141694679272
  time_since_restore: 32.08133411407471
  time_this_iter_s: 32.08133411407471
  time_total_s: 32.08133411407471
  timers:
    learn_throughput: 6975.507
    learn_time_ms: 23194.298
    sample_throughput: 18344.595
    sample_time_ms: 8819.601
    update_time_ms: 28.692
  timestamp: 1602383624
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      1 |          32.0813 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3627.9201388888887
    time_step_min: 3210
  date: 2020-10-11_02-34-16
  done: false
  episode_len_mean: 889.4018987341772
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 216.57064314026317
  episode_reward_min: 145.71717171717145
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1501378757613046
        entropy_coeff: 0.0
        kl: 0.008470796780394656
        model: {}
        policy_loss: -0.013708427831131433
        total_loss: 122.32958875383649
        vf_explained_var: 0.8201828002929688
        vf_loss: 122.3416017804827
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.918421052631576
    gpu_util_percent0: 0.25473684210526315
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.473684210526316
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16925357313068878
    mean_env_wait_ms: 1.1951855361469284
    mean_inference_ms: 5.471011502303029
    mean_raw_obs_processing_ms: 0.4522672687875735
  time_since_restore: 63.963526487350464
  time_this_iter_s: 31.882192373275757
  time_total_s: 63.963526487350464
  timers:
    learn_throughput: 6934.17
    learn_time_ms: 23332.569
    sample_throughput: 18871.197
    sample_time_ms: 8573.489
    update_time_ms: 25.234
  timestamp: 1602383656
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      2 |          63.9635 | 323584 |  216.571 |              279.657 |              145.717 |            889.402 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3626.7331838565024
    time_step_min: 3210
  date: 2020-10-11_02-34-47
  done: false
  episode_len_mean: 888.626582278481
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 217.4215573456078
  episode_reward_min: 145.71717171717145
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1431264877319336
        entropy_coeff: 0.0
        kl: 0.009144877416214772
        model: {}
        policy_loss: -0.016391686612873206
        total_loss: 46.991628646850586
        vf_explained_var: 0.9186553955078125
        vf_loss: 47.006190163748606
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.691891891891892
    gpu_util_percent0: 0.3264864864864865
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16606087997843544
    mean_env_wait_ms: 1.1919240782135114
    mean_inference_ms: 5.318657279524816
    mean_raw_obs_processing_ms: 0.4441752845054371
  time_since_restore: 94.43664979934692
  time_this_iter_s: 30.47312331199646
  time_total_s: 94.43664979934692
  timers:
    learn_throughput: 6953.108
    learn_time_ms: 23269.018
    sample_throughput: 19892.942
    sample_time_ms: 8133.136
    update_time_ms: 25.442
  timestamp: 1602383687
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      3 |          94.4366 | 485376 |  217.422 |              279.657 |              145.717 |            888.627 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3610.455298013245
    time_step_min: 3210
  date: 2020-10-11_02-35-17
  done: false
  episode_len_mean: 885.245253164557
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 219.40268188211203
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1170069234711784
        entropy_coeff: 0.0
        kl: 0.011232678179762192
        model: {}
        policy_loss: -0.01873889540937463
        total_loss: 27.166234833853586
        vf_explained_var: 0.9489374160766602
        vf_loss: 27.18272726876395
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.913888888888888
    gpu_util_percent0: 0.3702777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16384097124063526
    mean_env_wait_ms: 1.1908849314153283
    mean_inference_ms: 5.20148454619115
    mean_raw_obs_processing_ms: 0.4375479367129329
  time_since_restore: 124.71409821510315
  time_this_iter_s: 30.277448415756226
  time_total_s: 124.71409821510315
  timers:
    learn_throughput: 6975.083
    learn_time_ms: 23195.71
    sample_throughput: 20458.46
    sample_time_ms: 7908.318
    update_time_ms: 23.564
  timestamp: 1602383717
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      4 |          124.714 | 647168 |  219.403 |              279.657 |              136.172 |            885.245 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3593.179790026247
    time_step_min: 3210
  date: 2020-10-11_02-35-47
  done: false
  episode_len_mean: 879.7759493670886
  episode_reward_max: 279.65656565656525
  episode_reward_mean: 221.5313259174017
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0890576498849052
        entropy_coeff: 0.0
        kl: 0.011715871947152274
        model: {}
        policy_loss: -0.01949298351662167
        total_loss: 22.39234515598842
        vf_explained_var: 0.958861231803894
        vf_loss: 22.4094945362636
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.59444444444444
    gpu_util_percent0: 0.33888888888888885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1621696261224226
    mean_env_wait_ms: 1.1913690835603097
    mean_inference_ms: 5.110279129361596
    mean_raw_obs_processing_ms: 0.43232937361687007
  time_since_restore: 154.98470330238342
  time_this_iter_s: 30.270605087280273
  time_total_s: 154.98470330238342
  timers:
    learn_throughput: 6986.882
    learn_time_ms: 23156.538
    sample_throughput: 20833.426
    sample_time_ms: 7765.981
    update_time_ms: 23.494
  timestamp: 1602383747
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      5 |          154.985 | 808960 |  221.531 |              279.657 |              136.172 |            879.776 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3565.9598506069096
    time_step_min: 3194
  date: 2020-10-11_02-36-18
  done: false
  episode_len_mean: 869.024567788899
  episode_reward_max: 282.08080808080797
  episode_reward_mean: 225.39001479765795
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 309
  episodes_total: 1099
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0688665849821908
        entropy_coeff: 0.0
        kl: 0.010106426464127643
        model: {}
        policy_loss: -0.014363441814761504
        total_loss: 31.374551909310476
        vf_explained_var: 0.9595679044723511
        vf_loss: 31.386894362313406
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.70555555555556
    gpu_util_percent0: 0.3908333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888888
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1599859479225957
    mean_env_wait_ms: 1.1946785905437247
    mean_inference_ms: 4.987885627625575
    mean_raw_obs_processing_ms: 0.42579298400766225
  time_since_restore: 185.124169588089
  time_this_iter_s: 30.139466285705566
  time_total_s: 185.124169588089
  timers:
    learn_throughput: 6993.318
    learn_time_ms: 23135.226
    sample_throughput: 21164.245
    sample_time_ms: 7644.591
    update_time_ms: 23.014
  timestamp: 1602383778
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      6 |          185.124 | 970752 |   225.39 |              282.081 |              136.172 |            869.025 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3555.8681229773465
    time_step_min: 3194
  date: 2020-10-11_02-36-48
  done: false
  episode_len_mean: 865.8378164556962
  episode_reward_max: 282.08080808080797
  episode_reward_mean: 226.9565033243829
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 165
  episodes_total: 1264
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0679272498403276
        entropy_coeff: 0.0
        kl: 0.010920979215630464
        model: {}
        policy_loss: -0.01906705368310213
        total_loss: 14.9096326146807
        vf_explained_var: 0.9713901877403259
        vf_loss: 14.926515715462822
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.243243243243246
    gpu_util_percent0: 0.34270270270270276
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15917639055668156
    mean_env_wait_ms: 1.196039844569306
    mean_inference_ms: 4.939896089447469
    mean_raw_obs_processing_ms: 0.4231417878124063
  time_since_restore: 215.55391573905945
  time_this_iter_s: 30.42974615097046
  time_total_s: 215.55391573905945
  timers:
    learn_throughput: 6988.79
    learn_time_ms: 23150.217
    sample_throughput: 21381.096
    sample_time_ms: 7567.058
    update_time_ms: 24.375
  timestamp: 1602383808
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      7 |          215.554 | 1132544 |  226.957 |              282.081 |              136.172 |            865.838 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3543.888091822095
    time_step_min: 3179
  date: 2020-10-11_02-37-19
  done: false
  episode_len_mean: 862.6090014064698
  episode_reward_max: 284.3535353535351
  episode_reward_mean: 228.50251459745118
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0401062284197127
        entropy_coeff: 0.0
        kl: 0.010780988793287958
        model: {}
        policy_loss: -0.019559223878396943
        total_loss: 14.642739023481097
        vf_explained_var: 0.9717629551887512
        vf_loss: 14.660142149244036
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.325
    gpu_util_percent0: 0.33111111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585107995119999
    mean_env_wait_ms: 1.197255630139681
    mean_inference_ms: 4.900556884438196
    mean_raw_obs_processing_ms: 0.4209610929952728
  time_since_restore: 245.85779333114624
  time_this_iter_s: 30.303877592086792
  time_total_s: 245.85779333114624
  timers:
    learn_throughput: 6988.89
    learn_time_ms: 23149.884
    sample_throughput: 21555.063
    sample_time_ms: 7505.986
    update_time_ms: 24.518
  timestamp: 1602383839
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      8 |          245.858 | 1294336 |  228.503 |              284.354 |              136.172 |            862.609 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3533.0296391752577
    time_step_min: 3171
  date: 2020-10-11_02-37-49
  done: false
  episode_len_mean: 858.9626582278481
  episode_reward_max: 285.5656565656561
  episode_reward_mean: 230.30290244214282
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0133909668241228
        entropy_coeff: 0.0
        kl: 0.009917031973600388
        model: {}
        policy_loss: -0.018415473052300513
        total_loss: 12.945594310760498
        vf_explained_var: 0.9726513028144836
        vf_loss: 12.962026255471367
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.88611111111111
    gpu_util_percent0: 0.3775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15794221171479492
    mean_env_wait_ms: 1.198422193528366
    mean_inference_ms: 4.866265638483006
    mean_raw_obs_processing_ms: 0.4189785211785768
  time_since_restore: 275.92149543762207
  time_this_iter_s: 30.06370210647583
  time_total_s: 275.92149543762207
  timers:
    learn_throughput: 6998.695
    learn_time_ms: 23117.454
    sample_throughput: 21674.135
    sample_time_ms: 7464.75
    update_time_ms: 23.856
  timestamp: 1602383869
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |      9 |          275.921 | 1456128 |  230.303 |              285.566 |              136.172 |            858.963 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3514.6738648947953
    time_step_min: 3171
  date: 2020-10-11_02-38-19
  done: false
  episode_len_mean: 853.3571428571429
  episode_reward_max: 285.5656565656561
  episode_reward_mean: 233.00443915711077
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 254
  episodes_total: 1834
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9708845657961709
        entropy_coeff: 0.0
        kl: 0.009615118216191019
        model: {}
        policy_loss: -0.015960073165063347
        total_loss: 18.404777118137904
        vf_explained_var: 0.9733225703239441
        vf_loss: 18.4188141141619
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.80833333333333
    gpu_util_percent0: 0.3383333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15717463375152624
    mean_env_wait_ms: 1.200562132036695
    mean_inference_ms: 4.820348099259264
    mean_raw_obs_processing_ms: 0.4163096157147707
  time_since_restore: 306.315550327301
  time_this_iter_s: 30.394054889678955
  time_total_s: 306.315550327301
  timers:
    learn_throughput: 6994.524
    learn_time_ms: 23131.24
    sample_throughput: 21791.738
    sample_time_ms: 7424.465
    update_time_ms: 23.522
  timestamp: 1602383899
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     10 |          306.316 | 1617920 |  233.004 |              285.566 |              136.172 |            853.357 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3500.0839091806515
    time_step_min: 3147
  date: 2020-10-11_02-38-50
  done: false
  episode_len_mean: 849.2492697176242
  episode_reward_max: 289.2020202020204
  episode_reward_mean: 235.22898901379904
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 220
  episodes_total: 2054
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9714691638946533
        entropy_coeff: 0.0
        kl: 0.009413634293845721
        model: {}
        policy_loss: -0.01820964747041996
        total_loss: 11.94624846322196
        vf_explained_var: 0.9780048131942749
        vf_loss: 11.962575095040458
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.16111111111111
    gpu_util_percent0: 0.3630555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15663996480079523
    mean_env_wait_ms: 1.2020746381950278
    mean_inference_ms: 4.7873747985177655
    mean_raw_obs_processing_ms: 0.4143894779389095
  time_since_restore: 336.64830684661865
  time_this_iter_s: 30.332756519317627
  time_total_s: 336.64830684661865
  timers:
    learn_throughput: 6998.83
    learn_time_ms: 23117.005
    sample_throughput: 22276.61
    sample_time_ms: 7262.865
    update_time_ms: 22.853
  timestamp: 1602383930
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     11 |          336.648 | 1779712 |  235.229 |              289.202 |              136.172 |            849.249 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3490.356227106227
    time_step_min: 3147
  date: 2020-10-11_02-39-20
  done: false
  episode_len_mean: 846.5452079566004
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 236.77257201307822
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.950008898973465
        entropy_coeff: 0.0
        kl: 0.009780466290456908
        model: {}
        policy_loss: -0.020223332036818777
        total_loss: 9.65990434374128
        vf_explained_var: 0.979585587978363
        vf_loss: 9.678171498434883
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.266666666666666
    gpu_util_percent0: 0.36083333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15629490440708294
    mean_env_wait_ms: 1.2030878223104826
    mean_inference_ms: 4.766716971473709
    mean_raw_obs_processing_ms: 0.4131765309211282
  time_since_restore: 366.76766562461853
  time_this_iter_s: 30.119358777999878
  time_total_s: 366.76766562461853
  timers:
    learn_throughput: 7020.108
    learn_time_ms: 23046.937
    sample_throughput: 22603.984
    sample_time_ms: 7157.676
    update_time_ms: 22.684
  timestamp: 1602383960
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     12 |          366.768 | 1941504 |  236.773 |              289.657 |              136.172 |            846.545 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3482.6951323654994
    time_step_min: 3147
  date: 2020-10-11_02-39-50
  done: false
  episode_len_mean: 843.8367088607595
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 237.89726377701052
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.917963696377618
        entropy_coeff: 0.0
        kl: 0.01026541633265359
        model: {}
        policy_loss: -0.016984207784324617
        total_loss: 10.849162646702357
        vf_explained_var: 0.9785847067832947
        vf_loss: 10.86409364427839
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.310810810810807
    gpu_util_percent0: 0.3694594594594595
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15598775240472368
    mean_env_wait_ms: 1.20406905629119
    mean_inference_ms: 4.747893550864915
    mean_raw_obs_processing_ms: 0.41205410085380123
  time_since_restore: 397.09490990638733
  time_this_iter_s: 30.3272442817688
  time_total_s: 397.09490990638733
  timers:
    learn_throughput: 7028.195
    learn_time_ms: 23020.421
    sample_throughput: 22566.676
    sample_time_ms: 7169.51
    update_time_ms: 22.549
  timestamp: 1602383990
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     13 |          397.095 | 2103296 |  237.897 |              289.657 |              136.172 |            843.837 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3469.4504367641475
    time_step_min: 3147
  date: 2020-10-11_02-40-21
  done: false
  episode_len_mean: 840.1210071401729
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 239.9992825663625
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 291
  episodes_total: 2661
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8958467415400914
        entropy_coeff: 0.0
        kl: 0.008748011663556099
        model: {}
        policy_loss: -0.016389003422643458
        total_loss: 15.554971013750349
        vf_explained_var: 0.978577733039856
        vf_loss: 15.569610595703125
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.555555555555557
    gpu_util_percent0: 0.31333333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15548736402580002
    mean_env_wait_ms: 1.2057634083342048
    mean_inference_ms: 4.71760737540238
    mean_raw_obs_processing_ms: 0.4102770392547641
  time_since_restore: 427.52023434638977
  time_this_iter_s: 30.42532444000244
  time_total_s: 427.52023434638977
  timers:
    learn_throughput: 7021.811
    learn_time_ms: 23041.348
    sample_throughput: 22593.548
    sample_time_ms: 7160.982
    update_time_ms: 23.833
  timestamp: 1602384021
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     14 |           427.52 | 2265088 |  239.999 |              289.657 |              136.172 |            840.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3461.9946732954545
    time_step_min: 3147
  date: 2020-10-11_02-40-51
  done: false
  episode_len_mean: 838.3048523206751
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 241.17944210032806
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 183
  episodes_total: 2844
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8919523273195539
        entropy_coeff: 0.0
        kl: 0.008902052750012704
        model: {}
        policy_loss: -0.01592102533738528
        total_loss: 9.513706956590925
        vf_explained_var: 0.982586681842804
        vf_loss: 9.527847358158656
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.38918918918919
    gpu_util_percent0: 0.34945945945945955
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15522878514693284
    mean_env_wait_ms: 1.2067240281596576
    mean_inference_ms: 4.701288035004256
    mean_raw_obs_processing_ms: 0.40934078885173236
  time_since_restore: 457.99711775779724
  time_this_iter_s: 30.47688341140747
  time_total_s: 457.99711775779724
  timers:
    learn_throughput: 7018.016
    learn_time_ms: 23053.808
    sample_throughput: 22570.525
    sample_time_ms: 7168.287
    update_time_ms: 23.772
  timestamp: 1602384051
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     15 |          457.997 | 2426880 |  241.179 |              289.657 |              136.172 |            838.305 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3456.3776059179554
    time_step_min: 3147
  date: 2020-10-11_02-41-22
  done: false
  episode_len_mean: 836.9800133244504
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 242.04038048708261
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8757352232933044
        entropy_coeff: 0.0
        kl: 0.009629194491675921
        model: {}
        policy_loss: -0.017089556703077897
        total_loss: 9.079770769391741
        vf_explained_var: 0.9816855192184448
        vf_loss: 9.094934395381383
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.827777777777776
    gpu_util_percent0: 0.3716666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550166328746049
    mean_env_wait_ms: 1.2074309859761168
    mean_inference_ms: 4.688201415578681
    mean_raw_obs_processing_ms: 0.408574453177367
  time_since_restore: 488.46272802352905
  time_this_iter_s: 30.46561026573181
  time_total_s: 488.46272802352905
  timers:
    learn_throughput: 7012.67
    learn_time_ms: 23071.384
    sample_throughput: 22532.09
    sample_time_ms: 7180.515
    update_time_ms: 25.835
  timestamp: 1602384082
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     16 |          488.463 | 2588672 |   242.04 |              289.657 |              136.172 |             836.98 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3451.495065265839
    time_step_min: 3147
  date: 2020-10-11_02-41-52
  done: false
  episode_len_mean: 835.4774376775008
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 242.83847946170437
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 167
  episodes_total: 3169
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.838376488004412
        entropy_coeff: 0.0
        kl: 0.009771477497581924
        model: {}
        policy_loss: -0.01842148162956749
        total_loss: 10.92150810786656
        vf_explained_var: 0.9806362390518188
        vf_loss: 10.937975338527135
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.722222222222218
    gpu_util_percent0: 0.33833333333333326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888888
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15480782970633652
    mean_env_wait_ms: 1.2081407142111604
    mean_inference_ms: 4.675466637960968
    mean_raw_obs_processing_ms: 0.4078179191305292
  time_since_restore: 518.6286778450012
  time_this_iter_s: 30.165949821472168
  time_total_s: 518.6286778450012
  timers:
    learn_throughput: 7020.557
    learn_time_ms: 23045.465
    sample_throughput: 22535.519
    sample_time_ms: 7179.422
    update_time_ms: 26.295
  timestamp: 1602384112
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     17 |          518.629 | 2750464 |  242.838 |              289.657 |              136.172 |            835.477 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3442.5579499126384
    time_step_min: 3146
  date: 2020-10-11_02-42-23
  done: false
  episode_len_mean: 833.6735990756788
  episode_reward_max: 293.44444444444423
  episode_reward_mean: 244.25690177336614
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 293
  episodes_total: 3462
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8185249652181353
        entropy_coeff: 0.0
        kl: 0.009092008362391166
        model: {}
        policy_loss: -0.017341606551781297
        total_loss: 10.249885218484062
        vf_explained_var: 0.9857155084609985
        vf_loss: 10.265408311571393
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.321621621621624
    gpu_util_percent0: 0.3489189189189189
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15447704582275834
    mean_env_wait_ms: 1.2092220483351344
    mean_inference_ms: 4.655399610410031
    mean_raw_obs_processing_ms: 0.40662625624965526
  time_since_restore: 549.0835418701172
  time_this_iter_s: 30.454864025115967
  time_total_s: 549.0835418701172
  timers:
    learn_throughput: 7022.07
    learn_time_ms: 23040.499
    sample_throughput: 22475.654
    sample_time_ms: 7198.545
    update_time_ms: 26.133
  timestamp: 1602384143
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     18 |          549.084 | 2912256 |  244.257 |              293.444 |              136.172 |            833.674 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3436.751802551303
    time_step_min: 3142
  date: 2020-10-11_02-42-54
  done: false
  episode_len_mean: 832.6755641166758
  episode_reward_max: 293.44444444444423
  episode_reward_mean: 245.0183841719339
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 172
  episodes_total: 3634
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8156776087624686
        entropy_coeff: 0.0
        kl: 0.008894942900432008
        model: {}
        policy_loss: -0.016205964011273215
        total_loss: 9.152823039463588
        vf_explained_var: 0.9833360314369202
        vf_loss: 9.167249815804619
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.262162162162166
    gpu_util_percent0: 0.3286486486486486
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154303747002391
    mean_env_wait_ms: 1.2097739019989748
    mean_inference_ms: 4.644686000124785
    mean_raw_obs_processing_ms: 0.40600404960979464
  time_since_restore: 579.5391983985901
  time_this_iter_s: 30.4556565284729
  time_total_s: 579.5391983985901
  timers:
    learn_throughput: 7011.942
    learn_time_ms: 23073.779
    sample_throughput: 22468.143
    sample_time_ms: 7200.951
    update_time_ms: 27.373
  timestamp: 1602384174
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | RUNNING  | 172.17.0.4:18606 |     19 |          579.539 | 3074048 |  245.018 |              293.444 |              136.172 |            832.676 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_178a0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3432.3440488841657
    time_step_min: 3142
  date: 2020-10-11_02-43-24
  done: true
  episode_len_mean: 832.0179324894515
  episode_reward_max: 293.44444444444423
  episode_reward_mean: 245.6307057920981
  episode_reward_min: 136.17171717171732
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: e25184ad79e4490099301e9ba46a5cad
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8058715675558362
        entropy_coeff: 0.0
        kl: 0.00891160625698311
        model: {}
        policy_loss: -0.017559678476702954
        total_loss: 10.45106908253261
        vf_explained_var: 0.9796765446662903
        vf_loss: 10.466846329825264
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.608333333333334
    gpu_util_percent0: 0.3372222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18606
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15415713292645586
    mean_env_wait_ms: 1.2102351445565867
    mean_inference_ms: 4.635574179451068
    mean_raw_obs_processing_ms: 0.4054653092055984
  time_since_restore: 609.9651036262512
  time_this_iter_s: 30.425905227661133
  time_total_s: 609.9651036262512
  timers:
    learn_throughput: 7016.313
    learn_time_ms: 23059.404
    sample_throughput: 22416.226
    sample_time_ms: 7217.629
    update_time_ms: 27.346
  timestamp: 1602384204
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 178a0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | TERMINATED |       |     20 |          609.965 | 3235840 |  245.631 |              293.444 |              136.172 |            832.018 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_178a0_00000 | TERMINATED |       |     20 |          609.965 | 3235840 |  245.631 |              293.444 |              136.172 |            832.018 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


