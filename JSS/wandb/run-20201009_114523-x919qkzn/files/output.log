2020-10-09 11:45:25,849	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_eccb2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=52940)[0m 2020-10-09 11:45:28,938	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=52926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=52914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=52914)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_11-46-00
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 1.0e-05
        entropy: 1.1653586149215698
        entropy_coeff: 0.0
        kl: 0.0017178191803395749
        model: {}
        policy_loss: -0.0016468966379761696
        total_loss: 817.1713439941407
        vf_explained_var: -0.1541799008846283
        vf_loss: 817.1726684570312
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 38.113793103448266
    gpu_util_percent0: 0.2789655172413793
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003448275862068966
    ram_util_percent: 9.541379310344825
    vram_util_percent0: 0.27390834756449267
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17781453722971166
    mean_env_wait_ms: 1.657387918070092
    mean_inference_ms: 5.729192384564975
    mean_raw_obs_processing_ms: 0.4819968012462026
  time_since_restore: 25.33529806137085
  time_this_iter_s: 25.33529806137085
  time_total_s: 25.33529806137085
  timers:
    learn_throughput: 10337.794
    learn_time_ms: 15650.534
    sample_throughput: 16837.402
    sample_time_ms: 9609.084
    update_time_ms: 43.535
  timestamp: 1602243960
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      1 |          25.3353 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3245.0
  date: 2020-10-09_11-46-23
  done: false
  episode_len_mean: 875.5284810126582
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 227.78487405702575
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.14036523103714
        entropy_coeff: 0.0
        kl: 0.0024373983265832066
        model: {}
        policy_loss: -0.002080372301861644
        total_loss: 635.471240234375
        vf_explained_var: -0.17065294086933136
        vf_loss: 635.4730651855468
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.33333333333333
    gpu_util_percent0: 0.22703703703703704
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1727172848474168
    mean_env_wait_ms: 1.6502208199439303
    mean_inference_ms: 5.453696154214028
    mean_raw_obs_processing_ms: 0.4657890464451915
  time_since_restore: 48.95186471939087
  time_this_iter_s: 23.61656665802002
  time_total_s: 48.95186471939087
  timers:
    learn_throughput: 10395.632
    learn_time_ms: 15563.46
    sample_throughput: 18306.28
    sample_time_ms: 8838.06
    update_time_ms: 32.383
  timestamp: 1602243983
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      2 |          48.9519 | 323584 |  227.785 |              273.131 |              115.788 |            875.528 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-46-47
  done: false
  episode_len_mean: 871.9409282700421
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 229.8466095554701
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.1392397999763488
        entropy_coeff: 0.0
        kl: 0.0026243787724524736
        model: {}
        policy_loss: -0.001696465874556452
        total_loss: 485.4395294189453
        vf_explained_var: 0.03789454698562622
        vf_loss: 485.44110107421875
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.66153846153846
    gpu_util_percent0: 0.28423076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1693761500736111
    mean_env_wait_ms: 1.6458267954561063
    mean_inference_ms: 5.305395822731486
    mean_raw_obs_processing_ms: 0.4552200134154966
  time_since_restore: 72.73461151123047
  time_this_iter_s: 23.7827467918396
  time_total_s: 72.73461151123047
  timers:
    learn_throughput: 10391.106
    learn_time_ms: 15570.239
    sample_throughput: 18824.56
    sample_time_ms: 8594.73
    update_time_ms: 35.219
  timestamp: 1602244007
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      3 |          72.7346 | 485376 |  229.847 |              279.889 |              115.788 |            871.941 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-47-11
  done: false
  episode_len_mean: 870.5696202531645
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 229.55074478966864
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 1.0e-05
        entropy: 1.1237578392028809
        entropy_coeff: 0.0
        kl: 0.0029971495270729063
        model: {}
        policy_loss: -0.0018027651240117848
        total_loss: 352.71287841796874
        vf_explained_var: 0.3353293538093567
        vf_loss: 352.7146057128906
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.473076923076924
    gpu_util_percent0: 0.27384615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16713477179446773
    mean_env_wait_ms: 1.6433899710481163
    mean_inference_ms: 5.1968397245467575
    mean_raw_obs_processing_ms: 0.4481757359547316
  time_since_restore: 95.95353293418884
  time_this_iter_s: 23.218921422958374
  time_total_s: 95.95353293418884
  timers:
    learn_throughput: 10425.225
    learn_time_ms: 15519.281
    sample_throughput: 19286.564
    sample_time_ms: 8388.845
    update_time_ms: 33.143
  timestamp: 1602244031
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      4 |          95.9535 | 647168 |  229.551 |              279.889 |              115.788 |             870.57 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-47-34
  done: false
  episode_len_mean: 869.2911392405064
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 229.20934663086538
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 1.1025540471076964
        entropy_coeff: 0.0
        kl: 0.0037793378811329602
        model: {}
        policy_loss: -0.0023927515256218614
        total_loss: 240.47129669189454
        vf_explained_var: 0.5557008981704712
        vf_loss: 240.47363739013673
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.707692307692305
    gpu_util_percent0: 0.2973076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16550585830634504
    mean_env_wait_ms: 1.6428887080084693
    mean_inference_ms: 5.115437935150868
    mean_raw_obs_processing_ms: 0.4428104470835087
  time_since_restore: 119.31895732879639
  time_this_iter_s: 23.365424394607544
  time_total_s: 119.31895732879639
  timers:
    learn_throughput: 10441.35
    learn_time_ms: 15495.314
    sample_throughput: 19524.408
    sample_time_ms: 8286.653
    update_time_ms: 34.166
  timestamp: 1602244054
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      5 |          119.319 | 808960 |  229.209 |              279.889 |              98.9697 |            869.291 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-47-57
  done: false
  episode_len_mean: 864.4113924050633
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 228.06078871901636
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 1.0e-05
        entropy: 1.1251319169998169
        entropy_coeff: 0.0
        kl: 0.0035941021516919134
        model: {}
        policy_loss: -0.0024408457393292338
        total_loss: 219.8350570678711
        vf_explained_var: 0.7317196726799011
        vf_loss: 219.8374816894531
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.38461538461539
    gpu_util_percent0: 0.31153846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1633892634695784
    mean_env_wait_ms: 1.6445299527645707
    mean_inference_ms: 5.005883948051698
    mean_raw_obs_processing_ms: 0.4359889297879883
  time_since_restore: 142.58513832092285
  time_this_iter_s: 23.266180992126465
  time_total_s: 142.58513832092285
  timers:
    learn_throughput: 10457.164
    learn_time_ms: 15471.881
    sample_throughput: 19708.471
    sample_time_ms: 8209.262
    update_time_ms: 34.927
  timestamp: 1602244077
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      6 |          142.585 | 970752 |  228.061 |              279.889 |              98.9697 |            864.411 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-48-21
  done: false
  episode_len_mean: 861.7278481012659
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 228.37434471295208
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 1.0e-05
        entropy: 1.1282580733299254
        entropy_coeff: 0.0
        kl: 0.0038017146522179245
        model: {}
        policy_loss: -0.003010254632681608
        total_loss: 105.60435104370117
        vf_explained_var: 0.7917715907096863
        vf_loss: 105.60734786987305
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.17307692307692
    gpu_util_percent0: 0.2896153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773076923076925
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16260965859456333
    mean_env_wait_ms: 1.6454507236308344
    mean_inference_ms: 4.96651065013427
    mean_raw_obs_processing_ms: 0.4336274450441487
  time_since_restore: 165.843186378479
  time_this_iter_s: 23.258048057556152
  time_total_s: 165.843186378479
  timers:
    learn_throughput: 10469.22
    learn_time_ms: 15454.064
    sample_throughput: 19843.716
    sample_time_ms: 8153.312
    update_time_ms: 33.265
  timestamp: 1602244101
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      7 |          165.843 | 1132544 |  228.374 |              279.889 |              98.9697 |            861.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-48-44
  done: false
  episode_len_mean: 858.8713080168776
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 228.51771583628104
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 1.0e-05
        entropy: 1.1165814042091369
        entropy_coeff: 0.0
        kl: 0.004298287071287632
        model: {}
        policy_loss: -0.002643949200864881
        total_loss: 90.01453475952148
        vf_explained_var: 0.8252876400947571
        vf_loss: 90.01716766357421
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.05925925925926
    gpu_util_percent0: 0.2925925925925926
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77777777777778
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16193424050691846
    mean_env_wait_ms: 1.6465020051641173
    mean_inference_ms: 4.932461785869283
    mean_raw_obs_processing_ms: 0.43158339604260537
  time_since_restore: 189.24591493606567
  time_this_iter_s: 23.40272855758667
  time_total_s: 189.24591493606567
  timers:
    learn_throughput: 10464.775
    learn_time_ms: 15460.629
    sample_throughput: 19949.189
    sample_time_ms: 8110.204
    update_time_ms: 31.662
  timestamp: 1602244124
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      8 |          189.246 | 1294336 |  228.518 |              279.889 |              98.9697 |            858.871 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-49-08
  done: false
  episode_len_mean: 855.8563291139241
  episode_reward_max: 279.88888888888897
  episode_reward_mean: 229.03724587648617
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 1.0e-05
        entropy: 1.0931544303894043
        entropy_coeff: 0.0
        kl: 0.004379455000162125
        model: {}
        policy_loss: -0.002938608622207539
        total_loss: 79.16043472290039
        vf_explained_var: 0.8430339097976685
        vf_loss: 79.16336975097656
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.87692307692308
    gpu_util_percent0: 0.3403846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384615
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1613559042356352
    mean_env_wait_ms: 1.647774895906156
    mean_inference_ms: 4.902646202111094
    mean_raw_obs_processing_ms: 0.4297397669469616
  time_since_restore: 212.5927538871765
  time_this_iter_s: 23.34683895111084
  time_total_s: 212.5927538871765
  timers:
    learn_throughput: 10480.303
    learn_time_ms: 15437.721
    sample_throughput: 19974.618
    sample_time_ms: 8099.88
    update_time_ms: 30.196
  timestamp: 1602244148
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |      9 |          212.593 | 1456128 |  229.037 |              279.889 |              98.9697 |            855.856 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-49-31
  done: false
  episode_len_mean: 849.9267515923567
  episode_reward_max: 280.27272727272697
  episode_reward_mean: 230.24101417572737
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 304
  episodes_total: 1884
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 1.0e-05
        entropy: 1.0769874691963195
        entropy_coeff: 0.0
        kl: 0.0038290681783109902
        model: {}
        policy_loss: -0.002600499941036105
        total_loss: 78.8740219116211
        vf_explained_var: 0.8955995440483093
        vf_loss: 78.87662200927734
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.76923076923077
    gpu_util_percent0: 0.3826923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16045918723643215
    mean_env_wait_ms: 1.650872528347115
    mean_inference_ms: 4.855817937589065
    mean_raw_obs_processing_ms: 0.42687819163650503
  time_since_restore: 235.90144896507263
  time_this_iter_s: 23.308695077896118
  time_total_s: 235.90144896507263
  timers:
    learn_throughput: 10487.204
    learn_time_ms: 15427.562
    sample_throughput: 20025.703
    sample_time_ms: 8079.217
    update_time_ms: 29.282
  timestamp: 1602244171
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     10 |          235.901 | 1617920 |  230.241 |              280.273 |              98.9697 |            849.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_11-49-54
  done: false
  episode_len_mean: 846.7702044790652
  episode_reward_max: 281.91919191919163
  episode_reward_mean: 230.94781800477983
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 170
  episodes_total: 2054
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 1.0e-05
        entropy: 1.0890187859535216
        entropy_coeff: 0.0
        kl: 0.0037084931274875997
        model: {}
        policy_loss: -0.0025518824462778867
        total_loss: 60.759572982788086
        vf_explained_var: 0.8791815638542175
        vf_loss: 60.76212425231934
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.284615384615385
    gpu_util_percent0: 0.35500000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784615384615385
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16007006636745896
    mean_env_wait_ms: 1.6526257615558246
    mean_inference_ms: 4.834462418077641
    mean_raw_obs_processing_ms: 0.4256232472691642
  time_since_restore: 259.089230298996
  time_this_iter_s: 23.18778133392334
  time_total_s: 259.089230298996
  timers:
    learn_throughput: 10510.529
    learn_time_ms: 15393.327
    sample_throughput: 20483.162
    sample_time_ms: 7898.781
    update_time_ms: 26.761
  timestamp: 1602244194
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     11 |          259.089 | 1779712 |  230.948 |              281.919 |              98.9697 |             846.77 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-50-18
  done: false
  episode_len_mean: 843.8942133815551
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 231.82335105119896
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 1.0e-05
        entropy: 1.078171396255493
        entropy_coeff: 0.0
        kl: 0.004185306327417493
        model: {}
        policy_loss: -0.0026458908338099717
        total_loss: 55.51853637695312
        vf_explained_var: 0.8804265856742859
        vf_loss: 55.521183013916016
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.166666666666664
    gpu_util_percent0: 0.33888888888888896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77777777777778
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15973897056096345
    mean_env_wait_ms: 1.654179070029203
    mean_inference_ms: 4.8167972131862875
    mean_raw_obs_processing_ms: 0.42455413458328917
  time_since_restore: 282.76731300354004
  time_this_iter_s: 23.678082704544067
  time_total_s: 282.76731300354004
  timers:
    learn_throughput: 10513.395
    learn_time_ms: 15389.13
    sample_throughput: 20481.657
    sample_time_ms: 7899.361
    update_time_ms: 34.827
  timestamp: 1602244218
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     12 |          282.767 | 1941504 |  231.823 |              284.747 |              98.9697 |            843.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-50-42
  done: false
  episode_len_mean: 841.0763713080169
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 232.65397860461135
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 1.0e-05
        entropy: 1.045783245563507
        entropy_coeff: 0.0
        kl: 0.0036704705096781256
        model: {}
        policy_loss: -0.002205352857708931
        total_loss: 55.444689178466795
        vf_explained_var: 0.88795405626297
        vf_loss: 55.446894836425784
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.13076923076923
    gpu_util_percent0: 0.30269230769230765
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943840171094936
    mean_env_wait_ms: 1.6558381823050736
    mean_inference_ms: 4.800841923235564
    mean_raw_obs_processing_ms: 0.42356468919790924
  time_since_restore: 306.2419617176056
  time_this_iter_s: 23.47464871406555
  time_total_s: 306.2419617176056
  timers:
    learn_throughput: 10526.315
    learn_time_ms: 15370.242
    sample_throughput: 20516.718
    sample_time_ms: 7885.861
    update_time_ms: 33.747
  timestamp: 1602244242
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     13 |          306.242 | 2103296 |  232.654 |              284.747 |              98.9697 |            841.076 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-51-05
  done: false
  episode_len_mean: 835.7252419955324
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 234.09061200237653
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 316
  episodes_total: 2686
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 1.0e-05
        entropy: 1.046378242969513
        entropy_coeff: 0.0
        kl: 0.0036519796587526797
        model: {}
        policy_loss: -0.002881097700446844
        total_loss: 56.786461639404294
        vf_explained_var: 0.9214253425598145
        vf_loss: 56.78934288024902
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.48461538461538
    gpu_util_percent0: 0.3046153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15891653898935243
    mean_env_wait_ms: 1.6592275891568158
    mean_inference_ms: 4.773363849453783
    mean_raw_obs_processing_ms: 0.4219355665631602
  time_since_restore: 329.93412041664124
  time_this_iter_s: 23.692158699035645
  time_total_s: 329.93412041664124
  timers:
    learn_throughput: 10521.71
    learn_time_ms: 15376.968
    sample_throughput: 20414.332
    sample_time_ms: 7925.412
    update_time_ms: 33.657
  timestamp: 1602244265
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     14 |          329.934 | 2265088 |  234.091 |              284.747 |              98.9697 |            835.725 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-51-29
  done: false
  episode_len_mean: 833.1870604781997
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 234.71561962806672
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 1.0e-05
        entropy: 1.0433767676353454
        entropy_coeff: 0.0
        kl: 0.0038375679403543474
        model: {}
        policy_loss: -0.002651304961182177
        total_loss: 51.748402786254886
        vf_explained_var: 0.8966096043586731
        vf_loss: 51.75105285644531
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.06923076923077
    gpu_util_percent0: 0.29653846153846153
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.776923076923078
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15868794662924032
    mean_env_wait_ms: 1.6608362287853407
    mean_inference_ms: 4.761468991585271
    mean_raw_obs_processing_ms: 0.4212448555185161
  time_since_restore: 353.1613574028015
  time_this_iter_s: 23.22723698616028
  time_total_s: 353.1613574028015
  timers:
    learn_throughput: 10521.173
    learn_time_ms: 15377.753
    sample_throughput: 20450.853
    sample_time_ms: 7911.259
    update_time_ms: 32.092
  timestamp: 1602244289
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     15 |          353.161 | 2426880 |  234.716 |              284.747 |              98.9697 |            833.187 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-51-52
  done: false
  episode_len_mean: 830.9943371085943
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 235.34213891075967
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 1.0e-05
        entropy: 1.0220543265342712
        entropy_coeff: 0.0
        kl: 0.0036180004710331557
        model: {}
        policy_loss: -0.0024588758358731868
        total_loss: 43.46776847839355
        vf_explained_var: 0.9055516123771667
        vf_loss: 43.470228576660155
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.849999999999994
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384617
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15847868765767542
    mean_env_wait_ms: 1.662427853008623
    mean_inference_ms: 4.750423060813528
    mean_raw_obs_processing_ms: 0.420584891334737
  time_since_restore: 376.47157096862793
  time_this_iter_s: 23.310213565826416
  time_total_s: 376.47157096862793
  timers:
    learn_throughput: 10514.293
    learn_time_ms: 15387.815
    sample_throughput: 20464.795
    sample_time_ms: 7905.869
    update_time_ms: 30.66
  timestamp: 1602244312
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     16 |          376.472 | 2588672 |  235.342 |              284.747 |              98.9697 |            830.994 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-52-16
  done: false
  episode_len_mean: 827.3373823261463
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 236.48729015021135
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 291
  episodes_total: 3293
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 1.0e-05
        entropy: 0.9927088260650635
        entropy_coeff: 0.0
        kl: 0.0034470262238755823
        model: {}
        policy_loss: -0.0024836335913278164
        total_loss: 49.87735557556152
        vf_explained_var: 0.9308609962463379
        vf_loss: 49.879838943481445
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.91481481481482
    gpu_util_percent0: 0.2611111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581273045323883
    mean_env_wait_ms: 1.6653065778759588
    mean_inference_ms: 4.73221578792226
    mean_raw_obs_processing_ms: 0.41949674524960257
  time_since_restore: 400.22431921958923
  time_this_iter_s: 23.752748250961304
  time_total_s: 400.22431921958923
  timers:
    learn_throughput: 10509.599
    learn_time_ms: 15394.689
    sample_throughput: 20354.021
    sample_time_ms: 7948.896
    update_time_ms: 30.325
  timestamp: 1602244336
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     17 |          400.224 | 2750464 |  236.487 |              284.747 |              98.9697 |            827.337 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-52-40
  done: false
  episode_len_mean: 825.1441311852705
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 237.05370157268877
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 183
  episodes_total: 3476
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 1.0e-05
        entropy: 1.008714997768402
        entropy_coeff: 0.0
        kl: 0.003925736085511744
        model: {}
        policy_loss: -0.002776376367546618
        total_loss: 39.016239166259766
        vf_explained_var: 0.9249537587165833
        vf_loss: 39.019016647338866
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.41538461538461
    gpu_util_percent0: 0.2973076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77692307692308
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15794730706409718
    mean_env_wait_ms: 1.6671072325442873
    mean_inference_ms: 4.721966949938787
    mean_raw_obs_processing_ms: 0.4189129098644271
  time_since_restore: 423.5764899253845
  time_this_iter_s: 23.352170705795288
  time_total_s: 423.5764899253845
  timers:
    learn_throughput: 10521.903
    learn_time_ms: 15376.687
    sample_throughput: 20319.557
    sample_time_ms: 7962.378
    update_time_ms: 30.389
  timestamp: 1602244360
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     18 |          423.576 | 2912256 |  237.054 |              284.747 |              98.9697 |            825.144 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-53-03
  done: false
  episode_len_mean: 823.2762795817281
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 237.50155100815513
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.62939453125e-07
        cur_lr: 1.0e-05
        entropy: 1.0027955055236817
        entropy_coeff: 0.0
        kl: 0.003652680735103786
        model: {}
        policy_loss: -0.002465048909652978
        total_loss: 39.28152694702148
        vf_explained_var: 0.9159768223762512
        vf_loss: 39.283992767333984
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.96666666666666
    gpu_util_percent0: 0.2777777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.781481481481482
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15779687093585507
    mean_env_wait_ms: 1.668560766516612
    mean_inference_ms: 4.713697880763389
    mean_raw_obs_processing_ms: 0.4184228735829242
  time_since_restore: 447.2675564289093
  time_this_iter_s: 23.69106650352478
  time_total_s: 447.2675564289093
  timers:
    learn_throughput: 10504.091
    learn_time_ms: 15402.761
    sample_throughput: 20303.944
    sample_time_ms: 7968.501
    update_time_ms: 31.779
  timestamp: 1602244383
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     19 |          447.268 | 3074048 |  237.502 |              284.747 |              98.9697 |            823.276 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-53-27
  done: false
  episode_len_mean: 820.7857883817427
  episode_reward_max: 284.74747474747454
  episode_reward_mean: 238.2877740056162
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 222
  episodes_total: 3856
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625e-07
        cur_lr: 1.0e-05
        entropy: 0.9668638467788696
        entropy_coeff: 0.0
        kl: 0.0031139862723648546
        model: {}
        policy_loss: -0.002417577791493386
        total_loss: 40.98961296081543
        vf_explained_var: 0.9351641535758972
        vf_loss: 40.99203186035156
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.992592592592594
    gpu_util_percent0: 0.29518518518518516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77037037037037
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15759466506256842
    mean_env_wait_ms: 1.6706879821747476
    mean_inference_ms: 4.70301099995729
    mean_raw_obs_processing_ms: 0.41778835396837855
  time_since_restore: 471.075909614563
  time_this_iter_s: 23.808353185653687
  time_total_s: 471.075909614563
  timers:
    learn_throughput: 10493.731
    learn_time_ms: 15417.967
    sample_throughput: 20219.142
    sample_time_ms: 8001.922
    update_time_ms: 31.929
  timestamp: 1602244407
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     20 |          471.076 | 3235840 |  238.288 |              284.747 |              98.9697 |            820.786 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-53-51
  done: false
  episode_len_mean: 818.2573028237586
  episode_reward_max: 290.2222222222223
  episode_reward_mean: 239.35254689052147
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 252
  episodes_total: 4108
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.9073486328125e-07
        cur_lr: 1.0e-05
        entropy: 0.9801251113414764
        entropy_coeff: 0.0
        kl: 0.00333946431055665
        model: {}
        policy_loss: -0.0023551805526949464
        total_loss: 38.620233154296876
        vf_explained_var: 0.9290066957473755
        vf_loss: 38.622588348388675
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.77307692307692
    gpu_util_percent0: 0.24000000000000002
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573995037847042
    mean_env_wait_ms: 1.6728448996444873
    mean_inference_ms: 4.691757807551359
    mean_raw_obs_processing_ms: 0.41715843567076316
  time_since_restore: 494.7860450744629
  time_this_iter_s: 23.710135459899902
  time_total_s: 494.7860450744629
  timers:
    learn_throughput: 10476.7
    learn_time_ms: 15443.03
    sample_throughput: 20154.865
    sample_time_ms: 8027.441
    update_time_ms: 32.226
  timestamp: 1602244431
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     21 |          494.786 | 3397632 |  239.353 |              290.222 |              98.9697 |            818.257 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3165.0
  date: 2020-10-09_11-54-15
  done: false
  episode_len_mean: 816.8049695264885
  episode_reward_max: 290.2222222222223
  episode_reward_mean: 239.89325036582406
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 4266
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.5367431640625e-08
        cur_lr: 1.0e-05
        entropy: 0.9674112498760223
        entropy_coeff: 0.0
        kl: 0.003184185572899878
        model: {}
        policy_loss: -0.0022959524067118764
        total_loss: 29.951312446594237
        vf_explained_var: 0.9347265362739563
        vf_loss: 29.953608512878418
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.19230769230769
    gpu_util_percent0: 0.29115384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773076923076925
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15728255245817485
    mean_env_wait_ms: 1.67416217127581
    mean_inference_ms: 4.685270501047802
    mean_raw_obs_processing_ms: 0.4167859747421764
  time_since_restore: 518.342714548111
  time_this_iter_s: 23.55666947364807
  time_total_s: 518.342714548111
  timers:
    learn_throughput: 10477.401
    learn_time_ms: 15441.998
    sample_throughput: 20161.848
    sample_time_ms: 8024.661
    update_time_ms: 24.149
  timestamp: 1602244455
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     22 |          518.343 | 3559424 |  239.893 |              290.222 |              98.9697 |            816.805 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3146.0
  date: 2020-10-09_11-54-39
  done: false
  episode_len_mean: 815.2660509123676
  episode_reward_max: 290.2222222222223
  episode_reward_mean: 240.6055122069989
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 173
  episodes_total: 4439
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.76837158203125e-08
        cur_lr: 1.0e-05
        entropy: 0.9399717628955842
        entropy_coeff: 0.0
        kl: 0.00341903583612293
        model: {}
        policy_loss: -0.002365742239635438
        total_loss: 29.571248245239257
        vf_explained_var: 0.9446180462837219
        vf_loss: 29.5736141204834
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.337037037037035
    gpu_util_percent0: 0.274074074074074
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77037037037037
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15716071620429978
    mean_env_wait_ms: 1.6756498378041171
    mean_inference_ms: 4.678635389144646
    mean_raw_obs_processing_ms: 0.41640486201983734
  time_since_restore: 541.926825761795
  time_this_iter_s: 23.584111213684082
  time_total_s: 541.926825761795
  timers:
    learn_throughput: 10474.585
    learn_time_ms: 15446.148
    sample_throughput: 20140.957
    sample_time_ms: 8032.985
    update_time_ms: 23.436
  timestamp: 1602244479
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     23 |          541.927 | 3721216 |  240.606 |              290.222 |              98.9697 |            815.266 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3126.0
  date: 2020-10-09_11-55-03
  done: false
  episode_len_mean: 812.7516877637131
  episode_reward_max: 290.6262626262628
  episode_reward_mean: 241.6683075480543
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 301
  episodes_total: 4740
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.384185791015625e-08
        cur_lr: 1.0e-05
        entropy: 0.942484849691391
        entropy_coeff: 0.0
        kl: 0.0032466201344504954
        model: {}
        policy_loss: -0.0022262843674980106
        total_loss: 33.90775718688965
        vf_explained_var: 0.9435359239578247
        vf_loss: 33.90998306274414
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.974074074074075
    gpu_util_percent0: 0.29703703703703704
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15696515757360527
    mean_env_wait_ms: 1.6780347295191167
    mean_inference_ms: 4.667738263231935
    mean_raw_obs_processing_ms: 0.41578977619071483
  time_since_restore: 565.5930526256561
  time_this_iter_s: 23.666226863861084
  time_total_s: 565.5930526256561
  timers:
    learn_throughput: 10476.087
    learn_time_ms: 15443.935
    sample_throughput: 20161.967
    sample_time_ms: 8024.614
    update_time_ms: 23.103
  timestamp: 1602244503
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     24 |          565.593 | 3883008 |  241.668 |              290.626 |              98.9697 |            812.752 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3126.0
  date: 2020-10-09_11-55-26
  done: false
  episode_len_mean: 811.4816251531237
  episode_reward_max: 290.6262626262628
  episode_reward_mean: 242.23458554512032
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 158
  episodes_total: 4898
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.1920928955078126e-08
        cur_lr: 1.0e-05
        entropy: 0.9381504893302918
        entropy_coeff: 0.0
        kl: 0.0031331499805673955
        model: {}
        policy_loss: -0.0024421264650300147
        total_loss: 25.06185836791992
        vf_explained_var: 0.9431091547012329
        vf_loss: 25.064300537109375
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.59615384615385
    gpu_util_percent0: 0.34346153846153854
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784615384615385
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15686930850413844
    mean_env_wait_ms: 1.6792300389935353
    mean_inference_ms: 4.662477342859959
    mean_raw_obs_processing_ms: 0.41549104118913016
  time_since_restore: 589.0181617736816
  time_this_iter_s: 23.425109148025513
  time_total_s: 589.0181617736816
  timers:
    learn_throughput: 10483.073
    learn_time_ms: 15433.643
    sample_throughput: 20090.542
    sample_time_ms: 8053.143
    update_time_ms: 23.296
  timestamp: 1602244526
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | RUNNING  | 172.17.0.4:52940 |     25 |          589.018 | 4044800 |  242.235 |              290.626 |              98.9697 |            811.482 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_eccb2_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3100.0
  date: 2020-10-09_11-55-50
  done: true
  episode_len_mean: 810.2190400948055
  episode_reward_max: 295.55555555555566
  episode_reward_mean: 242.8229061302337
  episode_reward_min: 98.9696969696972
  episodes_this_iter: 165
  episodes_total: 5063
  experiment_id: 7141ef715a8a4463851eacc9f3716a90
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 5.960464477539063e-09
        cur_lr: 1.0e-05
        entropy: 0.9111439049243927
        entropy_coeff: 0.0
        kl: 0.0034332590410485865
        model: {}
        policy_loss: -0.0023865369648774504
        total_loss: 26.296745109558106
        vf_explained_var: 0.9458352327346802
        vf_loss: 26.29913196563721
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.03846153846154
    gpu_util_percent0: 0.33807692307692305
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.78076923076923
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 52940
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15677590758341442
    mean_env_wait_ms: 1.6804915713945419
    mean_inference_ms: 4.657241951652007
    mean_raw_obs_processing_ms: 0.4151896336951354
  time_since_restore: 612.5664269924164
  time_this_iter_s: 23.54826521873474
  time_total_s: 612.5664269924164
  timers:
    learn_throughput: 10483.093
    learn_time_ms: 15433.613
    sample_throughput: 20035.518
    sample_time_ms: 8075.259
    update_time_ms: 24.093
  timestamp: 1602244550
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: eccb2_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | TERMINATED |       |     26 |          612.566 | 4206592 |  242.823 |              295.556 |              98.9697 |            810.219 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_eccb2_00000 | TERMINATED |       |     26 |          612.566 | 4206592 |  242.823 |              295.556 |              98.9697 |            810.219 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


