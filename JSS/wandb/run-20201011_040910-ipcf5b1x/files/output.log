2020-10-11 04:09:12,343	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_85b2a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=44068)[0m 2020-10-11 04:09:15,279	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=44043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44039)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44039)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44031)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_04-09-54
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1814624496868678
        entropy_coeff: 0.00010000000000000002
        kl: 0.007987113436684012
        model: {}
        policy_loss: -0.005784422092671905
        total_loss: 19.85569041115897
        vf_explained_var: 0.45542749762535095
        vf_loss: 19.85999502454485
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.72
    gpu_util_percent0: 0.26775000000000004
    gpu_util_percent1: 0.00025
    gpu_util_percent2: 0.00025
    ram_util_percent: 6.284999999999999
    vram_util_percent0: 0.19151361102000655
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17465515466485726
    mean_env_wait_ms: 1.2122138336360655
    mean_inference_ms: 5.961987821361688
    mean_raw_obs_processing_ms: 0.4717947355425259
  time_since_restore: 33.86176538467407
  time_this_iter_s: 33.86176538467407
  time_total_s: 33.86176538467407
  timers:
    learn_throughput: 6671.028
    learn_time_ms: 24252.934
    sample_throughput: 16975.471
    sample_time_ms: 9530.929
    update_time_ms: 44.811
  timestamp: 1602389394
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      1 |          33.8618 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3595.5173611111113
    time_step_min: 3312
  date: 2020-10-11_04-10-26
  done: false
  episode_len_mean: 880.4556962025316
  episode_reward_max: 264.2020202020202
  episode_reward_mean: 218.4478007927373
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.146446364266532
        entropy_coeff: 0.00010000000000000002
        kl: 0.01007875454212938
        model: {}
        policy_loss: -0.005185379646718502
        total_loss: 12.171252591269356
        vf_explained_var: 0.7768694758415222
        vf_loss: 12.174536773136683
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.77567567567568
    gpu_util_percent0: 0.3027027027027027
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17022653076456024
    mean_env_wait_ms: 1.2070690983104395
    mean_inference_ms: 5.717931336640919
    mean_raw_obs_processing_ms: 0.46194509197809946
  time_since_restore: 65.91859889030457
  time_this_iter_s: 32.05683350563049
  time_total_s: 65.91859889030457
  timers:
    learn_throughput: 6720.581
    learn_time_ms: 24074.109
    sample_throughput: 18387.274
    sample_time_ms: 8799.129
    update_time_ms: 43.005
  timestamp: 1602389426
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      2 |          65.9186 | 323584 |  218.448 |              264.202 |              145.717 |            880.456 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3598.7869955156953
    time_step_min: 3312
  date: 2020-10-11_04-10-58
  done: false
  episode_len_mean: 870.1645569620254
  episode_reward_max: 268.2929292929292
  episode_reward_mean: 219.44751310574074
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1273591007505144
        entropy_coeff: 0.00010000000000000002
        kl: 0.009265705743538482
        model: {}
        policy_loss: -0.006317438266705722
        total_loss: 13.590082713535853
        vf_explained_var: 0.8628048300743103
        vf_loss: 13.594659669058663
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.82702702702703
    gpu_util_percent0: 0.21621621621621623
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16700797955434035
    mean_env_wait_ms: 1.206224598221524
    mean_inference_ms: 5.520541675431604
    mean_raw_obs_processing_ms: 0.45253660023827985
  time_since_restore: 97.49423432350159
  time_this_iter_s: 31.57563543319702
  time_total_s: 97.49423432350159
  timers:
    learn_throughput: 6720.316
    learn_time_ms: 24075.059
    sample_throughput: 19414.519
    sample_time_ms: 8333.557
    update_time_ms: 43.435
  timestamp: 1602389458
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      3 |          97.4942 | 485376 |  219.448 |              268.293 |              145.717 |            870.165 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3597.8344370860927
    time_step_min: 3312
  date: 2020-10-11_04-11-30
  done: false
  episode_len_mean: 860.3401898734177
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 220.05213527681863
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0928999185562134
        entropy_coeff: 0.00010000000000000002
        kl: 0.00773396053617554
        model: {}
        policy_loss: -0.00647254052455537
        total_loss: 15.111130782536097
        vf_explained_var: 0.901397168636322
        vf_loss: 15.116165706089564
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.92972972972973
    gpu_util_percent0: 0.3648648648648648
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16472111141790372
    mean_env_wait_ms: 1.2076027193723438
    mean_inference_ms: 5.375101356425582
    mean_raw_obs_processing_ms: 0.44521088679643794
  time_since_restore: 128.90490412712097
  time_this_iter_s: 31.410669803619385
  time_total_s: 128.90490412712097
  timers:
    learn_throughput: 6720.548
    learn_time_ms: 24074.229
    sample_throughput: 20062.508
    sample_time_ms: 8064.395
    update_time_ms: 41.385
  timestamp: 1602389490
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      4 |          128.905 | 647168 |  220.052 |               269.96 |              145.717 |             860.34 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3600.9747807017543
    time_step_min: 3312
  date: 2020-10-11_04-12-01
  done: false
  episode_len_mean: 844.8308510638298
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 219.99973135611415
  episode_reward_min: 135.41414141414103
  episodes_this_iter: 308
  episodes_total: 940
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0547069992337907
        entropy_coeff: 0.00010000000000000002
        kl: 0.0077953593406294075
        model: {}
        policy_loss: -0.006590143868899239
        total_loss: 22.101474353245326
        vf_explained_var: 0.9391645789146423
        vf_loss: 22.106610979352677
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.819444444444443
    gpu_util_percent0: 0.3994444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16180973022653755
    mean_env_wait_ms: 1.2140083404735416
    mean_inference_ms: 5.192853835548653
    mean_raw_obs_processing_ms: 0.435926447866908
  time_since_restore: 160.202739238739
  time_this_iter_s: 31.297835111618042
  time_total_s: 160.202739238739
  timers:
    learn_throughput: 6739.183
    learn_time_ms: 24007.659
    sample_throughput: 20364.676
    sample_time_ms: 7944.737
    update_time_ms: 40.633
  timestamp: 1602389521
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      5 |          160.203 | 808960 |      220 |               269.96 |              135.414 |            844.831 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3598.446196660482
    time_step_min: 3278
  date: 2020-10-11_04-12-33
  done: false
  episode_len_mean: 837.883363471971
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 220.10193252598302
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 166
  episodes_total: 1106
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0365248322486877
        entropy_coeff: 0.00010000000000000002
        kl: 0.008489335421472788
        model: {}
        policy_loss: -0.006410734590774935
        total_loss: 15.227985790797643
        vf_explained_var: 0.9475179314613342
        vf_loss: 15.232801641736712
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.351351351351354
    gpu_util_percent0: 0.3067567567567567
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497297297297297
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16075233918722145
    mean_env_wait_ms: 1.217065858094676
    mean_inference_ms: 5.1247986157088254
    mean_raw_obs_processing_ms: 0.43247885170947686
  time_since_restore: 191.7619059085846
  time_this_iter_s: 31.55916666984558
  time_total_s: 191.7619059085846
  timers:
    learn_throughput: 6735.923
    learn_time_ms: 24019.277
    sample_throughput: 20603.812
    sample_time_ms: 7852.527
    update_time_ms: 41.137
  timestamp: 1602389553
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      6 |          191.762 | 970752 |  220.102 |               269.96 |              104.657 |            837.883 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3592.7912621359224
    time_step_min: 3278
  date: 2020-10-11_04-13-04
  done: false
  episode_len_mean: 831.875
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 220.91327835315167
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0032443617071425
        entropy_coeff: 0.00010000000000000002
        kl: 0.007615489951734032
        model: {}
        policy_loss: -0.005696002057188058
        total_loss: 13.002459117344447
        vf_explained_var: 0.9616175293922424
        vf_loss: 13.006732531956263
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.62972972972973
    gpu_util_percent0: 0.3943243243243243
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15990090640662738
    mean_env_wait_ms: 1.2197884817636113
    mean_inference_ms: 5.069526113343157
    mean_raw_obs_processing_ms: 0.4294913285407956
  time_since_restore: 223.0185785293579
  time_this_iter_s: 31.256672620773315
  time_total_s: 223.0185785293579
  timers:
    learn_throughput: 6739.944
    learn_time_ms: 24004.946
    sample_throughput: 20834.676
    sample_time_ms: 7765.516
    update_time_ms: 40.288
  timestamp: 1602389584
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      7 |          223.019 | 1132544 |  220.913 |               269.96 |              104.657 |            831.875 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3590.8295774647886
    time_step_min: 3278
  date: 2020-10-11_04-13-35
  done: false
  episode_len_mean: 825.7886740331492
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.09428539539027
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 184
  episodes_total: 1448
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9391497586454663
        entropy_coeff: 0.00010000000000000002
        kl: 0.006740697759336659
        model: {}
        policy_loss: -0.0040255132023178574
        total_loss: 13.512497765677315
        vf_explained_var: 0.9756850600242615
        vf_loss: 13.515269143240792
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.063888888888886
    gpu_util_percent0: 0.21861111111111112
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15903106322545893
    mean_env_wait_ms: 1.2233149207353269
    mean_inference_ms: 5.014337011074414
    mean_raw_obs_processing_ms: 0.42639100779657035
  time_since_restore: 254.42740416526794
  time_this_iter_s: 31.408825635910034
  time_total_s: 254.42740416526794
  timers:
    learn_throughput: 6741.795
    learn_time_ms: 23998.356
    sample_throughput: 20967.237
    sample_time_ms: 7716.42
    update_time_ms: 39.252
  timestamp: 1602389615
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      8 |          254.427 | 1294336 |  221.094 |               269.96 |              104.657 |            825.789 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3592.016374269006
    time_step_min: 3278
  date: 2020-10-11_04-14-07
  done: false
  episode_len_mean: 817.9850402761795
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.13449221792138
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 290
  episodes_total: 1738
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9216465183666774
        entropy_coeff: 0.00010000000000000002
        kl: 0.0070315049628594094
        model: {}
        policy_loss: -0.0035181493897523198
        total_loss: 11.777162075042725
        vf_explained_var: 0.9789220094680786
        vf_loss: 11.779365812029157
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.63888888888889
    gpu_util_percent0: 0.3102777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15794460412978945
    mean_env_wait_ms: 1.2286136598224813
    mean_inference_ms: 4.94575166121538
    mean_raw_obs_processing_ms: 0.4226996436828028
  time_since_restore: 285.6410229206085
  time_this_iter_s: 31.213618755340576
  time_total_s: 285.6410229206085
  timers:
    learn_throughput: 6746.565
    learn_time_ms: 23981.391
    sample_throughput: 21099.366
    sample_time_ms: 7668.098
    update_time_ms: 38.946
  timestamp: 1602389647
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |      9 |          285.641 | 1456128 |  221.134 |               269.96 |              104.657 |            817.985 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3591.5947537473235
    time_step_min: 3278
  date: 2020-10-11_04-14-38
  done: false
  episode_len_mean: 814.625
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.38852128883767
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8677753550665719
        entropy_coeff: 0.00010000000000000002
        kl: 0.00773714911857886
        model: {}
        policy_loss: -0.00605661029008583
        total_loss: 7.062860012054443
        vf_explained_var: 0.986225962638855
        vf_loss: 7.067455734525408
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.84594594594595
    gpu_util_percent0: 0.3613513513513513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15745126938031612
    mean_env_wait_ms: 1.2310068292738954
    mean_inference_ms: 4.9147666300371515
    mean_raw_obs_processing_ms: 0.42097190685248015
  time_since_restore: 317.0728642940521
  time_this_iter_s: 31.431841373443604
  time_total_s: 317.0728642940521
  timers:
    learn_throughput: 6749.244
    learn_time_ms: 23971.871
    sample_throughput: 21153.243
    sample_time_ms: 7648.567
    update_time_ms: 36.999
  timestamp: 1602389678
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     10 |          317.073 | 1617920 |  221.389 |               269.96 |              104.657 |            814.625 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3589.863188976378
    time_step_min: 3278
  date: 2020-10-11_04-15-10
  done: false
  episode_len_mean: 811.6271844660195
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.55881631852498
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 164
  episodes_total: 2060
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8131397536822728
        entropy_coeff: 0.00010000000000000002
        kl: 0.006315944716334343
        model: {}
        policy_loss: -0.004929877759423107
        total_loss: 6.3686599390847345
        vf_explained_var: 0.990157961845398
        vf_loss: 6.372408253805978
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.62702702702703
    gpu_util_percent0: 0.27189189189189183
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.505405405405405
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569778573291779
    mean_env_wait_ms: 1.2334764248969685
    mean_inference_ms: 4.885723119696148
    mean_raw_obs_processing_ms: 0.4192842940558334
  time_since_restore: 348.73813343048096
  time_this_iter_s: 31.665269136428833
  time_total_s: 348.73813343048096
  timers:
    learn_throughput: 6753.237
    learn_time_ms: 23957.697
    sample_throughput: 21744.627
    sample_time_ms: 7440.551
    update_time_ms: 36.126
  timestamp: 1602389710
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     11 |          348.738 | 1779712 |  221.559 |               269.96 |              104.657 |            811.627 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3588.853970964987
    time_step_min: 3278
  date: 2020-10-11_04-15-42
  done: false
  episode_len_mean: 806.8345991561181
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.77387802071343
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 310
  episodes_total: 2370
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7739090323448181
        entropy_coeff: 0.00010000000000000002
        kl: 0.0060552385236535755
        model: {}
        policy_loss: -0.0033563938465834197
        total_loss: 8.182357481547765
        vf_explained_var: 0.9890614151954651
        vf_loss: 8.184580428259713
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.791891891891893
    gpu_util_percent0: 0.23783783783783785
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486486
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1562328301254186
    mean_env_wait_ms: 1.237928366939909
    mean_inference_ms: 4.839361391908913
    mean_raw_obs_processing_ms: 0.41670169360355536
  time_since_restore: 380.3997917175293
  time_this_iter_s: 31.66165828704834
  time_total_s: 380.3997917175293
  timers:
    learn_throughput: 6748.953
    learn_time_ms: 23972.902
    sample_throughput: 21908.416
    sample_time_ms: 7384.925
    update_time_ms: 36.225
  timestamp: 1602389742
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     12 |            380.4 | 1941504 |  221.774 |               269.96 |              104.657 |            806.835 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3589.4184
    time_step_min: 3278
  date: 2020-10-11_04-16-13
  done: false
  episode_len_mean: 804.6977848101266
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 221.75074718706043
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7445913553237915
        entropy_coeff: 0.00010000000000000002
        kl: 0.005177083624792951
        model: {}
        policy_loss: -0.003643083494223122
        total_loss: 5.051493678774152
        vf_explained_var: 0.9913114309310913
        vf_loss: 5.054175955908639
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.954054054054055
    gpu_util_percent0: 0.24054054054054055
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594594
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15590460880399393
    mean_env_wait_ms: 1.2398888515573612
    mean_inference_ms: 4.819111329134205
    mean_raw_obs_processing_ms: 0.41554030594259
  time_since_restore: 411.90669679641724
  time_this_iter_s: 31.50690507888794
  time_total_s: 411.90669679641724
  timers:
    learn_throughput: 6751.91
    learn_time_ms: 23962.403
    sample_throughput: 21900.381
    sample_time_ms: 7387.634
    update_time_ms: 35.437
  timestamp: 1602389773
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     13 |          411.907 | 2103296 |  221.751 |               269.96 |              104.657 |            804.698 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3587.063933809703
    time_step_min: 3278
  date: 2020-10-11_04-16-45
  done: false
  episode_len_mean: 802.7242277633048
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 222.1287944574137
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 159
  episodes_total: 2687
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7155326306819916
        entropy_coeff: 0.00010000000000000002
        kl: 0.005639474173741681
        model: {}
        policy_loss: -0.002816146431931494
        total_loss: 4.332496098109654
        vf_explained_var: 0.9930559992790222
        vf_loss: 4.3342558997018
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.645945945945947
    gpu_util_percent0: 0.34243243243243243
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1555999349549603
    mean_env_wait_ms: 1.2418427584448877
    mean_inference_ms: 4.800158445103608
    mean_raw_obs_processing_ms: 0.4144191737959715
  time_since_restore: 443.266375541687
  time_this_iter_s: 31.359678745269775
  time_total_s: 443.266375541687
  timers:
    learn_throughput: 6753.275
    learn_time_ms: 23957.56
    sample_throughput: 21904.331
    sample_time_ms: 7386.302
    update_time_ms: 35.587
  timestamp: 1602389805
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     14 |          443.266 | 2265088 |  222.129 |               269.96 |              104.657 |            802.724 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3583.509414929388
    time_step_min: 3278
  date: 2020-10-11_04-17-16
  done: false
  episode_len_mean: 799.3404397068621
  episode_reward_max: 269.95959595959556
  episode_reward_mean: 222.760153163884
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 315
  episodes_total: 3002
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.6715464890003204
        entropy_coeff: 0.00010000000000000002
        kl: 0.005552140430414251
        model: {}
        policy_loss: -0.004252046762433436
        total_loss: 5.4696586813245505
        vf_explained_var: 0.9928674101829529
        vf_loss: 5.472867352621896
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.575
    gpu_util_percent0: 0.25527777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550752394418339
    mean_env_wait_ms: 1.2455394731985545
    mean_inference_ms: 4.767288949528219
    mean_raw_obs_processing_ms: 0.4125115872399232
  time_since_restore: 474.65631318092346
  time_this_iter_s: 31.38993763923645
  time_total_s: 474.65631318092346
  timers:
    learn_throughput: 6745.971
    learn_time_ms: 23983.502
    sample_throughput: 21954.953
    sample_time_ms: 7369.271
    update_time_ms: 35.347
  timestamp: 1602389836
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     15 |          474.656 | 2426880 |   222.76 |               269.96 |              104.657 |             799.34 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3580.324712643678
    time_step_min: 3268
  date: 2020-10-11_04-17-48
  done: false
  episode_len_mean: 797.8458860759494
  episode_reward_max: 270.86868686868735
  episode_reward_mean: 223.19295806162896
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.6509947393621717
        entropy_coeff: 0.00010000000000000002
        kl: 0.004623214082260217
        model: {}
        policy_loss: -0.0038768164376961067
        total_loss: 3.499133995601109
        vf_explained_var: 0.9935474395751953
        vf_loss: 3.502151301928929
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.82702702702703
    gpu_util_percent0: 0.34324324324324323
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15483952697060152
    mean_env_wait_ms: 1.2471879583330037
    mean_inference_ms: 4.752683534865128
    mean_raw_obs_processing_ms: 0.41164789568208415
  time_since_restore: 506.0682997703552
  time_this_iter_s: 31.411986589431763
  time_total_s: 506.0682997703552
  timers:
    learn_throughput: 6743.93
    learn_time_ms: 23990.758
    sample_throughput: 22022.855
    sample_time_ms: 7346.55
    update_time_ms: 34.993
  timestamp: 1602389868
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     16 |          506.068 | 2588672 |  223.193 |              270.869 |              104.657 |            797.846 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3578.037970838396
    time_step_min: 3268
  date: 2020-10-11_04-18-19
  done: false
  episode_len_mean: 796.4882530120482
  episode_reward_max: 270.86868686868735
  episode_reward_mean: 223.65747839844227
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 160
  episodes_total: 3320
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6263312569686345
        entropy_coeff: 0.00010000000000000002
        kl: 0.007184991213892188
        model: {}
        policy_loss: -0.002938258494915707
        total_loss: 3.1315094573157176
        vf_explained_var: 0.9944126009941101
        vf_loss: 3.133791889463152
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.070270270270274
    gpu_util_percent0: 0.28864864864864864
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494594594594595
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15461348131267189
    mean_env_wait_ms: 1.2488163897952738
    mean_inference_ms: 4.738787131837017
    mean_raw_obs_processing_ms: 0.410807668614864
  time_since_restore: 537.5921063423157
  time_this_iter_s: 31.52380657196045
  time_total_s: 537.5921063423157
  timers:
    learn_throughput: 6745.533
    learn_time_ms: 23985.057
    sample_throughput: 21926.07
    sample_time_ms: 7378.979
    update_time_ms: 34.927
  timestamp: 1602389899
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     17 |          537.592 | 2750464 |  223.657 |              270.869 |              104.657 |            796.488 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3571.9309484193013
    time_step_min: 3268
  date: 2020-10-11_04-18-51
  done: false
  episode_len_mean: 794.0781507980187
  episode_reward_max: 270.86868686868735
  episode_reward_mean: 224.71697992584072
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 314
  episodes_total: 3634
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.5734129335199084
        entropy_coeff: 0.00010000000000000002
        kl: 0.006703532267627972
        model: {}
        policy_loss: -0.0034790564449005096
        total_loss: 3.8803347860063826
        vf_explained_var: 0.9944785237312317
        vf_loss: 3.883200866835458
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.711111111111116
    gpu_util_percent0: 0.25333333333333324
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15422268691094765
    mean_env_wait_ms: 1.251896574102785
    mean_inference_ms: 4.714287545564837
    mean_raw_obs_processing_ms: 0.4093699309559336
  time_since_restore: 568.7808222770691
  time_this_iter_s: 31.188715934753418
  time_total_s: 568.7808222770691
  timers:
    learn_throughput: 6747.469
    learn_time_ms: 23978.177
    sample_throughput: 21971.855
    sample_time_ms: 7363.602
    update_time_ms: 34.079
  timestamp: 1602389931
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | RUNNING  | 172.17.0.4:44068 |     18 |          568.781 | 2912256 |  224.717 |              270.869 |              104.657 |            794.078 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_85b2a_00000:
  custom_metrics:
    time_step_max: 4143
    time_step_mean: 3567.6663124335814
    time_step_min: 3268
  date: 2020-10-11_04-19-22
  done: true
  episode_len_mean: 792.9941983122363
  episode_reward_max: 270.86868686868735
  episode_reward_mean: 225.31996387929937
  episode_reward_min: 104.65656565656566
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 3d4e3d8241734d3da43ae12ea50fca6f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.5491554481642587
        entropy_coeff: 0.00010000000000000002
        kl: 0.007109751359426549
        model: {}
        policy_loss: -0.003735634993063286
        total_loss: 2.6353827714920044
        vf_explained_var: 0.9945369362831116
        vf_loss: 2.638462407248361
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.735135135135135
    gpu_util_percent0: 0.3135135135135135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 44068
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1540467465658204
    mean_env_wait_ms: 1.2532689658922516
    mean_inference_ms: 4.703166173019122
    mean_raw_obs_processing_ms: 0.4087101169671494
  time_since_restore: 600.0301983356476
  time_this_iter_s: 31.24937605857849
  time_total_s: 600.0301983356476
  timers:
    learn_throughput: 6747.45
    learn_time_ms: 23978.244
    sample_throughput: 21986.62
    sample_time_ms: 7358.657
    update_time_ms: 33.746
  timestamp: 1602389962
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 85b2a_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | TERMINATED |       |     19 |           600.03 | 3074048 |   225.32 |              270.869 |              104.657 |            792.994 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_85b2a_00000 | TERMINATED |       |     19 |           600.03 | 3074048 |   225.32 |              270.869 |              104.657 |            792.994 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


